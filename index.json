[{"categories":["“随笔”"],"content":"我老家每年的除夕上午都会去扫墓。扫的墓里面有我的老爷爷、老奶奶、老老爷爷、老老奶奶、老老堂奶奶。所有人我都没有见过，也不太知道叫什么名字，但是竟也拜了十几年了。我只见过老爷爷和老奶奶的照片，因为就挂在家里大厅里，不像是相机拍的，更像是手画的。 我老家应该是比较典型的南方山区的农村，村子散落在平原地区，有零星几户住在山里。有人去世，一般就埋山里了。我们那里的人，对鬼神都比较敬畏，我也听说过很多当地关于鬼神的故事。最近的一次是老家搞景区开发，上级要求把一座老庙推了，要搞一个别墅区。后来，开挖机的司机第二年就出事故死了。我相信是有鬼神的，所以经过庙宇、墓地的时候，都会怀着敬畏。但是先人们的墓地相比陌生人的，在敬畏中也会多了些亲切感，不让人感觉那么害怕。 在我的记忆里，老家的扫墓、敬神一直都是很庄重的事情；我家实行的一直是三拜九扣头，一次仪式的时间比较久，所以也够向先人默默许下心里的愿望，如果时间不够，最后一拜就祈祷就一点，把愿望说完给先人们听。 老爷爷的墓地比较近，往年家里会去好多人，但是父亲车祸截肢后就再也没上山了，其他伯伯们也因为各种事情没有来，今年只有我、爷爷、大伯、叔叔一起走路去扫墓，老爷爷的墓地不算远，所以比较快也就扫完了。其他先辈的墓地比较远，又因为家里的车子开走了，所以是爷爷骑他的三轮电瓶车带我和大伯去扫墓。车小，只能带一个人，所以需要带两趟。 大伯会砍树除草，他先上山开路和打扫。然后爷爷骑车回来接我，我们再一起上山。 去给老老奶奶扫墓路上，爷爷在丘田隆上扭了腿，就上不了山。我扶他在山下等，然后再上山找大伯。老老奶奶、老老爷爷、老老堂奶奶的墓地是挨着的，我一般认为死了的人都在地下的，所以他们在地下可能也是邻居。 去给老奶奶扫墓的时候，爷爷因为脚扭了，所以在山下等，我去找大伯。不过，我现在确实也不太清楚为什么老奶奶和老爷爷没有葬在一起。 我以为爷爷是不会上山的，但是他还是来了。不知道从哪里找了一根黑色的树干，树皮还在，他还是走得很慢。到了老奶奶墓前，他哭得很惨。往年去给老奶奶扫墓的时候，爷爷都会哭，在我记忆里一直是这样，但是今年他更撕心裂肺。他说：“娘啊！狗里以后就不能来看你了！”爷爷八十多岁了，这种话听了让人很难受。我也想了解爷爷和他母亲的故事，但是从来都不知道如何开口问；他也写了一些书，但是印象中没有看到过他和他母亲的故事。 小时候扫墓，大多都是许愿要好的成绩，或者能得到什么样的礼物。我曾经许愿想要一辆遥控汽车，后来真的就得到了一辆。再稍微大一点，就会许愿爱情，小时候的爱情就是喜欢一个人，希望她也喜欢我，然后用这种方式祈祷。这种愿望倒是从来没有实现过。然后更大了…(我本想说说现在的愿望，但是说出来可能就不灵了。) 因为爷爷在老奶奶墓前的痛哭，让我当时有感而发，想写一篇记录老家扫墓的文章。但是文笔是在有限，写一半又不知如何措辞了，所以断断续续。 这些年看着家人们老去，爷爷奶奶老了、父母老了。有时候总会有一种悲观的情绪。但是，我也知道，长大后，这就是生活的一部分，也是生活的常态。我也知道，我要努力活得好一点，让家人们少操心一点。我外婆去世的时候，刚是我工作第一年，我没为她付出一些我想付出的东西，从那之后，有时候想起，就会有一种“子欲养而亲不待”的感觉。所以，我现在的感触是，对于老去的亲人们，如果想做什么，就尽量去做，十年、几十年一晃就过去了。 ","date":"2024-02-09","objectID":"/202402/saomu/:0:0","tags":["扫墓","碎碎念"],"title":"扫墓","uri":"/202402/saomu/"},{"categories":["工具"],"content":"已经很久沒有更新博客，主要是现在工作太忙，一天压得比较紧，回家之后就就没有太多精力去写博客了。 最近更新了一个Python工具，主要是用来视频监控。基本想法是通过延时摄影的方式，每隔一段时间拍摄一张照片，然后组合成视频，这样就可以看到一段时间内的变化。 想做这个工具是因为我的电脑不太方便关或者锁屏，所以一般是打开的状态，但是我又想知道在我不在的时候，我的电脑有没有被别人使用，所以就想到了这个工具。目前处于可以使用的状态，后续我想加一些检测功能，比如检测到非自己的人脸就提高检测频率之类的，或者考虑视频压缩，可以减少一些重复、静态帧。 ","date":"2024-01-08","objectID":"/202401/work-monitor/:0:0","tags":["opencv","Python"],"title":"Work Monitor 视频监控工具","uri":"/202401/work-monitor/"},{"categories":["工具"],"content":"安装 相关的包已经上传到了pypi，可以通过pip安装。依赖的包有opencv-python，numpy。 pip3 install work-monitor 或者通过源码直接使用。 git clone git@github.com:caibingcheng/work-monitor.git cd work-monitor python3 -m monitor ","date":"2024-01-08","objectID":"/202401/work-monitor/:0:1","tags":["opencv","Python"],"title":"Work Monitor 视频监控工具","uri":"/202401/work-monitor/"},{"categories":["工具"],"content":"使用 首先是启动监控服务。 work-monitor server 然后可以通过客户端来设置或查看服务端的状态，比如查看服务端的配置。 work-monitor get_config 或者设置服务端的配置。 work-monitor set_config \u003ckeys...\u003e \u003cvalue\u003e help命令可以查看更多的命令。 $ work-monitor help Usage: python3 -m monitor \u003ccommand\u003e [arguments] Commands: help: Print help server: Start server [video_path], default video_path is empty stop: Client command, stop server restart: Client command, restart server get_config: Client command, get config set_config: Client command, set config ","date":"2024-01-08","objectID":"/202401/work-monitor/:0:2","tags":["opencv","Python"],"title":"Work Monitor 视频监控工具","uri":"/202401/work-monitor/"},{"categories":["工具"],"content":"代码讲解 源码地址： https://github.com/caibingcheng/work-monitor 几个模块分类如下： app.py: 入口，调用command模块 command.py: 命令行模块，在其中配置该项目支持的命令 config.py: 配置模块，用于配置服务端的配置 server.py: 服务端模块，用于启动服务端，客户端和服务端的通信也在其中实现 log.py: 日志模块，用于记录日志 capture.py: 拍照模块，用于拍照和保存图片 video.py: 视频模块，用于将图片组合成视频 policy.py: 策略模块，用于配置拍照和视频的策略，比如拍照的间隔时间，视频的长度等 入口 主要关注server的入口。 @add_command(\"server\", \"Start server [video_path], default video_path is empty\") def server(*args): log_info(\"Starting\") policy = config[\"policy\"] log_info(f\"Using policy {policy}\") # str to function policy = globals()[policy] from monitor.server import start_server, should_stop start_server() video_path_for_debug = \"\" if len(args) == 0 else args[0] while not should_stop(): try: policy(video_path_for_debug) except Exception as e: log_error(e) # backtrace import traceback traceback.print_exc() stop() log_info(\"Stopped\") 先找到policy，然后启动命令监听的server，然后执行对应的policy。如果发生异常时，会给server发送stop命令，然后退出。（这里有问题，如果是server异常，则命令不一定能发送到server，所以需要改进。） 配置 原始配置如下： raw_config = { \"camera_id\": 0, \"video_dir\": \"$HOME/Videos\", \"frames_dir\": \"$HOME/Pictures/work-monitor\", \"config_dir\": \"$HOME/.work-monitor\", \"log_dir\": \"$HOME/.work-monitor/log\", \"fps\": 60, \"quality\": 75, \"frames_save\": False, \"policy\": \"easy_policy\", \"easy_policy\": {\"frames_interval\": 10, \"frames_per_video\": 1000}, \"server\": { \"port\": 22311, }, } 各项配置的含义如下： camera_id: 摄像头id，如果有多个摄像头，可以通过这个配置来选择摄像头 video_dir: 视频保存的目录 frames_dir: 帧图片保存的目录 config_dir: 配置文件保存的目录 log_dir: 日志保存的目录 fps: 视频的帧率 quality: 帧图片的质量，取值范围[0, 100]，0表示最差，100表示最好 frames_save: 是否保存帧图片，一般设置为False，因为帧图片会占用很大的空间 policy: 策略，目前只有easy_policy，后续可以添加更多的策略 easy_policy: easy_policy的配置，包括帧图片的间隔时间和视频的长度 server: 服务端的配置，目前只有端口号 提示 对于frames_save配置目前还有一些问题，如果设置值为True，并且policy是通过帧图片数判断是否要保存视频的话，则在第一次触发阈值之后会频繁触发且保存相同的帧。 配置是通过一个全局变量config来保存的，初始化流程如下： try: config = initialize_config(config) verify_config(config) except Exception as e: print(e) choise = input(\"Reset config? (y/n)\") if choise == \"y\": print(\"Resetting config\") config = raw_config config = initialize_config(config, force=True) else: print(\"Using raw config\") config = raw_config config = preprocess_config(config) verify_config(config) initialize_config会对原始的config作预处理，替换其中的环境变量，比如$HOME；判断值范围是否正确，比如quality的值范围是[0, 100]，如果不在范围内，则会抛出异常；创建目录，比如video_dir，frames_dir等；如果是第一次启动，则会将配置写入到文件。预处理之后会调用verify_config来验证配置是否正确，主要是检查config和raw_config的key是否一致，如果不一致，则会抛出异常。 当有异常的时候会尝试用raw_config来初始化config，如果用户允许的话，会覆盖掉原来的配置文件。 在server中可以动态更新参数，对应的修改会更新到配置文件中。 @add_server_command(\"set_config\") def set_config_server(*args): if len(args) \u003c 2: raise Exception(\"Not enough arguments\") current = config.copy() current_header = current keys = args[:-1] value = args[-1] for key in keys[:-1]: if key not in current or not isinstance(current[key], dict): raise Exception(f\"Key {key} not found\") current = current[key] current[keys[-1]] = value current_header = initialize_config(current_header, force=True) config_str = json.dumps(current_header, indent=4).encode(\"utf-8\") log_info(f\"Sending config {config_str}\") update_config(config, current_header) return config_str 比如设置video_dir。 work-monitor set_config video_dir /home/bing/Videos 通信 server在主线程中启动，在子线程中监听客户端的连接。 def start_server(): # create a socket object serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # get local machine name host = socket.gethostname() port = config[\"server\"][\"port\"] # force to release the port serversocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) # set keep alive serversocket.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1) serversocket.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPIDLE, 1) serversocket.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPINTVL, 1) serversocket.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPCNT, 5) # bind to the port serversocket.bind((host, port)) # queue up to 5 requests serversocket.listen(5) def server_loop(): log_info(\"Server started\") while True: # establish a connection clientsocket, addr = serversocket.accept() log_info(f\"Got a connection from {addr}\") ms","date":"2024-01-08","objectID":"/202401/work-monitor/:0:3","tags":["opencv","Python"],"title":"Work Monitor 视频监控工具","uri":"/202401/work-monitor/"},{"categories":["工具"],"content":"小结 总算更新了一篇博客，这个工具还有很多可以改进的地方，但是比如之前写的fstats、fkfish之类的工具在第一版之后就已经很久没有更新了，目前看起来也够用，总之随心所欲吧。也有几个其他的工具还在推进中，还没有成品，后续慢慢更新。 另外，感觉我这段时间有些闭塞，在制作这个工具的过程中，知道了以下更新： python3.10支持pyproject.toml了，并且setup.py是不推荐的了 pypi用github action + twine发布会报错了，可以通过Trusted Publisher Management来管理发布者 不过，这段时间也不是废了，只是接触的领域不同。目前对DMA、Misra规则、QNX系统等等有一些接触和了解，也是扩展了自己的知识面，并且目前所在的激光雷达领域对我来说，就像是我在相机领域的延续，所以这也是缘分了。后续的年终总结中会想介绍介绍我的想法。 ","date":"2024-01-08","objectID":"/202401/work-monitor/:0:4","tags":["opencv","Python"],"title":"Work Monitor 视频监控工具","uri":"/202401/work-monitor/"},{"categories":["工具"],"content":"家里已经有一台服役了三年的R3500X + RTX1660S的台式机，主要是女朋友在用。我的主力机是Acer Swift S3, i5 1240P CPU + 核显，日常刷视频、写写代码、写写文章是完全够用，但是如果想玩游戏或者想做点其他东西，性能就不够了，因此又组了一台机器，并且将NAS的机箱升级了一下。 装机的目的，一是想有一台性能还可以的电脑，二是想尝试一种家庭服务器的方案。 我想象的是家里只有一台高性能的服务器（NAS和软路由是另外独立的机器），用户（我和女朋友）通过笔记本或者瘦客户机连接服务器的虚拟机，这样不需要两台物理机，甚至可以和NAS、软路由等一起放机柜里。不过实际操作下来，还没有将其变成现实，目前只是安装了物理机的Win11，通过Windows RDP或者Parsec远程连接。连接体验在下文会介绍。 ","date":"2023-07-18","objectID":"/202307/3k-diypc-nasup/:0:0","tags":["nas"],"title":"3000元装机和NAS升级","uri":"/202307/3k-diypc-nasup/"},{"categories":["工具"],"content":"硬件 配置如下：核心原则是能丐就丐，暂不追求7*24h的稳定性，能日常使用没问题就行。 主板是昂达的，只有两个内存插槽，所以这个配置中的2*8g方案就没有扩展空间了。使用2*8g主要是想限制在3k预算内，如果虚拟机方案可行，再扩充到32/64g，这两条8g内存条就可以给老电脑用，如果不可行就暂保持16g的方案。 显卡没有买RX6600TX，是因为当心矿卡。没买N卡则是预算不够，RX6600和RTX3060性能接近，但是价格低了很多。不过缺点是，A卡没有cuda，只能用ROCm替代，很多软件也没有针对A卡优化。 如果不考虑7*24h运行，上面这样配置的电源还是可以选择的，最好选择知名度好点的牌子，以防在参数上作假。选择电源需要关注各个电压对应的功率有多少。如图： +12V电压对应的额定功率有480W，用R5500 + RX6600的方案是完全够用的，这两个硬件的满载功耗是低于300W的。 选择F10机箱则是给NAS用的，和NAS的平头哥M2机箱交换。F10有10个3.5寸硬盘位，尽管我肯定插不满，不过看着这么多硬盘位还是很舒服的。装好后如图（忽略走线吧～）： 新机器装机后如图，没有光污染： 另外还有7个机箱风扇没有标注在配置单里，不可调速，均价约10元，所以一共约70元。7个机箱风扇，4个给新机器用，3个给NAS用。 为什么要给NAS加风扇？没有为什么，实际上不加也行。不加风扇的日常温度保持在40摄氏度，硬盘约是45摄氏度，加上风扇后温度为35摄氏度，硬盘也是约35摄氏度。另外，因为软路由是直接放在NAS上的(如下图)，也顺便给软路由降温了，从原来的40摄氏度，降低为36摄氏度。加装三个风扇，带来了约4W的功耗，每年约增加35度电，约18元。 F10机箱是真的大！ 上图中有一个新加的设备-蒲公英X10，可以不在家的时候和家庭网络组网，方便访问NAS或其他设备。相较于内网穿透方案，VPN更安全些，但是不便于分享。 最后，因为电脑不接显示器，需要再插一个显卡欺骗器，以免机器启动的时候硬件检测不通过。 ","date":"2023-07-18","objectID":"/202307/3k-diypc-nasup/:0:1","tags":["nas"],"title":"3000元装机和NAS升级","uri":"/202307/3k-diypc-nasup/"},{"categories":["工具"],"content":"远程 主要使用了两种远程方法，RDP和Parsec。 RDP最多30FPS，如下图，并且按照微软的说法，RDP是不建议用于游戏的，我体验下来RDP玩3D视角游戏的最大问题是转向会过于灵敏，因为RDP没有对鼠标做优化（某帖子，找不到原帖了…）。也有特殊版本的Windows（似乎是Win10 LTS，但是我未验证），RDP可以支持到60FPS。 Parsec可以接近60FPS，目前体验极好，除了剑三不支持串流（辣鸡游戏）。另外，如图，Parse编码解码过程会带来10+ms的延迟。 ","date":"2023-07-18","objectID":"/202307/3k-diypc-nasup/:0:2","tags":["nas"],"title":"3000元装机和NAS升级","uri":"/202307/3k-diypc-nasup/"},{"categories":["工具"],"content":"后记 关于NAS的用处，除去多媒体，其他是在生活中的细节处作用的。比如本文拍摄的图片，手机拍照，PC端比较自然地就可以看到了，然后下载上传到去不图床。如果没有NAS，可能需要再折腾一会，或者使用其他公有云。 另外的作用，电脑或者手机上的文档、软件包等等数字形式的内容，如果不确定要不要删除，但是又想整理电脑或者手机的时候，直接扔NAS里就行了。 这些体验是细节中的，没有也可以，但是有的话体验更好。 关于家庭中心服务器的想法，如果实现的话，因为服务器和NAS是放在一起的，可以用万兆网连接，想必可以带来极好的体验。客户端用WiFi或千兆网连接中心服务器即可，可以降低成本，因为基本只有画面传输需求，只需要网络稳定就行。 ","date":"2023-07-18","objectID":"/202307/3k-diypc-nasup/:0:3","tags":["nas"],"title":"3000元装机和NAS升级","uri":"/202307/3k-diypc-nasup/"},{"categories":[],"content":"cpuocup是一款设置CPU使用率的工具, 可以设置若干线程的CPU使用率, 可以将线程绑定到对应的CPU核心, 也可以设置线程的执行优先级(需要sudo权限). 在一些需要低效CPU的测试场合, 该工具可能帮得上忙. 项目地址: caibingcheng/cpuocup (github.com) 已经很久没有更新. 在二月份的时候经历了裁员, 三月份开始找工作, 入职了一家新公司, 每个工作日都需要花费3个小时的通勤时间, 有点累… 停更了很久, 其实在这期间也写了一些内容, 但是因为工作的原因没有及时更新和润色, 并且有些玩意儿做的不是很好, 还需要改进, 所以并没有贴出来. 现在已经工作一个多月, 对工作和通勤都适应起来了, 所以, 博客也要继续搞起来. 期望可以保持原来的更新速度, 以及学习和探索一些更有意思的问题. 没有什么十分明确的契机, 可能因为最近用上了Copilot, 工作上又做了一些性能测试相关的内容, 便想到了做这样一个和性能有些相关的东西. 详细用法可以见仓库的README, 简单用法如下: cpuocup 0.5 #set thread 0 to 50% usage cpuocup 1,0.5 #set thread 1 to 50% usage, and bind to cpu 1 设计上, cpuocup最多可以启动cpu核心数个线程, 以确保可以让每个核心分配一个工作线程. 如以上cpuocup 0.5指令, 会启动一个线程, 将线程的cpu占用率设置为50%附近, 但是不会绑定到某个核心, 因此实际情况上, 可能会又多个核心分担这个线程的资源消耗, 从而在使用top指令观察的时候, 可能看不到某个核心占用为50%的情况. 又如cpuocup 1,0.5 指令, 会启动一个线程, 将线程的cpu占用率设置为50%附近, 并且将该线程绑定到cpu 1上, 因此在使用top指令观察时, 是可以观察到cpu 1的占用率接近50%的. 当然如果有其他线程也在消耗这个核心, 那么其占用率可能是超过50%的. ","date":"2023-05-09","objectID":"/202305/cpuocup/:0:0","tags":[],"title":"设置CPU使用率的工具-cpuocup","uri":"/202305/cpuocup/"},{"categories":[],"content":"体验Copilot 关于cpuocup这个工具, 其实我的核心是体验Copilot. 通过Copilot, 可以减少在浏览器和编辑器之间的切换次数. 还在学校的时候, 我试用过tabnine, tabnine更像是上下文提示(现在不知道是什么程度了), Copilot远不止如此. 比如, 当需要写cpu绑核相关代码的时候, 我可能不知道对应API是什么, 以及如何使用, 那么我可以: // bind thread to cpu 只需要相关的注释, Copilot就有可能帮助我完成相关的代码. 比如, 它可能为我生成: cpu_set_t set; CPU_ZERO(\u0026set); CPU_SET(arg.cpu_id, \u0026set); pthread_setaffinity_np(threads.back().native_handle(), sizeof(cpu_set_t), \u0026set); 在这之后, 我先验证设置是否成功, 也只需要注释: // check if cpu affinity set success 那么Copilot就可以帮助生成验证cpu affinity设置时候成功的代码, 比如: cpu_set_t get; CPU_ZERO(\u0026get); pthread_getaffinity_np(threads.back().native_handle(), sizeof(cpu_set_t), \u0026get); check(CPU_ISSET(arg.cpu_id, \u0026get), \"Set cpu affinity failed\"); 注意到, 它还自己动调用了我在这份文件中写的check接口, 并且帮助生成了错误提示代码. 又比如, 我想为每个command绑定函数的时候, 有这样一段代码: std::unordered_map\u003cchar, cmd_job_t\u003e g_cmd_jobs = { {'f', [](std::vector\u003cthread_args\u003e\u0026 args, thread_args\u0026 arg) { for (auto i = 0; i \u003c args.size(); ++i) { args[i] = arg; } }}, {'F', [](std::vector\u003cthread_args\u003e\u0026 args, thread_args\u0026 arg) { for (auto i = 0; i \u003c args.size(); ++i) { args[i] = arg; args[i].cpu_id = i; } }}, {'r', [](std::vector\u003cthread_args\u003e\u0026 args, thread_args\u0026 arg) { for (auto i = 0; i \u003c args.size(); ++i) { if (!args[i].specific) { args[i] = arg; } } }}, {'R', [](std::vector\u003cthread_args\u003e\u0026 args, thread_args\u0026 arg) { for (auto i = 0; i \u003c args.size(); ++i) { if (!args[i].specific) { args[i] = arg; args[i].cpu_id = i; } } }}, }; 这是Copilot帮助生成的. 在这之前, 我在parse_args函数内部实现了相关的代码, 在整理代码的时候我想改成map的形式, 因此, 当我输入std::unordered_map这几个字符的时候, Copilot就以及帮助我生成了剩下的代码, 我几乎不需要再去修改, 只需要将原来的代码删除即可. 另外, 在忘记#include \u003cunordered_map\u003e时, 光标移动到include区域, Copilot也自动补全了缺少的部分. 再比如, helper_str也是Copilot生成的, 可以看看它的内容: std::string g_helper_str = // unix style helper \"\\033[1mNAME\\033[0m\\n\" \" cpuocup - set cpu userspace usage rate\\n\" \"\\033[1mVERSION\\033[0m\\n\" \" \" + std::string(VERSION_STRING) + \"\\n\" \"\\033[1mUSAGE\\033[0m\\n\" // can set [rate] [cpu_id,rate] [cpu_id,priority,rate] [cmd,rate] [cmd,priority,rate] \" \\033[1mcpuocup\\033[0m [\\033[4mrate\\033[0m] [\\033[4mcpu_id\\033[0m,\\033[4mrate\\033[0m] [\\033[4mcpu_id\\033[0m,\\033[4mpriority\\033[0m,\\033[4mrate\\033[0m] [\\033[4mcmd\\033[0m,\\033[4mrate\\033[0m] [\\033[4mcmd\\033[0m,\\033[4mpriority\\033[0m,\\033[4mrate\\033[0m] ...\\n\" \"\\033[1mDESCRIPTION\\033[0m\\n\" \" This program is used to set cpu rate. Max \" + std::to_string(g_hardware_threads) + \" threads are supported at the device.\\n\" \" \\033[1mrate\\033[0m: thread rate, 0.0 \u003c= rate \u003c= 1.0\\n\" \" \\033[1mcpu_id\\033[0m: cpu id, -1 means thread not bind any cpu, range: [-1, \" + std::to_string(g_hardware_threads-1) + \"]\\n\" \" \\033[1mpriority\\033[0m: thread priority, range: [0, 99]\\n\" // cmd support: f, F, r, R \" \\033[1mcmd\\033[0m: f, r, F, R\\n\" \" f: set to all threads\\n\" \" r: set to all threads which is not specific\\n\" \" F: set to all threads, and bind to corresponding cpu\\n\" \" R: set to all threads which is not specific, and bind to corresponding cpu\\n\" \"\\033[1mEXAMPLE\\033[0m\\n\" // give 5 classic examples of each usage, and explain the meaning of each example \" \\033[1mcpuocup\\033[0m 0.5 0.9\\n\" \" set thread 0 to 50% usage, and thread 1 to 90% usage\\n\" \" \\033[1mcpuocup\\033[0m 1,0.5\\n\" \" set thread 1 to 50% usage, and bind to cpu 1\\n\" \" \\033[1mcpuocup\\033[0m 1,20,0.5\\n\" \" set thread 1 to 50% usage, and bind to cpu 1, and set thread priority to 20\\n\" \" \\033[1mcpuocup\\033[0m f,0.5\\n\" \" set all threads to 50% usage\\n\" \" \\033[1mcpuocup\\033[0m 1,20,0.5, r,40,0.9\\n\" \" set thread 1 to 50% usage, and bind to cpu 1, and set thread priority to 20\\n\" \" set all threads which is not specific to 90% usage, and set thread priority to 40, and bind to corresponding cpus\\n\" \"\\033[1mAUTHOR\\033[0m\\n\" \" Written by \\033[1mcaibingcheng\\033[0m.\\n\" \"\\033[1mREPORTING BUGS\\033[0m\\n\" \" Report bugs to \\033[1mjack_cbc@163.com\\033[0m.\\n\" \"\\033[1mCOPYRIGHT\\033[0m\\n\" \" This is free software: you are free to change and redistribute it.\\n\" \" There is NO WARRANTY, to the extent permitted by law.\\n\" ; 当然, 这已经是迭代了好几个版本之后的内容, 在Copilot描述的cpuocup用法上, 稍微有点不准, 但是需要修改的地方不多. 在生成hel","date":"2023-05-09","objectID":"/202305/cpuocup/:0:1","tags":[],"title":"设置CPU使用率的工具-cpuocup","uri":"/202305/cpuocup/"},{"categories":[],"content":"小结 以上. 项目中, 有注释的部分基本都是Copilot协助完成的, 这些部分, 我基本只需要输出注释, 有些注释因为在早期开发变动较大, 就删除了. 项目中的一些重复性较大的代码, 也是由Copilot协助完成. 对此, 我最大的感触是, 对于这些独立的小项目, 我只需要关心整体设计, 至于代码如何实现, 接口如何调用我已经不需要关心了, 甚至也不需要浏览器. 不过对于比较大的项目, 目录结构比较复杂, Copilot就显得没有那么\"机智\"了. (这篇文章有点水~除去代码时间, 文章内容可能只准备两个小时. 不过博客可算更新了, 也算是又步入正轨了吧, 用输出来促进我的输入! 前段时间还做了心率检测相关的东西, 以及调查了文件buffer指针相关的内容, 期望能尽快有输出. 还有, Copilot体验还是非常好的!) ","date":"2023-05-09","objectID":"/202305/cpuocup/:0:2","tags":[],"title":"设置CPU使用率的工具-cpuocup","uri":"/202305/cpuocup/"},{"categories":[],"content":"写这个小游戏是因为在leetcode做题的时候, 遇到了37. 解数独这个题, 做完便想到可以将其扩展为一个小游戏. 项目地址: https://github.com/caibingcheng/sudoku 运行截图 ","date":"2023-03-06","objectID":"/202303/terminal-sudoku/:0:0","tags":[],"title":"终端数独游戏","uri":"/202303/terminal-sudoku/"},{"categories":[],"content":"编译 \u0026 运行 支持Windows和Linux平台. g++ ./main.cpp -o sudoku \u0026\u0026 ./sudoku ","date":"2023-03-06","objectID":"/202303/terminal-sudoku/:1:0","tags":[],"title":"终端数独游戏","uri":"/202303/terminal-sudoku/"},{"categories":[],"content":"操作 移动: w/a/s/d 填写: 1-9, .表示留空 重置: r 新游戏: n, 生成同等难度的新游戏 检查: c, 检查所有所填项是否可以解决该题 提示: h, 提示当前空格可以填入的候选项, 该候选项不保证可解 更换难度: -/=, -表示降低难度, =表示提高难度, 难度等级1-7 退出: q ","date":"2023-03-06","objectID":"/202303/terminal-sudoku/:2:0","tags":[],"title":"终端数独游戏","uri":"/202303/terminal-sudoku/"},{"categories":[],"content":"生成方法 生成一个9x9宫格 随机的11个位置填入随机的数字(有人证明说11个数有解的概率最大) 解该数独(回溯/DFS) 对解完的数独擦除若干个数字, 最后结果就是题目 ","date":"2023-03-06","objectID":"/202303/terminal-sudoku/:3:0","tags":[],"title":"终端数独游戏","uri":"/202303/terminal-sudoku/"},{"categories":[],"content":"已知问题 ","date":"2023-03-06","objectID":"/202303/terminal-sudoku/:4:0","tags":[],"title":"终端数独游戏","uri":"/202303/terminal-sudoku/"},{"categories":[],"content":"不保证唯一解 以上生成方法不保证唯一解, 如果需要唯一解, 可以在擦除数字的时候, 每擦除一个, 判断新题的解的个数, 但是这样时间太久了. 有查到DLX算法, 但是暂不计划花时间去看. ","date":"2023-03-06","objectID":"/202303/terminal-sudoku/:4:1","tags":[],"title":"终端数独游戏","uri":"/202303/terminal-sudoku/"},{"categories":[],"content":"偶现生成时间很久 主要耗时部分: 生成数独过程中的解数独部分, 解的位置离起始位置可能很远 没有保证随机11数之后的数独一定可解, 因此可能导致遍历完整个解空间 可以通过设置最大查询深度来解决这个问题, 如果一定深度后还没有找到解, 则重新执行生成步骤. 但是最大深度如何设置合理? 还没有去研究. ","date":"2023-03-06","objectID":"/202303/terminal-sudoku/:4:2","tags":[],"title":"终端数独游戏","uri":"/202303/terminal-sudoku/"},{"categories":["随笔"],"content":"\u003c刻意练习\u003e是一本教人如何练习的书, 是一种从开始如何练习, 到中期如何继续保持提高, 到最后小有所成的练习方法论. 本来很早应该看完, 但是刚好在阅读计划快结束的时候经历了大裁员, 便放下所有事情, 放开心随心玩了一段时间. 而后才开始继续恢复学习状态. 该书大部分内容在用案例佐证作者的一些研究结论. 作者(们)是博士, 案例都有出处(或者是自己的研究), 因此是具有很高可信度的, 继而作者的很多研究结论也是具备高可信度的. 但是该书的很多研究对象是音乐/国际象棋/运动员/记忆力这些对象, 对我从事的行业, 以及希望取得一定进步的方向基本没有案例支撑, 因此本文的大部分内容只是个人通过阅读\u003c刻意练习\u003e而总结的一些观点和想法, 不一定和该书作者十分符合. 并且我认为不能只限于将刻意练习当作一套完全封闭的方法论, 其中很多的观点都是可以拆开来使用的, 独立使用其中的一些观点也可以对自己起到警醒和提升的作用. 学习刻意练习的方法, 我认为分为两个大方向, 一个是自己怎么做, 一个是作为导师应该怎么做. 自己就是期望提高某个自身某个技能的人, 导师是指培养自己训练这方面的人(比如老师和教练), 也可以是引导自己对这方面技能产生兴趣的人(比如父母或抚养人), 当然也可能是自己. ","date":"2023-02-22","objectID":"/202302/deliberate-practice/:0:0","tags":["学习"],"title":"刻意练习","uri":"/202302/deliberate-practice/"},{"categories":["随笔"],"content":"专注+反馈+纠正 专注不是说一辈子只专注于一个技能, 而是像番茄工作法一样的练习. 在训练某个技能时, 以效率最大化为目的, 以达到单位时间内获取最大技能点的效果. 关于专注学习方法, 我只了解过番茄工作法, 但是没有实践过, 因为我认为这种方法不太适合我. 比如, 有时候我会陷入几个小时的专注时期, 这时候40分钟(假设定义40分钟)的周期就一定会打断我. 但是有时候又难以陷入专注, 或者只有很少量时间的专注期, 这时候如果规定40分钟专注时间, 则是属于浪费时间. 所以, 单纯一个多少时间学习+多少时间休息的方法可能暂时还不太适合我, 还需要寻找一种更加适合我的, 可以用于规划和陷入专注期的方法论. 只有专注的练习一定是不够的, 这这只会让人原地踏步, 还需要反馈和纠正. 专注+反馈+纠正在书中的表述是3F法则(Focus+Feedback+Fix). 反馈的意思是说练习需要得到反馈, 而不是只有输入和输出, 还有输出和目标(正确输出)之间的偏差, 有了反馈就可以寻找纠正的方法. 因此纠正就是说通过反馈纠正输出, 以达到正确的输出为目的. 近几年, 我曾完全忽视了反馈和纠正这两个法则. 但是通过阅读本书和自我反省之间, 我得到了\"忽视\"这种反馈, 从而有机会纠正这种\"忽视\". 反馈和控制这两个概念令我想到了自控中的反馈控制(想要系统尽快响应, 达到期望输出, 一种方法就是通过反馈控制.), 我认为拿过来做可视化的解说是很适合的. 以下是一种负反馈控制, 它可以表述刻意练习中反馈和纠正这两个概念的关系. 比如, 当测量的系统输出与期望输出不匹配的时候, 会得到一个非零反馈, 控制模块就可以根据反馈调整输出, 最终达到等于/逼近期望输出的目的, 其中系统响应速度和反馈/控制模块有关. 反馈控制 针对刻意练习, 我认为的反馈包含两个方面: 事实和心理. 所谓事实反馈就是针对练习结果的反馈. 我们每个人都经历过的一个例子就是考试. 我认为这是一种很好的反馈机制. 通过考试的结果可以得到对自己在这一阶段的学习结果的反馈. 通过考试结果上的错题部分/扣分部分就可以知道哪些方面的不足, 从而有机会针对的改正. 但是考试的周期是比较长的, 可能一个学期才有一次, 因此这种长周期的反馈会拉长纠正的周期, 使系统响应变慢. 又比如随堂测验/课后作业等周期较短的测验, 就可以缩短反馈周期, 也缩短了纠正周期. 但是这些周期还是比较长, 可能需要一两天甚至一两个星期才可以得到反馈结果. 如何可以快速获得反馈呢? 在上面的举例中, 都是针对团体练习的(大课堂是一种团体练习.), 这必然导致导师没法很快地给每一个学生反馈. 书中提到的一个方法是, 尽量提供一对一的辅导. 通过一对一的辅导可以尽快得到反馈, 比如练习小提琴找专业导师, 导师可以在练习者在拉提琴的过程中就可以帮助反馈错误之处, 这近乎可以认为是一种实时响应系统了. 但是寻找一对一辅导的导师对绝大数人来说是难以达到的. 另一个方法是通过自己设计反馈环节, 但是这依赖一定的熟练度和设计, 我举例我印象中的几个例子. 一个例子是超级记忆者的练习. 比如记忆数字, 在复述一串数字的时候, 可以在错误之处立即打断, 因此得到自己记忆了多长数字串的一种反馈. 是否复述错误的判断可以依赖第三人或者计算机. 比如, 这个是一个记忆训练网页, 仅依赖计算机就可以快速得到已记忆的数字串长度的反馈. 如果拿到考试中来说, 这种反馈提供者就可以是在线判题系统, 依赖这种判题系统, 练习者可以在考试结束后就立即得到反馈, 从而缩短反馈周期. 另一个例子是国际象棋的练习. 在初级阶段也可以依靠教练或者计算机来得到反馈, 该反馈描述的是自己的走法和\"大师\"走法之间的差异. 如果自己就是大师了(对国际象棋来说人类还是很难打败计算机的), 那如何获得反馈呢? 书中很多地方用了一个词叫心理表征, 不过我对其理解有些差异, 我一直想用另外一个词替代就是定式(国际象棋的心理表征除了定式还有空间想象, 但是我认为都属于定式), 或者我叫广义定式, 它包含了开局走法和残局棋谱. 以下定式都指广义定式. 定式这个词我是从围棋中学到的, 拿到国际象棋中就是, 当走到某某残局的时候, 是不是可以和看过的某个或某些残局对应起来, 因此就容易得到后续的走法, 大师和新手的区别是, 他们脑海里又很多各式各样的残局, 或许alphaGo就是因为学习了太多的残局而变强的吧. 当这种心理表征(定式)建立起来的时候, 练习者就有办法通过自己得到反馈和纠正. 到这里我想到了另一个观点, 定式或许是很重要的, 拿棋类来讲, 因为其走法是有限集合, 因此必定存在最优解, 定式就是在前人的基础上一步一步获得的最优解(也可能是次优解). 心理反馈不是客观的反馈, 但是也能起到很好的纠正效果. 比如在低落的时候, 施加以激励的反馈, 这时候练习者或许就可以从低落情绪中走出来, 提高练习效率; 在骄傲的时候, 就可以尝试施加一些负面反馈, 降低训练者骄傲的态度. 心理反馈的方法肯定有很多, 而且不能单纯依赖训练者当前的情绪给予反馈, 还会和训练者的性格特点有关系. 如果通过\"反馈+纠正\"这个环节得不到提高了怎么办? 可以尝试换一种纠正方法. 书中的一个例子是记忆力练习. 当受试者已经可以记忆几十个数字, 但是没有再继续提高的时候, 受试者尝试换了一种记忆方法, 从而得到了提高. 这一节看着有点\"假大空\", 大部分都是案例, 但是我认为这是对的. 因为大概率是无法针对每一种练习提炼出统一的和详细的方法的. 所谓只统一不详细的方法就是3F法则. 因此, 在尝试某技能提高的时候, 就需要针对该技能的特点, 尝试是能否按照3F法则详细化该技能的练习步骤. ","date":"2023-02-22","objectID":"/202302/deliberate-practice/:0:1","tags":["学习"],"title":"刻意练习","uri":"/202302/deliberate-practice/"},{"categories":["随笔"],"content":"一万小时定律 天才是不存在的, 我们必须认同这个观点, 否则很多人的成功都只能归结于天赋了. 很多天才无非是在年龄很小, 没人关注的时候, 经过了某些方面的训练, 从而在其以很小年龄出名的时候, 表现出来就像天才. 比如莫扎特, 他的父亲是一位不得志的音乐家, 并且他父亲也在尝试一种新的音乐教学方法, 在莫扎特还很小的时候, 就对其产生的了影响, 从而塑造了这样一位音乐天才. 关于练习, 经常提到的一个观点是一万小时定律. 但是不能认为是定数的一万个小时, 或是简单重复的长时间练习. 比如很多业余打篮球的, 因为只是偶尔打打篮球, 在其球技达到一定高度时候, 就不会刻意练习球技了, 因此在此后即使打过很多次篮球, 其球技依然不会有很大的提高. 很明显的例子是, 专业的篮球运动员和业余篮球爱好者比较, 前者有专业的教练, 可以得到正确的反馈和纠正, 后者大多在打野球, 得不到正确的反馈和纠正. 因此, 对一万小时定律的理解是: 经过\"专注+反馈+纠正\"方法的长时间练习. 当然, 不是每个人都要成为专家, 也不是只有一项技能需要提升. 但是这部分要表述的是, 如果需要提高那么就要按照\"3F法则 + 长时间练习\"的去行动. 有个词叫笨鸟先飞, 这是很有道理的. 智商对技能的练习有影响吗? 作者在书中的表示是有影响的, 但是仅局限于在练习初期. 因为智商高的人, 更容易接受新的知识和训练方法, 因此在训练初期表现的一般会更好的. 但是对于很多高手来说, 智商没有表现出区分度, 即智商和能力不相关. 为什么会这样? 因为智商较低的人在练习一项技能时, 大多会察觉到自己和智商更高人的差异, 因此更加刻苦练习. 而智商高者因为在练习时更加轻松, 不容易意识到自己需要更加努力才会追赶上别人, 因此练习时间相对更少. 所以, 从长远来看, 占上风的是那些练习更加勤奋的人, 而不是智商或其他方面才华稍有优势的人. ","date":"2023-02-22","objectID":"/202302/deliberate-practice/:0:2","tags":["学习"],"title":"刻意练习","uri":"/202302/deliberate-practice/"},{"categories":["随笔"],"content":"保持动力而不是依靠意志力 我时常认为坚持不是一件很容易的事情, 需要依靠强大的意志力. 但是作者在书中表述, 没有一个叫做意志力的东西. 比如让在A技能上能够坚持练习的人去练习B技能, 很大可能是无法坚持的. 为什么有这种差异呢? 因为我们认为的意志力, 很大程度上就是动力. 在一项技能练习上, 越能保持动力, 就越能坚持下去. 当认为无法坚持的时候, 可以尝试\"强化前进的理由, 弱化停下的理由\". 坚持的另一种方法是可以尝试写\"未来日记\". 当打算执行一个长期计划的时候, 可以在制定初期就想象如果这个计划很好的完成了, 我会成为什么样子的人, 当完成的那一天我会是怎样的? 把这种想象写下来, 时常去看看自己的未来日记, 以此保持动力. ","date":"2023-02-22","objectID":"/202302/deliberate-practice/:0:3","tags":["学习"],"title":"刻意练习","uri":"/202302/deliberate-practice/"},{"categories":["随笔"],"content":"像物理学家一样思考 “像物理学家一样思考\"这是我在书中获得的另一个很有用的观点. 为什么叫像物理学家一样思考? 物理学家不太关心怎么计算当地气压, 不太关心怎么计算地球的质量. 他们会关系为什么会有四季变化, 为什么会有黑天白夜. 前者是简单概念和公式的运用, 后者则是设计到多个概念或流程的运用. 会使用物理公式, 可以帮助完成学业, 但是无法在物理上有太高造诣. (是不是有专门做计算的物理?) 要成为物理学家, 第一是要有能力解答上述后者的问题, 第二是要有能力提出这样的问题. ","date":"2023-02-22","objectID":"/202302/deliberate-practice/:0:4","tags":["学习"],"title":"刻意练习","uri":"/202302/deliberate-practice/"},{"categories":["随笔"],"content":"一些针对特定方向的刻意练习想法 以下是针对一些特定方向的刻意练习的个人想法. 背英语单词 通过英剧/美剧等构建起对英语文化的兴趣 将提升工作技能/和外国人交流等目标作为动力 通过定期的单词数量测试作为反馈 数据结构与算法刷题 通过对计算机或者其他技术引起对程序的兴趣 将找工作/社区影响力等目标作为动力 通过周赛/其他竞赛等方式作为反馈 将竞赛错题整理作为纠正的方向 人物传记阅读 因为某些事情对某些人物产生了兴趣 将读后感等输出作为动力 健身 将喜欢的身材/健康的身体/或者加入某场比赛等作为动力 将体脂率作为反馈 通过不同部位的体脂率得到之后待纠正的方向 ","date":"2023-02-22","objectID":"/202302/deliberate-practice/:0:5","tags":["学习"],"title":"刻意练习","uri":"/202302/deliberate-practice/"},{"categories":["随笔"],"content":"小结 刻意练习的几个步骤: 建立/产生兴趣 构建动力 开始行动 获得反馈, 思考纠正方法和纠正方向 长时间练习 保持动力, 强化前进的理由, 弱化停下的理由 ","date":"2023-02-22","objectID":"/202302/deliberate-practice/:0:6","tags":["学习"],"title":"刻意练习","uri":"/202302/deliberate-practice/"},{"categories":["工具"],"content":"在使用codebrowser查阅一些源码的时候, 因为没有书签跳转功能, 有时候追踪调用栈就不是很方便. 因此, 开发了一款用于codebrowser书签功能的油猴插件. 该项目地址: https://github.com/caibingcheng/codebrowser-bookmark codebrowser书签插件 主要功能有: 点击灰色\"小圆点\"添加书签 点击黑色\"小圆点\"删除书签 点击书签栏的对应书签可以跳转到该书签位置 点击书签栏的\"-“号可以删除对应书签或对应文件下的所有书签 按住顶部bar可以拖动书签栏 双击笑脸图标可以显示或者隐藏书签栏 书签信息以明文信息存储在localStorage的code-browser-bookmarks条目下. 因此, 如果清空了浏览器或者对应域名的localStorage也会清空codebrowser的书签. 如需使用, 可以在greasyfork导入脚本, 链接如下: https://raw.githubusercontent.com/caibingcheng/codebrowser-bookmark/master/index.js ","date":"2023-02-08","objectID":"/202302/codebrowser-bookmark-script/:0:0","tags":["插件"],"title":"codebrowser书签插件","uri":"/202302/codebrowser-bookmark-script/"},{"categories":["随笔"],"content":"昨晚和朋友聊到扫地机器人、无人机、视觉，就想起来“年轻”时候参加的RoboMaster机甲大师赛，因此想分享一下参赛那年的经历。 赛事规则每年都会有变化，因此本文所述的赛事规则对当前比赛大多已不适用。 RM是一项主要以大学生为目标人群的机器人对抗赛，有点像MOBA类游戏，但是玩家操控的“角色”是真实存在的物理设备。除了专门做研发的同学外，也有专门练习操作的同学，也有一些研发同学会做操作手。说到分工，大概有：队长、运营、电路、嵌入式、视觉、机械、操作手这几大类。 这场比赛的机器人分为：英雄机器人、步兵机器人、哨兵机器人、工程机器人、无人机、基地、补给站。主办方还会限制每一类型机器人的最大尺寸、功率等，以防威力过大破坏赛场或造成安全事故。这些机器人都是学生们自主设计和调试的，尽管赛场上看起来很多机器人长相差不多，但是不同团队在很多细节设计上都会有很多的差别，这也是比赛成败的关键之一。这项比赛每年都会举办，留给学生的准备时间大概是半年到一年，很多学生在完成学校的课业后，大部分时间都需要泡在团队里。 工程机器人 机器人怎么攻击的？通过发射弹丸。但是比如工程机器人是不允许攻击的，步兵、英雄和无人机是可以攻击的。但是英雄发射的是大弹丸（高尔夫球）。下图是哨兵和步兵对抗的画面，上方是哨兵机器人，这是一台全自动的机器人，但是只能在一条导轨上运动。 哨兵机器人 如何判定攻击是否有效呢？依赖裁判系统。比如上图中的“装甲板”（比如贴了1号的模块）就是属于裁判系统的一环。弹丸击中裁判系统后，被击中的机器人会被扣血，如果血量归零，那么就会被裁判系统断电，这时候就需要依靠工程机器人将阵亡的机器人拖回补给站等待复活。 神符系统 上图右边9x9宫格就是神符系统，可以用来给团队加成。如何获得这个buff？需要机器人击打九宫格，九宫格上面的数码管会显示一串数字，届时九宫格中的每一格将会刷新出一个新的内容，这时候就需要机器人识别数码管，然后在九宫格上找到对应的数字击打，击中目标数字后，九宫格会刷新。这项功能可以由操作手完成，但是实际上九宫格会按照一定频率重新刷新内容，因此每次数字的位置是不一样的，依靠人眼观察是来不及的，所以需要视觉和嵌入式一起来执行自动操作。 我在团队的时候是在视觉组，做的是自动瞄准部分。当时的视觉大概分为两个方向，自动瞄准和神符。如上所述，打击神符需要需要识别数字或者图案，因此大多是通过ML的方案来做的。自动瞄准因为需要很高的检测频率，因此基本是通过传统视觉方案来做的。以下我会主要介绍自动瞄准。 自瞄要做的一方面是需要检测对方装甲的空间坐标，第二可能需要判断对方机器人的运动方向，第三是需要和嵌入式一起联调云台，以求最快将“枪管”移动到目标位置。 检测对方装甲主要是通过灯条的特征。通过上面哨兵机器人那张图也可以看到，装甲左右两边是有两个灯条的，红色或者蓝色，这是和所在队伍是哪方相关的。并且规则会规定，不允许在装甲周围投射灯光，因此可以保证装甲周围的灯光是比较纯净的。当然，这是理想情况，因为赛场也是会有灯光污染的，因此无法保证装甲周围的灯光环境一定干净。当时的规则也会存在一些漏洞，如下图，会有队伍在装甲周围安装衍射片以干扰对装甲的视觉检测。不过既然规则也没说明，这也是不违规的。（不是上交、这只是截图，来自知乎。） 衍射片干扰 如何检测？主要是通过颜色空间转换，使用颜色信息，滤掉很多无用的信息，可以得到很多候选灯条矩形块，然后再通过一些先验知识（比如装甲一定是一个矩形）等信息讲相应的矩形块组合，得到装甲区域，这时候就检测到了目标。除了软件方法，也可以采用一些硬件方法提高检测效果，比如在镜头前使用滤波片，使用高帧率的工业相机等，软件上也有额外可以做的，比如检测到目标装甲后，会通过AI目标识别方法，判断“装甲”是否在机器人身上，以降低误检测。 但是这时候仅可以得到像平面坐标，有用的是物理空间坐标。如何做？通俗方式可以使用双目视觉，但是会提高成本（如果使用工业相机，一个很贵），和需要比较高精度的机械装配。比较节省的方案是使用单目视觉，只要能够提高相机帧率和算法帧率，那么使用相邻帧计算空间坐标就是可行的，因为检测帧率很高，可以认为目标的实际位置距离计算位置不是很远，这时候可以通过一些预测方法得到目标的大致真实位置。 如何预测目标位置？为什么要预测？是因为从成像到检测到计算目标位置是存在时延的，而且在“子弹”出膛到击中目标也是需要消耗时间的，这些时间不可忽略（主要是子弹飞行时间），所以需要预测目标下一次的位置。主要做法就是通过目标的加速度（通过历史位置可以得到，是个矢量）和空间距离预估新位置。 仅有以上部分还是不够的，只是完成了视觉部分，要让子弹射出去，还需要依赖嵌入式。云台摆动到目标位置不是一条指令就可以达到的，因为存在抖动和加速度。因此很重要的一点是，如何让云台尽快响应到达目标位置。控制方法有很多种，比如模糊控制、PID控制等等。视觉在这套系统里作为上位机，需要给云台发送位置信息，嵌入式会控制云台运动到目标位置。因为软件架构设计的缺陷（我现在是这样认为的），当时发送数据需要考虑底层的响应速率，在云台开始摆动的时候，数据发送太快或者太慢都不行，都可能提高云台的响应时间。所以需要上层控制发送速率，比如目标丢失的时候，需要依赖历史信息，预测出目标的位置，以补充这些缺失的帧。 自动瞄准主要是运用在哨兵机器人上，但是比如步兵、英雄、无人机也是会应用的，只是一般需要操作手手动开启。 在RM的比赛中，每一个角色都起到了很重要的作用。仅凭我浅薄的记忆和理解，列一列每个角色的大概职能。 队长：赛务安排、资源分配、团队精神支柱等 运营：宣传、招聘，团队建设等 机械：所有机器的结构，需要考虑赛制规则，也需要很强的稳定性，以保证机器人下台阶、碰撞或者被高尔夫击中后不会散架或爆炸 视觉：目标检测、目标识别 电路：电路设计和制作，功率控制（大概是这样）等 嵌入式：云台、电机控制、通信 操作手：熟悉机器人操作和机器人特性 我离开团队很久了，也没再特意关注过这场比赛，但是在团队群里可以看到一些老队员对这场比赛依然保持着很高的热情。 我想起来有人对这个比赛的评论：这个比赛最重要的是过程，而不是最后的奖杯。很多人通过比赛的过程能收获很多，是学校教学给不了的，也是工作经验给不了的。 我记得的是，大家累了就坐在地上吃外卖，困了就躺在泡沫板上睡觉，也有同学为了能尽快调试出期望的效果刷了多少个夜（不是我），吵完架也会记得回来工作，大家还是兄弟。现在回过头去看，这就是热情呀。一群人为了同一个目标，日日夜夜，没心没肺，只为了同一个简简单单的目标。或者说有时候也没有目标，只是想着把自己的事情做好，做得更好。这种热情是我在团队的时候没有意识到的，也是在离开团队、参加工作后开始怀念和珍惜的，可能未来也很难有这样一个纯粹的团队了吧~ ","date":"2023-01-15","objectID":"/202301/robomaster-experience/:0:0","tags":["RM"],"title":"我在RoboMaster那些年","uri":"/202301/robomaster-experience/"},{"categories":["操作系统","glibc"],"content":"Linux文件系统可以分为两层，虚拟文件系统(VFS)和驱动。VFS主要和驱动对接，以实现对不同文件系统的适配和管理。本文阅读的read/write函数是VFS层面的，源码如下：https://codebrowser.dev/linux/linux/fs/read_write.c.html 大致结构如下，当然以下所指的设备不一定是真实的物理设备。 VFS-驱动 ","date":"2023-01-08","objectID":"/202301/glibc-read-write/:0:0","tags":["Linux","glibc"],"title":"glibc-read/write源码阅读","uri":"/202301/glibc-read-write/"},{"categories":["操作系统","glibc"],"content":"read read的入口如下，输入参数是文件fd、buffer、长度。回顾之前的文章中学习过的，fd是指文件在task_struct中files table的下标，通过fd可以找到struct file，从而拿到inode，获取到文件内容。 SYSCALL_DEFINE3(read, unsigned int, fd, char __user *, buf, size_t, count) { return ksys_read(fd, buf, count); } ksys_read展开如下： ssize_t ksys_read(unsigned int fd, char __user *buf, size_t count) { struct fd f = fdget_pos(fd); ssize_t ret = -EBADF; if (f.file) { loff_t pos, *ppos = file_ppos(f.file); if (ppos) { pos = *ppos; ppos = \u0026pos; } ret = vfs_read(f.file, buf, count, ppos); if (ret \u003e= 0 \u0026\u0026 ppos) f.file-\u003ef_pos = pos; fdput_pos(f); } return ret; } 其中，fdget_pos会调用到以下这个函数： unsigned long __fdget_pos(unsigned int fd) { unsigned long v = __fdget(fd); struct file *file = (struct file *)(v \u0026 ~3); if (file \u0026\u0026 (file-\u003ef_mode \u0026 FMODE_ATOMIC_POS)) { if (file_count(file) \u003e 1) { v |= FDPUT_POS_UNLOCK; mutex_lock(\u0026file-\u003ef_pos_lock); } } return v; } fdput_pos展开如下： static inline void fdput_pos(struct fd f) { if (f.flags \u0026 FDPUT_POS_UNLOCK) __f_unlock_pos(f.file); fdput(f); } 如果文件被标记了FMODE_ATOMIC_POS，并且有多线程使用，那么f_pos会被加锁保护（认为是原子操作了）。在最后fdput_pos的时候则会对应解锁。注意到struct file *file = (struct file *)(v \u0026 ~3);这在tagged-pointer-让指针包含更多信息一文是介绍过的。 再回ksys_read到先是通过unsigned int fd拿到struct fd，其定义如下： struct fd { struct file *file; unsigned int flags; }; 这时候可以拿到struct file了，回顾一下其中重要的成员有： struct file { struct path f_path; struct inode *f_inode; /* cached value */ const struct file_operations *f_op; //... } path包含dentry、mnt信息，inode可以指向物理设备中的信息，file_operations保护一组操作表。 ksys_read接下来会尝试获取文件的pos（这里是读位置）信息： loff_t pos, *ppos = file_ppos(f.file); file_ppos的返回值被赋给了long long*，为什么是一个指针？展开file_ppos看看： /* file_ppos returns \u0026file-\u003ef_pos or NULL if file is stream */ static inline loff_t *file_ppos(struct file *file) { return file-\u003ef_mode \u0026 FMODE_STREAM ? NULL : \u0026file-\u003ef_pos; } 如果不是file stream的情况下，会返回struct file成员f_pos的地址。为什么要返回一个地址，而不是值呢？关注这段逻辑： if (ppos) { pos = *ppos; ppos = \u0026pos; } ppos是指针，ppos本来是指向struct file的f_pos成员，上述逻辑走完后，ppos指向了一个临时的pos，这时候f_pos相当于被保护起来了。上述说法说得通，但是为什么不直接赋值给pos，这样也不会影响f_pos呀？回到file_ppos，因为对file stream的情况需要返回NULL，如果直接赋值给pos再处理这种NULL情况的话，事情也不会变得更简单，因此引入一个ppos是合理的。 再往下看： ret = vfs_read(f.file, buf, count, ppos); if (ret \u003e= 0 \u0026\u0026 ppos) f.file-\u003ef_pos = pos; fdput_pos(f); 这段逻辑也可以说ppos起到了保护作用，在vfs_read之后，如果成功了，则会更新f_pos的值，如果失败也就不会更新了。这样做是可以保证失败的时候不会动f_pos，但是如果是多线程情况，且没有FMODE_ATOMIC_POS标记，f_pos的值不是乱套了吗？先进去vfs_read看看： ssize_t vfs_read(struct file *file, char __user *buf, size_t count, loff_t *pos) { //... 校验 ... if (count \u003e MAX_RW_COUNT) count = MAX_RW_COUNT; if (file-\u003ef_op-\u003eread) ret = file-\u003ef_op-\u003eread(file, buf, count, pos); else if (file-\u003ef_op-\u003eread_iter) ret = new_sync_read(file, buf, count, pos); else ret = -EINVAL; if (ret \u003e 0) { fsnotify_access(file); add_rchar(current, ret); } inc_syscr(current); return ret; } 如果驱动实现了read接口，那么就调用read接口，这里依赖驱动实现，就先跳过了；如果驱动没有实现read，而是实现read_iter，那么就是调用new_sync_read，进去看看： static ssize_t new_sync_read(struct file *filp, char __user *buf, size_t len, loff_t *ppos) { struct kiocb kiocb; struct iov_iter iter; ssize_t ret; init_sync_kiocb(\u0026kiocb, filp); kiocb.ki_pos = (ppos ? *ppos : 0); iov_iter_ubuf(\u0026iter, READ, buf, len); ret = call_read_iter(filp, \u0026kiocb, \u0026iter); BUG_ON(ret == -EIOCBQUEUED); if (ppos) *ppos = kiocb.ki_pos; return ret; } 这里遇到了之前没有接触过的结构体（概念）struct kiocb和struct iov_iter，定义如下： struct kiocb { struct file *ki_filp; loff_t ki_pos; void (*ki_complete)(struct kiocb *iocb, long ret); void *private; int ki_flags; u16 ki_ioprio; /* See linux/ioprio.h */ struct wait_page_queue *ki_waitq; /* for async buffered IO */ }; struct iov_iter { u8 iter_type; bool nofault; bool data_source; bool user_backed; union { size_t iov_offset; int last_offset; }; size_t count; union { const struct iovec *iov; const struct kvec *kvec; const struct bio_vec *bvec; struct xarray *xarray; struct pipe_inode_info *pipe; void __user *ubuf; }; union { unsigned long nr_segs; struct { unsigned int head; unsigned int start_head; }; loff_t xarray_start; }; }; 这两个结构体可以获取什么信息呢？一个是struct kiocb扩展了struct file的一些信息，一个是struct iov_iter包含用","date":"2023-01-08","objectID":"/202301/glibc-read-write/:1:0","tags":["Linux","glibc"],"title":"glibc-read/write源码阅读","uri":"/202301/glibc-read-write/"},{"categories":["操作系统","glibc"],"content":"小结 以上就是VFS这一层read的大致逻辑。大致流程就是先通过fd获取到struct file（这就是为什么read之前要先open），然后再获取当前的read指针位置，然后调用驱动的read/read_iter方法，如果读取成功则发送access fsnotify，最后把read指针更新后的位置回写给struct file。 上文还遗留一个问题，如果多线程读怎么办？可以假设驱动层的read/read_iter是原子的（那是驱动的事情），但是glibc的read默认是没有保护的，所以可能存在一些不安全的情况，比如f_pos的更新没有被保护，就可能导致多线程读错位。 关于多线程读的问题，可以再参考fread： size_t _IO_fread (void *buf, size_t size, size_t count, FILE *fp) { size_t bytes_requested = size * count; size_t bytes_read; CHECK_FILE (fp, 0); if (bytes_requested == 0) return 0; _IO_acquire_lock (fp); bytes_read = _IO_sgetn (fp, (char *) buf, bytes_requested); _IO_release_lock (fp); return bytes_requested == bytes_read ? count : bytes_read / size; } 可以看到，因为_IO_acquire_lock和_IO_release_lock，这是可以保证fread默认情况下就是线程安全的。 ","date":"2023-01-08","objectID":"/202301/glibc-read-write/:1:1","tags":["Linux","glibc"],"title":"glibc-read/write源码阅读","uri":"/202301/glibc-read-write/"},{"categories":["操作系统","glibc"],"content":"write write流程和read类似的，区别在vfs_write的实现： ssize_t vfs_write(struct file *file, const char __user *buf, size_t count, loff_t *pos) { // ... 校验 ... file_start_write(file); if (file-\u003ef_op-\u003ewrite) ret = file-\u003ef_op-\u003ewrite(file, buf, count, pos); else if (file-\u003ef_op-\u003ewrite_iter) ret = new_sync_write(file, buf, count, pos); else ret = -EINVAL; if (ret \u003e 0) { fsnotify_modify(file); add_wchar(current, ret); } inc_syscw(current); file_end_write(file); return ret; } 两者区别除了write发送的是fsnotify_modify通知外，vfs_write默认会保护struct file的读，怎么做的呢？file_start_write最终会调到__sb_start_write： static inline void __sb_start_write(struct super_block *sb, int level) { percpu_down_read(sb-\u003es_writers.rw_sem + level - 1); } 这时候给读加上了锁，可以参考percpu-rw-semaphore。 在写完之后file_end_write调用__sb_end_write给读解锁： static inline void __sb_end_write(struct super_block *sb, int level) { percpu_up_read(sb-\u003es_writers.rw_sem + level-1); } ","date":"2023-01-08","objectID":"/202301/glibc-read-write/:2:0","tags":["Linux","glibc"],"title":"glibc-read/write源码阅读","uri":"/202301/glibc-read-write/"},{"categories":["随笔"],"content":"这是第一次在博客上写年终总结，主要围绕以下方面展开：工作变化和感受、换城市的想法、博客建设、技术成长、今年计划完成度、明年的大致计划。 ","date":"2022-12-25","objectID":"/202212/2022-summary/:0:0","tags":["碎碎念"],"title":"2022年终总结","uri":"/202212/2022-summary/"},{"categories":["随笔"],"content":"博客建设 本博客已经持续维护快两年了，是我目前为止维护最久的一份博客。一直折腾来折腾去，主要是针对阅读体验、个人表达和展示的一些修改，博客主题一直没换，后续还是计划继续使用这个主题（LoveIt），不会花时间切换和迁移主题，当然个人还是会花一些时间用于提高本博客的阅读体验（仅凭个人主观感受）。 今年新增了两个域名：caibingcheng.com和imcbc.cn，再加上原来的bbing.com.cn，一共三个域名指向本站，目前是都会重定向到imcbc.cn。（使用重定向的原因是因为现在使用的gitalk评论是需要绑定域名的，且只可以绑定一个域名，因此只好通过重定向的方式实现多域名。）我现在我也不知道使用哪个域名好，可能都会继续使用吧，这三个域名加上rssblog.cn一年的维护费用不到两百元，目前来说还可以接受的。 博客的更新数量是在计划中的，平均一个月大概是2~3篇。但是内容上还不达预期，原本计划到今年为止需要有累计5篇的STL源码阅读和累计10篇的glibc阅读（此项已完成源码部分的研究，但是还没能输出文字。），以及去年计划的一些读后感，都没有达到。博文内容也主要集中在了一些应用上，基础知识的学习产出比较少，我认为我现在这个阶段还不能停止对基础知识的积累，所以后续还需加强对基础知识的学习。当然，如果有任何想法还是计划会去实现的，而不会因为要输出更多基础知识而放弃实现一些个人觉得有意思的想法。另外的，今年也有一些负面情绪的产出，我并不认为这是坏的，之后还是可能会有类似的文章，但是希望字里行间可以稍微多点中立和理智。 在文字上，有些内容还是需要更“独立”一点，不需要迎合任何读者。 ","date":"2022-12-25","objectID":"/202212/2022-summary/:1:0","tags":["碎碎念"],"title":"2022年终总结","uri":"/202212/2022-summary/"},{"categories":["随笔"],"content":"工作变化和感受 工作最大的变化就是从小米离职加入了zoom。 在之前的一些博文中，我发表了我对上一份工作的看法。当时感觉多么多么的不公平，但是换了环境工作一段时间后，慢慢领悟一些现实，工作就这样，都是来赚钱，有利益就有竞争，我以前所想的那种纯粹的、以技术为向导的环境，大概率是不存在的了。要是所谓感受不到，那也只是站的太高或者是利益既得者罢了。这就是“屁股决定脑袋”。 上一份工作，我算是渐渐陷入了一种舒适圈。拿到了集团当届（也是第一届）“最年轻”的青年工程师荣誉，也拿到了部门的xx奖，在开发路上没遇到太大的坎，也没有太多的批评，只是绩效相比之下一直平平，没有太多的升值加薪，所以很普通很普通，没有一丝波澜，这也导致我看不到希望，当心再呆下去，我的上限也就到头了。所以离开也是迟早的。 在新工作中，以前的所有成绩都被抹零了。现在我陷入了一种难受的境地。开始被他人否定，一直被否定，然后独自站起来自我肯定，然后再次被否定。我总是当心以后会被否定地站不起来了，不过幸好现在我还有站起来的力气。令人沮丧的是，现在的我甚至被暗示试用期都可能过不了！ 在选择工作的时候，也有其他的机会，有更好的赛道、高得多的工资，有人推荐我先不要来苏州，但是我还是来了，因为当时不仅考虑换工作，也想把城市尽快确定了。现在也不能说后悔吧，成年人没有后悔这一说，只能向前看，现在的遭遇只是一道坎，所以要想办法踏踏实实跨过去。我想起当时别人劝我先留在北京时，我说的一个观点：我还年轻，还有很多试错的机会，我总不能一直在你们的经验下长大。这不叫自作自受，换一个说法这是跳出舒适圈。现在的处境对我来说，是不小的挑战，是渡劫期，是机遇。跨过去，心态可能会经历一次很好的磨练！ （记下现在的心态，来年要记得回来看看。） 现在回想工作上的很多问题，还是不太会表达、太胆怯造成的。有时候姿态太低了，任谁都敢来踩一脚。有时候不反驳别人，导致别人误解你；本来你不是这样做的，也会被别人说的你是这样做的。在之前的文章中，我记录了这种想法，也期望在新工作中可以转变，但是没能做到。在跨入社会的时候，我身上还是有很多棱角的，可能那就是典型的书生气。虽然社会经历不多，但是工作上的很多事情，也让我感觉到，这些棱角渐渐被磨平了。很多本认为不合理的现象，也逐渐变得合理，这是现实，不是脑子里臆想的世界。我担心我会慢慢变成自己讨厌的样子，那时候我会怎么告诉我的孩子这个世界是怎样的？虽然我现在认为还不至于跨过这条底线。 另一个毛病是，太把工作当回事了。以我现在的经历没法评判这对不对（尽管对我来说这种想法十分错误），但是“太把工作当回事”导致我外婆去世的时候我没回去看最后一眼、总是和父母因为工作的事情吵架、总是因为工作上的事情郁郁寡欢、很少发自内心的笑。“太把工作当回事”是因为我害怕失去每一份工作，害怕得不到别人的肯定，害怕因为现在的工作影响我一辈子（这是最担心的），这种态度应该尝试去改一改了。我尝试过暗示自己，“一份工作而已嘛，凭我的学历和能力还担心找不到好工作？”这种暗示有时候奏效，但是没几天就失灵了。 ","date":"2022-12-25","objectID":"/202212/2022-summary/:2:0","tags":["碎碎念"],"title":"2022年终总结","uri":"/202212/2022-summary/"},{"categories":["随笔"],"content":"换城市的想法 我有时候容易想得太远太远，然后被这种未来的期望折磨。 想当年，意气风发地来到北京，计划着如何拿到百万年薪（哈哈，现在还是有这种自信）。但是呆久了发现还是不太适合，主要是房价太贵了，也没法靠父母，自身和女朋友的收入都不高，也不愿意做房奴。当时我们租的地方在西三旗，已经是海淀边上了，如果买的话，房价也八万多一平（好点的小区十万一平），如果不做房奴的定义是在40岁之前还清房贷，那么这意味着在40岁之前需要积累到大概1000万的资产（计算很复杂，此处简化，因为也要考虑房贷利息，生活成本之类）。单靠工资难度很大，即使达到百万年薪目标也够不着，因为扣税太多了。而且令我感触很深的一件事是，“字节一男子猝死，独留怀孕妻子偿还几百万的房贷”。在这种房贷骗局下，她可能会因还不起房贷，不仅得不到房子，还倒欠银行几百万（这是较坏的假设了）。我很害怕这种情况。 所以换城市其实只是让自己看 得到希望一点，而不是像中彩票那样想着会突然出来一些“利民”政策。在次一线、二线城市至少可以对未来作出大致的计划，在某些意外情况下也可以给家庭带来尽可能小的损失。 其实去哪个城市也是不确定的。来苏州只是一种选择吧，武汉、南京都是我们的选项。 ","date":"2022-12-25","objectID":"/202212/2022-summary/:3:0","tags":["碎碎念"],"title":"2022年终总结","uri":"/202212/2022-summary/"},{"categories":["随笔"],"content":"技术成长 今年很少时间能沉下心研究一个东西。 上半年还在继续看一些glibc的源码，下半年就很少接触了。不过收获还是不少的。其实很多代码看下来得到的一些结论，就是书上有的，但是我还是愿意去看，这就是与渔和鱼的区别了。在今年准备换工作的面试中，问到的八股文，我是没有背过书的，都是靠研究这些相对底层的代码获取到的知识。我也很高兴，这些积累起到作用了。所以现在可以总结出一点，看这些代码的时候，可以先看“热门”的部分，相当于一举多得。 应用上主要折腾的是tkinter、omv和openwrt。 tkinter是python的一款标准gui工具包。我只是当作纯工具使用，需要的时候看看demo怎么用，不会去研究实现原理。关注这个库的主要目的是实现几个想法：摸鱼工具-fkfish、系统信息悬浮窗-fstats、以及在公司实现的一款测试脚本的UI界面（但是没有推广使用）。 对omv的折腾就比较久了，也有一点连续性。最开始是使用笔记本刷omv系统。就像我一般刷系统一样，开始接触的时候总会遇到很多坑，然后刷很多遍，然后就成为了“刷系统高手”😅。通过omv，开始接触到了samba协议，真的很好用（但是话说回来，这个协议是什么内容、怎么运作的，还是不知道），又巩固了对docker的使用。到后来搬家之后就升级了omv的硬件，做垃圾佬组了一款自认为性价比很高的设备。在这期间又接触到了openwrt，我很早是了解过旁路由概念的，然后一直没有行动去做，这是在和同学聊天的情况下想起来的，然后去实现部署了。（这也说明了圈子的重要性。）不过因为成本和家庭网络的原因，我目前使用的是单臂路由的方案。通过部署openwrt的收获也是比较多的，了解和复习的概念有：DNS和内网点对点直连，这也解答了我对单臂路由运作的一些疑问，也提醒了我可以用交换机的方案提升PC和NAS之间的访问速度，这些知识在未来的家庭网络建设中也是有用的。 再有就是实现了：指数基金估值查询-djeva。这实际上是对rssblog实现方案的延续。都是通过github action拉取数据，备份到github本地，然后通过raw content请求对应的数据。我认为设计出一种方案，能将这种方案应用在不同的应用是比较重要的，这能证明这种方案的有效性。所以有时候实现某些想法，可以参考过去使用过的一些技术方案，以延续这些技术方案的生命周期和证明其有效性（可迁移）。 还有一个说小不小的点就是了解到了dotfiles的概念，从而维护了一套自己的dotfiles环境，也将dotfiles的思想应用在了日常的应用上，比如玩欧卡，为了在游戏内的电台听音乐，通过文件夹映射避免了音乐文件的拷贝。 最后就是python实现的一些cli工具。包括上文中也有一些应用是通过python实现的。不过我依然将这门语言定位在工具阶段，所以不会去了解其历史、原理。只会看看怎么用，怎么实现即可。 在新工作上，主要使用的是Objective-C，这对我来说比较新。本来计划是也和C/C++一样看作一门“饭碗语言”，不过现在还是放弃了。缺少社区、应用面太窄、过于高级，所以现在计划也只是当作一门工具语言了。不过，其实抛开OC本身不谈，其继承的“消息”这种思想还是值得去深入学习的。 ","date":"2022-12-25","objectID":"/202212/2022-summary/:4:0","tags":["碎碎念"],"title":"2022年终总结","uri":"/202212/2022-summary/"},{"categories":["随笔"],"content":"今年计划完成度 计划不是KPI，不需要必须完成。计划是前进的方向，防止我左搞右搞不专一。 今年是第一次量化目标，从年中开始写计划，但是都没有达成。主要方面是：输出指定内容的博客xx篇、学习英语累计xx天、leetcode累计xx天。 学习英语本来是进行的好好的，一直在连续学习，然后忘记是因为什么原因中断了一段时间，导致后续一直中断。这也是我的一个很大问题，很难持续一个计划（不过基本是针对英语，从在学校开始就这样）。不过我还是要依然说服自己英语的重要性，这也是在社会上你和别人差异性的体现。另外有一点我认为可以保持的就是“三分钟”热度（不只是学习英语）。我经历过这样几个阶段：三分钟热度==\u003e犹豫不决==\u003e三分钟热度。我还是喜欢并且期望继续保持三分钟热度这种态度。因为犹豫不决的时候我总是容易在脑子里考虑某种方案的可行性，然后试图发现不可行的点，然后否决；三分钟热度的时候就是考虑某种方案是否有机会可行，有机会并且有时间（还有有钱），那就去干了，脑子不用想太多。 我现在是缺少冲劲的，想得太多了，所以很需要“三分钟热度”，想到有可能就可以去干，不管是工作还是学习上。当然这种态度不是对任何人、任何阶段都适用的。因为我现在容易犹犹豫豫，所以它才会适合现在的我。 ","date":"2022-12-25","objectID":"/202212/2022-summary/:5:0","tags":["碎碎念"],"title":"2022年终总结","uri":"/202212/2022-summary/"},{"categories":["随笔"],"content":"明年的全年计划 明年主要解决什么问题？有什么想做的？围绕生活、技术、工作： 去别的城市旅游，今年因为疫情严重和工作原因是没有计划旅游的 尝试夜跑，来到苏州后持续了几天，后来因为太冷就放弃了，等来年气温回暖后可以继续 继续保持博客月2篇以上的输出 增加基础知识的学习和输出，切忌浮躁 尝试阅读文学书籍，培养处事不惊的心态，需要佛性一点 需要试着找找有没有什么方法可以减少抱怨和负面情绪，但不需要抑制 不要和父母吵架 交朋友！交朋友！交朋友！试着和同事交朋友！ 试着“骚”一点，现在还欠缺表达出内心想法的勇气，所以可以试着多在博客里写写自己的想法，而不要害羞 具体量化指标待尝试执行一段时间后再定。 ","date":"2022-12-25","objectID":"/202212/2022-summary/:6:0","tags":["碎碎念"],"title":"2022年终总结","uri":"/202212/2022-summary/"},{"categories":["工具"],"content":"此前用废旧笔记本刷上OMV改了一个NAS，但总因为散热问题，当心着火（实际上温度一直不高）。因此，最近对家里的NAS做了一次软硬件的升级。 ","date":"2022-12-14","objectID":"/202212/omv-update/:0:0","tags":["nas","omv","openwrt"],"title":"OMV硬件和软件升级","uri":"/202212/omv-update/"},{"categories":["工具"],"content":"硬件升级 硬件做的改造主要是： 从笔记本换成了台式机； 将原本AIO的openwrt拆分出来，单独用一个小主机做openwrt的硬件设置； 客厅多媒体设备使用千兆交换机直连； ","date":"2022-12-14","objectID":"/202212/omv-update/:1:0","tags":["nas","omv","openwrt"],"title":"OMV硬件和软件升级","uri":"/202212/omv-update/"},{"categories":["工具"],"content":"笔记本换台式机 从笔记本换台式机的需求之一是，尽可能的减少成本，在好朋友@qhw0的帮助下，定制了以下的台式机设备： 硬件 价格 备注 七彩虹CQ1900M主板 110.00 咸鱼，包含4GB内存 台达NX350电源 70.00 咸鱼，不包含电源线 先马M2机箱 89.80 京东自营 金士顿240GB SSD 168.98 京东自营，笔记本拆机，但是买了不到两个月，算作原价 西数1TB 机械 0.00 五六年前买的，读写很少，平均成本算作0 SATA硬盘线 0.00 两三年前的剩余材料，平均成本算作0 电饭煲线 0.00 用作电源线，厨房有其他线可以给电饭煲使用 以上总计：438.78元 在保证硬件性能不降低的情况下，以上设备可能不太好再降低预算了。（机箱可以换成鞋盒，但是又陷入了我当心的着火问题。） 七彩虹CQ1900M主板的特性有： 集成赛扬J1900（四核四线程）CPU TDP功耗15w 提供1个千兆有线网口 支持2个内存插槽（DDR3 1066/1333MHZ） 支持2个SATA 2.0接口 提供1个PCIE2.0 X16插槽，2个PCIE X1插槽 180mm*215mm mATX规格 我主要是看中千兆网口，这是必须条件，需要注意，有些类似规格的主板或者mini主机不提供千兆网口。对于家庭NAS目的来说，2个内存插槽扩充到8GB内存也是完全足够使用的，目前4GB的容量也足够我使用。该主板只有2个SATA接口，除去一个系统盘，那么只剩下一个存储盘了，但是可以使用PCIE转SATA卡，用以提供更多的SATA接口。 我目前配置了一块SSD做系统盘，一块1TB机械做存储盘。没有配备CPU风扇或机箱风扇，没有遇到明显的发热问题。不过我这快机械盘的噪声有点大，会和机箱共振（机箱摆放在电视柜上），目前做法是在机箱的垫脚上垫了海绵以降低和电视柜的共振。 台达NX350是朋友推荐的，主要特性是输出功率稳定。该电源提供的SATA供电线只有三个，如果后期需要扩充硬盘的话，需要再接4Pin转SATA供电。不过目前的机箱只有2个3.5寸机械硬盘位，所以SATA电源线是足够使用的。 电饭煲线和机箱不太搭，一个白色的，一个黑色的，但是没必要再去买根线了。使用非原装电源线需要注意线材的负载，不过一般电饭煲电源线的负载是足够的（基本是2000w）。 ","date":"2022-12-14","objectID":"/202212/omv-update/:1:1","tags":["nas","omv","openwrt"],"title":"OMV硬件和软件升级","uri":"/202212/omv-update/"},{"categories":["工具"],"content":"openwrt硬件 在更换硬件之前，我使用的是All in One的方案，在OMV中使用docker运行openwrt，这样的问题有两个： host和docker通信不太会调，导致host不可以走代理，使用再增加一个macvlan的中转方案也没能解决这个问题； 网口限制，虽然局域网设备直连，但因为是AIO，所以共用网口和线路的最大速率，因此当心会有一些极端情况出现，继而影响家庭网络； 参考了一些电视盒子，性价比都不太理想，最后采用的是J1800方案。在咸鱼上淘了一个二手盖网魔盒，135元，J1800集成主板，一个千兆网口，2.4G无线网卡，带2GB内存、16GB固态。 ","date":"2022-12-14","objectID":"/202212/omv-update/:1:2","tags":["nas","omv","openwrt"],"title":"OMV硬件和软件升级","uri":"/202212/omv-update/"},{"categories":["工具"],"content":"千兆交换机 使用交换机主要是为了提高内网访问速率。因为是租的房子，埋的网线猜测是100M的（设备直连测速大概是200Mbps），不使用交换机的话，家庭的物理线路就会成为网络访问的最大瓶颈。在使用交换机之前的网络拓扑大致如下： 使用交换机之前 因为家里是300Mbps的单宽带，又因为路由器\u003c--\u003eopenwrt的通路也认为可以达到300Mbps（一些小损失就忽略了），因此这时候可以认为访问外网不受影响。但是这时候内网访问nas的速率也最多只能到300Mbps，而且一般是无法持续维持的，并且又要“和外网共用线路”（参考上文的说法），这就不太合理了。（为什么不使用无线网络？一是无论使用mesh方案或者升级无线网卡都需要增加不少成本，二是实际体验不好，稳定性不足。（mesh方案没试验过，没钱））所以，此次改造的核心目的是提高nas和内网设备之间的物理线路的速度。 那么，在使用交换机+分离openwrt之后，家庭网络拓扑如下： 使用交换机+分离openwrt之后 可以看到，nas和电脑/游戏机/电视之间可以通过千兆线路直连，对使用体验有明显提升，测试速度大概在800Mbps左右。当然，手机和nas之间的体验暂时还是想到又便宜又好的方案，不过手机对nas的访问比较少，目前也不需要大带宽。 以上，改造前后都在openwrt设备上标记了一个lan口，是为了说明使用的是单臂路由的方案，又因为是全双工，所以影响不是很大。 ","date":"2022-12-14","objectID":"/202212/omv-update/:1:3","tags":["nas","omv","openwrt"],"title":"OMV硬件和软件升级","uri":"/202212/omv-update/"},{"categories":["工具"],"content":"软件升级 软件升级主要有： OMV5升级到OMV6； 重新设计用户权限和共享目录权限； 重新设定docker bind目录； 添加了code-server； openwrt使用官方镜像； OMV5升级到OMV6只是因为换了设备，原来的系统复制到新设备上总有些问题，因此就索性刷了最新的OMV6，不过我个人认为UI还是好看了很多的，这是现在的仪表盘页面。 OMV6 ","date":"2022-12-14","objectID":"/202212/omv-update/:2:0","tags":["nas","omv","openwrt"],"title":"OMV硬件和软件升级","uri":"/202212/omv-update/"},{"categories":["工具"],"content":"用户权限、共享目录 修改用户权限和控制共享目录主要是为了控制个人隐私，比如未来家里来了访客，是可以访问public权限的目录，这里只存放一些可以被所有人共享的内容，但是无法访问其他目录（比如存放媒体文件的一些目录）。那么，我的设计如下： 两组用户：bing（我）具备最高权限，可以访问任意路径；public（访客）被我控制，只能访问部分路径； 共享目录一：Documents目录，SMB协议且公开，public用户具有递归的wrx权限，配置SMB时也要设置允许访客读写。我现在认为，在nas配置了多媒体服务的情况下，媒体文件就可以由这些服务管理（比如jellyfin、transmission），不再需要一个一个像文件一样被人手动管理（比如通过拷贝、复制、移动之类），因此，理应将这些文件隐藏起来，一般只允许通过多媒体服务来访问，那么对我来说，nas剩下的主要用途就是备份电脑文件和家庭照片，这时候就将可以通过映射将Documents目录当作电脑的普通硬盘用来备份即可；当然，照片也可以由nextcloud等服务管理，但是之前使用感受不算惊艳，因此目前没有继续配置该服务。 共享目录二：Meidas目录，不公开，给来jellyfin、transmission等挂载使用，由bing创建，权限可以是700，电影等文件就存放在该目录下。 通过以上设置，就可以有以下使用场景： 通过给jellyfin不同账号配置不同的媒体权限，因此实现分级制度，并且被管理的用户是确实看不到不被许可的内容的； Documents可以随意访问，可以不设置密码；（仅内网） ","date":"2022-12-14","objectID":"/202212/omv-update/:2:1","tags":["nas","omv","openwrt"],"title":"OMV硬件和软件升级","uri":"/202212/omv-update/"},{"categories":["工具"],"content":"code-server 在之前的方案中就使用过code-server，但是因为host不能走docker openwrt的代理，因此没有继续使用了。在现在的方案中，这个问题不存在了，因此继续添加了这个服务。参考docker hub的配置还是很简单的，因此这里就简单贴一下我的配置： --- version: \"2.1\" services: code-server: image: linuxserver/code-server:latest container_name: vscode environment: - PUID=1000 - PGID=1000 - TZ=Asia/Shanghai - SUDO_PASSWORD=2 volumes: - /srv/xxxxxxxxxxxxxxx/config/vscode:/config ports: - 8443:8443 - 1313:1313 restart: unless-stopped 主要区别之处是绑定了1313:1313端口，这样就可以在code-server上运行hugo server，然后内网访问，以便测试了。本文就是在该code-server上写的，在家庭网络中，我可以在台式机上写，也可以在笔记本上写（有三台笔记本），达到了局域网下多设备同步的目的。相较于codespace，缺少了外网访问的功能，但是访问速度上是完胜，目前没有丝毫卡顿。（现在大爱这个功能！！！） ","date":"2022-12-14","objectID":"/202212/omv-update/:2:2","tags":["nas","omv","openwrt"],"title":"OMV硬件和软件升级","uri":"/202212/omv-update/"},{"categories":["工具"],"content":"openwrt镜像 在AOI方案中，我是用的是lean的镜像，功能很多，但是很多都用不上。我使用openwrt只是为了全局代理，因此，在更换硬件设备后，就使用了官方镜像，然后按需安装插件。不过该镜像的问题是写死了分区大小，导致16GB的硬盘实际只能使用不到1GB，该问题我目前还没去折腾，因为不影响使用。 ","date":"2022-12-14","objectID":"/202212/omv-update/:2:3","tags":["nas","omv","openwrt"],"title":"OMV硬件和软件升级","uri":"/202212/omv-update/"},{"categories":["工具"],"content":"小结 以上，主要修改还是硬件部分。因为硬件的修改，带来了软件使用体验的提升。这次折腾的主要收获还是了解到了一些网络设备，比如单臂路由、软路由等，也学会了简单分析家庭网络的物理瓶颈，比如通过绘制本文的网络拓扑图，又加深了我对现在家庭网络的认知。 ","date":"2022-12-14","objectID":"/202212/omv-update/:3:0","tags":["nas","omv","openwrt"],"title":"OMV硬件和软件升级","uri":"/202212/omv-update/"},{"categories":["Cpp"],"content":"在C++中，我们可以指定类型在内存中的对齐方式。比如使用 __attribute__((aligned(4)))，使得使用该类型的变量以4Byte方式对齐。一般讨论内存对齐的作用主要有两点： 跨平台移植（和硬件相关） 提高CPU访问性能 除此之外还有什么作用，是本文要探索的。提出该问题是源于以下代码： unsigned long __fdget_pos(unsigned int fd) { unsigned long v = __fdget(fd); struct file *file = (struct file *)(v \u0026 ~3); if (file \u0026\u0026 (file-\u003ef_mode \u0026 FMODE_ATOMIC_POS)) { if (file_count(file) \u003e 1) { v |= FDPUT_POS_UNLOCK; mutex_lock(\u0026file-\u003ef_pos_lock); } } return v; } 关注以下部分： unsigned long v = __fdget(fd); struct file *file = (struct file *)(v \u0026 ~3); 通过__fdget(fd)拿到struct file的地址v，然后通过v \u0026 ~3得到真正的struct file地址。是不是很奇怪？ 通过搜索kernel邮件，关于这段代码，查询到了这个关键词 - tagged pointer。 tagged pointer是苹果提出的概念，用于减少内存占用和提高访问速度等（在OC的NSNumber中有使用）。网上有很多人对这个概念做出了翻译/解释，因此不再赘述。对于在C++中的应用，我的理解是： 比如有一个类型Number可以存储任意大小的数字，那么设计时一般会在其内部塞入一个ptr指针，指向堆内存，在那里存放了这个数字的信息。对于很大的数字比较好理解，但是对于小数字，比如0~65535之类，还需要在堆内存上分配一块吗？如果对小数字也分配内存，势必有些浪费，那么这时候就可以在上述的ptr指针上做手脚。比如约定ptr指针一定是一个4Byte对齐的指针，这意味着ptr指向的地址一定是0x???..???00。现在有两种使用方法： 直接使用低2位，如果低2位不为0，那么低2位代表的数字就是这个小数字； 将低2位作为标志位，如果低2位不为0，则高位数字[2:]就是代表这个小数字； 针对Number类型，方法1表示的小数范围更小，方法2表示的小数范围更大。两种方法的并无好坏之分，使用场景不同而已，比如方法1可以用来保存一些状态信息，方法2就如Number类型一样，用来存储小数字。回到struct file，可以找到如下申明： struct file { //... } __randomize_layout __attribute__((aligned(4))); /* lest something weird decides that 2 is OK */ struct file按照4Byte对齐，这意味着它的地址表示方法是0x???..???00，这时候用户就可以在低2位插入一些有用的字段了（方法1）。所以现在可以很好的解释struct file *file = (struct file *)(v \u0026 ~3);就是为了剔除可能标志位，得到struct file真正的有效地址。 这时候有另外一个问题，内存对齐一定会消耗更多内存吗？ 我想是的，但是可能不如我们想象的多。比如一个32Byte大小的结构体，按照8Byte对齐，它可能会增加0~7Byte的align内存，不是一定增加7Byte。如果是一个上述类型的数组，那么这个数组整体可能增加0~7Byte的align内存，这依赖于第一个元素的地址如何。 ","date":"2022-11-20","objectID":"/202211/tagged-pointer/:0:0","tags":["Cpp","指针"],"title":"tagged-pointer-让指针包含更多信息","uri":"/202211/tagged-pointer/"},{"categories":["工具"],"content":"我学习到的dotfiles的核心想法就是：1. 通过软链接将不同路径下的文件统一管理；2. 通过软链接将统一管理的文件分配给不同路径； 受这两个观点的启发，在日常开发/生活中也可以通过软链接实现一些应用。 ","date":"2022-11-14","objectID":"/202211/dotfiles-more/:0:0","tags":["dotfiles","软链接"],"title":"dotfiles之外的一些应用","uri":"/202211/dotfiles-more/"},{"categories":["工具"],"content":"文件分类 （文件分类这个标题有点大，但是也不是不可以～～） 我遇到的实际问题是，把需要的log文件放在特定的文件夹中，如以下目录结构： logs config_1.yml config_2.yml config_3.yml log_1.log log_2.log log_3.log log_4.log static_1.png static_2.png static_3.png 我期望文件夹中只有log_*.log这些文件，这样就可以方便的用vscode之类的打开和查看了。 一种想法是将log_*.log文件拷贝出来，如： mkdir -p log_view \u0026\u0026 cp logs/log_*.log log_view 这样的问题是多增加了一次不必要的拷贝。那么引用dotfiles的思想，可以这样做： mkdir -p log_view \u0026\u0026 ln logs/log_*.log log_view 不增加额外的内容拷贝，可以在log_view目录下查看log文件这一分类，我们可以添加更多这样的分类，来达到‘零拷贝’文件分类的目的。（比如实现一个文件标签功能的应用） ","date":"2022-11-14","objectID":"/202211/dotfiles-more/:1:0","tags":["dotfiles","软链接"],"title":"dotfiles之外的一些应用","uri":"/202211/dotfiles-more/"},{"categories":["工具"],"content":"文件映射 （没有想到一个好的标题…） 最近沉迷欧卡2，其中有一项功能就是可以在卡车上播放本地下载的音乐，做法是在[User]\\Documents\\Euro Truck Simulator 2\\music路径下放置音乐文件。但是Document默认是和系统挂载在一起的，我期望本地音乐在Nas的硬盘上（已打开SMB），而不是再拷贝一份到上述目录下。有了dotfiles的提示，就很简单了，直接从SMB的音乐目录选中喜欢的音乐，创建软链接（快捷方式）到上述music路径就行了。 （欧卡真好玩…入了g29方向盘，最近下班回家都会送上一趟货，被迫加班😄） ","date":"2022-11-14","objectID":"/202211/dotfiles-more/:2:0","tags":["dotfiles","软链接"],"title":"dotfiles之外的一些应用","uri":"/202211/dotfiles-more/"},{"categories":["工具"],"content":"曾经遇到过一个问题，我的工作电脑、个人电脑、服务器如何同步一些个人设置？ 因为很多配置文件都是在~/路径下的，我最开始的做法是在~/路径下维护一个git仓库，然后在不同机器间同步。这样的问题是，这个仓库“太大了”，相当于~/路径下的所有文件对它都是可见的，因此维护起来比较麻烦。 最近看Codespace文档的时候了解到了dotfiles这个概念，目前完全可以满足我的需求。 ","date":"2022-10-18","objectID":"/202210/summary-dotfiles/:0:0","tags":["dotfiles"],"title":"同步不同设备间的设置-dotfiles","uri":"/202210/summary-dotfiles/"},{"categories":["工具"],"content":"dotfiles dotfiles如其名，就是点文件，因为类Linux系统下的大多数配置文件都是.xxx的形式，因此而得名。其思想也是使用一个git仓库管理所有的配置文件，但是不像开头那样在~/下维护一个仓库，而是在任意路径下维护诸如名字为dotfiles的仓库。这样配置文件的路径不是乱套了吗？dotfiles的核心思想就是使用软链接将配置文件链接到正确的路径。 比如在.dotfiles目录下管理如下配置文件： .dotfiles ├── aliases ├── tag-rcm │ └── rcrc └── tag-zsh ├── zinit_plugins ├── zshrc ├── zshrc_alias └── zshrc_bindkeys 经过软链接后在~/目录下映射为了如下配置文件： .aliases -\u003e /home/codespace/.dotfiles/aliases .rcrc -\u003e /home/codespace/.dotfiles/tag-rcm/rcrc .zinit_plugins -\u003e /home/codespace/.dotfiles/tag-zsh/zinit_plugins .zshrc -\u003e /home/codespace/.dotfiles/tag-zsh/zshrc .zshrc_alias -\u003e /home/codespace/.dotfiles/tag-zsh/zshrc_alias .zshrc_bindkeys -\u003e /home/codespace/.dotfiles/tag-zsh/zshrc_bindkeys 以上，还使用了tag来管理不同类别的配置文件，这样不会很复杂吗？如何简化？使用rcm. rcm是一款dotfiles的管理工具。用它可以实现对dotfiles的创建、映射、打标签等功能。不过有点奇怪，虽然是通过apt install rcm之类的命令安装的，但是rcm并不是一条命令，它提供了4条相关命令： lsrc mkrc rcdn rcup 分别是打印(ls)、创建(mk)、删除(dn)、构建/更新(up). 除基础命令外，还带额外参数，比如打标签(-t)，不加点(-U)等。要了解更多参数和用法，更好的方法是阅读man。 ","date":"2022-10-18","objectID":"/202210/summary-dotfiles/:1:0","tags":["dotfiles"],"title":"同步不同设备间的设置-dotfiles","uri":"/202210/summary-dotfiles/"},{"categories":["工具"],"content":"我的配置 以前设备上的配置文件已经丢失，之后我会使用dotfiles的方式重新管理设备的配置文件。目前的配置文件更新在https://github.com/caibingcheng/dotfiles. 目前，我的终端环境切换到了zsh，此前一直是bash。在“初次”使用zsh时发现了一些比较好用的东西： zinit，主要用于替换oh-my-zsh，zinit一个zsh插件管理器，oh-my-zsh是一个zsh配置环境，前者很轻后者有点重。 fzf，是一款查找工具，可以查找管道信息，也可以查找文件，和find对比的话，非常人性化，很早就有朋友给我推过，但是现在才使用。 ripgrep，使用Rust编写，主要是用于替换grep，很早就开始使用了，对我来说属于必装项目。 exa，主要用于替换ls，还在体验中，因为zinit的fzf-tab插件才了解到这个工具。 （这篇拖了好几天了，动手写之后发现也没太多内容） ","date":"2022-10-18","objectID":"/202210/summary-dotfiles/:2:0","tags":["dotfiles"],"title":"同步不同设备间的设置-dotfiles","uri":"/202210/summary-dotfiles/"},{"categories":["工具"],"content":"这两天在整理博客的github action，仅期望在有修改的时候才会触发build\u0026deploy，但是在实践过程中遇到一些问题，因此编写了md5any这个工具。 ","date":"2022-10-11","objectID":"/202210/md5fileandic-md5any/:0:0","tags":["Linux"],"title":"文件和文件夹md5工具-md5any","uri":"/202210/md5fileandic-md5any/"},{"categories":["工具"],"content":"背景 我遇到的问题是，我期望在content、theme等目录有修改的时候才会触发build\u0026deploy的job，这里不方便使用last modified time来计算，因为github action的schedule触发时间是不确定的，用last modified time计算的话，会有一段模糊期（比如我是在+8时区的0点开始触发，那么这段时间是模糊期（我瞎编的名字）），容易遗落或者重复计算。 那么，我使用tar来计算，先将我期望观测的目录和文件归档成一个文件，然后计算该文件的md5值，通过比较md5来判断是否有更新。在本地测试结果很好，但是推送到github上测试时发现，每次触发action得到的归档包的md5值都不一样，很奇怪！我目前并没有找到针对该问题的解决方案，仅查询到一些零碎信息，比如tar如果使用gzip压缩，则可能每次压缩结果会不一样，因为这其中会涉及到一个随机数。不过我在上述操作过程中，并没有使用任何压缩，仅使用-cf指令创建归档文件，而且，本地测试每次打包的md5值是一样的，只是在github action上，该情况就不满足了。 ","date":"2022-10-11","objectID":"/202210/md5fileandic-md5any/:1:0","tags":["Linux"],"title":"文件和文件夹md5工具-md5any","uri":"/202210/md5fileandic-md5any/"},{"categories":["工具"],"content":"md5any 为了解决上述问题，那么我就尝试编写了md5any。linux提供的指令md5sum只可以计算文件的md5值。不过仔细想想，这是对的，因为文件夹（目录）的md5值是不好定义的。我是如何定义的呢？ 我认为，文件夹的md5与其中文件的内容以及文件夹的目录结构有关，但是和最顶层文件夹无关，比如有这样的结构: test/ ├── d1 │ └── f1 ├── d2 ├── f1 └── f2 那么test这个文件夹的md5值和这些有关: ├── d1 │ └── f1 ├── d2 ├── f1 └── f2 和test自身的名字无关，这样的话，即时test名字改了，只要其目录结构以及文件内容不变（但是是否应该对文件属性敏感呢？比如文件修改日期之类？目前认为应该对其敏感），那么其md5值还是一样。 在这个前提条件下，就可以开始工作了：对于常规文件，计算其文件内容的md5值作为目标输出值；对于目录，则遍历其下的文件，计算文件md5值，然后与文件名、目录名一起作用再计算一个md5值作为其md5的结果，这是因为需要考虑文件在该目录下的位置，因此目录名和文件名需要考虑进去。可以参考以下代码（现在实验阶段，未来可能会变动）: 对常规文件，比如执行md5any filename则做以下操作： with Path(filepath).open('rb') as f: abs = hash(str(f.read())) if dentry is not None: abs = hash(str(dentry) + str(abs)) return abs 对目录，比如执行md5any dircname则做以下操作： hashList = [] path = Path(dirpath) for item in path.iterdir(): if item.is_dir(): hashList.append(self._hash_dir(str(item), str(item.name))) if item.is_file(): hashList.append(self._hash_file(str(item), Path(dentry).joinpath(str(item.name)))) hashList.sort() abs = hash(str(dentry) + ''.join(hashList)) （经@qhw0提醒，将os.path替换为pathlib.Path） 对目录是考虑递归思路，文件内容的md5值和文件名以及所在目录名拼接为一个字符串，然后以该字符串计算新的md5值作为该目录下该文件的md5，把该目录下所有这样的md5值以字典序拼接为一个长字符串，再以该长字符串和该目录名拼接为一个新长字符串，再以该新长字符串的md5值作为上一级目录下该目录的md5值，以此递归。对根目录以'.'替代以表示对其不敏感。 这样做会有什么问题？我想的是，一个文件夹的md5被其子文件和子文件夹的md5值的拼接字符串经过再计算之后的md5代替了，相当于只需要这个文件夹下的一个包含某些字符串的文件经过计算也可以得到相同的结果。但是这个包含某些字符串的文件应该包含哪些内容？不太好计算。因为文件和文件夹的md5计算方式实际上有区别，文件会把上级目录考虑进去，而文件夹是只考虑自身的，这是有区别的。所以，如果只使用md5any计算，也没有太大风险，这和md5撞库可能是类似的（我没计算过概率）。 以上。最终期望是可以和md5sum一样的用法，但是增加对文件夹的支持，目前博客的github action使用该方法是好的，可以满足需求。 ","date":"2022-10-11","objectID":"/202210/md5fileandic-md5any/:2:0","tags":["Linux"],"title":"文件和文件夹md5工具-md5any","uri":"/202210/md5fileandic-md5any/"},{"categories":["工具"],"content":"Github/Gitlab等平台上，有添加GPG keys的选项，GPG keys有什么用呢？ 如题，使用GPG认证可以防止commiter冒充。 如何生成和管理GPG密钥对的详细过程可以参考阮一峰的《GPG入门教程》。 我们来简化过程（学会多用help和man）。 ","date":"2022-09-28","objectID":"/202209/gunpg-commiter-sign/:0:0","tags":["gpg","Git"],"title":"使用GPG防止commiter冒充","uri":"/202209/gunpg-commiter-sign/"},{"categories":["工具"],"content":"使用GPG 首先，生成一组密钥对： gpg --gen-key 默认会使用RSA加密算法，根据提示输入需要的信息即可，比如姓名、邮箱。 然后查看生成的密钥对： gpg --list-keys 得到类似以下信息： ------------------------------ pub rsa3072 2022-09-28 [SC] [expires: 2024-09-27] DD723C3FC1B7322FEB3FD431C3238EDE9A24AC28 uid [ultimate] caibingcheng \u003cjack_cbc@163.com\u003e sub rsa3072 2022-09-28 [E] [expires: 2024-09-27] 其中DD723C3FC1B7322FEB3FD431C3238EDE9A24AC28是我们需要用到的一段key，只是一段摘要信息，即使暴露也是安全的。 现在，需要导出该密钥对的public key： gpg --armor --export DD723C3FC1B7322FEB3FD431C3238EDE9A24AC28 将得到如下类似的串： -----BEGIN PGP PUBLIC KEY BLOCK----- ...[此处是public key] -----END PGP PUBLIC KEY BLOCK----- 复制上述段全部，接下来以Github举例。在Github GPG keys中导入该public key。在git配置中，先配置好默认的GPG签名密钥对： git config [--global] user.signingKey DD723C3FC1B7322FEB3FD431C3238EDE9A24AC28 在作为修改后，尝试带上签名提交，如下(这样提交不是好的写法，仅做简写)： git commit -a -sS -m 'update with signature' (如果在生成GPG key的时候，输入了密码，那么在上述命令执行后是需要输入密码的。) 通过git log可以得到以下类似的提交信息，然后push到仓库： Author: caibingcheng \u003cjack_cbc@163.com\u003e Date: Wed Sep 28 20:16:52 2022 +0800 update with signature Signed-off-by: caibingcheng \u003cjack_cbc@163.com\u003e 提交后，就可以在Github的commits处看到有如下记录： 携带verify认证 如果不进行签名，那么就不会携带verify认证： 未携带verify认证 ","date":"2022-09-28","objectID":"/202209/gunpg-commiter-sign/:1:0","tags":["gpg","Git"],"title":"使用GPG防止commiter冒充","uri":"/202209/gunpg-commiter-sign/"},{"categories":["工具"],"content":"GPG防止commiter冒充 那么，GPG是如何防止commiter冒充的？在Github等平台上，可以通过上述verify标签判断是否真正的commiter。在PR阶段，仓库管理员就可以通过verify标签验证，来确定是否merge。（或者CI自动化判断也可以） commiter如何被冒充？ 因为git配置的时候，邮箱和用户名是可以随意修改，当其他人对你的仓库有提交权限的时候（比如一个开源仓库的开发人员），他就可以通过修改用户名、邮箱信息来冒充commiter。 这时候可能有些“不法分子”就会通过冒充commiter来博取信任，从而提交一些违规代码，或者扰乱项目正常进行。 通过GPG秘钥签名，保证物理安全，只要GPG私钥不泄露，那么一方面就可以保证代码是从真正commiter的设备上提交的；另一方面，通过设置签名密码，也可以加强commiter认证，降低被冒充的风险。 攻击者不是可以通过把他的GPG公钥放到Github GPG keys列表中来冒充吗？ →_→ 他都能破解你的Github账户了，那也没什么好防御的了~ ","date":"2022-09-28","objectID":"/202209/gunpg-commiter-sign/:2:0","tags":["gpg","Git"],"title":"使用GPG防止commiter冒充","uri":"/202209/gunpg-commiter-sign/"},{"categories":["Cpp","软件设计"],"content":"最近在读C++之父 Bjarne Stroustrup 关于 HOPL4（History of Programming Language，约十五年举办一次）会议的论文，以下称白皮书。主要讲述的是C++98到C++20的语言发展历史，包括一些语言特性和基础库的由来和相关讨论，以及为什么有些是语言特性，有些变成了基础库。了解语言发展历史，有助于理解语言设计的核心思想。 类似的，这是一篇一周目的读后感（22.06.18开始写…到现在三个多月了, 实际上差不多二周目），同SICP系列（目前还在一周目…）的理念，我认为上述论文也是值得多次拜读的，积累一定知识后再开启多周目肯定会有不一样的收获。 本篇读后感和SICP笔记的区别是，读后感是读完全文的所想，笔记是读完每一章节的所学和所想。 中文译版下载：在这里 ","date":"2022-09-27","objectID":"/202209/cpp_hopl4_reading/:0:0","tags":["HOPL","Cpp"],"title":"《现代C++白皮书》一周目读后感","uri":"/202209/cpp_hopl4_reading/"},{"categories":["Cpp","软件设计"],"content":"C++是一门全新的语言 首先，我们需要再一次重新认识到，C++并不是C的补充，也不是C的扩展，C++是一门全新的语言，我甚至认为这种认识是十分重要的。认识到C++是一门全新的语言将对我们的编码风格、组织以及思考方式都有帮助。在Stroustrup早期著作《C++语言的设计和演化》中，有这样一张图说明这种语言的演化关系： C++的演化历史 同样的，因为我最近在学习Objective-C，有很多人说OC是C语言的超集，实际上是不对的，如果把OC认为是C语言的超集那应该是大错特错了。我们只能说，OC兼容了或者大部分兼容了C，两个不是同一种东西，包括代码的编写和设计思想都不应该一样。需要了解这种区别，我认为需要了解了解Smalltalk这门语言。 最开始的C with Classes是通过C和Simula演化而来的，而后参考其他诸多语言演化为了C++，当然，就如Stroustrup所说，C++有很多特性也是通过长期实验和实践而得来的，更像是一个经验老道的工程师。 C with Classes最开始的目标是像C一样可以直接而高效的处理硬件，又可以像Simula一样组织代码。我认为C with Classes的说法，可能是将大部分人引入把C++看作是一门面向对象语言这样的一种误区的原因。其实很多教科书或者参考书都会说明（尽管他们的大多数还是说C++是一门面向对象的语言），C++也可以面向过程，函数式编程、泛型编程等等，尽管这些定义会和面向对象有所关联，但是理应区分他们之间的关系，这些定义是关系到代码组织方式和思考方式的。这种认知和“C++是一门全新的语言”一样重要，就如我在工作中经常会看到有人不假思索的就说“把XX定义为一个类”之类的说法，始终觉得很奇怪，万物都是对象吗？我想是的，万物都可以是对象，但是是不是万物都应该看作是对象？值得思考，现在主流观点都说万物皆对象，尽管我对此持怀疑的态度，但是大部分时候不得不随波逐流。 关于C++，我们经常会提到“零开销抽象”，到现在为止我也不能十分地理解该描述地含义，Stroustrup对此的解释是： 你不用的东西，你就不需要付出代价 你使用的东西，你手工写代码也不会更好 我的个人看法，“零开销抽象”是一种被C++采用，而被诸如Python、Javascript等解释器语言抛弃的设计哲学，因为解释器是runtime的，所以总有用户设计之外的开销，而类似Java因采用JVM机制，所以也不符合“零开销抽象”的设计哲学。在“零开销抽象”的设计框架下，用户或编译器更像是一个专家，需要考虑到更细致的东西，介错人的角色只会出现在用户的脑子里或者编译期（rust的编译器就像是编译期的介错人）。而在一些其他语言中（比如解释型），用户就是用户，不需要考虑太多，专心将思路转化为代码即可，介错人会在运行期出现。 关于C++用户更像一个专家的说法，我想到了一种解释。因为最近在看OC，OC主要参考自Smalltalk的设计思想，Smalltalk的一个思想是–创造性。用户不仅仅是程序的使用者，也是程序的开发者。那么这时候的语言设计就需要简单，用户不需要特别的了解各种不同的硬件构造，他们只需要把他们的想法表达出来即可。换句话说，我的理解是，C++是站在机器角度思考问题的，所以用户需要迎合它；Smalltalk是站在用户角度思考问题的，所以用户只需要关心自己。这么看来，C++用户会渐渐成为专家，而Smalltalk用户会渐渐成为资深用户（产品用户，就好像熟悉Windows系统一样）。（Smalltalk的设计目的，用现在的话语说就是一套操作系统 + 编程语言 + IDE的集成环境，用户在获得计算机后，会学习如何使用计算机，因为计算机的软件和环境全部由Smalltalk编写，那么这个过程中，用户也就慢慢学会了如何使用Smalltalk，那么他就会学会如何编程，而这个过程是不太需要像现在这样专门去学习编程课程的。） （还是回到C++吧，几个祖师爷级别的语言还是得找时间大概学习学习的。） 早期C++的发展史，是C++类的成长史。从白皮书所列的年表可以看到98年以前C++的发展主要是围绕类来展开的（当然，可能也有其他核心工作，但是我没读过其他HOPL的论文，而白皮书中也为着重介绍早期C++的发展，所以认知到此为止）。Stroustrup提到，C++的核心是构造函数和析构函数，在早期对应的是new和delete操作，但是不仅仅是指代内存，而是一切资源。我认为，不要把析构、构造函数和面向对象同等看待，他们不是包含或者被包含的关系，而更像是有所交集的两个不同集合，包含析构和构造的对象只是面向对象的一种实现方式而已。通过构造和析构，可以演化出C++的RAII设计哲学，这种设计可能成为C++不那么需要GC的论据之一。 在1980年代期间，又为C++类提供了继承、虚函数、重载、纯虚函数的支持。这是C++的类和Python或者Javascript等不同之处，多态迫使C++用户写出更加抽象的代码，迫使用户从问题中寻找更高层次的解释。我遇到有人会比较排斥多态，认为过度封装，但是我个人看来只是能力不够（也可能是认为“可以运行就可以了”，这是很多人会持有的态度，我有时候也会）。 C++98是大多数人学习的第一个C++版本，在98版本中，添加了模板、异常、namespace等语言特性，RAII的技术也是在C++98版本中确立的（很早就是这种技术，只是没有名字），此外，跟随C++98发布的，还有STL、智能指针等标准库。RAII和智能指针的出现否定了C++对GC的需求，namespace将构建复杂而庞大的库变得更容易（C++20的包也可以改变代码的组织方式和编译方式），模板的标准化催生了新的、图灵完备的编程流派–泛型编程（更早的时候也有）。 现在C++的很多特性在21世纪初就已经初见模型，可能因为标准化的原因，很多推迟了十几年、二十几年才得以发布。似乎强大的标准委员会在某些程度上来说，也阻碍了C++的发展和壮大。 ","date":"2022-09-27","objectID":"/202209/cpp_hopl4_reading/:1:0","tags":["HOPL","Cpp"],"title":"《现代C++白皮书》一周目读后感","uri":"/202209/cpp_hopl4_reading/"},{"categories":["Cpp","软件设计"],"content":"C++11是迈向现代化的一步 我刚开始学的C++是C++98，所以学习C++11的时候，颇有一种“这是啥？”的想法，两个版本的跨度对我来说相当不小，而C++11到C++17之间的跨度，却几乎是无感的。当然到了C++20，又有不小的改动，尽管很多概念都是近乎二十年前的。 C++11和之前的版本相比，富有现代感，加入了如下更新： auto推导 范围for 统一初始化 移动语义，如右值引用和std::move 用nullptr指代空指针 constexpr函数 lambda表达式 强枚举类型enum class 变参模板 扩展using意义，类型重命名、别名 unique_ptr和shared_ptr，扩充了依赖RAII的资源管理指针 aotmic变量 标准thread库 future-promise、packaged_task模型 type trait，更丰富的模板元编程 etc. 我想补充关于对nulltpr的认识。此前我找过一段时间关于nullptr的实现原理，最终得到了一种可信任的解释。nulltpr是语言上面更新，对nulltpr的支持是编译器层面的，而不是简单的认为对NULL的替换。 如果对这些更新分类，我想可以是： 用户层面的更新，这里的用户是程序员，减少劳动成本，比如auto推导、范围for、lambda表达式等 语言哲学的更新，是对语言认知转变的更新，比如nullptr、移动语义、内存模型等 用户更新偏向上层，语言哲学更新偏向底层。用上一节的话说，用户更新更倾向于smalltalk，让用户更具创造力；语言哲学更新更倾向于C++本身，让用户更像是专家。 言归正传，以上是语言自身的更新和标准库的更新，有部分没有列出，从我的浅见来看，最重要的更新是： 移动语义，减少内存拷贝，提高软件性能 对模板、类型的支持，丰富元编程技术 对内存模型的更新 对多线程标准库的支持，再也不用三方库了 我认为，这些更新让C++代码写起来更加现代化（我想的是和Python对比，会比较像了）。因为更多标准库的支持，此前不少复杂的特性、写法也变得更加简单和统一。比如范围for、thread库之类。 此外，C++11还有内存模型上的更新，这可能是最重要的更新，但是我对此暂时还不太了解，因此暂时略过。至于emplace运算之类，我认为是移动语义的附属产品。还有time库、random库之类，因为用的比较少，所以对此了解也不多。 到这里，我也想到了我们大学的C++教材，使用的是C++98的版本 – 说的就是《C++程序设计》。极其复杂和无聊的解说，把对C++语言的学习就当做是对一些条条框框的背诵和记忆，没有为什么，没有怎么来。所以那时候很多同学也学不下去，对这东西没什么兴趣。在我认识的同学里面，应该是没有因为这个教材喜欢上C++的，基本都是完全自学的。 在该译文中，Stroustrup也如是说： 直到 2018 年，我仍能看到 C++98 前的编译器被用于教学。我认为这是对学生的虐待，剥夺了他们接触学习我们 20 多年的进展的机会。 （我们被要求用的编译器是Borland C…） 不过，C++11如此大的变动，也导致了很多公司更新的困难，这意味着很多代码可能需要重写。在我工作一段时间之后，对此有很明显的感觉。公司使用的平台源代码，使用的是C++98的标准，最近几个release版本才可以从中看到部分C++11及以上的特性。公司很多老员工也是使用的C++98标准，或者是C with class。 总结其原因，大概率还是因为老教材不更新，以及版本特性差别较大导致的切换和学习困难。 ","date":"2022-09-27","objectID":"/202209/cpp_hopl4_reading/:2:0","tags":["HOPL","Cpp"],"title":"《现代C++白皮书》一周目读后感","uri":"/202209/cpp_hopl4_reading/"},{"categories":["Cpp","软件设计"],"content":"C++14 - C++17小版本升级 我认为C++14-C++17是C++11的小版本（小数点版本）升级，当然这是个人看法，按照ISO的计划，C++11后的每3年的都是一次（等同的）常规版本升级。 依照Stroustrup的说法，C++14是： 依据大版本和小版本交替发布的计划，C++14的目标是“完成C++11” 其更新概括为： 字面量更新和支持数字分隔符 变量模板 函数返回值auto推导和lambda参数auto推导 constexpr函数支持局部变量 移动捕获 按类型访问元组（这部分可以看之前的文章《STL-tuple源码阅读》） 日常用得多的是对auto推导的扩充和对constexpr函数的扩充。 使用auto扩充，可以写出更统一格式代码。对lambda表达式的输入输出基本统一，但是对函数输入来说，目前还没有auto支持。不过，在C++20版本中也指出了这种auto推导相对于template推导的缺陷，在概念引入后，也会慢慢修复这些缺陷。 使得constexpr函数可以支持局部变量，则允许写出更具通用性的编译期代码。可能有利有弊吧。对于程序开发人员来说，将有条件写出性能更好的代码；但是对于编译器开发人员来说，使得提高编译速度这项issue更具挑战性。 C++17被当做了大版本升级，添加了如下内容： 构造函数模板推导和推导指引，如可以shared_lock lck {m};而不用再shared_lock\u003cmutex\u003e lck {m}; 结构化绑定 复制消除，减少拷贝 更严格的表达式求值顺序，减少未定义行为，可以参考《i++和++i在函数入参时的一些问题 》 对optional、any、variant的支持，any源码可以参考《STL-any源码阅读 》 etc 可以看到C++17也没有像C++11这样的巨大改动，更多的是补充和优化。 在文中，Stroustrup提到了“结构化绑定”这一特性的由来，他说： 而正当 2015 年 11 月底在科纳 Ville Voutilainen 刚要结束 EWG 会议时，我注意到我们离午饭还有 45 分钟，我觉得小组应该会想要看到这个提案。2015 年科纳的会议是我们冻结 C++17 的功能集的时间点，所以这 45 分钟很关键。我们甚至没时间去另一个小组找到 Herb，我就直接讲了这个提案。EWG 喜欢这个提案，会议纪要说鼓掌以资鼓励；EWG 想要这样的东西。 他说的是关于auto {x,y,z} = f();这类表达式的提案（由Herb Sutter建议），不只是支持tuple，也支持struct的结构化绑定。令我觉得有意思的，他们的工作就像是学生，没有很强的上下级（可能因为他级别本来就高），卡着饭点前的45分钟提出了这个提案，还通过了。很羡慕这种工作氛围。 ","date":"2022-09-27","objectID":"/202209/cpp_hopl4_reading/:3:0","tags":["HOPL","Cpp"],"title":"《现代C++白皮书》一周目读后感","uri":"/202209/cpp_hopl4_reading/"},{"categories":["Cpp","软件设计"],"content":"C++20大版本升级 C++20的大更新就是关于概念的引入。（我目前并没有关心最近的C++20发版工作） 关于概念的写法，我是更偏向于Stroustrup的自然派，当然在C++20中采用的是一种折中写法。 当出现类型的时候，一般想的是“给我一个某某类型”，这是非常具体的；然后出现了模板，这时候会想“随便给我一个XX我就能YY”，这是非常宽泛的，覆盖所有可能性；然后有了enable_if，这时候想的是“给我一个满足XX条件的YY我才能ZZ”，是介于类型和普通模板之间的一种相对比较宽泛的东西。如果用集合描述，类型就是只有一个元素的集合，普通模板是全集，enable_if是子集，这三种描述方法基本可以表达所有可能的组合的情况了。 概念的出现，在我看来是对上述三种情况的统一，而不仅仅是为了简化复杂的enable_if的写法，当然，要是仅凭我现在的认知，我还是认为基础类型是不少的。有了概念之后，普通类型可以描述为“XX类型是类型为XX类型的类型”，普通模板可以描述为“XX类型是类型为任意类型的类型”，enable_if则描述为“XX类型是满足以下YY等条件的类型”。都是共用一套描述方法，所以我会更倾向于自然派写法： auto sum(Iteratable iter) {//...} Iteratable是一个概念或者模板，普通类型也可以，但是引入概念之后都当作我们曾经认知的普通类型来看待。Stroustrup一派的想法是让泛型编程变得和普通编程一样，可惜的是，C++20中并没有采用概念自然表示的写法，而是一种复杂的写法和所谓简写法： 最仔细的写法： template\u003ctypename S\u003e requires Sortable\u003cS\u003e void sort(S\u0026); 稍简化： template\u003cSortable S\u003e void sort(S\u0026); 简化： Sortable auto sort(Sortable auto\u0026 s); 就算最简单的写法，也没有脱离模板的影子，仍然要用一个auto标识符，来说明这是一个概念/模板。 此外的更新还有： 引入概念 引入模块 对协程库的支持 etc. 对于概念、模块、协程库还得多写写才能深刻体会，概念和模块虽然Stroustrup说是很老的东西了，但是对我来说还是很新，得多写多用多体会；关于协程，此前看过一些实现方法，比如云风的方案。之后会输出关于协程的文章。 ","date":"2022-09-27","objectID":"/202209/cpp_hopl4_reading/:4:0","tags":["HOPL","Cpp"],"title":"《现代C++白皮书》一周目读后感","uri":"/202209/cpp_hopl4_reading/"},{"categories":["Cpp","软件设计"],"content":"关于学习编程语言的观点 这是一段简短的个人观点，现在时间是2022年09月27日。 以我学生时期的思想来说，学习一门编程语言很简单，我一度认为学会某种（比如C、C++）之后再学习其他的就会很简单。所以那时候会学习很多编程语言。 但是现在我并不持有这种观点，如果对C或C++一类有颇深的执念，再学习其他语言可能会更难。我想说的就是“思想、灵魂”。比如Python、JavaScript、C、C++，虽然相似，但是编程思想、代码结构并不是一样的，语言、语法只是皮囊罢了。因为我此前的观点，导致我写Python、JavaScript都会像写C/C++一样，这就是完全没学会嘛！写出来的是四不像。甚至最近在看OC的时候，我还想说，这TM是什么东西，怎么会有这种语言？！其实还是见识少了。 所以，学习编程语言，不只是学习语法、关键词；还需要学习对应语言的编程思想、代码结构、语言发展史（说的就是OC，看了OC的发家史，我才觉得，牛啊，这语言的思想好！！！有意思。）。这就像我们学习外语一样，背单词、学语法总是达不到native speaker的水平，说到底还是我们缺少对语言文化和思想的学习。 虽然这篇HOLP没有对C++知识点的详细叙述，但是其描述的历史过程、提案过程，确实帮助我加深了对C++的理解，也有查漏补缺，也有了解各个版本区别。之后的我将更向C++ native programmer靠近。 ","date":"2022-09-27","objectID":"/202209/cpp_hopl4_reading/:5:0","tags":["HOPL","Cpp"],"title":"《现代C++白皮书》一周目读后感","uri":"/202209/cpp_hopl4_reading/"},{"categories":["工具"],"content":"在《闲置笔记本改NAS-omv踩坑记录》简单介绍了我为什么要把废旧笔记本改NAS以及大致操作。但是最近给比较本换固态重新装系统的时候，发现之前的文章没法拿来就用，因此需要详细记录。本文主要内容是docker容器的配置工作，OMV基础配置并不涉及。 ","date":"2022-09-21","objectID":"/202209/nas-omv-reprocesss/:0:0","tags":["nas","docker","omv"],"title":"NAS-OMV容器配置","uri":"/202209/nas-omv-reprocesss/"},{"categories":["工具"],"content":"升级 我使用作为NAS的机器是七年前的笔记本（Acer E5-572GMX），CPU是i5-4210M，TDP大概在37 W。 只给笔记本换了一下系统硬盘，原来的系统盘是500G的机械硬盘，已经有七年的历史了，所以给换成了250G的固态硬盘。前文中已经提到过，如果使用OMV直接刷系统（不是通过先Debian再OMV），那么系统盘是无法直接作为存储盘的，因此不需要很大，只需要满足一些docker过kvm的空间即可。 因为将系统盘换成了固态盘，最明显的区别是，OMV反应速度变快了。在上面安装插件、安装docker的速度以及部分视频播放的流畅度有明显改善。 不过，笔记本是通过WiFi和家庭网络连接的，传输速度并不是很快，而且是14年产的笔记本，使用的是2.5G的WiFi，日常传输速度只有大概10MB/s。（很慢很慢了…） 因为网络速度瓶颈，目前也就刚刚够用的状态，大部分还是只能满足备份的需求。我测试过将游戏安装在上面（打开SMB），并不能正常游玩，会卡死。所以，下一步的硬件升级计划是提高网速。 至于为什么不用有线连接，一是因为记得购买的时候有说明有线网卡的速度是100Mbps，现在不方便升级，无线网卡更容易升级；二是因为现在租的房子有线网络有问题，家里所有设备现在都是使用无线网络连接的。 至于换什么网卡，还在考虑中，现在家里的路由器是WDR7650，目标是能跑满。如果未来速度满足需求的话，很多免装软件就可以直接放在远程硬盘上了。 再下一步是要升级（扩容）硬盘，但是我并不考虑raid阵列，使用硬盘柜扩充即可，目前还在调查中。 ","date":"2022-09-21","objectID":"/202209/nas-omv-reprocesss/:0:1","tags":["nas","docker","omv"],"title":"NAS-OMV容器配置","uri":"/202209/nas-omv-reprocesss/"},{"categories":["工具"],"content":"docker compose docker安装的几个服务主要是jellyfin、transmission、nextcloud，目前就这些，未来可能考虑openwrt，但是因为网络环境不太好，网速提不上去之前是不会考虑的。再下一个计划就是装上code server，这样在台式机或者笔记本上都可以写博客并且在线预览。（现在使用的是小书匠写，虽然体验很好，但是有在线预览需求，小书匠的预览效果和我的博客主题并不一样。） 公网IP暂时不考虑，内网穿透在计划中，但是不一定实施。 因为网上教程太杂，不容易成功，以下主要介绍几个docker compose的配置，是参考docker hub的配置的，基本只是修改了值。 jellyfin jellyfin主要作为媒体库，体验过本地安装jellyfin和emby，实际感觉差不多，没有很明显的区别，因此还是使用docker安装。（而且docker也是号称不吃资源。） --- version: \"2.1\" services: jellyfin: image: lscr.io/linuxserver/jellyfin:latest container_name: jellyfin environment: - PUID=1000 - PGID=1000 - TZ=Asia/Shanghai volumes: - /srv/xxxxxxxxxxx/Medias/config:/config - /srv/xxxxxxxxxxx/Medias/movies:/data/movies - /srv/xxxxxxxxxxx/Medias/musics:/data/musics - /srv/xxxxxxxxxxx/Medias/pictures:/data/pictures ports: - 8096:8096 - 8920:8920 #optional - 7359:7359/udp #optional - 1900:1900/udp #optional restart: unless-stopped 推荐image加上latest标签，这样下次更新的时候方便，我在电视上安装jellyfin的时候，就遇到过服务器版本太老导致电视jellyfin无法登陆的问题，因此将服务器版本保持最新也是有用的。 PUID、PGID两项主要是配置用户权限的，通过id [user]查看user的id和所属group id，主要是涉及对jellyfin目录的读写权限，或者是对驱动的读写权限，推荐权限不要给太高，满足即可。当然，只在家庭网络环境使用的话，问题也不是很大，但是也是可以学习学习权限配置的，控制好权限也没有那么简单。 volumes做目录影射，不细表，只有/config项是必须项，其他按照需求填写即可。 端口按照需求配置即可。 transmission transmission主要用来当做下载器，可以下载bt种子和做种，挂着24h下就行了。 --- version: \"2.1\" services: transmission: image: lscr.io/linuxserver/transmission:latest container_name: transmission environment: - PUID=1000 - PGID=1000 - TZ=Asia/Shanghai - TRANSMISSION_WEB_HOME=/transmissionic/ #optional - USER=********* #optional - PASS=********* #optional volumes: - /srv/xxxxxxxxxxx/Medias/config:/config - /srv/xxxxxxxxxxx/Medias/downloads:/downloads - /srv/xxxxxxxxxxx/Medias/downloads/transmission_watch:/watch ports: - 9091:9091 - 51413:51413 - 51413:51413/udp restart: unless-stopped TRANSMISSION_WEB_HOME是用来配置主题的，我还是推荐transmissionic，挺漂亮的。 USER和PASS是用来设置登陆账户的，如果不设置该项，则使用transmission就不需要登陆。 volumes的/watch可以用来自动下载，将下载好的种子，放在/watch对应的目录下，即可实现自动下载。 nextcloud 我有纠结过nextcloud和SMB的区别是什么，其实功能上nextcloud就可以等同于onedrive。 以照片同步来说，如果使用SMB备份照片，则是将照片拖动到SMB映射的硬盘，然后等待复制进度条走完，如果复制失败了，则可能一张照片都没有备份过去。如果是nextcould，则是照片拖动过去，然后nextcloud自己负责一张一张地复制到“云端”，基本不会有某次失败导致全部失败的情况。 但是也有问题，比如nextcloud之类的会占用本地存储空间，需要同步完然后释放本地空间才可，而SMB移动过去之后就不会占用本地空间。另外通过SMB也可以将游戏之类的应用装在远程硬盘上，而不占用本地存储空间，使用nextcloud之类就可能很难实现该功能。使用nextcloud云盘的好处是，照片等媒体查看会比SMB协议方便和人性化很多，可以当做一个小的媒体服务器，如果是处理一些文档数据，我认为也很方便，因为可以在其他如手机、平板、Linux、Mac上处理，不会受到协议的限制。（当然，这里是不考虑三方平台的。） 所以，使用nextcloud的作用是，当做照片、文档跨平台查看和备份的工具。（今天正好在同步照片，没想到有20G，SMB可以当做冷备份。） version: '2' volumes: nextcloud: db: services: db: image: mariadb:10.5 restart: always command: --transaction-isolation=READ-COMMITTED --binlog-format=ROW volumes: - /srv/xxxxxxxxxxx/nextcloud/db:/var/lib/mysql environment: - MYSQL_ROOT_PASSWORD=********* - MYSQL_PASSWORD=********* - MYSQL_DATABASE=nextcloud - MYSQL_USER=nextcloud app: image: nextcloud restart: always ports: - 8080:80 links: - db volumes: - /srv/xxxxxxxxxxx/nextcloud/nextcloud:/var/www/html environment: - MYSQL_PASSWORD=********* - MYSQL_DATABASE=nextcloud - MYSQL_USER=nextcloud - MYSQL_HOST=db 我目前在试用的方案是，手机上安装nextcloud，打开自动同步手机照片。尽管目前还只支持局域网，但是每天回到家，连上wifi就会自动同步/备份照片，这也是可以接受的。 以上很多密码，我是使用keepass作为密码管理工具，已经使用了差不多大半年了，支持跨平台很方便，并且keepass开源，号称是目前无法破解，可以推荐使用。Windows上的工具叫keepass2， Andriod上是keepass2andriod，iOS上的是fantasypass（注意，iOS暂未开源）。 ","date":"2022-09-21","objectID":"/202209/nas-omv-reprocesss/:0:2","tags":["nas","docker","omv"],"title":"NAS-OMV容器配置","uri":"/202209/nas-omv-reprocesss/"},{"categories":["随笔"],"content":"此前三年，我的工作内容主要是Android相机底层的算法集成。现在总算是离职了，换了一个方向工作，是时候回忆回忆我做了些什么、学到些什么。虽然级别很低，也没有竞业协议之类，但是出于道德还是需要注意信息保密。该总结涉及的框架不涉及细节、也不涉及具体的工作内容，仅大致了解即可。本文所有内容仅代表个人观点和看法，与其他任何集体或个体无关。 未来一段时间的工作方向和相机系统无关，没有去继续追求热门赛道，但是大方向还是有软件设计和C++等，也不算偏离得很远吧。 ","date":"2022-09-16","objectID":"/202209/2019-2022-work-summary/:0:0","tags":["工作","相机","android"],"title":"2019-2022·相机算法集成·总结概述","uri":"/202209/2019-2022-work-summary/"},{"categories":["随笔"],"content":"前言 在我前段时间的面试过程中发现，不少人对算法集成的工作可能比较陌生。算法集成可能会和SDK工程师有点像，但是我们不仅仅需要大致了解算法，还需要了解集成平台（系统）。了解算法是因为软件需要根据算法需求做一些输入数据之类的调整，以此达到尽可能好的效果或者性能。又比如我们主要在高通平台工作，那么就需要对高通平台的相机软件流程比较了解以便可以得到更好的性能以及效果，如果换到MTK平台，那么就需要重新熟悉MTK的系统。 一般来说，一个相机功能从开发到落地，参与的工程人员会有：算法、软件、调试、测评、测试、驱动。算法顾名思义，就是某个相机功能中涉及到的算法，比如超级夜景、HDR等等，当然不是所有功能都需要复杂算法参与，有些也可以直接硬件完成，一个功能也不仅仅一个单一算法就可以完成。算法集成扮演的就是其中的软件角色，因为算法是和平台“无关”的，算法提供出来是不能直接在手机上使用的，这时候就需要算法集成来将算法落地在手机上。调试角色一般叫做tuning，他们会负责一些3A（AE、AWB、AF）或者其他ISP模块的调试工作。测评和测试的区别在于，测评一般会有主观测评或客观测评，主观测评会由一些摄影师组成，由他们来评判一张照片的视觉效果（有主观因素也有一些客观数据），以便给算法、软件、调试指明优化方向。测试一般会测试系统功能、性能等，主要评判功能是否准备好以及是否存在稳定性、性能等问题。驱动在我们的工作中接触比较少，因为他们主要是在相机bring up的阶段中参与的，比如负责点亮sensor之类，相机功能的开始落地则是在bring up之后。 以下再简单总结各个角色： 算法：提供如超级夜景、HDR等功能的核心算法； 集成：将算法在对应平台落地； 调试：调整图片3A、ISP模块参数； 测评：评价成像效果； 测试：评价功能性能； 驱动：点亮sensor； 以上一般会有类似这样的关系： 角色关系 为了方便后续的阅读，再补充一些前提： 部分情况也需要平台商参与，因为部分代码是闭源的； 本总结主要针对拍照功能； ","date":"2022-09-16","objectID":"/202209/2019-2022-work-summary/:0:1","tags":["工作","相机","android"],"title":"2019-2022·相机算法集成·总结概述","uri":"/202209/2019-2022-work-summary/"},{"categories":["随笔"],"content":"Android相机底层结构 我们不讨论什么HAL、Framework的框架，现在按照我的语言和认知来看看更小的部分，以此来了解Android相机拍照是怎么大致工作的。 在我看来，主要部分是：app、graph、feature、pipeline、node。（还有session、stage等概念，但是不影响对整体的认知，便不叙述了。） app就是我们使用的相机app，把它当做一个客户即可，他负责发送指令和接收结果（实际不止这些），并且app和上述几个概念是隔离开的。从graph开始则是底层概念（当然app到graph之间不是这么简单，它们之间至少还有一层，会有各种调度逻辑之类的，不过现在可以省略他们，因为这对整体认知没有太大影响），可以把它当做就是描述整个数据流的，整个数据流要当做是一个单向链表，数据从哪来到哪去。graph下面则有feature的概念，feature可以当做是整个数据流程中相对独立的一小段，我认为feature是一个分类的概念。feature再下面的就是pipeline，数据实际上是在pipeline这个概念上流动的，feature相当于是一个pipeline的管理器，负责选择当前使用哪条pipeline。如上所述，feature是一些数据流小段的分类，同一个类别的功能可能有不同的数据流动过程，那么这些不同的流动过程就可以是不同的pipeline，但是他们又是完成相同或类似的功能，所以可以用一个feature来管理和调度他们。在pipeline之下，就是node的概念，node就是节点的意思，是数据处理的节点，可以认为是最基本的单位。 以上，从上到下，我们可以有以下的结构图： 从上往下 举个例子来说，比如我们执行了某个拍照功能，其中数据流是从node1 ~ node9，每个node执行了不同的功能。现在再将数据流分成一些小段，比如node1 ~ node3组成pipeline1，node4 ~ node5组成pipeline2，node6 ~ node9组成pipeline3，现在可以认为不同的pipeline又完成了不同的任务，同一条pipeline里面的几个node连接一起共同完成的这条pipeline的某个功能。又因为feature是pipeline的调度器，因此用不同的feature管理不同功能的pipeline，但是以上每个feature暂时只管理一条pipeline。feature之上则是graph，可以认为graph是最大的分类，对应的就是用户功能（比如夜景、HDR等等），用户通过app界面调用不同的功能则可能对应底层不同的graph。 那么，从下往上看，现在又有如下结构： 从下往上 上面一段描述的是sensor出图后，数据的流动过程。我们在app上点击拍照到生成jpeg照片的数据流是怎样的？如下： 点击拍照按钮，生成一个request（包含一些参数信息等以及待填充的一块buffer）； request流转到底层，根据其中包含的拍照模式等信息选择对应的graph； request送到对应的graph，先在数据流上从高级向低级流动，给每个feature、pipeline、node配置对应的参数（因为还没有图像数据，这时候仅做一些初始化或者配置工作）； request从高级到低级一直走到最终的node层的最后一个node（一般是sensor node），开始通知sensor出图（现在有真正的图像buffer了）； buffer从sensor出来经过ISP模块（也看做一个node），做一些硬件去噪、去坏点、颜色校正之类； buffer按照顺序经过数据流上的其他node，有些node可能会修改buffer，比如提亮、去噪、融合之类；（还记得前文说的吗？node是最基础的单位，数据实际上是在node上流动的，那么node之间怎么调度？那就是靠更高级的概念，比如以此是pipeline、feature、graph等。） buffer解码成app下发的格式，比如yuv； buffer填充到app下发的“待填充”buffer中； app显示buffer或者送去encode成jpeg保存； 以上是一次拍照的大致流程，但是实际情况也不是这么简单的。 比如“倒着”走的配置过程、feature/pipeline/node的初始化过程、出图过程、ISP处理过程、buffer分发过程、buffer合并过程、buffer encode成jpeg的通路过程、整个数据通路（比如A可以到B，A也可以通过C再到B，如何设计是需要思考的）等等，都是可以有很多工作和优化的。不过一次拍照的大致流程还是这样的。 ","date":"2022-09-16","objectID":"/202209/2019-2022-work-summary/:0:2","tags":["工作","相机","android"],"title":"2019-2022·相机算法集成·总结概述","uri":"/202209/2019-2022-work-summary/"},{"categories":["随笔"],"content":"算法集成 算法集成是我的本职工作。 算法集成和SDK工程师的区别可能就在于（总是拿这两者比较是因为我认为两者很相似），SDK更了解算法，算法集成则更了解平台，比如上述《app上点击拍照到生成jpeg照片的数据流》的几个过程中，算法集成工程师需要参与2~9的所有过程。 集成的一般开发过程和其他职业可能没有太大区别：确认需求、预研、上项目、debug、发布。 如果细分，一般可能的工作有：确认需求、在旧平台预研、告知算法平台可以提供的能力、获取SDK、和算法交涉（接口、性能、效果、协助测试）、在旧平台测试、和tuning交涉（效果）、和平台商交涉（bug、提问、需求）、新平台落地、代码移植、debug、发布等。（可以参考上文的关系图。） 因为集成是比较底层（叶子结点）的划分，所以每一个具体功能就当做我们的一个项目，比如前置夜景功能、xxx供应商的后置夜景功能、xxx供应商的HDR功能、xxx供应商的人脸检查功能等等。一般这个层次的集成项目可以由一人到多人完成，而且我所了解到的基本是一人完成。 对一个集成项目我们需要做什么？ 首先是看是不是在已有的数据通路上工作。在上文中，我也详细介绍了什么是数据通路，按照我的总结，算法集成的核心工作就是设计和编写数据通路。 如果是数据通路以及满足集成需求，那么集成工作就会简单很多，一般就只需要在node层面工作就可以了，而且一般也只涉及到一个node。 如果数据通路不满足需求，那么就需要重新设计数据通路。首先会和核心算法确认好算法的输入输出结构，包括一些环境参数、图像格式等。确认好算法的输入输出需求后，需要和sensor、芯片厂商确认硬件输出能力，以便决定在哪个硬件端口输出或者输入数据。算法和硬件确认好后，可以设计第一版的数据通路，一般先从feature层面开始设计，因为对app来说，确定某个功能之后，graph就是确定的，因此可以认为没有选择的余地，graph层面需要做的，就是事先想好这个功能大概会有那些feature参与，然后将这些feature拼接成graph即可，可操作空间不太大。feature层面设计我认为是比较抽象的，一般来说，需要描述feature的输入输出端口，决定如何调用pipeline，但是并不关心更底层的数据流动，只关心feature这一层面的数据流动。feature内部数据如何流动，是pipeline层面关心的，完成feature的基本设计之后，需要设计pipeline的结构，主要内容就是node之间是如何链接的，有串联、并联之类的链接方式，完成某些功能可能有不同的连接方式或者工作层面（意思是，有些功能可以不需要pipeline参与），具体怎么做，除了按照算法、硬件、tuning等需求外，其余部分我认为是比较经验化的东西。pipeline设计完就是node的编写工作了，node是模板化的，主要职责是负责调用算法SDK或者处理图像，主要操作性在于代码结构和逻辑的优化。 以上就是新设计一条数据通路的大致工作。当然并不是每个feature、pipeline、node都需要重新编写，很多时候是考虑复用的。比如新增某个功能，可能只需要设计一个新的feature，一个新的pipeline，一两个新的node就行了，其余部分，复用已经写好的就行了。 我这三年在工作技术上最大的收获，就莫过于这种分层设计的思想了。到现在为止，我依然认为还有很多可以学习的地方，不只是看懂代码说怎么怎么分层就好了，我还缺少一点让我豁然开朗的契机。为什么我认为我的最大收获是这种分层思想？因为有两个相悖观点： 软件问题，中间加一层就好了 添加中间层只会让问题越来越复杂 对我来说，除了graph目前认为有点冗余外，feature、pipeline、node的设计就平衡了上述1、2的优点和缺点。是如何考虑到这样分层的，这是我需要长期思考的问题。其中更细节的，如node工厂的设计、调度器的设计等，我则认为是比较通俗的想法了。 （写到这里，思考上述分层设计，我想到的一个点是：分层和复用，又分层又复用，是不是可以降低相对复杂度了。） 以上，是集成开发的基本工作。更多的，还有数据通路的优化。现在补充一点预备知识： app和底层是两个不同的进程。（完整的相机功能是多进程参与） 那么针对数据通路的优化，可以考虑： 数据通路全部放在底层？ 数据通路拆成两部分，一部分底层完成，一部分app进程完成？ 数据通路拆成多部分，底层完成某些部分，app进程完成某些部分？ 在这条数据通路上，底层和app的数据交互方式是一对一还是多对一？ 数据一定要按部就班的沿着数据通路流动吗？ 底层通路间或者同一条通路中各个节点的通信方式？ 不同通路的性能、功耗问题？ 其他 集成开发除了完成功能集成工作，也需要考虑功能的性能、功耗等优化问题。因此所涉及的部分就比较广了。 除了技术上的问题，因为需要接触不同职责的同事比较多，交流、交际能力也算得上是算法集成的一个比较重要的技能。因为需要给出“合理”的理由拒绝一些需求，或者给出一些“合理”的理由给其他同事发送一些需求。 从事相机算法集成的成长是什么？ 可以了解某些soc平台，比如高通平台或者MTK平台 能够了解到硬件部分，比如sensor出图方式、ISP处理流程、DSP调用方式等 可以了解到相机整个通路和运作原理，包括APP到sensor的整个流程 可以了解到Android底层的一些原理，比如binder通信 可以更熟悉Linux平台 可以了解部分库的编译、链接原理 可以接触到一些项目管理、编译工具链的编写的过程（makefile、repo） 可以了解到一些图像处理过程，比如Demosaic算法、DRC、gamma、AWB统计原理等 可以提高代码能力，主要原因是，代码量不算少，项目周期也比较长，因此有时间来优化代码 可以提高大型工程的工程能力，算法集成设计的层面比较多，接触的代码量是比较大的 可以提高社交能力，因为会需要和产品、测试、算法battle 不足之处有什么？ 杂而不精，正因为接触面很多，所以比较难对某一个方面有很深的耕耘，目前接触到的同事（基本在1~7年），没有一个是对某方面可以做到“倒背如流”的，都是“会”而不是“不仅会，还知道为什么，还知道还可以怎么做”的层次 技术不纯粹，因为接触的人多、交涉多，算法集成不是纯粹的技术流（当然对有些人来说这是优点，但是对我来说是缺点） 挑战性不高，类似于第一点缺点，因为没有某方面的深入，算法集成是很容易上手的 技术不前沿，虽然相机技术是前沿的，但是相机算法集成的技术并不新，反而很老套；我认为，只需要C with class阶段的知识就可以完成大部分工作，当然，如果要做得更好，那么也是需要广泛涉猎的，比如数据结构与算法（一些循环结构的优化、数组的优化、读写优化等）、设计模式（框架、node层面）、数字图像处理方面的内容；不过话说回来，上述技能树也是属于传统技能的 上限低，和技术不前沿有点类似，另一部分原因是，尽管算法集成的上限取决于soc、相机模组的上限，但是算法集成属于业务部门，并不承担研究任务（不会给研究资源），所以算法集成的上限变成了soc、相机模组等平台的下限，基本就是拿来能用就行了的状态 所接触的代码，很多闭源 当然，以上说的优点、缺点仅仅是个人体验， 并不代表所有类似的岗位，我认为这些体验是和个人规划、公司管理相关的。 ","date":"2022-09-16","objectID":"/202209/2019-2022-work-summary/:0:3","tags":["工作","相机","android"],"title":"2019-2022·相机算法集成·总结概述","uri":"/202209/2019-2022-work-summary/"},{"categories":["随笔"],"content":"工具开发 除了项目开发，我或者其他同事也有提议过一些其他的项目。比如看图软件、数据分析平台等。 我们开发平台主要是Ubuntu，该系统上目前是没有一款方便的看大部分Raw格式的看图软件的。我大概在2020年2月份意识到了这个问题，认为我们亟需一款方便的看图软件，不然每次还需要Windows电脑来看图。 最开始开发的是一个格式转换脚本，但是如果将脚本发布出去便十分用户不友好，遂考虑需要加上图形界面。因为该需求是个人想法，所以未占用项目时间，算作是业余时间开发。再确认需要图形界面后，便约上了大学的一位好友一起开发，由他帮助我完成了第一个带图形界面版本的UI部分。 第一个版本之后便由个人开发。修改了界面样式、参考pipeline的设计来设计了解码链、也有诸多软件上的加速优化，比如Demosaic加速、buffer池优化等。 因为最初想法是当做个人作品发布，在第一次发版之前也未占用项目时间。大约历时七个月，基本功能完成，可用之后，便以“集成组”的名义在软件大组发布了（自己YY太多了，如果以个人名义发布，又会当心被别人说闲话），之后就一直被当做“集成组”的项目，然后由我一直维护。我之后的一些遭遇也可能由此开始了吧~~~ （之后写点其他的项目，就被人阴阳我又在憋大招，或者被说，我自私，就想着做新东西 :-\u003c ） 先不管别人如何评价我，能发布一个软件我依然还是很高兴的，该看图软件也得到了大组和其他部门同事的好评，我认为这是我这三年来最大的收获之一吧，我认为是高于“青年工程师”等称号给予我的荣誉的。 在看图软件开发期间，有同事提出了另外一个需求，数据分析，这是算作团队的项目了。最初目的是用来可视化手机上一些sensor的数据（比如ois、gyro等）。 我最初想法是做成一个web应用，但是leader期望是桌面应用，只安排我一个人做。在考虑复杂度后，我还是决定以web应用发布。细节不表。该应用制作时间大概在6个月以上，之后一直由我维护，并且扩展接口供其他项目组使用。令我高兴的是，也有不少项目组接入了这个应用，并且用户人次也不少。 除了以上项目，也有一些其他自制小项目，比如测试工具，但是因为发布测试版本后没有得到其他同事的任何有效反馈，该项目便只有零星几个人在使用了。 未来工作中，我还是会期望继续保持对这些技术的热爱吧。通过这三年的经历（集成和工具开发），还是得学会一些社会现实。比如： 适当高调。因为刚工作太低调了，已经设定了这种人设，做很多事情，都考虑和别人分享成果，尽管他们可能什么都没做（只是同事，不是leader），这很容易导致自己受伤，因为别人会不断压低你的下限，它们会像蛀虫一样一直汲取 要让别人知道你做了什么，不要以为别人知道，因为他们可以假装不知道 学会表达。类似第一点，不会表达的人就会被当作老实人，老实人是只能被欺负的，除非他死了或者它死了。学会表达不一定要说的天花乱坠，但是要学会敢于把自己的想法说出来 不要把自己表现得像老实人（我在网络上可能才算正常人吧，现实工作中像一头牛，基本谁都能来抽我两鞭子，让我替他耕地）。摒弃老实人人设不止是学会表达，还要学会拒绝，以及偶尔的生气，这样才能让别人知道你的底线，而不是让别人毫无底线的压低你的底线 分清楚工作和个人，公司（表示公司以及公司里面的人）对个人是没有感情的，所以也不需要对公司有过多感情 大概就想到这些吧。也期望在未来的工作中，我能摆正自己的心态，心里要能更抗揍才好！ 声明：本文采取 CC BY-NC-ND 4.0 协议，如与本站其他共享协议冲突，则以该声明为准。 ","date":"2022-09-16","objectID":"/202209/2019-2022-work-summary/:0:4","tags":["工作","相机","android"],"title":"2019-2022·相机算法集成·总结概述","uri":"/202209/2019-2022-work-summary/"},{"categories":["“随笔”"],"content":"因为北京的户口、房价问题等等，算是很早就决定要换城市了，但是去哪里是没有确定好的。我备选的城市是武汉、南京和苏州，前段时间在投递简历，除了北京，其他城市就只投递了苏州的一家公司，刚好也拿到了这家公司的offer，然后就决定换到苏州。 关于换城市，此前考虑过两种思路： 先在北京干几年，积累一定的资本再切换城市 尽早切换城市，到新城市积累经验 两种思路各有优劣，如果继续呆在北京干几年，然后再换城市，到时候因为结婚生子的问题，就有可能急急忙忙，导致各种将就。如果现在就换城市，一是我现在才25岁，似乎少了点拼劲，二是资本积累不够，换了城市也还需要工作几年才可能有资格定居。 我现在选择了第二种。不过现在想，具体选哪种不重要，因为人生的选择没有对错，换工作、换城市之类的就是人生中需要面临的选择，我们要倾听自己需要的是什么，要钱？要生活？要事业？其他所有人的建议，都不过是其他人的人生，或者他们意淫出来的你的人生，所以怎么选择，要想想自己的根本需求，要记住，别人的只是建议。 这是我和一位猎头聊天之后得到的启发，本来在纠结选择北京还是选择苏州的offer，听到她的说法之后，我真的是豁然开朗。北京的offer比苏州多了很多钱，但是我是为了钱工作吗？当然是，但是因为没有富有过，也没有特别穷过，所以现在的我还是难以体会到多这么多钱的作用，对我来说，差不多就行了。所以，我想，我现在的迫切需求不是赚钱，而是能够感受到生活，感受到周围人的善意，这至少会给我一些继续拼搏的动力，而不是原来那般行尸走肉地活着就行了。 题外话，工作可以累一点，但是无法接受一天都是工作，更接受不了工作成果都是别人的，这让我想到了这两天看的电影–《隐入烟尘》。 我在北京的工作大概是早上九点到晚上九点，工作日除了上班基本就是在家，两点一线，不过决定离职之后我大概八点就下班了。我原本以为加入的是一家号称具有“工程师文化”的公司，但是现在发现只干活是没用的，有输出也是没用的，这是我完全没有想到的。PUA话术满天飞，奇怪的组织架构，任何事情没有沟通，只有通知，会有派系，会有战功文化等等。你得到的和你付出的没有太大的关系，和你的派系，和你的PPT关系却非常大。他们给你安排了活，拿着你的输出上台领了奖，却还要到处说你自私、说你只会做新东西。我看着我就像那头驴或者是有铁，他们吸了我的血，还要给我泼脏水，还要嫌我脏。这是我短短一个月时间，就下定决心并且付诸行动决定离职的原因。 我的计划是先去苏州找好房子，然后顺便预先体验体验苏州的生活，房子找好后再回北京处理完的离职流程以及北京的租房交接，最后搬家到苏州。 8月21日，初到苏州的第一天。因为是换城市，总是会很不自觉地就和北京比较。 下高铁的第一感觉就是非常非常热，是带着潮湿的闷热。尽管我是南方人，但是因为在北京度过了三个夏天，对南方的闷热感已经记不太清了，不过这种热总算还可以接受。 出车站就是去做核酸，但是北站看起来非常小，和我们老家四五线城市的高铁站一样的小。核酸点似乎没有北京的多，我们查了地图，不少都是需要去医院自费做核酸检测的。 出站后找了很久的地铁站，因为地铁站不在车站里。令我惊讶的是，京津冀一卡通在这里也能使用，害得我还提前注册了一张江苏交通一卡通（TAT）。 因为提前预定了观前街附近的如家，所以出车站就直接向观前街出发了。晚上一般都在观前街逛逛，以下是观前街的夜景。 一广场 一寺庙 我很喜欢观前街这种感觉，对我来说这就是生活的气息，尽管这只是一个旅游景点。我在北京工作的时候没去过这样的地方，可能簋街或南锣鼓巷是这样的？但是在我离开之前，最终还是没去过的。在武汉上学的时候倒是去过户部巷，但是那是小吃一条街，我看起来就是一个景点，和观前街比还差点感觉。 在观前街的第一顿，就是尝尝松鼠鱼。但是看了菜单太贵了，最后点的是美团上的套餐，结果是鲈鱼做的，据说不正宗。不过我媳妇儿还是很喜欢吃的。套餐的菜很多，两个人吃了七八个菜。 PS：观前街有个卖鸡蛋糕的很好吃！！！不过小吃普遍偏贵一些。 当天晚上在路口看交警抓骑电动车不戴头盔的，看了很久，周围也有很多人围观，有被抓到的小姐姐翻白眼表示很无奈，也有被抓到的大叔企图逃走，然后被抓去教育站教育了。 接下来的几天就是找房子。 苏州租房的价格对比北京便宜，但是波动也很大。比如整租二室一厅，我们查询到的价格有从2000 ~ 7000的。价格跨度非常大，但是在北京，普遍在7000 ~ 8000这个范围，差距相对较小。 我们找的链家租房，我感觉区别也很大，不过也可能是对比样本比较少的原因。在北京找房的时候，中介喜欢多说话，也不太愿意带你找很多的房子，他们可能不缺客户，所以在北京我们一般都是看了两三套就定下来了。苏州的链家话没有这么多，都是我们在系统上看好房子，然后中介就带我们过去看，看的过程也不会有太多的话，因为我们没有电动车，看房子的时候，链家的人就给我们提供了一辆（不过他们骑车太猛了，不遵守红绿灯、车速也在40km/h以上）。三天时间我们看了有不下十套房子，最后才定下来的，对比起来，苏州的链家似乎没有这么着急。 找房的过程回想起来也算比较顺利了，主要矛盾就是价格区间大、房子质量差别大才导致找了很久。 至于饮食，并没有太大体会。一是因为我们大多数吃的外卖或者小吃街吃的小吃；二是苏州大多也是外地人，饮食大概率是会满足大多数人口味的。 在最终离开北京的那一天，火车上，也确实亲身见识到了网上有些人所说的“苏州人的优越感”。这是一位和我们同一个软卧包间的老人（她的票不在这个房间），聊天过程中就透露着一些优越感，比如她是昆山的，女婿在上海上班，我聊到我有一位同事现在回到太仓了，也在上海上班，她就说太仓怎么怎么不行，昆山怎么怎么好，就让人感觉很不舒服，其他细节就不细表了。记录此事也是期望我能尽快在这里找到归属感吧，成熟一些，不需要对外界环境继续抱着美好的愿景，需要接受一些让你不舒服的人或事的存在，因为周围环境就已经是这么去运转了。 回到北京又恢复了一点焦虑，因为长期压抑，有点被害妄想症，总担心他们卡我离职流程。不过现在总算是顺利离职了。也已经顺利搬家到苏州。 异地搬家实在是太累了。 因为东西很多，叫搬家公司会很贵，做了很多对比，最终我们是通过顺丰大件运行李的。22个包裹，占地大概1~2立方米，花了大概1500元。 除了一些比较贵重的或者有意义的物品，大多数东西能扔的就扔，就当作断舍离了。被子啊、锅碗瓢盆啊、猫猫饮水机啊、旧衣服啊等等，一点一点的扔到楼下垃圾桶，因为没有断舍离的习惯，一次全扔掉的话总感觉舍不得，一点一点扔总会有反悔的机会，不过总归没有任何反悔过。 骑了两年的电动车也卖了，两年大概3500km，相当于我从北京来回老家一趟了。电动车卖完办了过户，主要是当心未来万一有什么事故可能引起纠纷。本来打12123询问的结果是需要发票、行驶本、车、身份证，但是最后去到车管所的时候没有要求出示发票，将其他三样带上就行了。不过不同地区的规则可能不一样，不太有参考价值，最好还是12123+当地车管所电话询问。 最“麻烦”的就是我们家猫猫（名字叫毛毛），纠结了很久到底是我们带着他托运还是找托运公司托运，最终还是选择找托运公司托运，因为带着他的话复杂程度太大了。 猫猫托运到家后，应激了。大致反应就是大口哈气、吐舌头哈气。不过幸好他还认识我们，我们抱着他的时候就会缓解一点，在家呆了两三天之后他就好多了，不过还没有恢复到在北京时候的“窝里横”的状态。 大致过程就以上吧~ 有点流水账，仅记下以便未来看看~~ ","date":"2022-08-24","objectID":"/202208/wlb-suzhou/:0:0","tags":["搬家","碎碎念"],"title":"换城市了","uri":"/202208/wlb-suzhou/"},{"categories":["工具"],"content":"我使用的是Ubuntu18.04, 最近将python3命令从python3.6指向了python3.7, 在重启系统后, 会出现终端无法打开的问题, 这时候切换tty打开也是不可以的. 其原因可能和库的查找逻辑有关. 打开Ubuntu Software, 下载xterm 打开xterm cd /usr/lib/python3/dist-packages/gi 复制并重命名以下文件: sudo cp _gi.cpython-36m-x86_64-linux-gnu.so _gi.cpython-37m-x86_64-linux-gnu.so sudo cp _gi_cairo.cpython-36m-x86_64-linux-gnu.so _gi_cairo.cpython-37m-x86_64-linux-gnu.so 如果是其他版本的python, 基本同理, 但是需要考虑库兼容性的问题. ","date":"2022-08-01","objectID":"/202208/terminal-python-version/:0:0","tags":["Python","终端"],"title":"切换Python版本后导致终端打不开","uri":"/202208/terminal-python-version/"},{"categories":["工具"],"content":"日常开发过程中, 一次编译经常会占用满系统的CPU和内存资源. 我使用tmux作为终端环境, 有tmux-cpu等插件可以监控系统资源, 但是退出该环境后(比如切换到其他应用)就不容易实时查看到系统资源的占用. 为了解决这个问题, 我开发了fstats这款显示系统信息的悬浮窗工具, 同fkfish, 使用python作为主要开发语言, 也使用tkinter来编写界面. 项目地址: https://github.com/caibingcheng/fstats ","date":"2022-07-21","objectID":"/202207/sysinfo-fstats/:0:0","tags":["Linux"],"title":"系统信息悬浮窗-fstats","uri":"/202207/sysinfo-fstats/"},{"categories":["工具"],"content":"基础功能 最基础的需求是能够显示CPU和内存的占用率, UI界面也可以根据占用率有所变化, 如下: 低占用是白色背景: 低占用 高占用是红色背景: 高占用 ","date":"2022-07-21","objectID":"/202207/sysinfo-fstats/:1:0","tags":["Linux"],"title":"系统信息悬浮窗-fstats","uri":"/202207/sysinfo-fstats/"},{"categories":["工具"],"content":"扩展 如果只有默认显示, 总感觉少了些什么. 现在fstats支持用户扩展, 通过扩展接口, 用户可以自定义更丰富的显示, 通过以下路径配置\u003cHOME path\u003e/.fstats/config.json: { \"width\": 96, \"height\": 64, \"style\": \"\u003cHOME path\u003e/.fstats/style.py\", \"items\": [ [\"CPU\", \"\u003cHOME path\u003e/.fstats/cpu.py\", \"{:\u003c3}: {:\u003c5}%\"], [\"MEM\", \"\u003cHOME path\u003e/.fstats/mem.py\", \"{:\u003c3}: {:\u003c5}%\"], [\"LIVE\", \"\u003cHOME path\u003e/.fstats/live.py\", \"{:\u003c4}: {:\u003c4}\"] ] } 通过width和height, 用户可以定义悬浮窗的大小, 通过items, 用户可以定义显示的内容, 如上描述, 第一行显示CPU占用率, 第二行显示内存占用率, 第三行显示一个计数器, 表示存活状态, 这几个item的实现如下: ## cpu import psutil def info(): return psutil.cpu_percent(interval=1) ## mem import psutil def info(): return psutil.virtual_memory().percent ## live count = 0 def info(): global count count %= 10000 count += 1 return count 更多的, 比如想显示座右铭, 那么可以实现一个info接口, 返回你喜欢的句子即可, 或者可以通过request请求远端的数据, 实现座右铭的动态切换. 再或者, 想监控某个进程的存活状态, 也可以通过实现一个info接口实现. 但是目前仅支持显示文字, 也只支持python脚本, 后续还需至少添加对shell脚本和纯字符串的支持. 至于图片之类的内容显示, 目前并不在计划中. style指向的脚本则是用来更新UI状态, 比如一种实现如下: def style(infoItems, label): high = False for item in infoItems: if item[0] in {'CPU', 'MEM'} and item[1] \u003e 90: high = True if high: label['bg'] = 'red' label['fg'] = 'white' else: label['bg'] = 'white' label['fg'] = 'black' 以上通过CPU/MEM的占用率, 修改label的样式, 这里的label就是tkinter中的Label对象, 是目前所有信息的容器(所有信息都当作是Label的text成员). 该接口的扩展方向是, 把每一个item都当作是一个label对象, 这样就可以控制某些item的样式, 而不是整体的样式. 那么, 我个人做了以下扩展: 个人扩展 LIVE用来标识是不是卡死了, 这是一个计数器, 每次轮循的时候+1. BUILD用来监视编译进程, 因为一次编译可能会消耗几十分钟, 那么我在切换到其他应用的时候, 就可以通过BUILD判断编译是否完成了(ON表示还在编译, OFF表示编译完成). ","date":"2022-07-21","objectID":"/202207/sysinfo-fstats/:2:0","tags":["Linux"],"title":"系统信息悬浮窗-fstats","uri":"/202207/sysinfo-fstats/"},{"categories":["工具"],"content":"开始使用 该库已提交到pypi, 因此pip安装即可: pip3 install fstats 使用的时候, 可以配置到系统启动项, 或者手动启动, 手动启动推荐以下方式, 可以在后台启动: fstats \u0026 ","date":"2022-07-21","objectID":"/202207/sysinfo-fstats/:3:0","tags":["Linux"],"title":"系统信息悬浮窗-fstats","uri":"/202207/sysinfo-fstats/"},{"categories":["STL","Cpp"],"content":"std::tuple是C++11开始支持的一个编译期确定长度的, 可支持任意参数类型的容器, 相当于是std::pair的扩展, 平常只使用过它, 却没有了解其实现原理. Class template std::tuple is a fixed-size collection of heterogeneous values. It is a generalization of std::pair. ","date":"2022-07-13","objectID":"/202207/cpp-stl-tuple/:0:0","tags":["Cpp","tuple"],"title":"STL-tuple源码阅读","uri":"/202207/cpp-stl-tuple/"},{"categories":["STL","Cpp"],"content":"TinyTuple 我们先来实现一个简易版的std::tuple - TinyTuple, 支持任意参数类型和get\u003cN\u003e方法(先不考虑get\u003cType\u003e). 遇到的第一个问题是, 如何将任意数量的, 不同参数类型的值打包起来? 一种想法是, 用一块动态内存来存, 每输入一个参数var, 动态内存就扩大sizeof(var), 然后记下当前位置. 在获取的时候, 根据N就能确定内存的位置, 不过这时候用户还需要输入数据类型才能正确获取值, get接口可能就变成了get\u003cN, Type\u003e, 相当于是一个array any了. 能不能省略Type输入呢? 参考我们上一篇STL-any源码阅读, 是不是用一个类似AnyData的模板类来保存数据类型? 可能不太好使, 因为get方法不带type类型的话, AnyData似乎也束手无策(对应的问题是, 返回值如何统一?). std::tuple是借助\"继承可变参模板类\"来实现的, 看看简化版的TinyTuple如何实现: 定义如下: template \u003ctypename ...Tps\u003e class TinyTuple; 现在\"偏特化\"模板, 提取第一个参数的类型, 并以此递归下去: template \u003ctypename Tp, typename ...Tps\u003e class TinyTuple\u003cTp, Tps...\u003e : public TinyTuple\u003cTps...\u003e { public: TinyTuple(const Tp\u0026 val, Tps\u0026\u0026 ...params) : TinyTuple\u003cTps...\u003e(std::forward\u003cTps\u003e(params)...) { value = val; } Tp get_value() const { return value; } private: Tp value; }; 注意到构造函数TinyTuple(Tp \u0026\u0026 val, Tps \u0026\u0026 ...params) : TinyTuple\u003cTps...\u003e(std::forward\u003cTps\u003e(params)...)的原地构造是递归的, 在函数体内部才赋值当前值, 因此TinyTuple参数的初始化(复制)顺序是从右往左的. 参数为空就是递归的终止条件: template \u003c\u003e class TinyTuple \u003c\u003e { }; 对于一个实例TinyTuple\u003cType1, Type2, ..., TypeN\u003e tuple(var1, var2, ..., varN)可以得到其内存排列如下: TinyTuple内存排列 以上, 我们将TinyTuple的值和类型保存了下来, 如何获取值呢? 注意到, 我们实例化的TinyTuple对象, 实际上是一个子类. 如下: TinyTuple\u003cType1, Type2, ..., TypeN\u003e tuple(var1, var2, ..., varN); 其父类类型是: TinyTuple\u003cType2, ..., TypeN\u003e TinyTuple\u003c..., TypeN\u003e ... TinyTuple\u003cTypeN\u003e 因此, 可以向上转换成对应的父类, 该父类的value成员就是我们需要获取的值. 那么可以定义如下接口: template\u003csize_t N, typename ...Tps\u003e auto get(const TinyTuple\u003cTps...\u003e \u0026ttuple) { using tuple_t = Elements\u003cN, Tps...\u003e::tuple_t; return static_cast\u003cconst tuple_t \u0026\u003e(ttuple).get_value(); } 通过Elements\u003cN, Tps...\u003e可以获取第N阶父类的类型. 然后将tuple转换成对应父类类型访问value即可. Elements的实现方法类似TinyTuple, 不过是通过N递归来获取第N阶父类类型: template \u003csize_t N, typename ...Tps\u003e struct Elements; template \u003csize_t N\u003e struct Elements\u003cN\u003e { static_assert(N \u003e 0, \"Index overflow\"); }; template \u003csize_t N, typename Tp, typename ...Tps\u003e struct Elements\u003cN, Tp, Tps...\u003e : public Elements \u003cN - 1, Tps...\u003e{ }; template \u003ctypename Tp, typename ...Tps\u003e struct Elements\u003c0, Tp, Tps...\u003e { using tuple_t = TinyTuple\u003cTp, Tps...\u003e; }; 那么, 可以这样使用: int main() { TinyTuple\u003cint, char, double, const char*\u003e ttuple{1, 'a', 0.2, \"abc\"}; std::cout \u003c\u003c get\u003c0\u003e(ttuple) \u003c\u003c std::endl; std::cout \u003c\u003c get\u003c1\u003e(ttuple) \u003c\u003c std::endl; std::cout \u003c\u003c get\u003c2\u003e(ttuple) \u003c\u003c std::endl; std::cout \u003c\u003c get\u003c3\u003e(ttuple) \u003c\u003c std::endl; } 完整代码: https://gcc.godbolt.org/z/v3bYnxWrP ","date":"2022-07-13","objectID":"/202207/cpp-stl-tuple/:1:0","tags":["Cpp","tuple"],"title":"STL-tuple源码阅读","uri":"/202207/cpp-stl-tuple/"},{"categories":["STL","Cpp"],"content":"std::tuple std::tuple的实现比以上的TinyTuple复杂得多, 但是核心思想还是类似的, std::tuple的类间关系如下: std::tuple 继承关系 ","date":"2022-07-13","objectID":"/202207/cpp-stl-tuple/:2:0","tags":["Cpp","tuple"],"title":"STL-tuple源码阅读","uri":"/202207/cpp-stl-tuple/"},{"categories":["STL","Cpp"],"content":"_Head 和 _Head_base 最底层部分是_Head这个\"类\", _Head是什么? 我们看下面的定义就可以知道了, _Head会是用户需要存储的一种类型: template\u003csize_t _Idx, typename _Head\u003e struct _Head_base\u003c_Idx, _Head, true\u003e { //... } 比如std::tuple\u003cint, double\u003e, 那么_Head就是int和double. _Head_base和_Head的关系有两种实现方法, 一种是is a, 一种是use a, 如下: // is a template\u003csize_t _Idx, typename _Head\u003e struct _Head_base\u003c_Idx, _Head, true\u003e : public _Head { //... } // use a template\u003csize_t _Idx, typename _Head\u003e struct _Head_base\u003c_Idx, _Head, true\u003e { //... [[__no_unique_address__]] _Head _M_head_impl; } 以use a关系为例, _Head_base偏特化了两个实现, 如下: template\u003csize_t _Idx, typename _Head\u003e struct _Head_base\u003c_Idx, _Head, true\u003e { //... [[__no_unique_address__]] _Head _M_head_impl; } template\u003csize_t _Idx, typename _Head\u003e struct _Head_base\u003c_Idx, _Head, false\u003e { //... _Head _M_head_impl; }; 以上两个模板在实现上没有任何区别, 仅成员变量_M_head_impl的声明不同. 那么, 现在需要关注__no_unique_address__属性是什么意思. __no_unique_address__属性如其字面意思, 描述的是它修饰的东西没有独立的地址. 比如对一个空类, 一般来说会占用1B空间, 但是经过__no_unique_address__修饰后, 可以不占用额外的地址空间(0B). 什么时候会选中这个属性? 这时候需要关注_Head_base的第三个模板参数什么时候会特化为true, 什么时候特化为false. template\u003ctypename _Tp\u003e struct __is_empty_non_tuple : is_empty\u003c_Tp\u003e { }; // Using EBO for elements that are tuples causes ambiguous base errors. template\u003ctypename _El0, typename... _El\u003e struct __is_empty_non_tuple\u003ctuple\u003c_El0, _El...\u003e\u003e : false_type { }; // Use the Empty Base-class Optimization for empty, non-final types. template\u003ctypename _Tp\u003e using __empty_not_final = __conditional_t\u003c__is_final(_Tp), false_type, __is_empty_non_tuple\u003c_Tp\u003e\u003e; template\u003csize_t _Idx, typename _Head, bool = __empty_not_final\u003c_Head\u003e::value\u003e struct _Head_base; 如上, _Head_base的第三个模板参数特化为false的情况有: _Head是用final修饰的类 _Head是tuple类型 _Head不是empty的 _Head_base的第三个模板参数特化为true的情况有: _Head没有用final修饰并且不是tuple类型, 并且是empty的 is_empty描述如下: If T is an empty type (that is, a non-union class type with no non-static data members other than bit-fields of size 0, no virtual functions, no virtual base classes, and no non-empty base classes), provides the member constant value equal to true. For any other type, value is false. 以上, 我认为偏特化两种_Head_base的作用是为了将少无用内存的消耗. ","date":"2022-07-13","objectID":"/202207/cpp-stl-tuple/:2:1","tags":["Cpp","tuple"],"title":"STL-tuple源码阅读","uri":"/202207/cpp-stl-tuple/"},{"categories":["STL","Cpp"],"content":"_Tuple_impl _Tuple_impl是做可变参模板递归的类, 其实现类似于TinyTuple, 定义如下: template\u003csize_t _Idx, typename... _Elements\u003e struct _Tuple_impl; 偏特化为两个实现, 一个是通俗的递归过程: template\u003csize_t _Idx, typename _Head, typename... _Tail\u003e struct _Tuple_impl\u003c_Idx, _Head, _Tail...\u003e : public _Tuple_impl\u003c_Idx + 1, _Tail...\u003e, private _Head_base\u003c_Idx, _Head\u003e 一个是递归终止过程: template\u003csize_t _Idx, typename _Head\u003e struct _Tuple_impl\u003c_Idx, _Head\u003e : private _Head_base\u003c_Idx, _Head\u003e 递归的_Tuple_impl如何实现的? 先来关注其构造函数: typedef _Tuple_impl\u003c_Idx + 1, _Tail...\u003e _Inherited; typedef _Head_base\u003c_Idx, _Head\u003e _Base; //... explicit constexpr _Tuple_impl(const _Head\u0026 __head, const _Tail\u0026... __tail) : _Inherited(__tail...), _Base(__head) { } 同TinyTuple的内存排列, _Tuple_impl的排列也是从右往左的元素按照地址从高到低排列. 如何获取元素呢? _Tuple_impl充分借用了父子类的特性, 很值得学习和实践: static constexpr const _Head\u0026 _M_head(const _Tuple_impl\u0026 __t) noexcept { return _Base::_M_head(__t); } static constexpr const _Inherited\u0026 _M_tail(const _Tuple_impl\u0026 __t) noexcept { return __t; } _M_head可以获取tuple元素的值, _M_tail可以获取余下的\"队列\". 怎么做到的? 因为_Base::_M_head会将_Tuple_impl向上转换为_Head_base类, 这也是_Tuple_impl的父类. _M_tail则是通过返回值的类型, 将_Tuple_impl转换为_Inherited这个父类, 因此可以拿到余下的元素类. 递归终止类的实现类似, 此处就不继续看了. 这里涉及到多继承向上转换的隐式过程, 如下demo来验证: #include \u003ciostream\u003e class B1 { public: int val1; }; class B2 { public: int val2; }; class D : public B1, public B2 {}; int main() { D d; B1 \u0026b1 = d; B2 \u0026b2 = d; std::cout \u003c\u003c \u0026b1 \u003c\u003c \" \" \u003c\u003c \u0026b2 \u003c\u003c std::endl; } 输出是0x7fff2ac0bf38 0x7fff2ac0bf3c, b1和b2是不同的内存区域, 差值是4B, b2在高地址, b1在低地址, 实际上在编译期就已经计算好两个base的偏移了, 他们的内存布局就对应着相应的Base类的内存布局. ","date":"2022-07-13","objectID":"/202207/cpp-stl-tuple/:2:2","tags":["Cpp","tuple"],"title":"STL-tuple源码阅读","uri":"/202207/cpp-stl-tuple/"},{"categories":["STL","Cpp"],"content":"tuple 以上我们学习了三个数据类型, 最基础的是Head, 它表示的是用户需要的元素的类型, 比如int, double一类；然后是Head_base, 相当于是Head的封装, 与Head一般是use的关系. 再是_Tuple_impl, 这是一个变参模板递归的类, 采用双继承的结构, 一个父类是自身的递归类, 一个是 Head_base类. 接下来就看看tuple类型, tuple有几种特化类型, 如下: 基础类型: template\u003ctypename... _Elements\u003e class tuple : public _Tuple_impl\u003c0, _Elements...\u003e { //... } 空数据: template\u003c\u003e class tuple\u003c\u003e 2个元素的tuple: template\u003ctypename _T1, typename _T2\u003e class tuple\u003c_T1, _T2\u003e : public _Tuple_impl\u003c0, _T1, _T2\u003e 因为有_Tuple_impl的辅助, tuple的实现就不需要关系数据如何保存了, tuple类更多的是关心如何构造, 如何复制之类, 暂时就不展开看了. ","date":"2022-07-13","objectID":"/202207/cpp-stl-tuple/:2:3","tags":["Cpp","tuple"],"title":"STL-tuple源码阅读","uri":"/202207/cpp-stl-tuple/"},{"categories":["STL","Cpp"],"content":"get 访问tuple元素的方法之一是通过get方法, 一般接口如下, 我们需要关注两个实现__tuple_element_t和__get_helper. template\u003csize_t __i, typename... _Elements\u003e constexpr const __tuple_element_t\u003c__i, tuple\u003c_Elements...\u003e\u003e\u0026 get(const tuple\u003c_Elements...\u003e\u0026 __t) noexcept { return std::__get_helper\u003c__i\u003e(__t); } template\u003csize_t __i, typename... _Elements\u003e constexpr const __tuple_element_t\u003c__i, tuple\u003c_Elements...\u003e\u003e\u0026\u0026 get(const tuple\u003c_Elements...\u003e\u0026\u0026 __t) noexcept { typedef __tuple_element_t\u003c__i, tuple\u003c_Elements...\u003e\u003e __element_type; return std::forward\u003cconst __element_type\u003e(std::__get_helper\u003c__i\u003e(__t)); } __tuple_element_t的实现见cppreference-tuple_element, 和TinyTuple中Elements的实现基本一致, 这里也不展开了. 最终是通过__get_helper获取元素的, 实现如下: template\u003csize_t __i, typename _Head, typename... _Tail\u003e constexpr const _Head\u0026 __get_helper(const _Tuple_impl\u003c__i, _Head, _Tail...\u003e\u0026 __t) noexcept { return _Tuple_impl\u003c__i, _Head, _Tail...\u003e::_M_head(__t); } 这里的trick也比较有意思, 虽然 std::__get_helper\u003c__i\u003e(__t)传入的参数是\"最\"子类tuple, 但是__get_helper接收的是某个父类_Tuple_impl作为形参, 这时候size_t __i这个模板参数就起到作用了, 因为__get_helper\u003c__i\u003e可以直接匹配对应的_Tuple_impl类型, tuple作为__get_helper的参数入参后, 就会匹配并转换成_Tuple_impl\u003c__i, _Head, _Tail...\u003e父类, 然后通过_M_head接口获取元素的值即可. 在C++14后, get还支持将类型作为模板参数, 比如get\u003cint\u003e(tuple), 可以想想怎么实现. 比如参考Elements的做法, 将tuple的类型列表展开后, 匹配到对应的类型就返回对应的index, 一种实现如下: template \u003csize_t N, typename Tp, typename Head, typename ...Tps\u003e constexpr size_t ElementsIndex() { if constexpr (std::is_same\u003cTp, Head\u003e::value) return N; else return ElementsIndex\u003cN + 1, Tp, Tps...\u003e(); } template \u003csize_t N, typename Tp, typename Head\u003e constexpr size_t ElementsIndex() { if constexpr (std::is_same\u003cTp, Head\u003e::value) return N; static_assert(std::is_same\u003cTp, Head\u003e::value, \"No Matched Type\"); } 将这个更新加在TinyTuple可以扩展get方法, 如下使用: std::cout \u003c\u003c get\u003c0\u003e(ttuple) \u003c\u003c std::endl; std::cout \u003c\u003c get\u003c1\u003e(ttuple) \u003c\u003c std::endl; std::cout \u003c\u003c get\u003c2\u003e(ttuple) \u003c\u003c std::endl; std::cout \u003c\u003c get\u003c3\u003e(ttuple) \u003c\u003c std::endl; std::cout \u003c\u003c get\u003cchar\u003e(ttuple) \u003c\u003c std::endl; std::cout \u003c\u003c get\u003cdouble\u003e(ttuple) \u003c\u003c std::endl; 在gcc是这样实现的: template \u003ctypename _Tp, typename... _Types\u003e constexpr const _Tp\u0026 get(const tuple\u003c_Types...\u003e\u0026 __t) noexcept { constexpr size_t __idx = __find_uniq_type_in_pack\u003c_Tp, _Types...\u003e(); static_assert(__idx \u003c sizeof...(_Types), \"the type T in std::get\u003cT\u003e must occur exactly once in the tuple\"); return std::__get_helper\u003c__idx\u003e(__t); } 关注__find_uniq_type_in_pack: template\u003ctypename _Tp, typename... _Types\u003e constexpr size_t __find_uniq_type_in_pack() { constexpr size_t __sz = sizeof...(_Types); constexpr bool __found[__sz] = { __is_same(_Tp, _Types) ... }; size_t __n = __sz; for (size_t __i = 0; __i \u003c __sz; ++__i) { if (__found[__i]) { if (__n \u003c __sz) // more than one _Tp found return __sz; __n = __i; } } return __n; } 此处对变参模板使用得很灵活, __is_same(_Tp, _Types) ...用法值得学习(相当于一个参数固定, 另一个参数是可变参). ","date":"2022-07-13","objectID":"/202207/cpp-stl-tuple/:2:4","tags":["Cpp","tuple"],"title":"STL-tuple源码阅读","uri":"/202207/cpp-stl-tuple/"},{"categories":["STL","Cpp"],"content":"tie tuple的另一个功能是支持解包, 通过tie实现. tie怎么做的? 先看看源码: template\u003ctypename... _Elements\u003e constexpr tuple\u003c_Elements\u0026...\u003e tie(_Elements\u0026... __args) noexcept { return tuple\u003c_Elements\u0026...\u003e(__args...); } 相当于是返回了一个类型是引用类型的tuple, 那么我们可以给TinyTuple加上类似的功能, 其中的tie实现如下: template\u003ctypename ...Tps\u003e TinyTuple\u003cTps \u0026...\u003e tie(Tps \u0026...args) { return TinyTuple\u003cTps \u0026...\u003e(args...); } 需要再实现TinyTuple的赋值操作: template\u003ctypename...\u003e friend class TinyTuple; template \u003ctypename Head, typename ...Args\u003e TinyTuple\u003cTp, Tps...\u003e \u0026operator=(const TinyTuple\u003cHead, Args...\u003e \u0026t) { this-\u003evalue = t.value; TinyTuple\u003cTps...\u003e(*this) = TinyTuple\u003cArgs...\u003e(t); return *this; } 此处的TinyTuple\u003cTps...\u003e(*this) = TinyTuple\u003cArgs...\u003e(t);不需要递归终止条件, 因为最终的TinyTuple\u003cTps...\u003e会退化为TinyTuple\u003c\u003e. 那么, 在TinyTuple里面可以这样使用tie: int p1; char p2; double p3; const char* p4; tie(p1, p2, p3, p4) = ttuple; std::cout \u003c\u003c p1 \u003c\u003c std::endl; std::cout \u003c\u003c p2 \u003c\u003c std::endl; std::cout \u003c\u003c p3 \u003c\u003c std::endl; std::cout \u003c\u003c p4 \u003c\u003c std::endl; ","date":"2022-07-13","objectID":"/202207/cpp-stl-tuple/:2:5","tags":["Cpp","tuple"],"title":"STL-tuple源码阅读","uri":"/202207/cpp-stl-tuple/"},{"categories":["STL","Cpp"],"content":"std::any是C++17定义的支持任意可拷贝类型的标准容器. 描述如下: The class any describes a type-safe container for single values of any copy constructible type. 用法如下, 当然也支持复制, 拷贝构造一类: std::any var; var = 1; var = \"1\"; var = nullptr; ","date":"2022-07-06","objectID":"/202207/cpp-stl-any/:0:0","tags":["Cpp","any"],"title":"STL-any源码阅读","uri":"/202207/cpp-stl-any/"},{"categories":["STL","Cpp"],"content":"实现TinyAny 按照基本功能, std::any可以支持存放任意类型, 我们可以先尝试实现一个简单版本的TinyAny, 看看如果要写一个any类型, 应该怎么写. 简化起见, 就不需要考虑类型安全, 也不关注copy constructible, 实现如下(实际上是看完std::any才想到这种实现的, 核心在AnyData): #include \u003ctype_traits\u003e #include \u003cutility\u003e class TinyAny { /** ** AnyData 类保存了输入数据的类型 **/ template\u003ctypename Tp\u003e class AnyData { public: static void create(void **data, Tp \u0026\u0026 val) { *data = new Tp(std::forward\u003cTp\u003e(val)); } static void deleter(void *data) { auto ptr = static_cast\u003cTp *\u003e(data); delete ptr; } }; public: /** ** std::decay_t\u003cTp__\u003e 用于将const/reference等描述退化, 因为保存类型是不需要这些特性的 ** deleter 指向AnyData\u003cTp\u003e::deleter, 这样就保存了输入数据的类型了 **/ template \u003ctypename Tp__, typename Tp = std::decay_t\u003cTp__\u003e\u003e TinyAny(Tp__\u0026\u0026 val) : deleter(AnyData\u003cTp\u003e::deleter) { AnyData\u003cTp\u003e::create(\u0026data, std::forward\u003cTp\u003e(val)); } /** ** deleter的时候就可以调用对应类型的析构函数 **/ ~TinyAny() { deleter(data); data = nullptr; } // 采用swap copy template \u003ctypename Tp\u003e TinyAny \u0026operator = (Tp\u0026\u0026 val) { TinyAny temp{std::forward\u003cTp\u003e(val)}; swap(std::move(temp)); return *this; } template \u003ctypename Tp\u003e Tp get() { return *static_cast\u003cTp*\u003e(data); } private: TinyAny \u0026swap(TinyAny \u0026\u0026 another) noexcept { std::swap(data, another.data); std::swap(deleter, another.deleter); return *this; } private: void *data; void (* deleter)(void *data); }; 那么, 可以这样使用: int main() { TinyAny var{123}; std::cout \u003c\u003c var.get\u003cint\u003e() \u003c\u003c std::endl; var = std::string(\"123\"); std::cout \u003c\u003c var.get\u003cstd::string\u003e() \u003c\u003c std::endl; var = 0.123f; std::cout \u003c\u003c var.get\u003cfloat\u003e() \u003c\u003c std::endl; var = 'a'; std::cout \u003c\u003c var.get\u003cchar\u003e() \u003c\u003c std::endl; var = \"abc\"; // \"abc\"是const char*类型, 在TinyAny中会退化成char*, 因此, 保存的是指针 std::cout \u003c\u003c var.get\u003cconst char *\u003e() \u003c\u003c std::endl; var = \"def\"; std::cout \u003c\u003c var.get\u003cconst char *\u003e() \u003c\u003c std::endl; } 如开头所说, 它不是一个类型安全的容器, 所以也可能被这样误用, 编译期是不会报错的: var = \"defg\"; std::cout \u003c\u003c var.get\u003cint\u003e() \u003c\u003c std::endl; ","date":"2022-07-06","objectID":"/202207/cpp-stl-any/:1:0","tags":["Cpp","any"],"title":"STL-any源码阅读","uri":"/202207/cpp-stl-any/"},{"categories":["STL","Cpp"],"content":"std::any源码 下面来看标准库的实现: class any { //... } 首先注意到, std::any不是一个模板类, 应对我们的需求, 它也不能是一个模板类. ","date":"2022-07-06","objectID":"/202207/cpp-stl-any/:2:0","tags":["Cpp","any"],"title":"STL-any源码阅读","uri":"/202207/cpp-stl-any/"},{"categories":["STL","Cpp"],"content":"_Storage 接下来定义了一个_Storage联合体: // Holds either pointer to a heap object or the contained object itself. union _Storage { constexpr _Storage() : _M_ptr{nullptr} {} // Prevent trivial copies of this type, buffer might hold a non-POD. _Storage(const _Storage\u0026) = delete; _Storage\u0026 operator=(const _Storage\u0026) = delete; void* _M_ptr; aligned_storage\u003csizeof(_M_ptr), alignof(void*)\u003e::type _M_buffer; }; 不难猜到, 其作用就是用来存放数据的, 有_M_ptr和_M_buffer两个选项, 先看看aligned_storage实现: // other transformations [4.8]. template\u003cstd::size_t _Len, std::size_t _Align\u003e struct aligned_storage { union type { unsigned char __data[_Len]; struct __attribute__((__aligned__((_Align)))) { } __align; }; }; 以上说明, _M_buffer是栈上的一块内存, 大小是sizeof(void*), 并且做了内存对齐(TODO: 有什么用? 哪些地方需要对齐?). 总之, 现在可以知道std::any的数据可能存放在栈上, 也可能存放在堆上, 对于小内存(比如sizeof(void*)以下), 是存在栈上的. ","date":"2022-07-06","objectID":"/202207/cpp-stl-any/:2:1","tags":["Cpp","any"],"title":"STL-any源码阅读","uri":"/202207/cpp-stl-any/"},{"categories":["STL","Cpp"],"content":"_Manager 接下来根据类型的size, 决定了_Manager的类型, 分别有_Manager_internal和_Manager_external, 一个管理小内存, 一个管理堆内存. template\u003ctypename _Tp, typename _Safe = is_nothrow_move_constructible\u003c_Tp\u003e, bool _Fits = (sizeof(_Tp) \u003c= sizeof(_Storage)) \u0026\u0026 (alignof(_Tp) \u003c= alignof(_Storage))\u003e using _Internal = std::integral_constant\u003cbool, _Safe::value \u0026\u0026 _Fits\u003e; template\u003ctypename _Tp\u003e struct _Manager_internal; // uses small-object optimization template\u003ctypename _Tp\u003e struct _Manager_external; // creates contained object on the heap template\u003ctypename _Tp\u003e using _Manager = conditional_t\u003c_Internal\u003c_Tp\u003e::value, _Manager_internal\u003c_Tp\u003e, _Manager_external\u003c_Tp\u003e\u003e; _Manager的定义在哪? 我们往下看, 以_Manager_internal举例: // Manage in-place contained object. template\u003ctypename _Tp\u003e struct _Manager_internal { static void _S_manage(_Op __which, const any* __anyp, _Arg* __arg); template\u003ctypename _Up\u003e static void _S_create(_Storage\u0026 __storage, _Up\u0026\u0026 __value) { void* __addr = \u0026__storage._M_buffer; ::new (__addr) _Tp(std::forward\u003c_Up\u003e(__value)); } template\u003ctypename... _Args\u003e static void _S_create(_Storage\u0026 __storage, _Args\u0026\u0026... __args) { void* __addr = \u0026__storage._M_buffer; ::new (__addr) _Tp(std::forward\u003c_Args\u003e(__args)...); } }; 我认为_Manager的实现是很有意思的, 只包含了静态成员函数, 但是因为是模板类, 因此匹配之后是可以包含类型信息的, 又因为是静态成员函数, 就可以用函数指针指向这些静态成员函数, 从而又可以隐藏类型信息, 以上TinyAny实现的主要参考点即在这里. 因为_Manager_internal指向的是小内存, 因此这里使用的是placement new, 直接在给定的内存上构造, 在前面的文章中, 已经介绍过其用法了(TODO: 原理还不知道), 此处不再叙述. _Manager_external同理, 只不过是在堆上分配内存和构造的: // Manage external contained object. template\u003ctypename _Tp\u003e struct _Manager_external { static void _S_manage(_Op __which, const any* __anyp, _Arg* __arg); template\u003ctypename _Up\u003e static void _S_create(_Storage\u0026 __storage, _Up\u0026\u0026 __value) { __storage._M_ptr = new _Tp(std::forward\u003c_Up\u003e(__value)); } template\u003ctypename... _Args\u003e static void _S_create(_Storage\u0026 __storage, _Args\u0026\u0026... __args) { __storage._M_ptr = new _Tp(std::forward\u003c_Args\u003e(__args)...); } }; }; ","date":"2022-07-06","objectID":"/202207/cpp-stl-any/:2:2","tags":["Cpp","any"],"title":"STL-any源码阅读","uri":"/202207/cpp-stl-any/"},{"categories":["STL","Cpp"],"content":"构造 以下_Decay的定义也是实现any的核心, 通过decay, 可以将一些复杂属性退化, 比如const/\u0026等等, 这将帮助我们使用_Manager保存基本的数据类型: template\u003ctypename _Tp, typename _Decayed = decay_t\u003c_Tp\u003e\u003e using _Decay = enable_if_t\u003c!is_same\u003c_Decayed, any\u003e::value, _Decayed\u003e; 以其中一构造举例: /// Construct with a copy of @p __value as the contained object. template \u003ctypename _ValueType, typename _Tp = _Decay\u003c_ValueType\u003e, typename _Mgr = _Manager\u003c_Tp\u003e, __any_constructible_t\u003c_Tp, _ValueType\u0026\u0026\u003e = true, enable_if_t\u003c!__is_in_place_type\u003c_Tp\u003e::value, bool\u003e = true\u003e any(_ValueType\u0026\u0026 __value) : _M_manager(\u0026_Mgr::_S_manage) { _Mgr::_S_create(_M_storage, std::forward\u003c_ValueType\u003e(__value)); } 首先拿到了输入数据的退化类型typename _Tp = _Decay\u003c_ValueType\u003e, 然后根据其类型size选择了对应的_Manager, 再接下来判断其数据类型是否可拷贝构造或者赋值__any_constructible_t\u003c_Tp, _ValueType\u0026\u0026\u003e = true, __any_constructible_t定义如下, 是一个借助enable_if实现的SFINAE. template \u003ctypename _Res, typename _Tp, typename... _Args\u003e using __any_constructible = enable_if\u003c__and_\u003cis_copy_constructible\u003c_Tp\u003e, is_constructible\u003c_Tp, _Args...\u003e\u003e::value, _Res\u003e; template \u003ctypename _Tp, typename... _Args\u003e using __any_constructible_t = typename __any_constructible\u003cbool, _Tp, _Args...\u003e::type; __is_in_place_type先不关注了, 这是用来解决一些类型匹配问题的模板, 在C++17标准中, 模板是可以作为函数参数的. 匹配通过后, 在构造函数中初始化了_M_manager(\u0026_Mgr::_S_manage)和构造了数据的值(是拷贝的). 其他各种构造函数则是通过不同的可拷贝性或者in_place_type_t指定, 执行不同的实现. ","date":"2022-07-06","objectID":"/202207/cpp-stl-any/:2:3","tags":["Cpp","any"],"title":"STL-any源码阅读","uri":"/202207/cpp-stl-any/"},{"categories":["STL","Cpp"],"content":"_S_manage 在构造函数中, 我们看到初始化了一个_M_manager, 这是一个用来数据访问的接口, 实现如下: template\u003ctypename _Tp\u003e void any::_Manager_external\u003c_Tp\u003e:: _S_manage(_Op __which, const any* __any, _Arg* __arg) { // The contained object is *_M_storage._M_ptr auto __ptr = static_cast\u003cconst _Tp*\u003e(__any-\u003e_M_storage._M_ptr); switch (__which) { case _Op_access: __arg-\u003e_M_obj = const_cast\u003c_Tp*\u003e(__ptr); break; case _Op_get_type_info: #if __cpp_rtti __arg-\u003e_M_typeinfo = \u0026typeid(_Tp); #endif break; case _Op_clone: __arg-\u003e_M_any-\u003e_M_storage._M_ptr = new _Tp(*__ptr); __arg-\u003e_M_any-\u003e_M_manager = __any-\u003e_M_manager; break; case _Op_destroy: delete __ptr; break; case _Op_xfer: __arg-\u003e_M_any-\u003e_M_storage._M_ptr = __any-\u003e_M_storage._M_ptr; __arg-\u003e_M_any-\u003e_M_manager = __any-\u003e_M_manager; const_cast\u003cany*\u003e(__any)-\u003e_M_manager = nullptr; break; } } _Arg是一个联合体, 无需过多关注. 根据不同的需求, _S_manage可以执行获取\\拷贝\\删除等操作. 我们需要关注函数头部的static_cast\u003cconst _Tp*\u003e, _Tp就是_Manager_external模板类保存的类型参数, 但是又通过_S_manage这个函数指针, 隐藏了这个类型参数. 在delete的时候, 因为已经转换为了对应类型, 因此可以执行对应的析构函数. 再关注__arg-\u003e_M_typeinfo = \u0026typeid(_Tp);, 该方法可以获取参数的运行时类型, 我认为这是any类型安全的运行时保证, 有了该方法, 就可以在get的时候做类型判断, 以保证安全. ","date":"2022-07-06","objectID":"/202207/cpp-stl-any/:2:4","tags":["Cpp","any"],"title":"STL-any源码阅读","uri":"/202207/cpp-stl-any/"},{"categories":["STL","Cpp"],"content":"温故知新 type_info typeid怎么实现的? 在前面的文章中, C++类的内存分布(二)有提到, 类头部再倒退几个byte就是type_info结构体, 如下. 但是对于普通类型, 是怎么在运行时获取类型的呢? 类的type_info的位置 typeid可以先参考这篇C++中typeid实现原理和使用方法, 主要思路是, C++标准没有规定如何实现, 一般情况编译器在编译时就可以确定, 针对多态情况, 就依赖vtable头部负偏移的type_info结构体. ","date":"2022-07-06","objectID":"/202207/cpp-stl-any/:2:5","tags":["Cpp","any"],"title":"STL-any源码阅读","uri":"/202207/cpp-stl-any/"},{"categories":["STL","Cpp"],"content":"any_cast 对于any类型, 我们需要通过any_cast方法来获取其值, 现在来看看any_cast的基本实现, 主要关注__any_caster: template\u003ctypename _Tp\u003e void* __any_caster(const any* __any) { // any_cast\u003cT\u003e returns non-null if __any-\u003etype() == typeid(T) and // typeid(T) ignores cv-qualifiers so remove them: using _Up = remove_cv_t\u003c_Tp\u003e; // The contained value has a decayed type, so if decay_t\u003cU\u003e is not U, // then it's not possible to have a contained value of type U: if constexpr (!is_same_v\u003cdecay_t\u003c_Up\u003e, _Up\u003e) return nullptr; // Only copy constructible types can be used for contained values: else if constexpr (!is_copy_constructible_v\u003c_Up\u003e) return nullptr; // First try comparing function addresses, which works without RTTI else if (__any-\u003e_M_manager == \u0026any::_Manager\u003c_Up\u003e::_S_manage #if __cpp_rtti || __any-\u003etype() == typeid(_Tp) #endif ) { any::_Arg __arg; __any-\u003e_M_manager(any::_Op_access, __any, \u0026__arg); return __arg._M_obj; } return nullptr; } 首先是移除目标类型的const等描述, 然后判断decay之后的类型和原来的类型是否相等, 这里意味着不能对目标类型添加过多的修饰, 最好是只使用退化后的类型. 然后再判断可拷贝性等, 最后通过__any-\u003e_M_manager == \u0026any::_Manager\u003c_Up\u003e::_S_manage判断数据类型是否相等, 如果数据类型相等, 就会匹配同一个模板类, 从而有相同的函数地址, 对于支持RTTI的环境, 也可能通过type_info判断类型是否相同. ","date":"2022-07-06","objectID":"/202207/cpp-stl-any/:2:6","tags":["Cpp","any"],"title":"STL-any源码阅读","uri":"/202207/cpp-stl-any/"},{"categories":["Cpp"],"content":"当初始化一个类数组的时候，有什么方法可以减少构造和复制操作呢？ 假设有以下类： class Foo { public: Foo() : i(-1) { printf(\"construct %p %d\\n\", this, i); } Foo(int val) : i(val) { printf(\"construct %p %d\\n\", this, i); } ~Foo() { printf(\"distruct %p %d\\n\", this, i); } Foo \u0026operator=(const Foo\u0026 foo) { i = foo.i; printf(\"copy %p %d\\n\", this, i); return *this; } private: int i; }; 对于一个类Foo，我们的目标是构建其数组形式，并希望尽量减少构造和复制。 ","date":"2022-06-20","objectID":"/202206/cpp_placementnew_allocator/:0:0","tags":["Cpp","指针","内存"],"title":"C++在给定内存上构造","uri":"/202206/cpp_placementnew_allocator/"},{"categories":["Cpp"],"content":"常规数组 常规数组访问方式如下： printf(\"=================1\\n\"); Foo array1[2]; for (int i = 0; i \u003c 2; ++i) array1[i] = Foo(i); 将得到以下输出，构造4次，复制2次，十分普通： =================1 construct 0x7ffd5d59b504 -1 construct 0x7ffd5d59b508 -1 construct 0x7ffd5d59b510 0 copy 0x7ffd5d59b504 0 distruct 0x7ffd5d59b510 0 construct 0x7ffd5d59b510 1 copy 0x7ffd5d59b508 1 distruct 0x7ffd5d59b510 1 distruct 0x7ffd5d59b508 1 distruct 0x7ffd5d59b504 0 或者是初始化时构造： { printf(\"=================0\\n\"); Foo array0[2]{1, 2}; } 得到以下输出，只构造两次，没有复制，满足需求，但是如果数组很大的话，这种形式明显就不太好了： =================0 construct 0x7ffc8c1be584 1 construct 0x7ffc8c1be588 2 distruct 0x7ffc8c1be588 2 distruct 0x7ffc8c1be584 1 ","date":"2022-06-20","objectID":"/202206/cpp_placementnew_allocator/:1:0","tags":["Cpp","指针","内存"],"title":"C++在给定内存上构造","uri":"/202206/cpp_placementnew_allocator/"},{"categories":["Cpp"],"content":"复制 移除上述Foo array1[2];的默认构造过程，又可以产生以下的代码： printf(\"=================2\\n\"); char data2[sizeof(Foo) * 2]; Foo *array2 = reinterpret_cast\u003cFoo *\u003e(data2); for (int i = 0; i \u003c 2; ++i) array2[i] = Foo(i); for (int i = 0; i \u003c 2; ++i) array2[i].~Foo(); 注意到，我们需要手动调用析构，得到以下输出，构造2次，复制2次，已有所优化了： =================2 construct 0x7ffe4cf09c14 0 copy 0x7ffe4cf09c08 0 distruct 0x7ffe4cf09c14 0 construct 0x7ffe4cf09c14 1 copy 0x7ffe4cf09c0c 1 distruct 0x7ffe4cf09c14 1 distruct 0x7ffe4cf09c08 0 distruct 0x7ffe4cf09c0c 1 ","date":"2022-06-20","objectID":"/202206/cpp_placementnew_allocator/:2:0","tags":["Cpp","指针","内存"],"title":"C++在给定内存上构造","uri":"/202206/cpp_placementnew_allocator/"},{"categories":["Cpp"],"content":"placement new 通过这个问题，我学习到了placement new（以前可能学习过，但是完全忘记了TAT），使用placement new可以再次优化，直接在给定的内存上构造，其原理如何，我认为这些知识点不是我目前想追求的，所以不做讨论。总之，可以得到以下代码： printf(\"=================3\\n\"); char data3[sizeof(Foo) * 2]; Foo *array3 = reinterpret_cast\u003cFoo *\u003e(data3); for (int i = 0; i \u003c 2; ++i) auto pA = new(array3 + i * sizeof(Foo)) Foo(i); for (int i = 0; i \u003c 2; ++i) reinterpret_cast\u003cFoo*\u003e(array3 + + i * sizeof(Foo))-\u003e~Foo(); 得到以下输出，只构造2次，没有复制： =================3 construct 0x7ffe4cf09c00 0 construct 0x7ffe4cf09c10 1 distruct 0x7ffe4cf09c00 0 distruct 0x7ffe4cf09c10 1 ","date":"2022-06-20","objectID":"/202206/cpp_placementnew_allocator/:3:0","tags":["Cpp","指针","内存"],"title":"C++在给定内存上构造","uri":"/202206/cpp_placementnew_allocator/"},{"categories":["Cpp"],"content":"allocator 上述placement new方案有点不太美观，特别是reinterpret_cast之处，考虑使用allocator分配，得到以下代码： printf(\"=================4\\n\"); std::allocator\u003cFoo\u003e alloc; using traits_t = std::allocator_traits\u003cdecltype(alloc)\u003e; Foo *array4 = traits_t::allocate(alloc, 2); for (int i = 0; i \u003c 2; ++i) traits_t::construct(alloc, array4 + i, i); for (int i = 0; i \u003c 2; ++i) traits_t::destroy(alloc, array4 + i); traits_t::deallocate(alloc, array4, 2); 同样输出如下，只构造2次，没有复制，不过通过内存地址也可以看出，这是堆上分配的： =================4 construct 0x1e50ec0 0 construct 0x1e50ec4 1 distruct 0x1e50ec0 0 distruct 0x1e50ec4 1 ","date":"2022-06-20","objectID":"/202206/cpp_placementnew_allocator/:4:0","tags":["Cpp","指针","内存"],"title":"C++在给定内存上构造","uri":"/202206/cpp_placementnew_allocator/"},{"categories":["Cpp"],"content":"小结 以上只是针对今天一个问题的解答，placement new或者allocator是否是更优的答案，我认为具体问题还需要具体分析。如果是确定大小的数组，通过vector之类的容器，使用reserve事先分配好内存，再构造也是可以的，但是vector是不是最优的，就需要根据实际需求去分析。比如再考虑以下问题，数组大小是否固定，对随机访问的性能要求，对插入删除的性能要求，对堆或者栈的性能要求等等，不同的需求倾向可能会导致不同的选择。 本文代码可见https://gcc.godbolt.org/z/Y8s84q9ev ","date":"2022-06-20","objectID":"/202206/cpp_placementnew_allocator/:5:0","tags":["Cpp","指针","内存"],"title":"C++在给定内存上构造","uri":"/202206/cpp_placementnew_allocator/"},{"categories":["工具"],"content":"关于静态博客的写作方式，我此前是把仓库clone到本地，再通过vscode写作，然后再push回去。大概上个月，我在github的codespace申请通过了，就变为了在codespace上写作，然后再push，但始终和理想的写作体验有差别，不够存粹。 我需要的就是可以和正常笔记一样的写作方式，不需要每次都pull和push的繁琐过程，直到我发现了小书匠。这肯定不是一条广告，只是想分享和推广这种静态博客的写作方式。此外，也有 “静态博客 , 在线写” 可以支持静态博客的写作，但是我并没有体验过该应用，所以后文也不做对比和评价。 在小书匠的帮助下，只需要在初始化的时候配置静态博客文章的存储地址，比如我的文章存储在github，那么我就需要配置一些github的参数，再配置图床的参数就可以了。在填写github token的时候，小书匠明确说明了该token需要的权限，此处好评，因为这是我遇到的一款向用户明确了token权限的应用，有些应用因为未告知所需权限，我就全选了，这样就容易让人担心安全问题。 小书匠github-token权限 写作上，小书匠支持很多markdown扩展写法，但是我觉得有点太多了，默认开启的几个扩展也不够友好，比如默认开启了++这个符号的扩展，这样在我写C++这个词的时候就会渲染成奇怪的格式，容易在写作的时候引起误解。 但是，总归是优点多于缺点，我才决定使用它的。 小书匠支持meta信息的模板功能，这在创建新文章的时候很有用，可以替代hugo new的指令，比如我配置了如下模板： --- title: \"\" slug: \"\" date: \u003c% print(moment().format('YYYY-MM-DDThh:mm:ss+08:00')); %\u003e lastmod: \u003c% print(moment().format('YYYY-MM-DDThh:mm:ss+08:00')); %\u003e author: bbing draft: false tags: [] categories: [] --- \u003c!--more--\u003e 那么在创建新文章的时候，就会在头部插入以上信息，可以看到，可以通过一些简单的指令插入动态的元素，比如时间。 也支持片段功能，但是对我来说，目前没有任何需求。在编辑的时候，也支持动态渲染，类似Typora的功能，所见即所得，编辑界面如下： 小书匠-编辑界面 编辑界面的样式可以自行修改。小书匠对图片插入的支持也很好，在配置好图床信息后，本地图片直接拖拽到文章需要的地方就可以了，小书匠会帮助自动上传，以上图片都是通过直接拖拽插入的。 以上可以满足我对写作的基本需求，但是我还有跨设备跨平台的需求，因为我至少可能会在三台设备上写作，所以会期望在某台设备上编辑后，可以同步到其他设备。小书匠的数据默认保存在本地，无法满足需求，需要开启会员功能才可以开启云同步（各种设置、token、模板、文章等等的同步）。会员价格是40元一年，有没有优惠我就不知道了，这个可能需要寻求官方的帮助，暂不推荐开启80元/两年的会员，虽然该应用存在时间很久了，但是未来能否继续存在还是未知的。如果对小书匠方面提供的云同步不放心的话，可以配置自己的云同步功能（同样需要会员才可）。小书匠的云同步可能会不定期清空数据，所以不能将其作为文章的保存工具，仅仅是同步工具，文章内容的保存还是依赖浏览器的本地存储或第三方存储较好。 如何发布文章？通过热键Ctrl+S即可将文章发布到已配好的平台上，但是我不太喜欢该热键。幸好，小书匠是可以修改热键的，我将Ctrl+S改为同步保存，这样在按下Ctrl+S的时候就不会发布到博客平台上了，如果需要发布，则通过UI点击比较保险。 以上，通过小书匠发布静态博客，不再需要繁琐的pull和push的过程，仅需在第一次的时候做好配置即可，此后就像正常的笔记或者某些平台的博客一样写作就行了。 小书匠的功能远不止上述内容，但是对我足以，如果想注册体验的话，可以填写以下邀请码：275_zq2mwb ","date":"2022-06-19","objectID":"/202206/staticblog_xiaoshujiang/:0:0","tags":["博客","图床"],"title":"静态博客写作新体验-小书匠","uri":"/202206/staticblog_xiaoshujiang/"},{"categories":["随笔"],"content":"对小时候的我来说，一块钱是可以买来自尊心的。 今天早上骑电动车上班，突然就想到小时候父亲骑着三轮车带上我和我母亲回外婆家的场景。 在比那更小的时候，父亲是脚踩三轮车去乡下或郊区做生意，那时候我很喜欢和他一起去，因为可以吃上五毛到一块五一碗的臭豆腐。现在还有些模糊的印象，因为坐在三轮车车斗后面，有几个小孩在旁边笑我，可能觉得那样很滑稽。不确定是不是从那时候开始，我开始对坐三轮车总有一点抵触了。 再后来，可能年纪更大一点的时候，大概初中吧，总感觉父母有时候就变得特别小气。我们回外婆家需要一块钱的车费，但是那时候他们更期望我可以和他们一起坐三轮车回去，这样可以省下几块钱，对学习用品从不吝啬的他们，在这时候吝啬了一块钱。小孩子奇怪的自尊心开始作祟了，我总是不愿意，因为会害怕被同学看见，或者害怕我和别人不一样，甚至经常因为这个和父母斗嘴。当然，大部分时候我都得妥协，因为我自己没有钱坐车。 我告诉我父母，不想坐三轮车是因为我觉得不好意思，从来没有看不起父亲工作的意思，只是单纯是觉得不好意思，因为其他小孩看见了会笑话我。但是因为所在角度和身边环境不同，我认为父母总喜欢站在大人或者站在他们那个年代学生的角度来教育我，对当时的我来说，他们认为我不应该在意别人的眼光，应该忽略他们，仅此而已。说得没错，但是年纪还小的我，却无法理解。小孩子没法做到不在意别人的目光，因为我的社交圈就是小孩，我身边也只有小孩。可能和小伙伴一起玩的时候，就可能有人提起，“上次我看见xxx坐在他爸爸三轮车后面”，会有小孩无所谓，但是也会有小孩哈哈大笑，总之，是很奇怪的攀比。 当然，也不是每次都要求我坐三轮车回去，比如车没电了，或者他们认为可以坐汽车了，也或者我太闹的时候，那我们也会坐汽车回去。 有时候会想，要是小时候我可以不坐三轮车，而是坐汽车回外婆家，对小孩心理健康的培养可能会更好点。不过这谁也不知道啦。 长大后，便不在意这些事情了，但是，坐三轮车的事总是印在我心里。上下班路上有时候也会看见有老人骑三轮车带着小孩，或者年轻人骑三轮车，我都会下意识的回避目光，避免看着他们给他们造成不适，不过，或许即使看了，也不会有任何影响，可能也就我才玻璃心。 奇怪的自尊心。初中，可能因为家庭条件而比较自卑，但是因为相对还不错的成绩，而又可以捡起一点自信；大学时期，不在乎家庭条件了，可能会因为高学历，好成绩，做了什么好的项目等等，而自信心比较足；但是社会上，学生的很多自信来源，都不顶用。我在社会上是一条虫。以前也和别人聊过，现在人的自信心，要不就是从小建立起来的，要不就是你得有他妈的几百万（北京）。从我的观察来看，自信很多时候就是建立在金钱上的，即使是从小开始培养。自信心强的小孩，家庭条件基本都不错（父母有稳定工作，有房子），而自信心略差的小孩，要不就是从农村搬到城里去读书的，要不就是家里条件比较差的，当然也有一些是成绩差，父母管教严格的。 记录本文不是为了说我父母什么，我父母为了我上学付出了很多，不然也不会有现在的我，或者我可能还在乡下种田（认真）；我想表达的，只是教育方式的不同；在他们的经济教育下，我至少不会乱花钱，知道应该存钱。 本文只是提醒自己，教育小孩，成绩重要，但是小孩健全的人格也很重要。社会并不是理想的，所以我们也不能太理想（比如忽略别人怪异的目光），孩子们也会有属于自己的自尊心，我们应该尝试站在他们这个时代去理解他们，我们应该尝试去维护他们的自尊心，而这或许这只要几块钱就可以了，而不是用大人的想法和方式去强迫他们自我修复。另外我意识到的一点是，理财教育也很重要，不是说就得教育小孩如何理财，而是可以教育小孩什么是钱，什么是经济，让小孩了解家庭状况，而不至于陷入为“我家很穷，我好惨啊”这种内耗之中。 巴老爷子的一个观点就是：“开源节流，积累资产！” 资产累计到一定额度，自信心和社会地位自然就会上来一些了。 ","date":"2022-06-17","objectID":"/202206/1yzzx/:0:0","tags":["碎碎念"],"title":"一块钱买来的自尊心","uri":"/202206/1yzzx/"},{"categories":["工具"],"content":"又打开了评论…切换到了gitalk，原因是： 有评论比没评论好，如果朋友想交流的话则可以有联系方式 此前使用waline，因为官方大版本升级，我本地尝试升级了一下，没有弄好，所以切换到了gitalk gitalk配置相对简单，数据保存在github issue，相对长久和公开 以上。 gitalk如何配置网上可以搜到很多教程，基本都一致。 但是在配置验证时容易遇到“网络问题”， 如Error: Network Error有好的解决方案吗。此问题的根本原因是github跨域访问导致，gitalk通过https://cors-anywhere.azm.workers.dev/等代理接口来解决CORS问题，但是以上代理接口容易被墙，因此比较好的方法是通过自建服务器来转发和接收请求。 参考修改Gitalk代理地址，解决无法登录问题，我实现了如下版本，与原版本基本无差，但是该版本理论上可以适配github其他接口的转发。 import requests import flask from flask_cors import CORS app = flask.Flask(__name__) CORS(app, resources=r'/*') @app.route('/github/\u003cpath:ghpath\u003e', methods=[\"GET\", \"POST\"]) def github(ghpath): url = 'https://github.com/{}'.format(ghpath) params = { 'client_id': flask.request.json['client_id'], 'client_secret': flask.request.json['client_secret'], 'code': flask.request.json['code'] } headers = { 'accept': 'application/json' } result = requests.post(url=url, params=params, headers=headers, verify=False) return result.json() 更方便地，可以通过vercel帮助运行和执行该函数，因此在github上创建了proxy-vercel，部署该函数后，在gitalk配置项中，将proxy项改为https://[vercel_proxy_domain]/github/login/oauth/access_token即可。 ","date":"2022-06-16","objectID":"/202206/vercel-gitalk-cors/:0:0","tags":["gitalk","vercel","cors","博客"],"title":"vercel反向代理解决gitalk跨域问题","uri":"/202206/vercel-gitalk-cors/"},{"categories":["Cpp"],"content":"在leetcode做题的时候，遇到如下形式的递推公式： $ f(m, n) = f(m, n-1) + f(m - 1, n) $ 借助值引用，C++也可以实现形如以上公式的代码： f(m, n) = f(m, n-1) + f(m - 1, n); 但是个人并不推荐使用这种写法，除非所写代码是比较纯粹的数学逻辑，否则可读性太低了。 以上写法的灵感来自于题《63. 不同路径 II》: 一个机器人位于一个 m x n 网格的左上角。机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角。现在考虑网格中有障碍物。那么从左上角到右下角将会有多少条不同的路径？ 网格中的障碍物和空位置分别用 1 和 0 来表示。 本文主题不是探讨其解法，不过先直接上带代码吧： int uniquePathsWithObstacles(vector\u003cvector\u003cint\u003e\u003e \u0026obstacleGrid) { int m = obstacleGrid.size(); int n = obstacleGrid[0].size(); vector\u003cint\u003e fn(m * n, 0); // f(m, n) = g(m, n - 1) == 0 ? f(m, n-1) : 0 + g(m - 1, n) == 0 ? f(m - 1, n) : 0; auto g = [\u0026](int x, int y) -\u003e int \u0026 { return std::ref(obstacleGrid[y][x]); }; auto f = [\u0026](int x, int y) -\u003e int \u0026 { return std::ref(fn[y * n + x]); }; auto fmn = [\u0026](int x, int y) { return (g(x, y - 1) == 0 ? f(x, y - 1) : 0) + (g(x - 1, y) == 0 ? f(x - 1, y) : 0); }; if (g(0, 0) == 1) return 0; if (g(n - 1, m - 1) == 1) return 0; f(0, 0) = 1; for (int x = 1; x \u003c n; x++) { f(x, 0) = g(x - 1, 0) == 0 ? f(x - 1, 0) : 0; } for (int y = 1; y \u003c m; y++) { f(0, y) = g(0, y - 1) == 0 ? f(0, y - 1) : 0; } for (int y = 1; y \u003c m; y++) { for (int x = 1; x \u003c n; x++) { f(x, y) = fmn(x, y); } } return f(n - 1, m - 1); } 重点关注的是$f$和$g$两个函数的写法： auto g = [\u0026](int x, int y) -\u003e int \u0026 { return std::ref(obstacleGrid[y][x]); }; auto f = [\u0026](int x, int y) -\u003e int \u0026 { return std::ref(fn[y * n + x]); }; 返回值是数组的引用，是左值，因此可以继续赋值，这题相较于使用g[n][m]和f[n][m]，我还是认为上述f(x, y)的形式可读性好一些。 ","date":"2022-06-06","objectID":"/202206/mathlike-cpp/:0:0","tags":["Cpp","leetcode"],"title":"像数学公式一样写C++代码","uri":"/202206/mathlike-cpp/"},{"categories":["工具"],"content":"项目地址: https://github.com/caibingcheng/fkfish 合理地摸鱼可以提高工作效率，也有助于降低因资本压迫而带来的精神损耗，在当今如此内卷的互联网环境下，我认为学会摸鱼是十分有必要且合理的。 目前已有一些摸鱼插件可以帮助广大无产/中产阶级从部分无休止、无意义的工作中相对的解放出来，比如vscode下的彩虹屁、韭菜盒子等插件。但是除了精神的解放，身体的解放也不容忽视，这就是fkfish的目的。 fkfish通过将桌面环境伪装成重启、crash等界面，向外界释放“该机器暂时无法正常工作”的信号，但是该信号的持续时间不会太长，目标是5分钟（我们只是反对内卷和压迫，但不能违背劳动契约精神），用户可以在这段时间出去走走，或者伸伸懒腰，或者拉拉伸。当然，市面上也有类似的工具，比如从chrome商店可以找到，但是这类插件容易被识破，通过ESC等按键就可以退出，并且也不容易屏蔽鼠标。fkfish可以屏蔽鼠标和ESC等按键，但是目前无法屏蔽系统热键，这将是该工具后期努力的方向。 ","date":"2022-05-31","objectID":"/202205/about-fkfish/:0:0","tags":["摸鱼"],"title":"摸鱼工具-fkfish","uri":"/202205/about-fkfish/"},{"categories":["工具"],"content":"安装 依赖环境 fkfish依赖Python以及tkinter，因此在你的系统上需要安装上述依赖： Ubuntu apt install python3 apt install python3-tk Windows tkinter是Python的内置特性，因此在安装Python的时候勾选安装tk即可。 开始安装 准备好运行环境后，可以通过源码或pip安装, 推荐使用pip安装 源码安装 git clone git@github.com:caibingcheng/fkfish.git cd fkfish python3 setup.py install pip安装 pip3 install fkfish ","date":"2022-05-31","objectID":"/202205/about-fkfish/:0:1","tags":["摸鱼"],"title":"摸鱼工具-fkfish","uri":"/202205/about-fkfish/"},{"categories":["工具"],"content":"运行 fkfish可以根据不同的系统伪装成对应的界面，直接运行： ## 自动根据不同系统，伪装成重启界面 fkfish Linux下将得到以下界面(未来可能有所改动，但是形式不会改变)： Linux-Demo Windows下将得到以下界面(未来可能有所改动，但是形式不会改变)： Windows-Demo 以上，可以通过fkfish的热键退出： ## 如果设置了密码，则该热键不生效 \u003cctrl + m\u003e 此外，也可以通过参数指定伪装的界面： Linux 重启 ## 伪装Linux重启 fkfish -m linux windows 重启 ## 伪装windows重启 fkfish -m windows windows 蓝屏 ## 伪装windows蓝屏 fkfish -m winblue 也可以通过设置密码来退出界面，如下，这时候热键\u003cctrl + m\u003e失效，需要通过输入密码来退出： ## \u003cctrl + m\u003e失效，密码匹配后才可以退出 fkfish -p [passwd] ","date":"2022-05-31","objectID":"/202205/about-fkfish/:0:2","tags":["摸鱼"],"title":"摸鱼工具-fkfish","uri":"/202205/about-fkfish/"},{"categories":["工具"],"content":"工具地址: https://djeva.bbing.com.cn 项目地址: https://github.com/caibingcheng/djeva 前段时间读了几本关于理财投资的书籍，其中提到了指数基金定投策略，按照价值投资的理念，在低估时买入指数基金，在正常估值时停止或者降低买入，高估时卖出。估值方式多种多样，我现在可能参考PE、PB、ROE、股息率等估值数据，参考来源是蛋卷基金或者银行螺丝钉的公众号，但是遇到的问题是，我期望能记录我每一笔交易当日的估值，但有时候在当日会忘记记录，而后不太方便查找那日的估值（单项基金的历史数据会缺少一些项目），因此需要一个工具可以用来查找过去某日的全部估值数据。 数据来源是蛋卷基金，我们进入其估值页面，F12 -\u003e Network选项卡查找其数据来源，可以发现一条https://danjuanapp.com/djapi/index_eva/dj，查看其response可以知道这是我们需要的数据。 如果直接用python的request库get上述url是不可以的，服务器会拒绝该请求，这时候需要构造header，如下： _url = 'https://danjuanapp.com/djapi/index_eva/dj' _headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.64 Safari/537.36 Edg/101.0.1210.53' } 通过github action，在国内时间每晚8点左右会更新一次数据。 数据格式很简单，拿到后简单处理即可。djeva拿到数据后会保存三份： source，代表原始数据，是直接从response中获取的 json，是提取后的数据存储为json格式，此处的提取仅是提取source数据的data项 csv，同json，但是以csv存储 数据有冗余，以不同的格式存储只是为了客户端获取的方便，减少客户端的数据处理过程（rssblog-source项目也是此原因），并且我们一般也不太在意此类数据准备的时间。 数据准备好之后则期望可以比较方便的呈现，djeva采用的是表格形式，使用的是原生js编写的gridmanager组件，有了该组件我们可以比较方便的呈现数据，但是怎么切换数据来源呢？（比如查看某日期的估值。）可以根据某日期尝试get数据，如果超时则认为不存在，不过该方法显然不行，所以还是参考rssblog-source，在数据准备阶段，就会准备一个可用数据的列表，该项目生成的是djeva.js，其中包含的内容就是djeva已经备份的估值的日期。 不过，即使以上生成了js文件，由于跨域问题的存在，将数据源和客户端分离的话，获取数据将变得不方便，我只想到通过构建一个后端，然后再通过后端获取来屏蔽跨域问题的方案，并且认为其性价比不高（但是gridmanager就可以通过url获取，还没看其源码），因此索性将数据源和客户端放在一起。当前的djeva是通过vercel构建的，但是客户端只有index.html文件，又因为vercel会将该仓库的所有数拉取过去，因此不存在跨域问题。 ","date":"2022-05-25","objectID":"/202205/funds-djeva/:0:0","tags":["基金"],"title":"指数基金估值查询-djeva","uri":"/202205/funds-djeva/"},{"categories":["工具"],"content":"本站图传切换过程：路过图床-\u003egithub-\u003e本地-\u003e去不图床。 在这过程中, 我使用的是picvt用来切换图床, 该项目还在开发中, 因为我没有使用过很多图床, 所以目前仅支持上述几种。 项目传送门: https://github.com/caibingcheng/picvt ","date":"2022-05-19","objectID":"/202205/aboutpicvt/:0:0","tags":["图床"],"title":"图床转换工具-picvt","uri":"/202205/aboutpicvt/"},{"categories":["工具"],"content":"构建 为了未来的适配工作, picvt规定了一些接口, 分别是用于链接提取的extract, 用于下载的download, 用于上传的upload。 创建平台适配类 如果是新增平台, 比如新增xx图床, 则在platforms/picvt_xxxx.py创建对应平台的文件, 然后实现一个名为Porcess的类, 继承自PICVT, 如: class Process(PICVT): pass extract 需要实现一个名为extract的方法, 如: def extract(self, content): return None extract将用于原图床的链接提取, 输入是一段string, 比如一篇markdown的原始数据, 实现者需要从中提取出待转换的图床链接, 并使用一个list返回. download 需要实现一个名为download的方法, 如: def download(self, url): return False, None download将用于原图床图片的下载, 并且需要将下载文件保存在本地磁盘, 其输入是原图床图片的链接, 输出是下载成功的状态以及保存的本地文件地址, 如果下载失败, 则本地文件地址为None. 父类PICVT中提供了download的实现, 但是不适用于所有平台, 所以特殊平台需要自己实现download方法. 父类PICVT也提供了_save_image_default和_get_save_path用于将图片存储到本地位置, 或者从本地位置获取图片, 提供统一的存储位置将便于upload方法的实现。 upload 需要实现一个名为upload的方法, 如: def upload(self, path, params): return False, None upload将用于新图床的上传, 输入参数为本地需要上传的文件的路径, 以及与图床登录相关的参数, 包括但不限于用户名/密码/token. 该方法将返回上传成功与否的状态, 以及新图床的外链, 如果上传失败, 则外链应该为None. params的config字段可以提供很多与平台相关的参数, 比如与github等相关的repo、branch、path, 或者与local相关的path、link. 注意到不同平台有些字段是复用的, 但是意思不同, 比如github中的path代表github仓库中某路径, local中的path则代表本地某路径. ","date":"2022-05-19","objectID":"/202205/aboutpicvt/:0:1","tags":["图床"],"title":"图床转换工具-picvt","uri":"/202205/aboutpicvt/"},{"categories":["工具"],"content":"案例 更多案例可以参考项目, 或者使用help指令. 从路过图床迁移到github 命令是: python3 ./picvt.py -D ../blog/content/posts/ -F imgtu -T github -t **** --repo resources --branch main --path images -D ../blog/content/posts/待扫描的路径, 将从上述路径中扫描符合imgtu规则的图片链接, -F imgtu -T github表示从imgtu迁移到github, -t ****则是github的token, 也可以使用用户名或者密码(未测试), --repo resources --branch main --path images则表示上传到resources仓库的main分支的images目录下. 上述指令执行完成之后会将../blog/content/posts/中的对应链接替换成jsdelivr的链接. 从github迁移到本地 命令是: python3 ./picvt.py -D ../blog/content/ -F github -T local --path /home/xxxx/projects/blog/content/statics/ --link /statics/ -r 3 --path /home/xxxx/projects/blog/content/statics/表示会将文件下载到/home/xxxx/projects/blog/content/statics/路径下, --link /statics/则是本地的链接前缀, 用于替换图片地址, 比如我的域名是bbing.com.cn, 则替换后访问图片链接将是bbing.com.cn/statics/xxx.png. -r 3则代表失败项会尝试3次, 如果还是失败了…在执行一次上述命令即可, 此时已经成功的链接是不会再重复处理的. 从本地迁移到去不图床 命令是: python3 ./picvt.py -D ../blog/content/ -F local -T 7bu --path /home/xxx/projects/blog/content/ --user xx@xx.com --paasswd ***** 此处的--path /home/xxx/projects/blog/content/时local作为from的需求参数，表示本地图片的存储路径（比如图片/statics/text.png存储在blog/content/下），--user和--passwd则是去不图床的用户名（邮箱）和密码。 ","date":"2022-05-19","objectID":"/202205/aboutpicvt/:0:2","tags":["图床"],"title":"图床转换工具-picvt","uri":"/202205/aboutpicvt/"},{"categories":["随笔"],"content":"关闭评论 最初添加评论的目的是期望可以和读者互动，更期望的是可以有人一起讨论技术问题，或争辩或指出问题，无论如何，总归都是好的，都可以帮助拓宽思考的广度。但是一年下来，实际上没有多少读者，读者一般也不愿意和我互动。讨论问题的评论数量为零，更多的是互换友链，但是交换友链的朋友们或许从来没有读过我的文章。 可能文章质量差、或者漏洞百出？不过不重要了，现在要做的就是关闭评论，不再去关心有多少人可能会评论你的文章，反正我也没有做自媒体之类的打算。 在我关闭评论之后，在RSSBlog上浏览到了这篇文章《如何克服精神内耗？》，这就是我最近一年多或者两年多的状态，精神内耗严重。 ","date":"2022-05-04","objectID":"/202205/disbalecomment-makeitsimple/:1:0","tags":["博客","碎碎念"],"title":"关闭了评论，让一切简单起来","uri":"/202205/disbalecomment-makeitsimple/"},{"categories":["随笔"],"content":"多关注自己，少关注别人 这一两年，我时常能意识自我精神内耗严重的问题，意识到之后也时常去改变，但又容易陷入循环。不过，对我来说，好消息是，今年的状态已经比去年好太多了。所以，或许可以尝试《如何克服精神内耗？》里面的一个方法，多关注自己，少关注别人。 关闭评论会是减少内耗的第一步，如以往所说，我会尽量保证文章的正确性，贴上代码或者出处，就算是个人观点，也会尽量列出证据，所以评论看起来也不再重要了。 ","date":"2022-05-04","objectID":"/202205/disbalecomment-makeitsimple/:2:0","tags":["博客","碎碎念"],"title":"关闭了评论，让一切简单起来","uri":"/202205/disbalecomment-makeitsimple/"},{"categories":["随笔"],"content":"佛系一点，超越自己而不是别人 工作之前我都很佛系，工作的不公平、利益的冲突容易使得我思考太多，也害怕太多。 佛系一点可能会更好，作为一个小角色，什么都改变不了，除了自己。所以，与其关注别人得到了什么，是不是公平的，不如多关注关注自己。这让我想起这两天看的一本书《穷爸爸，富爸爸》。我认为它是讲投资的，但是在这件事情上也同样适用。多关注自己，多提升自己就是一项有效投资，可以给我提供源源不断的“现金流”，迟早有一天我会从中得到满意的回报，从别人那里得到的（比如说老板给的好处等等）就像是负债或者贷款，会刺激我更想得到更多，我已深有体会，但是又无能为力，从而陷入恶性循环。而我更认为，我会偏向于投资，而不是贷款或者负债。 ","date":"2022-05-04","objectID":"/202205/disbalecomment-makeitsimple/:2:1","tags":["博客","碎碎念"],"title":"关闭了评论，让一切简单起来","uri":"/202205/disbalecomment-makeitsimple/"},{"categories":["随笔"],"content":"有时间多看看书，不要太容易被社会污染 真实的社会太容易改变一个人了。我有一些朋友，初中毕业就出去工作了，已经可以很明显的感觉到，外面的社会会让人改变很多，或圆滑或狡黠等等，包括现在的我也是，我能清楚的认识到，有时候的我已经变成了我学生时期讨厌的那种类型。我没法脱离现在的这个真实的社会，但是可以尝试保护自己。大学时期，在我心烦意乱的时候就喜欢读林清玄的书，我读书可能不多，但是读下来也唯独他的书可以让我真的感觉到心静自然（菩提系列）。工作之后，心烦的时候我也尝试过再读他的书，但是已经没有学生时期那种效果了。我归结于想法太多，菩提的效果已经大打折扣了。不过这还是一个可以尝试的方法，从0到1，见多了社会上的尔虞我诈，要是有时间就强迫自己静下心来多读读书，可能还是会有用的，这里总可以找到干净的地方。 ","date":"2022-05-04","objectID":"/202205/disbalecomment-makeitsimple/:2:2","tags":["博客","碎碎念"],"title":"关闭了评论，让一切简单起来","uri":"/202205/disbalecomment-makeitsimple/"},{"categories":["随笔"],"content":"行动起来，有激情更需要行动 我已能感觉到，资本邪恶之处就是抹杀无产者的反抗心。通过提高一点少的可怜的待遇，让你觉得此处还有发展空间；或者散播各种谣言，让你害怕出去；还或者温水煮青蛙，限制你的发展，让你难以出去；等等。我现在的一个大问题就是想（说）的太多，而做得太少。尽管我也写下了这篇文章，但是我能不能做下去呢？能！！！ 现在的我并不缺少激情，而是缺少了行动的勇气。一旦涉及到真金白银了，可能就没那么容易了。不过《穷爸爸，富爸爸》中还是有一个观点可以再给我打点鸡血：越早失败就越早成功。这当然不是原文。所以，最好就在某个时刻，让我上头，干他娘的一把。 ","date":"2022-05-04","objectID":"/202205/disbalecomment-makeitsimple/:2:3","tags":["博客","碎碎念"],"title":"关闭了评论，让一切简单起来","uri":"/202205/disbalecomment-makeitsimple/"},{"categories":["工具"],"content":"这是我在下班路上想到的问题. 因为看见路边的车上会有鸟屎, 就想, 运动的汽车和停下的汽车, 被鸟拉屎的概率一样不一样呢? 如果车停在树下, 而树上比天上更容易产生鸟的话, 那树下的车被鸟拉屎的概率可能更高些(但是也不一定呀, 因为车一直在运动, 经过一些地方的时候, 这些地点上方的鸟可能会很多, 导致路途上平均的鸟的数量更多). 不过当时我也没想到很好的数学证明的方法, 因为车运动的情况比较复杂了, 当时没想清楚运动的概率应该怎么算. 这东西代码模拟不算复杂, 所以, 就假设, 运动的车和静止的车是在同一条大马路上, 然后运动的车是在马路上做往复运动, 车的运动是匀速且离散的(物理上也确实是离散的, 不过我们先在数学上假设是离散的), 也就是说, 每一个单位时间观察, 车总是在整数倍的单位长度的位置上, 最重要的是假设每个单位长度上, 鸟拉屎的概率相同. (写道这里仔细想想, 这时候运动的车和静止的车被鸟拉屎的概率应该是一样的, 不过当时我没想清楚, 所以这里还是把过程贴上来吧~) 以下是定义的一些状态, 如路的长度, 鸟拉屎的概率, 车的长度等等: road_length = 100 ## 路的长度 shit_rate = 0.3 ## 鸟拉屎的概率 shit_pos = [p for p in range(0, road_length)] ## 路上可能出现鸟屎的位置, 假设等概率 car_length = 4 ## 车的长度 car_speed = 1 ## 车的速度 car_start = 0 ## 运动的车开始的位置 static_car = 0 ## 对照组, 静止的车的位置 sim_times = 100000000 ## 模拟时长 static_count = 0 ## 对照组, 静止的车被鸟拉屎的次数 move_count = 0 ## 运动的车被鸟拉屎的次数 现在要生成一个鸟拉屎的位置, 我们先判断会不会有鸟拉屎, 然后在给它安排一个随机的位置: ## 生成一个鸟拉屎的位置, 如果这个时间点没有鸟拉屎, 则输出-1(假设拉在了别的地方) import random def generate_shit(shit_rate, shit_pos): should_shit = random.random() \u003c shit_rate shit_position = -1 if not should_shit else shit_pos[random.randrange(len(shit_pos))] return shit_position 车是往复运动的, 所以到了道路末尾又得掉头, 这里我们就理想化了, 假设车的速度可以直接反转: ## 车的运动函数, 如果车运动到了路的末尾, 则又从末尾向头运动, 假设匀速 direction = car_speed def move_car(car_start, car_length, road_length): global direction if (car_start + car_length) \u003e= road_length: direction = -car_speed if car_start \u003c= 0: direction = car_speed car_start = car_start + direction return car_start 根据鸟拉屎的位置, 以及车的长度, 判断鸟屎有没有拉在车上: ## 判断鸟屎是否拉在了车上 def hashit_car(car_start, car_length, shit_position): hashit = 1 if (car_start \u003c= shit_position and shit_position \u003c (car_start + car_length)) else 0 return hashit 开始模拟, 我这里的数据是模拟一亿次: for _ in range(sim_times): shit_position = generate_shit(shit_rate, shit_pos) car_start = move_car(car_start, car_length, road_length) has_static_shit = hashit_car(static_car, car_length, shit_position) has_move_shit = hashit_car(car_start, car_length, shit_position) static_count = static_count + has_static_shit move_count = move_count + has_move_shit # print(shit_position, static_car, has_static_shit, static_count, car_start, has_move_shit, move_count) print(static_count, move_count, sim_times) print(static_count / sim_times, move_count / sim_times) 得到静止车和运动车被鸟拉屎的概率几乎相同, 为0.012, 这个概率就是(鸟拉屎概率 x (车的长度 / 路的长度)): 1200522 1200946 100000000 0.01200522 0.01200946 以上结论的主要条件就是等概率拉屎, 但是我认为等概率拉屎这个假设是有意义的, 因为鸟无法存储粪便, 所以即使在飞的时候也可能拉屎. 但是鸟呆在树上的时间会更长吗? 我不知道, 就假设和空中等价吧. (这里需要考虑的就是, 鸟在树上一段时间之后就会飞走, 而树的高度又相对有限, 而空中的高度相对无限, 所以空中有概率叠加多只鸟…不过这些太复杂了, 也没研究过, 所以, 还是假设一样一样一样) 我想起来以前想过一个问题, 下雨的时候跑回去和走回去会淋湿一样吗? 先不考虑空气动力因素(因为跑回去的时候周围空气流动速度快, 会把雨水’吸’过来, 但是人跑的速度也不会很快, 所以先不考虑吧). 下雨至少可以认为是每个地方等概率的雨了, 所以现在好回答这个问题: 如果是相同的淋雨时间, 那么不管跑还是走还是不动, 淋湿程度是相同的; 如果淋雨时间不同, 那么呆在雨里的时间更短, 则淋湿程度越低(也就是跑), 不过淋湿是会饱和的, 如果湿透了, 那就不能更湿了. ","date":"2022-04-25","objectID":"/202204/birdshit-rate/:0:0","tags":["Python","仿真"],"title":"车运动时和静止时被鸟拉屎的概率","uri":"/202204/birdshit-rate/"},{"categories":["工具"],"content":"这不是一篇教程，所以不涉及omv从0到1的安装过程。网上教程很多，但是跟着做下来还是遇到很多问题（装了好几天\u003e:），本篇的目的是记录我在omv安装过程中遇到的一些问题以及解决方法（不涉及原理）。 ","date":"2022-04-16","objectID":"/202204/laptopnas-omv/:0:0","tags":["nas","omv"],"title":"闲置笔记本改NAS-OMV踩坑记录","uri":"/202204/laptopnas-omv/"},{"categories":["工具"],"content":"0. 预备工具，官方链接。 omv镜像: https://www.openmediavault.org/ U盘刻录工具: https://www.balena.io/etcher/ （！！！用起来看着很干净！！！） ","date":"2022-04-16","objectID":"/202204/laptopnas-omv/:0:1","tags":["nas","omv"],"title":"闲置笔记本改NAS-OMV踩坑记录","uri":"/202204/laptopnas-omv/"},{"categories":["工具"],"content":"1. 为什么要将笔记本改NAS？ 因为笔记本闲置很久了，大概7年前的笔记本，毕业之后就很少打开，所以打算把笔记本的存储和计算资源利用起来。相比较于买一个NAS，笔记本改的成本低很多，而且算力更牛逼，电费也不会高很多。 ","date":"2022-04-16","objectID":"/202204/laptopnas-omv/:0:2","tags":["nas","omv"],"title":"闲置笔记本改NAS-OMV踩坑记录","uri":"/202204/laptopnas-omv/"},{"categories":["工具"],"content":"2. 为什么选OMV？ github搜NAS，OMV按star数量排第一。 ","date":"2022-04-16","objectID":"/202204/laptopnas-omv/:0:3","tags":["nas","omv"],"title":"闲置笔记本改NAS-OMV踩坑记录","uri":"/202204/laptopnas-omv/"},{"categories":["工具"],"content":"3. 先安装Debian在安装OMV还是直接安装OMV的镜像？ 目的明确，直接使用OMV镜像。先安装Debian再安装OMV会有很多折腾的过程，而且我此前做法是不安装Debian的桌面环境，所以在配置网络的时候有些麻烦，随放弃。而官方OMV镜像也是包了一个Debian，所以在最终的结果上没有差别，各种配置在安装过程中，镜像的安装程序都帮你做好了，所以OMV镜像安装好后基本就能直接使用了。以下将通过OMV镜像安装的系统成为OMV系统。 ","date":"2022-04-16","objectID":"/202204/laptopnas-omv/:0:4","tags":["nas","omv"],"title":"闲置笔记本改NAS-OMV踩坑记录","uri":"/202204/laptopnas-omv/"},{"categories":["工具"],"content":"4. 安装在哪？ 我推荐安装在U盘。一是，OMV系统会禁止将系统盘作为存储盘使用，如果安装在大硬盘的话，就会损失很多存储空间，所以安装在U盘。二是，OMV系统有相关插件可以相对的延长U盘的使用寿命，所以无需太担心读写次数问题。三是，尽管打算利用笔记本的计算资源，但是也不可能像平常使用电脑那样长期利用，所以也相当于是小概率使用，大部分使用只是作为一个NAS。四是备份和移植方便，后期想换一个mini U盘，通过dd复制过去应该就行了。 ","date":"2022-04-16","objectID":"/202204/laptopnas-omv/:0:5","tags":["nas","omv"],"title":"闲置笔记本改NAS-OMV踩坑记录","uri":"/202204/laptopnas-omv/"},{"categories":["工具"],"content":"5. 推荐安装时系统U盘和安装U盘插在同类型的USB接口。 我的笔记本只有一个USB3.0，试过一个插USB3.0一个插USB2.0，结果安装速度超级慢，两个都插USB2.0，则安装速度稍快。 ","date":"2022-04-16","objectID":"/202204/laptopnas-omv/:0:6","tags":["nas","omv"],"title":"闲置笔记本改NAS-OMV踩坑记录","uri":"/202204/laptopnas-omv/"},{"categories":["工具"],"content":"6. 支持UEFI吗？ 官方说支持，repo的issue上有讨论。但是我没弄成功，所以启动的时候需要关闭UEFI。 ","date":"2022-04-16","objectID":"/202204/laptopnas-omv/:0:7","tags":["nas","omv"],"title":"闲置笔记本改NAS-OMV踩坑记录","uri":"/202204/laptopnas-omv/"},{"categories":["工具"],"content":"7. 硬盘格式化？ Debian的安装程序可以格式化硬盘，但是OMV的安装程序不能直接格式化，只可以选择安装硬盘，这导致OMV安装程序使用了大硬盘上的/分区（因为我试过安装在大硬盘上，但是这之后没有删除对应的分区）。可以在OMV安装程序中选择进入shell，使用fdisk指令清除硬盘分区。 ","date":"2022-04-16","objectID":"/202204/laptopnas-omv/:0:8","tags":["nas","omv"],"title":"闲置笔记本改NAS-OMV踩坑记录","uri":"/202204/laptopnas-omv/"},{"categories":["工具"],"content":"8. raids？ 这方面不太了解，我的设备尽管有两块硬盘但是不能组raids，原因说是这两块硬盘是通过USB链接的。因此可能是需要设备支持才可能支持raids，需要有心里准备。 ","date":"2022-04-16","objectID":"/202204/laptopnas-omv/:0:9","tags":["nas","omv"],"title":"闲置笔记本改NAS-OMV踩坑记录","uri":"/202204/laptopnas-omv/"},{"categories":["工具"],"content":"9. 初始化 安装之后先在host机器上操作，需要注意登录之后屏幕上的提示指令，大概是omv-firstaid，这可以帮助配置机器的网络连接、omv终端的用户名/用户密码等。相比较于debian的安装，这可以减少很多折腾的过程。另外，因为是笔记本，所以需要设置盖子关闭不挂起电脑。 ","date":"2022-04-16","objectID":"/202204/laptopnas-omv/:0:10","tags":["nas","omv"],"title":"闲置笔记本改NAS-OMV踩坑记录","uri":"/202204/laptopnas-omv/"},{"categories":["工具"],"content":"10. 更新 在客户端登录，一般是omv.local，这依赖于你安装omv时的配置，登录之后最好先更新系统，当然在服务器上更新也是可以的。 ","date":"2022-04-16","objectID":"/202204/laptopnas-omv/:0:11","tags":["nas","omv"],"title":"闲置笔记本改NAS-OMV踩坑记录","uri":"/202204/laptopnas-omv/"},{"categories":["工具"],"content":"11. 一般配置 要记得先做一些基础配置，比如：硬盘格式化、硬盘挂载、建立用户、配置用户权限、建立共享文件夹、开启SSH、SMB等服务。以上完成后，可以在客户机器上看看是不是可以找到共享文件夹了，此时基本工作已经完成了。 ","date":"2022-04-16","objectID":"/202204/laptopnas-omv/:0:12","tags":["nas","omv"],"title":"闲置笔记本改NAS-OMV踩坑记录","uri":"/202204/laptopnas-omv/"},{"categories":["工具"],"content":"12. 更多配置 除了做基础的网络存储，还可以实现多媒体等功能，但是这依赖于扩展插件，因此需要安装扩展插件，关键词是’omv-extra’，比如在这里可以找到https://wiki.omv-extras.org/安装方法。上网址国内可以访问，但是其提供的链接是github/raw，因此如果需要直接使用的话，就需要在服务器上配置魔法（但是服务器可能当作下载器使用，如果配置魔法而没有配置关闭策略的话，可能导致流量超出）。因此，推荐的方式是在客户机上操作。客户机配置魔法是简单的，或者不配置魔法，推荐关注fastgithub项目，可以先将omv-extra的deb下载下来。然后再客户端上找到插件，将此deb上传并安装即可。 以上操作后，就可以看到omv-extra的tab了，把docker或者portainer等安装上，安装之后我们就可以在客户端为服务器安装docker服务了。以下是目前使用的： jellyfin，免费的流媒体服务，目前使用下来是可以满足需求的，镜像是linuxserver/jellyfin，安装以及配置方式等，网上搜即可，配置最好是参考docker hub上对应image的说明即可。 transmisson，bt下载服务，可以不需要登录客户端，在客户机上直接下载内容到服务器上，十分的方便，镜像是linuxserver/transmission，如果第一个操作了，这个也就会安装了，配置同样看官方文档即可。 简单的多媒体方式，就可以在安装omv-extra后，在插件栏找到dlna即可，打开和配置dlna后，在家里也可以多设备访问服务器上的媒体文件了。 ","date":"2022-04-16","objectID":"/202204/laptopnas-omv/:0:13","tags":["nas","omv"],"title":"闲置笔记本改NAS-OMV踩坑记录","uri":"/202204/laptopnas-omv/"},{"categories":["工具"],"content":"-1. 使用感受 (2022-04-25T19:44:18+08:00) 用了一周多了, 已经冷静下来没那么折腾了. 现在主要用的依然是上述的两个插件transmisson和jellyfin. 这几天在家的时候都会找很多资源, 然后交给transmisson去下载, 有些可能需要下载好几天, 有些可能睡觉起来就好了, 总之会比使用主力机器下载省心不少(因为24h运行). 不过下载好后, 需要人工登录共享文件夹整理下载之后的内容. 虽然transmisson可以在下载完成之后执行一些用户自定义脚本, 我也尝试了一下, 然后transmisson就蹦了:\u003c jellyfin可以自动扫描指定目录的变更, 但是目前使用起来并没有那么迅速, 所以有时候我也会登录admin账户手动下达重新扫描的指令, 如果不是很着急的话, 等待一段时间, jellyfin基本也是可以帮助扫描的. 相比与DLNA, jellyfin尽管感知更新的速度比较慢, 但是在其他的用户体验上要智能得多, 可以指定扫描的路径, 可以自定义媒体库(分类), 还可以在空闲的时候自动更新媒体文件的一些meta信息, 比如海报/演员信息等等. Android也有jellyfin的客户端, 总之, 目前使用jellyfin的体验是比较好的. 至于虚拟机我并没有尝试配置, 因为机器性能不算很好, 而且主力机可以覆盖我的需求, 所以目前就把这个笔记本当作媒体设备了. U盘系统体验下来的感觉并不是很好, 主要是速度太慢了. 但是又不想浪费一块硬盘, 所以目前依然使用的是U盘系统. 不过, 如果只是作为一个多媒体设备的话, U盘系统还是没问题的. 最后, 有时候会担心笔记本着火了…所以不在家的时候可能会时不时看看家里的监控… ","date":"2022-04-16","objectID":"/202204/laptopnas-omv/:0:14","tags":["nas","omv"],"title":"闲置笔记本改NAS-OMV踩坑记录","uri":"/202204/laptopnas-omv/"},{"categories":["操作系统","glibc"],"content":"在上一篇中，存留了一些疑问: tcache fastbin smallbin unsorted_bin 以上如何管理？ 以上什么关系？ bin是怎么初始化的？ bin是怎么扩充的，可以扩充吗？ ","date":"2022-03-30","objectID":"/202203/glibc-malloc2/:0:0","tags":["Linux","glibc"],"title":"glibc-malloc源码阅读二","uri":"/202203/glibc-malloc2/"},{"categories":["操作系统","glibc"],"content":"bin ","date":"2022-03-30","objectID":"/202203/glibc-malloc2/:1:0","tags":["Linux","glibc"],"title":"glibc-malloc源码阅读二","uri":"/202203/glibc-malloc2/"},{"categories":["操作系统","glibc"],"content":"malloc_chunk 首先要清楚bin中的元素是什么, bin中的元素是memory chunk, 其定义如下: struct malloc_chunk { INTERNAL_SIZE_T mchunk_prev_size; /* Size of previous chunk (if free). */ INTERNAL_SIZE_T mchunk_size; /* Size in bytes, including overhead. */ struct malloc_chunk* fd; /* double links -- used only if free. */ struct malloc_chunk* bk; /* Only used for large blocks: pointer to next larger size. */ struct malloc_chunk* fd_nextsize; /* double links -- used only if free. */ struct malloc_chunk* bk_nextsize; }; mchunk_prev_size代表上一个chunk的大小 mchunk_size 代表当前chunk的大小 fd/bk双向链表的前后指针 fd_nextsize/bk_nextsize针对large chunk, 双向链表的前后指针 通过chunk的结构我们可以知道, chunk是通过链表链接起来的, 至于是单向链表还是双向链表就需要再看实现了. 注意到注释部分, 有些成员会标注是\"if free\", 表示这一项在chunk是free的时候才有效, 比如malloc之后, 这一项就是无效的, 这是用来复用的. malloc返回给用户的内存可以访问到这些区域, 比如mchunk_prev_size/fd_nextsize等, 但是诸如mchunk_size这块内存是不允许用户访问的(用户要是访问了, 修改了, 那glibc就无法正常管理了). chunk结构 malloc.c中对于此内存结构有如下表示: chunk-\u003e +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Size of previous chunk, if unallocated (P clear) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Size of chunk, in bytes |A|M|P| mem-\u003e +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | User data starts here... . . . . (malloc_usable_size() bytes) . . | nextchunk-\u003e +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | (size of chunk, but used for application data) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Size of next chunk, in bytes |A|0|1| +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ 通过这个图, 又可以了解到一些信息: 当前chunk加上mchunk_size则可以得到下一个chunk 当前chunk减去mchunk_prev_size则可以得到上一个chunk mchunk_prev_size是可能被上一个chunk返回给用户的 fd及一下等, 是可能被当前chunk返回给用户的 A|M|P是什么: A代表NON_MAIN_ARENA, 表示chunk的arena是不是main_arena, 如果是main_arena, 则A = 0, 否则A = 1 M代表IS_MMAPPED, 表示当前chunk是不是通过mmap申请的 P代表PREV_INUSE, 表示当前chunk的上一个chunk是不是被使用的, 如果是, 则上一个被使用, mchunk_prev_size也无效, 否则mchunk_prev_size代表上一个chunk的size, 第一个chunk节点的P总是1 等等!!上文说的上一个chunk是指? 链表的上一个吗? 可以参考这篇, 所以我理解的上一个chunk是指连续内存上的上一个chunk, 因为bin中的chunk可能不在相邻内存. 如图示: bin-chunk ","date":"2022-03-30","objectID":"/202203/glibc-malloc2/:1:1","tags":["Linux","glibc"],"title":"glibc-malloc源码阅读二","uri":"/202203/glibc-malloc2/"},{"categories":["操作系统","glibc"],"content":"malloc_state 再看看bin是什么, 在上一篇的内容中, 我们有提到一个参数av, bin被存放在av中, av是一个malloc_state指针, malloc_state的内容如下: struct malloc_state { /* Serialize access. */ __libc_lock_define (, mutex); /* Flags (formerly in max_fast). */ int flags; /* Set if the fastbin chunks contain recently inserted free blocks. */ /* Note this is a bool but not all targets support atomics on booleans. */ int have_fastchunks; /* Fastbins */ mfastbinptr fastbinsY[NFASTBINS]; /* Base of the topmost chunk -- not otherwise kept in a bin */ mchunkptr top; /* The remainder from the most recent split of a small request */ mchunkptr last_remainder; /* Normal bins packed as described above */ mchunkptr bins[NBINS * 2 - 2]; /* Bitmap of bins */ unsigned int binmap[BINMAPSIZE]; /* Linked list */ struct malloc_state *next; /* Linked list for free arenas. Access to this field is serialized by free_list_lock in arena.c. */ struct malloc_state *next_free; /* Number of threads attached to this arena. 0 if the arena is on the free list. Access to this field is serialized by free_list_lock in arena.c. */ INTERNAL_SIZE_T attached_threads; /* Memory allocated from the system in this arena. */ INTERNAL_SIZE_T system_mem; INTERNAL_SIZE_T max_system_mem; }; 类型mfastbinptr和mchunkptr都是malloc_chunk的指针, 在malloc_state中, 我们可以看到有fastbin和bin, 以及表示fastbin是否存在的have_fastchunks, 但是没有看到smallbin/largebin这些结构. 实际上, smallbin/largebin是包含在bin中的. 我的理解是, smallbin和largebin其实可以看作是同一种bin, 所以归类在一起, 但是fastbin和其他bin会有一些区别, 所以不算在普通bin类. 另外还注意到next和next_free两个成员, 由此也可以推断出malloc_state是某个链表的元素, 并且会有类似free list的存在. 这里可以看到main_arena的初始化, 它的next指向了自己, 是一个环状链表的结构: /* There are several instances of this struct (\"arenas\") in this malloc. If you are adapting this malloc in a way that does NOT use a static or mmapped malloc_state, you MUST explicitly zero-fill it before using. This malloc relies on the property that malloc_state is initialized to all zeroes (as is true of C statics). */ static struct malloc_state main_arena = { .mutex = _LIBC_LOCK_INITIALIZER, .next = \u0026main_arena, .attached_threads = 1 }; arena的扩展 arena如何扩展? 在malloc里面我们已经见过arena_get函数, 如下: #define arena_get(ptr, size) do { \\ ptr = thread_arena; \\ arena_lock (ptr, size); \\ } while (0) #define arena_lock(ptr, size) do { \\ if (ptr) \\ __libc_lock_lock (ptr-\u003emutex); \\ else \\ ptr = arena_get2 ((size), NULL); \\ } while (0) 首先是获取当前线程的thread_arena, 如果没有, 那么尝试arena_get2. thread_arena是什么? 在ptmalloc_init填充了thread_arena, 指向了main_arena: //ptmalloc_init (void) thread_arena = \u0026main_arena; 但是我们还需要注意, __malloc_hook只有在第一次调用malloc的时候才会被调用, 此后__malloc_hook会被赋空, 也就是说对应的ptmalloc_init只会被调用一次, 只有在进程启动的时候, 第一个线程的thread_arena才会被赋值为\u0026main_arena, 而其他线程此值为空. 在malloc的时候, 还有这么一段: if (SINGLE_THREAD_P) { victim = _int_malloc (\u0026main_arena, bytes); assert (!victim || chunk_is_mmapped (mem2chunk (victim)) || \u0026main_arena == arena_for_chunk (mem2chunk (victim))); return victim; } 这说明, 在单线程环境的时候, 直接使用main_arena就行了, 多线程环境, 不同的线程则可能使用不同的arena, 这是为了加速, 减少互斥锁而使用的. 再继续arena_get2, 它做的第一件事就是尝试从一个free的链表中获取, 如果获取到了, 那就返回了, 如果没获取到, 则尝试创建一个新的arena: a = get_free_list (); if (a == NULL) { //...... a = _int_new_arena (size); //...... a = reused_arena (avoid_arena); //...... } 当然, 是不是可以无限制的创建arena? 不是的, 会和当前系统有关. _int_new_arena的作用就本就是mmap一块heap, 然后改造成arena结构, 再将thread_arena指向这块新arena, 原先的arena则会被detach掉(detach的作用就是当前arena的引用计数器attached_threads减一), 但是目前还没有回收到free表中: mstate replaced_arena = thread_arena; thread_arena = a; //...... __libc_lock_lock (free_list_lock); detach_arena (replaced_arena); __libc_lock_unlock (free_list_lock); 新arena怎么和arena链表关联起来呢? 如下, 新arena总是插在链表的\"颈部\", 而链表\"尾部\"的元素总是指向\"头部\"的main_arena. 所以, 这类似于一个FIFO的队列: /* Add the new arena to the global list. */ a-\u003enext = main_arena.next; /* FIXME: The barrier is an attempt to synchronize with read access in reused_arena, which does not acquire list_lock while traversing the list. */ atomic_write_barrier (); main_arena.next = a; arena的复用 或者, 如果没办法创建新的arena了(和系统有关), 那么就会考虑复用, 调用reused_arena, 大致流程是: 获取arena链表头部节点: /* FIXME: Access to next_to_use suffers from dat","date":"2022-03-30","objectID":"/202203/glibc-malloc2/:1:2","tags":["Linux","glibc"],"title":"glibc-malloc源码阅读二","uri":"/202203/glibc-malloc2/"},{"categories":["操作系统","glibc"],"content":"fastbin 先来看free是怎么工作的: 一下是free的一部分, 如果是mmap的内存, 那么unmmap就好了: p = mem2chunk (mem); if (chunk_is_mmapped (p)) /* release mmapped memory. */ { /* See if the dynamic brk/mmap threshold needs adjusting. Dumped fake mmapped chunks do not affect the threshold. */ if (!mp_.no_dyn_threshold \u0026\u0026 chunksize_nomask (p) \u003e mp_.mmap_threshold \u0026\u0026 chunksize_nomask (p) \u003c= DEFAULT_MMAP_THRESHOLD_MAX \u0026\u0026 !DUMPED_MAIN_ARENA_CHUNK (p)) { mp_.mmap_threshold = chunksize (p); mp_.trim_threshold = 2 * mp_.mmap_threshold; LIBC_PROBE (memory_mallopt_free_dyn_thresholds, 2, mp_.mmap_threshold, mp_.trim_threshold); } munmap_chunk (p); return; } 如果不是mmap的内存, 而是从malloc_state获取的: ar_ptr = arena_for_chunk (p); _int_free (ar_ptr, p, 0); 现在走到_int_free里面: if ((unsigned long)(size) \u003c= (unsigned long)(get_max_fast ()) { //... unsigned int idx = fastbin_index(size); fb = \u0026fastbin (av, idx); /* Atomically link P to its fastbin: P-\u003eFD = *FB; *FB = P; */ mchunkptr old = *fb, old2; //... p-\u003efd = old2 = old; //... } 如果当前chunk的size小于fastbin的最大size, 那么就需要塞入到fastbin. 先根据size找到对应的fastbin, 然后把当前chunk塞入到头节点即可. 这里可以得到关于fastbin的几个信息: fastbin是单向链表 fastbin中每个bin中的chunk大小相等 fastbin对应小内存 ","date":"2022-03-30","objectID":"/202203/glibc-malloc2/:1:3","tags":["Linux","glibc"],"title":"glibc-malloc源码阅读二","uri":"/202203/glibc-malloc2/"},{"categories":["操作系统","glibc"],"content":"unsorted_bin 跟着_int_free继续走, 如果需要释放的chunk比fastbin的最大大小还要大, 则会尝试合并: else if (!chunk_is_mmapped(p)) { //... // 获取下一个chunk nextchunk = chunk_at_offset(p, size); // 拿到下一个chunk的size nextsize = chunksize(nextchunk); /* consolidate backward */ // 如果上一个chunk可被访问, 合并上一个chunk到当前chunk if (!prev_inuse(p)) { // 获取上一个chunk的大小 prevsize = prev_size (p); // 扩充当前chunk的size size += prevsize; // 获取上一个chunk的位置 p = chunk_at_offset(p, -((long) prevsize)); if (__glibc_unlikely (chunksize(p) != prevsize)) malloc_printerr (\"corrupted size vs. prev_size while consolidating\"); // 将上一个chunk从arena中移除(因为被合并到当前chunk了) unlink_chunk (av, p); } //... // 下一个chunk同理, 但是需要考虑是不是在top, 以下假设下一个chunk也合并了 // 合并后的chunk插入到unsorted_bin的头部 bck = unsorted_chunks(av); fwd = bck-\u003efd; if (__glibc_unlikely (fwd-\u003ebk != bck)) malloc_printerr (\"free(): corrupted unsorted chunks\"); p-\u003efd = fwd; p-\u003ebk = bck; if (!in_smallbin_range(size)) { p-\u003efd_nextsize = NULL; p-\u003ebk_nextsize = NULL; } bck-\u003efd = p; fwd-\u003ebk = p; // 设置新chunk的size set_head(p, size | PREV_INUSE); set_foot(p, size); } 现在可以知道了, unsorted_bin在调用free的时候可能会被扩充, 同时, 可能会将待free的chunk的上一个和下一个合并成一个大的chunk, 一起塞入unsorted_bin. 并且unsorted_bin是一个双向链表, 且只有一个. 但是, 如果上述假设的\"下一个chunk也合并\"不成立, 那么就不会将合并后的chunk(当前和上一个)塞入unsorted_bin, 因为top是比较特殊的结构, 详细见源码. 如果合并后的chunk太大了, 这时候就可以怀疑可能存在较大的内存碎片, 这时候就需要尝试释放部分内存了, 首先就是判断合并后的大小是否大过阈值, 以减少系统调用的次数, 如果大于阈值, 那么先把fastbin合并了. 为什么要合并fastbin才能缩减内存? 我的理解是: free之后, 内存要不就放到了fastbin, 要不就是unsorted_bin(unmmap的就不在考虑范围了), 假设要缩减内存, 那么也就只能在这两个bin中, 另外, 如果要缩减, 那也只能从堆的头部开始缩减, 但是又没法知道包含头部内存区域的chunk在哪个bin中, 又不可能在这时候合并所有的bin(比如把unsorted_bin也给合并成一个, 但是这样效率太低), 所以退而求其次, 先合并fastbin, 以增大扩充top chunk的可能性, 以达到尽可能缩减更大堆的目的. if ((unsigned long)(size) \u003e= FASTBIN_CONSOLIDATION_THRESHOLD) { if (atomic_load_relaxed (\u0026av-\u003ehave_fastchunks)) malloc_consolidate(av); //...... 之后调用systrim(mp_.top_pad, av);或heap_trim(heap, mp_.top_pad);来缩减堆. ","date":"2022-03-30","objectID":"/202203/glibc-malloc2/:1:4","tags":["Linux","glibc"],"title":"glibc-malloc源码阅读二","uri":"/202203/glibc-malloc2/"},{"categories":["操作系统","glibc"],"content":"smallbin和largebin 现在回过去看_int_malloc就比较容易理解了, 我们跳过从fastbin或者smallbin或者largebin中拿chunk的部分, 如果上面说的几个bin中没有chunk怎么办? 那就从unsorted_bin中找.(对应上一篇未完成的第四部分) 先是判断unsorted_bin中是不是有chunk: while ((victim = unsorted_chunks (av)-\u003ebk) != unsorted_chunks (av)) 然后拿到unsorted_bin的最后一个chunk和倒数第二个chunk: // bck表示上一个chunk bck = victim-\u003ebk; size = chunksize (victim); mchunkptr next = chunk_at_offset (victim, size); 如果unsorted_bin只有一个chunk(就没必要查找了), 并且当前需求的是一个small chunk, 并且需求的大小比这个chunk的大小还小一些, 那么就裁剪这个chunk, 然后放回需要的部分: // 检查大小以及unsorted_bin中chunk是不是只有一个 if (in_smallbin_range (nb) \u0026\u0026 // 判断unsorted_chunks中只有一个chunk bck == unsorted_chunks (av) \u0026\u0026 victim == av-\u003elast_remainder \u0026\u0026 (unsigned long) (size) \u003e (unsigned long) (nb + MINSIZE)) { /* split and reattach remainder */ // 只分配需要的大小 remainder_size = size - nb; // 多余的部分继续塞在unsorted_chunks remainder = chunk_at_offset (victim, nb); unsorted_chunks (av)-\u003ebk = unsorted_chunks (av)-\u003efd = remainder; av-\u003elast_remainder = remainder; remainder-\u003ebk = remainder-\u003efd = unsorted_chunks (av); if (!in_smallbin_range (remainder_size)) { remainder-\u003efd_nextsize = NULL; remainder-\u003ebk_nextsize = NULL; } // 设置chunk信息 set_head (victim, nb | PREV_INUSE | (av != \u0026main_arena ? NON_MAIN_ARENA : 0)); set_head (remainder, remainder_size | PREV_INUSE); set_foot (remainder, remainder_size); check_malloced_chunk (av, victim, nb); void *p = chunk2mem (victim); alloc_perturb (p, bytes); return p; } 不过, 这里还是没有smallbin什么事, 下次free的时候, 这个chunk又被还给unsorted_bin了. 继续往下看: 如果上面的不满足, 那先把这个chunk从unsorted_bin拿出来: unsorted_chunks (av)-\u003ebk = bck; bck-\u003efd = unsorted_chunks (av); 如果大小正好满足, 那直接返回, 否则: 如果chunk的size在smallbin的范围, 那先找到smallbin对应大小chunk的位置(largebin类似): if (in_smallbin_range (size)) { victim_index = smallbin_index (size); bck = bin_at (av, victim_index); fwd = bck-\u003efd; } else { //... //largebin的塞入位置是有序的, 会判断当前chunk的size而返回不同的插入部位 //总之, 这一步之后, largebin会变得有序 } 然后把当前chunk塞进去: mark_bin (av, victim_index); victim-\u003ebk = bck; victim-\u003efd = fwd; fwd-\u003ebk = victim; bck-\u003efd = victim; 但是现在并不会立即退出上文说的while循环, 而是直到达到最大的循环次数或者unsorted_bin中找到了需求的元素(只有一个chunk且大小满足或者大小刚好合适)或者unsorted_bin的所有元素都被塞入了smallbin或者largebin: #define MAX_ITERS 10000 if (++iters \u003e= MAX_ITERS) break; 以上, 假设没从unsorted_bin中找到合适的目标, 那么这时候unsorted_bin中所有的chunk都被填入了smallbin或者largebin了. 现在开始从这两个bin中查找: 首先是largebin: if (!in_smallbin_range (nb)) { /* skip scan if empty or largest chunk is too small */ if ((victim = first (bin)) != bin \u0026\u0026 (unsigned long) chunksize_nomask (victim) \u003e= (unsigned long) (nb)) { victim = victim-\u003ebk_nextsize; while (((unsigned long) (size = chunksize (victim)) \u003c (unsigned long) (nb))) victim = victim-\u003ebk_nextsize; //... if (remainder_size \u003c MINSIZE) { //... } /* Split */ else { //... } //... } } 不需要过多关注查找逻辑, 以上表达的是, 从largebin中找chunk, 是需要找最小的适合大小, 如果最终找到的目标还是太大了, 那么会裁剪, 多余的部分放在remainder表中, 这部分逻辑与上文是类似的. 如果上部分还是没有找到, 那么就一个一个遍历后续的bin(因为bin是按照大小排序的, 这部分代码省略), 先找到有chunk的bin, 然后找满足chunk大小的目标, 类似上述逻辑, 如果没有大很多, 则直接返回, 如果大很多, 那么先裁切, 多余部分串在remainder表中. 这部分逻辑就不继续追究了. 如果还是没找到!!! 那么尝试使用top的内存(堆顶内存), 如果top内存满足, 同样是裁切然后返回, 如果不满足, 那么检查是否可以合并fastbin, 如果可以合并, 那么就合并, 再继续查找(回到unsorted_bin, 再重复上述逻辑), 如果没有fastbin, 那么就扩展当前arena, 然后直接返回一个chunk, 如下: victim = av-\u003etop; size = chunksize (victim); if (__glibc_unlikely (size \u003e av-\u003esystem_mem)) malloc_printerr (\"malloc(): corrupted top size\"); if ((unsigned long) (size) \u003e= (unsigned long) (nb + MINSIZE)) { remainder_size = size - nb; remainder = chunk_at_offset (victim, nb); av-\u003etop = remainder; set_head (victim, nb | PREV_INUSE | (av != \u0026main_arena ? NON_MAIN_ARENA : 0)); set_head (remainder, remainder_size | PREV_INUSE); check_malloced_chunk (av, victim, nb); void *p = chunk2mem (victim); alloc_perturb (p, bytes); return p; } /* When we are using atomic ops to free fast chunks we can get here for all block sizes. */ else if (atomic_load_relaxed (\u0026av-\u003ehave_fastchunks)) { malloc_consolidate (av); /* restore original bin index */ if (in_smallbin_range (nb)) idx = smallbin_index (nb); else idx = largebin_index (nb); } /* Otherwise, relay to handle system-dep","date":"2022-03-30","objectID":"/202203/glibc-malloc2/:1:5","tags":["Linux","glibc"],"title":"glibc-malloc源码阅读二","uri":"/202203/glibc-malloc2/"},{"categories":["操作系统","glibc"],"content":"tcache 略.(TODO:待补充) ","date":"2022-03-30","objectID":"/202203/glibc-malloc2/:1:6","tags":["Linux","glibc"],"title":"glibc-malloc源码阅读二","uri":"/202203/glibc-malloc2/"},{"categories":["操作系统","glibc"],"content":"总结 先来回答最开始的问题: tcache: 略 fastbin: 单向链表, 存放小内存, 每个bin中的size相同, free的时候小内存直接还给fastbin, malloc的时候小内存也可以从fastbin获取 smallbin: 双向链表, 存放介于fastbin和largebin大小之间的内存, bin有大小顺序, bin中的chunk没有大小顺序, 可以通过unsorted_bin扩充；largebin同smallbin, 但是每个bin的chunks也是有大小序的 unsorted_bin: 类似回收机制, free的时候比fastbin大的chunk(mmap极大chunk除外)会被放到unsorted_bin, 并且这个chunk可能会与上一个和下一个合并后再加入unsorted_bin, fastbin在某个阈值之后也会被合并加入到unsorted_bin 以上如何管理？ 我的理解是fastbin/smallbin/largebin用于获取内存(unsorted_bin也有概率直接返回给用户内存), fastbin/unsorted_bin用于回收内存, 但是如果发现回收内存太大时, 则可能会通过trim缩减内存 以上什么关系？ 同上 bin是怎么初始化的？ 首先, arena的初始化也伴随着bin的初始化, 所以进程/线程初次调用malloc的时候, 就会初始化bin了, 如果各种bin(或者说arena)不满足需求了, 则还会通过sysmalloc扩充bin(或arena) bin是怎么扩充的，可以扩充吗？ 同上, 但是bin的数量是固定的, bin中的chunk的数量未见有限制 malloc的一般故事流程是(要说清楚每一个case的话, 太复杂了, 所以以下是我认为比较通常的情况): 启动进程, 调用malloc malloc init, 初始化main arena 通过各种bin没有找到需要的chunk, 扩充bin, 返回一个chunk 调用free 回收内存, 如果是很小的内存, 则暂存在fastbin, 如果是比较大的内存, 则与相邻内存合并后放入unsorted_bin 再调用malloc 如果发现fastbin符合要求, 则直接返回fastbin的内存 如果发现smallbin/largebin符合要求, 则返回对应内存 如果以上都不满足, 则从unsorted_bin中将内存搬运到smallbin/largebin后, 再从这两个bin中查找 重复以上步骤4~9, 发现回收的内存很大, 则尝试缩减内存 启动了一个新的线程 从free list尝试获取一个arena, 如果没法获取, 创建一个新的arena, 线程独立使用, 所以几乎无需担心竞争 如果不允许创建新的arena了, 则尝试复用\"最老\"的一个arena, 需要当心竞争, 所以会阻塞 线程退出, 检查对应的arena, 如果计数器为0了, 那么将对应arena加入free list ","date":"2022-03-30","objectID":"/202203/glibc-malloc2/:1:7","tags":["Linux","glibc"],"title":"glibc-malloc源码阅读二","uri":"/202203/glibc-malloc2/"},{"categories":["操作系统","glibc"],"content":"在上一篇中，我们了解到了mmap的一些性质和基本原理： 分配的是虚拟内存 通过红黑树找到目标内存块，并且通过红黑树管理 分配的内存可能比实际需要的大 是阻塞的 会有内存对齐 本篇将了解到malloc和mmap的关系，以及解答我在mmap学习中产生的一个疑问：mmap会不会导致内存碎片？（因为mmap的内存看起来是被内核维护的红黑树管理了，所以我理解不会存在内存碎片。） ","date":"2022-03-25","objectID":"/202203/glibc-malloc/:0:0","tags":["Linux","glibc"],"title":"glibc-malloc源码阅读","uri":"/202203/glibc-malloc/"},{"categories":["操作系统","glibc"],"content":"概述 以下是malloc.c中关于malloc的一小段概述： The main properties of the algorithms are: * For large (\u003e= 512 bytes) requests, it is a pure best-fit allocator, with ties normally decided via FIFO (i.e. least recently used). * For small (\u003c= 64 bytes by default) requests, it is a caching allocator, that maintains pools of quickly recycled chunks. * In between, and for combinations of large and small requests, it does the best it can trying to meet both goals at once. * For very large requests (\u003e= 128KB by default), it relies on system memory mapping facilities, if supported. 有些地方可能不理解，先看代码吧～ ","date":"2022-03-25","objectID":"/202203/glibc-malloc/:1:0","tags":["Linux","glibc"],"title":"glibc-malloc源码阅读","uri":"/202203/glibc-malloc/"},{"categories":["操作系统","glibc"],"content":"__libc_malloc void * __libc_malloc (size_t bytes) { mstate ar_ptr; void *victim; void *(*hook) (size_t, const void *) = atomic_forced_read (__malloc_hook); if (__builtin_expect (hook != NULL, 0)) return (*hook)(bytes, RETURN_ADDRESS (0)); #if USE_TCACHE /* int_free also calls request2size, be careful to not pad twice. */ size_t tbytes; checked_request2size (bytes, tbytes); size_t tc_idx = csize2tidx (tbytes); MAYBE_INIT_TCACHE (); DIAG_PUSH_NEEDS_COMMENT; if (tc_idx \u003c mp_.tcache_bins /*\u0026\u0026 tc_idx \u003c TCACHE_MAX_BINS*/ /* to appease gcc */ \u0026\u0026 tcache \u0026\u0026 tcache-\u003eentries[tc_idx] != NULL) { return tcache_get (tc_idx); } DIAG_POP_NEEDS_COMMENT; #endif if (SINGLE_THREAD_P) { victim = _int_malloc (\u0026main_arena, bytes); assert (!victim || chunk_is_mmapped (mem2chunk (victim)) || \u0026main_arena == arena_for_chunk (mem2chunk (victim))); return victim; } arena_get (ar_ptr, bytes); victim = _int_malloc (ar_ptr, bytes); /* Retry with another arena only if we were able to find a usable arena before. */ if (!victim \u0026\u0026 ar_ptr != NULL) { LIBC_PROBE (memory_malloc_retry, 1, bytes); ar_ptr = arena_get_retry (ar_ptr, bytes); victim = _int_malloc (ar_ptr, bytes); } if (ar_ptr != NULL) __libc_lock_unlock (ar_ptr-\u003emutex); assert (!victim || chunk_is_mmapped (mem2chunk (victim)) || ar_ptr == arena_for_chunk (mem2chunk (victim))); return victim; } ","date":"2022-03-25","objectID":"/202203/glibc-malloc/:2:0","tags":["Linux","glibc"],"title":"glibc-malloc源码阅读","uri":"/202203/glibc-malloc/"},{"categories":["操作系统","glibc"],"content":"hook 以上第一段是调用hook函数，也就是说malloc默认是提供hook接口的，只要实现了hook接口，malloc就可以变成对应的hook函数。 void *(*hook) (size_t, const void *) = atomic_forced_read (__malloc_hook); if (__builtin_expect (hook != NULL, 0)) return (*hook)(bytes, RETURN_ADDRESS (0)); __malloc_hook的默认值是指向的malloc_hook_ini，如下，malloc_hook_ini会给__malloc_hook赋空，所以malloc_hook_ini可以相当于就是__libc_malloc： static void * malloc_hook_ini (size_t sz, const void *caller) { __malloc_hook = NULL; ptmalloc_init (); return __libc_malloc (sz); } ","date":"2022-03-25","objectID":"/202203/glibc-malloc/:2:1","tags":["Linux","glibc"],"title":"glibc-malloc源码阅读","uri":"/202203/glibc-malloc/"},{"categories":["操作系统","glibc"],"content":"tcache 第二部分是tcache，暂且不用过分追究（因为内容比较多，虽然目前malloc可能依赖于tcache，但是即使不学习tcache也不太影响对malloc的理解）： #if USE_TCACHE /* int_free also calls request2size, be careful to not pad twice. */ size_t tbytes; checked_request2size (bytes, tbytes); size_t tc_idx = csize2tidx (tbytes); MAYBE_INIT_TCACHE (); DIAG_PUSH_NEEDS_COMMENT; if (tc_idx \u003c mp_.tcache_bins /*\u0026\u0026 tc_idx \u003c TCACHE_MAX_BINS*/ /* to appease gcc */ \u0026\u0026 tcache \u0026\u0026 tcache-\u003eentries[tc_idx] != NULL) { return tcache_get (tc_idx); } DIAG_POP_NEEDS_COMMENT; #endif 两个宏如下： #define request2size(req) \\ (((req) + SIZE_SZ + MALLOC_ALIGN_MASK \u003c MINSIZE) ? \\ MINSIZE : \\ ((req) + SIZE_SZ + MALLOC_ALIGN_MASK) \u0026 ~MALLOC_ALIGN_MASK) #define checked_request2size(req, sz) \\ ({ \\ (sz) = request2size (req); \\ if (((sz) \u003c (req)) \\ || REQUEST_OUT_OF_RANGE (sz)) \\ { \\ __set_errno (ENOMEM); \\ return 0; \\ } \\ }) 如上，先是内存对齐，得到tbytes，然后根据tbytes计算出来一个下标tc_idx，然后就可以根据下标去tcache里面找了。 tcache的基本定义如下： /* We overlay this structure on the user-data portion of a chunk when the chunk is stored in the per-thread cache. */ typedef struct tcache_entry { struct tcache_entry *next; /* This field exists to detect double frees. */ struct tcache_perthread_struct *key; } tcache_entry; /* There is one of these for each thread, which contains the per-thread cache (hence \"tcache_perthread_struct\"). Keeping overall size low is mildly important. Note that COUNTS and ENTRIES are redundant (we could have just counted the linked list each time), this is for performance reasons. */ typedef struct tcache_perthread_struct { char counts[TCACHE_MAX_BINS]; tcache_entry *entries[TCACHE_MAX_BINS]; } tcache_perthread_struct; static __thread bool tcache_shutting_down = false; static __thread tcache_perthread_struct *tcache = NULL; 可以知道几点： tcache是每个线程维护的 tcache是一个链表结构 在malloc中，通过tcache_get接口从tcache中获取了一块buffer，实现如下： /* Caller must ensure that we know tc_idx is valid and there's available chunks to remove. */ static __always_inline void * tcache_get (size_t tc_idx) { tcache_entry *e = tcache-\u003eentries[tc_idx]; assert (tc_idx \u003c TCACHE_MAX_BINS); assert (tcache-\u003ecounts[tc_idx] \u003e 0); tcache-\u003eentries[tc_idx] = e-\u003enext; --(tcache-\u003ecounts[tc_idx]); e-\u003ekey = NULL; return (void *) e; } 大概意思是，拿tcache的第tc_idx个作为输出，然后将原本第tc_idx的entry指向当前需要输出的entry的下一个，这意味着tcache里面不同的entry也可能指向同一个，然后再把对应的第tc_idx的count--。 再看一下和get对应的put操作： /* Caller must ensure that we know tc_idx is valid and there's room for more chunks. */ static __always_inline void tcache_put (mchunkptr chunk, size_t tc_idx) { tcache_entry *e = (tcache_entry *) chunk2mem (chunk); assert (tc_idx \u003c TCACHE_MAX_BINS); /* Mark this chunk as \"in the tcache\" so the test in _int_free will detect a double free. */ e-\u003ekey = tcache; e-\u003enext = tcache-\u003eentries[tc_idx]; tcache-\u003eentries[tc_idx] = e; ++(tcache-\u003ecounts[tc_idx]); } 恩！可以和get对应起来了，get的时候第tc_idx的entry被指向了下一个，在put的时候就可以记住下一个的位置，然后put的时候将tc_idx指回去就行了，所以链表又恢复到了原状。 这里有个疑问：entry的状态是怎么记录的？比如get的时候发送一个entry出去，那么free的时候怎么记得这个buffer的大小/来源等等之类的呢？可以想到一些类比结构，比如： task_struct和thread_info的内存关系（这里） class中type_info和类的内存关系（这里） 实际上，tcache entry的“头上”还有一块内存空间，在那里记录了malloc内存的一些状态信息。在这里可以看到详细的内存分布。 以上，我们大概了解到了malloc以及tcache： malloc可以从tcache中直接拿到内存 tcache可以用作缓存内存，也就是内存可以不立即交还给系统 tcache相当于是一个内存池，并且由每个线程维护 malloc的内存比实际需要的内存大 以上默认情况是可以从tcache中获取内存，如果不可以或者里面没有内存呢？ ","date":"2022-03-25","objectID":"/202203/glibc-malloc/:2:2","tags":["Linux","glibc"],"title":"glibc-malloc源码阅读","uri":"/202203/glibc-malloc/"},{"categories":["操作系统","glibc"],"content":"_int_malloc 如果上述条件不满足，__libc_malloc后续的主要逻辑就是调用_int_malloc函数，如下： arena_get (ar_ptr, bytes); victim = _int_malloc (ar_ptr, bytes); 第一部分 第一部分可能调用sysmalloc，其中会使用mmap或者brk分配内存。只有av为空的时候才可能进入这一段，av什么时候可能为空？在线程第一次调用malloc之前，av可能为空。这时候通过系统调用申请一块比较大的内存，然后再执行某种分配，填充到av，所以此后，部分内存可以直接通过av获取，而不需要频繁执行系统调用了。（sysmalloc不是系统调用） /* There are no usable arenas. Fall back to sysmalloc to get a chunk from mmap. */ if (__glibc_unlikely (av == NULL)) { void *p = sysmalloc (nb, av); if (p != NULL) alloc_perturb (p, bytes); return p; } 第二部分 第二部分代码很多，只看外部的一点： if ((unsigned long) (nb) \u003c= (unsigned long) (get_max_fast ())) { idx = fastbin_index (nb); mfastbinptr *fb = \u0026fastbin (av, idx); //... void *p = chunk2mem (victim); alloc_perturb (p, bytes); return p; //... } 只有在申请的内存小于get_max_fast ()的时候才可能进入。类似的，我们可以看到有fastbin这样的结构，和上文中看到的tcache一样，会有专门的表维护fastbin，并且其中储存的是较小的内存。 从fastbin这中拿到内存后，通过chunk2mem转换成用户可用的内存（实际上就是往高字节取）。 第三部分 /* If a small request, check regular bin. Since these \"smallbins\" hold one size each, no searching within bins is necessary. (For a large request, we need to wait until unsorted chunks are processed to find best fit. But for small ones, fits are exact anyway, so we can check now, which is faster.) */ if (in_smallbin_range (nb)) { idx = smallbin_index (nb); bin = bin_at (av, idx); //...... void *p = chunk2mem (victim); alloc_perturb (p, bytes); return p; //...... } /* If this is a large request, consolidate fastbins before continuing. While it might look excessive to kill all fastbins before even seeing if there is space available, this avoids fragmentation problems normally associated with fastbins. Also, in practice, programs tend to have runs of either small or large requests, but less often mixtures, so consolidation is not invoked all that often in most programs. And the programs that it is called frequently in otherwise tend to fragment. */ else { idx = largebin_index (nb); if (atomic_load_relaxed (\u0026av-\u003ehave_fastchunks)) malloc_consolidate (av); } 同理，如果fastbin的大小不满足要求，那么就在smallbin里面去找。 如果smallbin还不满足要求，那么认为需要一个large的内存，这时候会先将fastbin中的小内存合并。其目的是减少内存碎片化（brk内存容易产生碎片，mmap内存不产生碎片，一般情况下只有大内存才会使用mmap申请，比如128KB以上）。 合并到哪里呢？看malloc_consolidate大概是会合并到一个叫unsorted_bin的bin里面去。 第四部分 源码 （看不懂了！！！） 遗留问题是（TODO）： tcache fastbin smallbin unsorted_bin 以上如何管理？ 以上什么关系？ bin是怎么初始化的？ bin是怎么扩充的，可以扩充吗？ ","date":"2022-03-25","objectID":"/202203/glibc-malloc/:2:3","tags":["Linux","glibc"],"title":"glibc-malloc源码阅读","uri":"/202203/glibc-malloc/"},{"categories":["操作系统","glibc"],"content":"总结 尽管没全部看懂，不过也了解malloc的一些事情： malloc可以尽可能减少通过系统调用分配内存 malloc可以尽可能减少内存碎片 malloc在用户态管理内存（区别于mmap的rb_tree） malloc申请内存可能通过“内存池”直接返回，也有可能会通过系统调用返回，一般取决于需要的内存大小 malloc可能存在内存合并的过程 malloc管理的内存数量以及大小是有限的（通过idx的计算方式可以推断出） malloc管理的内存是按线程区分的，所以多线程情况下不存在阻塞 malloc分配虚拟内存的时候，实际的会比需求的更多（物理内存也会更多，因为需要有存放状态的内存，这时候是已经缺页中断了） free回收内存不一定直接交还给系统，可能会交由tcache或者bin管理，这是用户态的 ","date":"2022-03-25","objectID":"/202203/glibc-malloc/:2:4","tags":["Linux","glibc"],"title":"glibc-malloc源码阅读","uri":"/202203/glibc-malloc/"},{"categories":["随笔"],"content":"本来年初想写写2021这一年的总结，但总归是没有写。最近和家人聊天，聊到了最近心态上的一些变化，直到现在才想到，可以总结总结我工作之后的心态变化（可能是个流水账），期望以后再看的时候，也可以作为参考或者反面教材吧~ ","date":"2022-03-22","objectID":"/202203/work-summary-1922/:0:0","tags":["工作"],"title":"这两年工作心态上的一些变化","uri":"/202203/work-summary-1922/"},{"categories":["随笔"],"content":"刚参加工作 我刚找工作时是奔着梦想去的。 依稀还记得当时校招去公司面试，打车去的，司机竟然就是我老乡，他和我聊天，但是我不太会聊，所以可能聊的不是很顺畅，下车时他祝我面试顺利，很感动，所以现在还记得那副场景。 最终面试过程还算顺利，最后面试官问了我学历，因为学历达不到要求，就调剂到软件岗了。当时offer还没有给我，现在也忘记抱有多大的期望了。记得那时候还在等这家公司的offer，这期间我也收到了另外一家竞争对手公司的offer，但是对现在公司还是很喜欢，所以在没有收到现在公司offer的情况下，我拒签了另外一家。幸好如愿。 大四毕业之后入职了。还记得入职第一天我穿的黑色衬衫，没有穿运动裤（以前日常基本只穿运动裤），平时走路可能会有点驼背，但是那天我有意识的挺起腰背，展现我的精气神。 作为一个刚入职场，刚真正进入社会的新人，现在感觉我一切都小心翼翼。当时办公室是桶装水，每次没水的时候就会记起家里给我讲的故事，在职场看见没水了啊，地上有垃圾啊之类的，要主动去做（父母没有工作，但是总归是长辈的建议）。嗯，当时的我会很主动的去换水，不过现在可能不会了，因为现在会担心被说作。那时候的我问问题不敢问，当心被认为能力不够而被辞退，但是又不敢太过表现自己，当心被认为太爱表现，一切都要表现得有礼貌，要谨慎。就算有些问题我知道，但是如果公司老人在讲的话，还是要假装不知道，总之，想尽一切办法把自己伪装起来，害怕刚入职就被讨厌。不过当时并不觉得累，可能步入社会就这样吧。 写道这里，想想当时可能真的太累了，可能从小养成的自卑的习惯吧，不过最幸福的事情就是无知，那时候不会这样觉得，充满干劲。 那时候是我的一个老乡带我接触项目的，很感激他，他不只是说告诉项目怎么怎么做，还会故意出一些问题给我思考。入职大概一个月（或者一周），因为项目上一些比较麻烦的地方，开发了一个小工具，还得到了一些表扬，当时挺高兴的。不过，我不会聊，不会职场。老大夸我，我也不懂得怎么夸回去，到现在，我也不太懂得怎么夸人。 半年后，过年回家。 家里人很自然得就会问我工作的情况。有些会问工资多少，会问什么工作内容，我都“交代”了，除了问我有没有对象的问题我没有“老实交代”。 令我印象深刻的是，有人问我为什么不去另外一家公司，“他们工资高呀”。我说，“因为价值观不一样”。然后他们笑了。当时我心里还是有点气氛的，凭什么笑我。然后还把公司的价值观背诵给他们听，什么“xxxx做朋友”，什么“xxxx享受科技xxxx”，什么“xx、热爱”。他们说我被洗脑了，但是那时候我不以为然。 ","date":"2022-03-22","objectID":"/202203/work-summary-1922/:1:0","tags":["工作"],"title":"这两年工作心态上的一些变化","uri":"/202203/work-summary-1922/"},{"categories":["随笔"],"content":"工作一年半 其实在前半年的工作后心态上就有一些变化了，好的方向。我不再那么自卑，不再有那么多的在乎（除了害怕被讨厌）。想起今年和我叔聊天的时候他说的，“这个社会就是这样，你有他妈的两百万的时候就是会自信”。从学校出来，家里给了一些钱来到这个城市，然后再也不向家里要钱，还给家里输出了，虽然没多少钱，但总归自信了。不过，这也是初生牛犊不怕虎。 工作这件事情上，我认为我从来找不到诀窍，现在也是。只会埋头干，这是好的，也是不好的。如果我还是学生，我肯定会很自得。学生那段时间我很喜欢林清玄，埋头干这种事情我认为很符合他的心态呀！与世无争，自己干自己的。但是毕竟是社会人，而且团队中其实不能有太多我这样的人。 工作上我的效率很高，从这两年多的经历来看是组内新人最高的，前半年就接手了一个项目，然后年后新人来了，我开始把工作交接给他。 大概是在debug的时候又遇到了项目上的一些效率问题，然后就着手写了一个软件。偷偷摸摸写的，因为害怕被说我摸鱼。 具体花费时间已经不记得了，从开始到完成到进入维护期大概花了半年吧，一边做项目，累的时候就偷摸摸写这个软件。本来只是打算自用，然后想着如果开发出去可以节约公司很多人力成本，就慢慢做大一点。到软件可以用起来比较舒服的时候，我就在组内发布了，这个时间大概是四个月？然后这个软件慢慢就被推广了整个大组，然后到整个部门，其他部门也有在使用。后来老大知道了这个项目，这个软件可以推广到整个部门使用也是老大说的，他让我发邮件广而告之，这个项目大概是我们组对部门输出的第一个产品。不过此后他也基本没有管这个项目了。 在上面这个软件开发期间，老板和他身边的几个人找我想开发另一个应用。相当于是一个全栈应用，完成可以大量节约开发人员的分析时间。 我当然不能拒绝，也就接下，并且完成了。本来只是适配本组的需求，后来在需求review的时候，老大们也提出了一些意见，然后我改了接口和实现，到目前为止，这个项目适配好几种算法，也推广到了整个部门，跨组使用了。这相当于是我们组第二个对部门输出的产品。根据这个项目，老大也让我在部门露露脸了，这样至少可以混个脸熟（但是我其实并没有把握住，emmm估计现在没人认识我吧~）。 大概花了大半年的时间在上面这两个应用的开发上。我认为积极作用是扩展了我们组的业务面，不在只是局限于业务代码了。包括现在，组内有时候也会考虑一些业务之外的东西。（哈哈哈，其实我自认我的作用还是挺大的~~~）。但是不好的地方是，我被贴上了不喜欢业务的标签，我确实不喜欢，但是交给我的工作从来都能好好完成，也从不会拒绝。在上述开发期间，也承接了两个大方向的业务需求，按照我目前的经验来看，很多同级的同事一次也只做一个业务需求，所以做得确实不少，输出甚至数一数二。 在业务需求这件事上我确实很感谢他们可以让我做这些业务，通过那大半年的业务开发，我认为我的成长很大。不过成长也分很多种，具体来说，那段时间可能对事情规划、代码风格的提升都是不少的，对工作的项目框架熟悉度的提升也非常非常大，奠定了我现在的基础。啰嗦一句，我那一年在项目上的提升比后来很多新人一年半到两年的提升还要大。（不过现在带的一个新人感觉业务能力很强的~） 这时候我在想，上面写的好像我都是一个弱者的角色…到底工作上有没有什么地方没有做好的？可能人都这样？自动忽略自己差的一面了？想到一个： 再说上面两个独立项目。虽然做了，但是其实深度不够。很多时候我的心态都是实现就好了，不会去研究原因或者原理，主要还是因为现在主业不是这方面，所以只能浅尝辄止了，不然就是不务正业了。所以，尽管用到了QT啊、Flask啊、D3js啊这些，要问我的话，还是不知道的，需要去查API才会使。以及用到Javascript、Python这些语言，也都很肤浅，只会写一点，不懂原理，远不及C/C++这么熟悉。 年中的时候拿到了不错的绩效，当时的我确实很有干劲，拿到这个绩效心里也是符合预期的吧。 年终则因为年中给了所以就是非常普通的绩效。 ","date":"2022-03-22","objectID":"/202203/work-summary-1922/:2:0","tags":["工作"],"title":"这两年工作心态上的一些变化","uri":"/202203/work-summary-1922/"},{"categories":["随笔"],"content":"工作两年半 写这篇文章的时候是工作两年半多了。 心态变差主要是从去年开始的。其实上面说了一些业务上的事情，很快就能入手，也就说明了一个问题，我们的业务可能比较简单。这也是我入职大概一年后一直思考的问题。竟然我能很快入手，我也观察了一些其他的新同事，也不算慢，总归能慢慢接手项目的。另外就是相对于后台开发呀，图像算法呀这些，我所在的行业我不认为有核心技术。可能很像嵌入式开发，但是我们比嵌入式上层得多，却也不及应用那么上层，所以我们是“不接触底层硬件的嵌入式”–BSP软件工程师。如果硬要说核心技术，可能就是熟悉某套框架。如果追求高一点，就是会懂一些硬件的执行流程。但是毕竟不接触硬件，只是了解罢了。 所以我开始焦虑了。我的核心竞争力是什么？我的核心技术是什么？ 如果说熟悉某某框架，我还是觉得太拿不出手了，这东西基本一年一换，尽管趋于稳定，但是换个乙方，嗯，你就没用了（不同乙方实现可以说完全不一样，底层硬件流程也是完全不一样的），只能用几年积累下来的，可怜的debug经验获取优势。这也说明，这个行业在不考虑一些人际交往因素上，基本就是靠资历向上爬的。所以那段时间开始审视自己，我整理了笔记，想起了可以搭建一个博客来记录我的成长，然后将以前整理成博文的内容放到了这个网站上。 没有明确的目标，我就好好打牢基础。所以从那时候开始，我开始刷题，开始重新学习算法知识（后来也写过一篇博文表达我对这件事的看法）。不过也是那时候开始，业务上的事情没有那么上心了（其实我个人认为还是比较上心的，只是在完成业务之后，我会花很多时间在其他事情上，而不是用来进一步熟悉业务，所以老大们开始评价我不太喜欢做业务）。 看着周边同事都只埋头干自己的，我坐不住了。在我眼里，重复做业务上的事情，对外界的发展一无所知，我很担心自己就废了。尽管周围同事对我技术上的评价还不错，但是我开始怀疑了。一个怀疑是他们的客套话，一个怀疑是眼界不够。所以我写了简历。想让外界知道我，想知道我在外界的水平到底怎么样。在知乎上，我找到一位看着还不错的同学，简历发他问问意见。大概回答是，“有大厂经验，但是你做的什么我们不知道，因为是你们的专业内容”。没有得到我期望方向的评价。 大概金三银四的时候，我投简历，想面试看看自己水平怎么样。投了两家，面试都没通过。这对我很有打击。 能力不行，我还能干嘛？在这里是不是就行温水煮青蛙了，我跳不出去了？那一整年，心态开始爆炸，开始怀疑自己。当时约的HR，本来约大约3个月之后继续面，我爽约了，推来推去。因为太害怕失败了。 刷了越多的题（虽然就一两百道），看了越多的底层代码，我就会越觉得自己是井底之蛙。守着自己的一亩三分地，写业务代码，写应用…写得再多，也就是像一个机器人，不了解，不知道原理，不知道底层，就知道这么写就可以这么工作了。黑盒确实不错，但是把所有的事情都当作黑盒，那可被替代性太强了。 基础很重要，非常非常重要！现在意识到可能有点晚了（我认为在大学的时候就应该清楚的认识到这一点，但是我没有），但是也有人说，亡羊补牢，为时不晚。 这一年来，看了很多东西，做了不少题，我有种成仙了的感觉，不太好描述，就是真的觉得我是个仙人…(小时候洗完澡，涂完沐浴露，身上干干净净还香香的时候，也会有一种成仙的感觉，就是这种感觉。) 技术上我变得不一样了，和同事讨论问题的时候我会开始借助学习的一些知识去思考了。比如有些bug，我能意识到栈溢出了；我能意识到为什么框架的数据要这么这么传递了；写代码的时候也会下意识分析分析复杂度了；如果是需要发布出去的，我不会再乱写代码，会参考有没有这样的案例，用老大的话说就是不要走野路子。 总结这一年就是我的基础提高了很多，并且我认为这是正确的路子，会坚持走下去的。 再说到负面情绪的变化，主要有几点。 一是太在意得失，但是我不认为我错了，家里条件不是很好，又是独生子，不得不在意这些东西，不然怎么养活我自己，怎么结婚，怎么养活我父母？而且，虽然在意得失，我也只想得到我该得到的，而不是因为老大的一句话说，“不能把好处都给你”，“我只能是相对的公平”就不给我，但是和他走的近的人却可以比我们容易的得到比我们更多，不该给我的从来没想过要。但是我又想多说，这就是社会吧。我从没和老大说过我需要什么什么，他给了我就接着，他说今年不能给你的时候，我也是笑嘻嘻的答应着。所以，在别人眼里我多半会是个傻子。不爽的想法只能心里闷着，说给别人听，也解决不了。 二是上文说的焦虑，害怕自己变废，但是因为在这里工作，我也不能改变很多，有时候就容易越来越焦躁，越想跳出去，但就是出不去。 三是自己和同事的原因。我觉得这很重要。有人提醒我同事就是同事，但是我有时候把同事当作朋友了。因为都是应届生，都刚参加工作，所以我对他们没有任何防备。也就是那时候，我们什么都会说（准确是我对他们什么都会说），经常吐槽啊，发表不满啊，说着说着，负面情绪就上来了，越积累越多，把自己搞坏了。还有就是，我以前把他们当作朋友，所以期望把我知道的信息共享给他们，至少让他们知道可以得到什么，但是他们不会。这是我现在才知道的，说不上瞒着我，但是也在假装什么都没有，他们没必要告诉我，可能我有点自作多情吧。不过意识到了也不算晚，同事就当作同事吧，要不要成为朋友，就顺气自然。网上说的什么需要保密啊，什么不要告诉他们呀，这是对的。 （TODO，明天继续，感觉我与世界为敌） ","date":"2022-03-22","objectID":"/202203/work-summary-1922/:3:0","tags":["工作"],"title":"这两年工作心态上的一些变化","uri":"/202203/work-summary-1922/"},{"categories":["Cpp"],"content":"在C++中推荐使用nullptr代表空指针，虽然我一直坚持这个原则，但是实际开发中没有遇到非nullptr不可的情况，直到写了以下代码（已脱敏）： template \u003ctypename F, typename... Args\u003e using func_t = typename std::result_of\u003cF(Args...)\u003e::type; template \u003ctypename F, typename... Args, typename Rp = func_t\u003cF, Args...\u003e, bool is_void_v = std::is_void\u003cRp\u003e::value\u003e inline Rp call(F \u0026\u0026func, Args \u0026\u0026...args) { //... } ","date":"2022-03-21","objectID":"/202203/null-nullptr-problem/:0:0","tags":["指针","Cpp"],"title":"NULL和nullptr实际问题分析","uri":"/202203/null-nullptr-problem/"},{"categories":["Cpp"],"content":"问题 这段代码的目的是期望通过call调用一些方法，然后可以对这些方法做一些其他处理。然后假设如此调用： typedef void* handle; int AlgoProcess(handle p) { //processing return 0; } call(AlgoProcess, NULL); 编译时会报错，提示matching function。可能有如下报错信息： no type named 'type' in 'std::result_of\u003cint (\u0026(long))(void *)\u003e' 关注以上报错信息，可以知道是result_of匹配报错，这里将输入参数NULL解析为了long类型，但是AlgoProcess需求参数是void *类型，所以类型不匹配，又因为没有其他匹配项了，所以编译报错(SFINAE)。 只需要将NULL改成nullptr就可以编译通过，因为nullptr是可以匹配指针的。 call(AlgoProcess, nullptr); 那么新问题来了，到底应该不应该为用户匹配一个NULL的版本呢？ 因为在大型项目里面无法保证每个用户都会按照你的需要输入nullptr。不过幸好这是编译期的错误，对产品的影响不大。 如果要匹配一个NULL版本应该怎么做？此时需要考虑到和long的输入类型做区分。 ","date":"2022-03-21","objectID":"/202203/null-nullptr-problem/:1:0","tags":["指针","Cpp"],"title":"NULL和nullptr实际问题分析","uri":"/202203/null-nullptr-problem/"},{"categories":["Cpp"],"content":"nullptr原理 NULL的原理好理解，是一个宏，值是void* (0)或者0。 nullptr的实现原理是什么？超出了我的能力范围，找到过一些用类模拟nullptr的资料，但是都不太符合我的要求，以下文章讲的应该是比较正确的（看不懂…）。总结一句话就是nullptr依赖编译器的词法、语法和语义支持。 nullptr底层实现原理是什么？ - 蓝色的回答 - 知乎 ","date":"2022-03-21","objectID":"/202203/null-nullptr-problem/:2:0","tags":["指针","Cpp"],"title":"NULL和nullptr实际问题分析","uri":"/202203/null-nullptr-problem/"},{"categories":["Cpp"],"content":"结论 小心使用NULL，因为NULL可能会被解析为整形而不是指针类型，因而导致与指针类型不匹配等问题。那么，如果想表示空指针，就坚持使用nullptr吧～（Effective C++中也有此推荐。） ","date":"2022-03-21","objectID":"/202203/null-nullptr-problem/:3:0","tags":["指针","Cpp"],"title":"NULL和nullptr实际问题分析","uri":"/202203/null-nullptr-problem/"},{"categories":["操作系统","glibc"],"content":"本篇通过学习mmap的实现，将帮助解答《进程控制和通信(四) · PCB介绍 》中的一些问题，以及加深对虚拟内存的理解。 ","date":"2022-02-28","objectID":"/202202/glibc-mmap/:0:0","tags":["Linux","glibc"],"title":"glibc-mmap源码阅读","uri":"/202202/glibc-mmap/"},{"categories":["操作系统","glibc"],"content":"入口mmap 先看mmap的入口，首先是检查一个PAGE的大小以及偏移offset是不是满足要求，然后再系统调用mmap(2)。 void * __mmap (void *addr, size_t len, int prot, int flags, int fd, off_t offset) { MMAP_CHECK_PAGE_UNIT (); if (offset \u0026 MMAP_OFF_LOW_MASK) return (void *) INLINE_SYSCALL_ERROR_RETURN_VALUE (EINVAL); #ifdef __NR_mmap2 return (void *) MMAP_CALL (mmap2, addr, len, prot, flags, fd, offset / (uint32_t) MMAP2_PAGE_UNIT); #else return (void *) MMAP_CALL (mmap, addr, len, prot, flags, fd, MMAP_ADJUST_OFFSET (offset)); #endif } weak_alias (__mmap, mmap) libc_hidden_def (__mmap) 首先关注PAGE和offset的检查部分： MMAP_CHECK_PAGE_UNIT (); if (offset \u0026 MMAP_OFF_LOW_MASK) return (void *) INLINE_SYSCALL_ERROR_RETURN_VALUE (EINVAL); 对应的宏如下： /* This is the minimum mmap2 unit size accept by the kernel. An architecture with multiple minimum page sizes (such as m68k) might define it as -1 and thus it will queried at runtime. */ #ifndef MMAP2_PAGE_UNIT # define MMAP2_PAGE_UNIT 4096ULL #endif #if MMAP2_PAGE_UNIT == -1 static uint64_t page_unit; # define MMAP_CHECK_PAGE_UNIT() \\ if (page_unit == 0) \\ page_unit = __getpagesize (); # undef MMAP2_PAGE_UNIT # define MMAP2_PAGE_UNIT page_unit #else # define MMAP_CHECK_PAGE_UNIT() #endif 一般设置一个PAGE的大小是4096，但是也支持动态获取，通过__getpagesize可以实时地动态获取PAGE大小。 MMAP_OFF_LOW_MASK表示PAGE的大小减一，例如PAGE大小是4096，那么对应的MMAP2_PAGE_UNIT就是4095，转换成二进制就是(011111111111)。 /* Do not accept offset not multiple of page size. */ #define MMAP_OFF_LOW_MASK (MMAP2_PAGE_UNIT - 1) 为什么MMAP_OFF_LOW_MASK要表示为MMAP2_PAGE_UNIT - 1？ 如果PAGE一定是2^n大小，那么MMAP2_PAGE_UNIT的表示一定是后缀若干个1。用offset \u0026 MMAP_OFF_LOW_MASK判断，如果表达式为true，则表示offset末尾有1，那么它一定不是PAGE的整数倍；如果offset不是PAGE的整数倍，那么offset \u0026 MMAP_OFF_LOW_MASK一定为true吗？（是不是充要条件？）如果前提是，PAGE的大小一定是2^n，那么上述表述成立。可以大概证明一下： 如果offset不是PAGE的整数倍，假设offset的值是n × PAGE + m，n和m都是整数，且m \u003c PAGE。因为PAGE是2^n，二进制表示的首个数位是1, 末尾有若刚个连续的0，例如100000000000，所以n × PAGE末尾连续0的个数大于或等于PAGE末尾连续0的个数。又因为m \u003c PAGE，所以m的二进制数位长度小于PAGE末尾连续0的长度，这就会导致n × PAGE + m末尾连续0的个数小于PAGE末尾连续0的个数，因此offset \u0026 MMAP_OFF_LOW_MASK为true。 ","date":"2022-02-28","objectID":"/202202/glibc-mmap/:1:0","tags":["Linux","glibc"],"title":"glibc-mmap源码阅读","uri":"/202202/glibc-mmap/"},{"categories":["操作系统","glibc"],"content":"系统调用 ","date":"2022-02-28","objectID":"/202202/glibc-mmap/:2:0","tags":["Linux","glibc"],"title":"glibc-mmap源码阅读","uri":"/202202/glibc-mmap/"},{"categories":["操作系统","glibc"],"content":"do_mmap2 以下是mmap(2)系统调用，都指向了do_mmap2这个函数： #define PAGE_SHIFT 12 SYSCALL_DEFINE6(mmap2, unsigned long, addr, size_t, len, unsigned long, prot, unsigned long, flags, unsigned long, fd, unsigned long, pgoff) { return do_mmap2(addr, len, prot, flags, fd, pgoff, PAGE_SHIFT-12); } SYSCALL_DEFINE6(mmap, unsigned long, addr, size_t, len, unsigned long, prot, unsigned long, flags, unsigned long, fd, off_t, offset) { return do_mmap2(addr, len, prot, flags, fd, offset, PAGE_SHIFT); } do_mmap2如下，也会检查offset对齐之类，主要关注ksys_mmap_pgoff。 static inline long do_mmap2(unsigned long addr, size_t len, unsigned long prot, unsigned long flags, unsigned long fd, unsigned long off, int shift) { long ret = -EINVAL; if (!arch_validate_prot(prot, addr)) goto out; if (shift) { if (off \u0026 ((1 \u003c\u003c shift) - 1)) goto out; off \u003e\u003e= shift; } ret = ksys_mmap_pgoff(addr, len, prot, flags, fd, off); out: return ret; } ","date":"2022-02-28","objectID":"/202202/glibc-mmap/:2:1","tags":["Linux","glibc"],"title":"glibc-mmap源码阅读","uri":"/202202/glibc-mmap/"},{"categories":["操作系统","glibc"],"content":"ksys_mmap_pgoff ksys_mmap_pgoff如下： unsigned long ksys_mmap_pgoff(unsigned long addr, unsigned long len, unsigned long prot, unsigned long flags, unsigned long fd, unsigned long pgoff) { struct file *file = NULL; //...... if (!(flags \u0026 MAP_ANONYMOUS)) { audit_mmap_fd(fd, flags); file = fget(fd); if (!file) return -EBADF; if (is_file_hugepages(file)) len = ALIGN(len, huge_page_size(hstate_file(file))); retval = -EINVAL; if (unlikely(flags \u0026 MAP_HUGETLB \u0026\u0026 !is_file_hugepages(file))) goto out_fput; } else if (flags \u0026 MAP_HUGETLB) { struct user_struct *user = NULL; struct hstate *hs; hs = hstate_sizelog((flags \u003e\u003e MAP_HUGE_SHIFT) \u0026 MAP_HUGE_MASK); if (!hs) return -EINVAL; len = ALIGN(len, huge_page_size(hs)); /* * VM_NORESERVE is used because the reservations will be * taken when vm_ops-\u003emmap() is called * A dummy user value is used because we are not locking * memory so no accounting is necessary */ file = hugetlb_file_setup(HUGETLB_ANON_FILE, len, VM_NORESERVE, \u0026user, HUGETLB_ANONHUGE_INODE, (flags \u003e\u003e MAP_HUGE_SHIFT) \u0026 MAP_HUGE_MASK); if (IS_ERR(file)) return PTR_ERR(file); } //...... retval = vm_mmap_pgoff(file, addr, len, prot, flags, pgoff); //...... } 大致三个过程： 检查和设置flag 内存对齐 执行vm_mmap_pgoff 检查和设置flag阶段，我比较关注MAP_HUGETLB，这是Linux提供的大PAGE支持，在man7中可以找到大概的介绍，在HUGE PAGE模式下，可以支持2MB甚至1GB大小的PAGE！大PAGE可以减少IO访问的次数，同时也会带来大量的内存碎片。在《为什么 Linux 默认页大小是 4KB》中，作者有介绍PAGE不同大小的影响。 ","date":"2022-02-28","objectID":"/202202/glibc-mmap/:2:2","tags":["Linux","glibc"],"title":"glibc-mmap源码阅读","uri":"/202202/glibc-mmap/"},{"categories":["操作系统","glibc"],"content":"vm_mmap_pgoff 下面是vm_mmap_pgoff，这里比较接近mmap的本质了，current-\u003emm拿到了当前进程的内存映射结构： unsigned long vm_mmap_pgoff(struct file *file, unsigned long addr, unsigned long len, unsigned long prot, unsigned long flag, unsigned long pgoff) { unsigned long ret; struct mm_struct *mm = current-\u003emm; unsigned long populate; LIST_HEAD(uf); ret = security_mmap_file(file, prot, flag); if (!ret) { if (down_write_killable(\u0026mm-\u003emmap_sem)) return -EINTR; ret = do_mmap_pgoff(file, addr, len, prot, flag, pgoff, \u0026populate, \u0026uf); up_write(\u0026mm-\u003emmap_sem); userfaultfd_unmap_complete(mm, \u0026uf); if (populate) mm_populate(ret, populate); } return ret; } 大概分作以下几步： 检查文件安全性 mmap加锁 mmap映射 mmap解锁 （还有populate等步骤，不太明白，但是不影响对mmap的基本了解，所以本文不过分追究。不过，有机会我还是得去了解了解的～～～基础不太行，先把这些基本的问题搞清楚吧～） mmap加锁和解锁逻辑不需要过分关注，只需要知道rw_semaphore是个读写信号量，在这里实现了类似锁的功能，应该是为了保证数据一致性。 ","date":"2022-02-28","objectID":"/202202/glibc-mmap/:2:3","tags":["Linux","glibc"],"title":"glibc-mmap源码阅读","uri":"/202202/glibc-mmap/"},{"categories":["操作系统","glibc"],"content":"do_mmap mmap映射步骤调用的是do_mmap_pgoff，如下，指向的是do_mmap： static inline unsigned long do_mmap_pgoff(struct file *file, unsigned long addr, unsigned long len, unsigned long prot, unsigned long flags, unsigned long pgoff, unsigned long *populate, struct list_head *uf) { return do_mmap(file, addr, len, prot, flags, 0, pgoff, populate, uf); } do_mmap如下，摘取了部分片段： /* * The caller must hold down_write(\u0026current-\u003emm-\u003emmap_sem). */ unsigned long do_mmap(struct file *file, unsigned long addr, unsigned long len, unsigned long prot, unsigned long flags, vm_flags_t vm_flags, unsigned long pgoff, unsigned long *populate, struct list_head *uf) { struct mm_struct *mm = current-\u003emm; //...... /* Obtain the address to map to. we verify (or select) it and ensure * that it represents a valid section of the address space. */ addr = get_unmapped_area(file, addr, len, pgoff, flags); if (offset_in_page(addr)) return addr; //...... addr = mmap_region(file, addr, len, vm_flags, pgoff, uf); //...... } 先是检查和修改prot和flags，这里就不追究这些逻辑了。然后会做内存对齐，检查是否溢出，检查mapping count是不是满了（意味着mapping数量是有限的，为什么要有限呢？）之类的。 接着通过get_unmapped_area获取一个unmapped的地址，除了溢出检查外，get_unmapped_area大致流程如下： get_area = current-\u003emm-\u003eget_unmapped_area; if (file) { if (file-\u003ef_op-\u003eget_unmapped_area) get_area = file-\u003ef_op-\u003eget_unmapped_area; } else if (flags \u0026 MAP_SHARED) { /* * mmap_region() will call shmem_zero_setup() to create a file, * so use shmem's get_unmapped_area in case it can be huge. * do_mmap_pgoff() will clear pgoff, so match alignment. */ pgoff = 0; get_area = shmem_get_unmapped_area; } addr = get_area(file, addr, len, pgoff, flags); 如果传入了一个文件，那么用文件对应的get_unmapped_area获取地址，或者利用进程的get_unmapped_area或者利用shmem_get_unmapped_area。现在，我们的疑问是，文件或者进程等的get_unmapped_area是怎么mapping出一块地址给我们的？ 找到这么一段arch_get_unmapped_area，arch_get_unmapped_area会被赋值给current-\u003emm-\u003eget_unmapped_area： unsigned long arch_get_unmapped_area(struct file *filp, unsigned long addr, unsigned long len, unsigned long pgoff, unsigned long flags) { struct mm_struct *mm = current-\u003emm; struct vm_area_struct *vma; struct vm_unmapped_area_info info; unsigned long begin, end; addr = mpx_unmapped_area_check(addr, len, flags); if (IS_ERR_VALUE(addr)) return addr; if (flags \u0026 MAP_FIXED) return addr; find_start_end(addr, flags, \u0026begin, \u0026end); if (len \u003e end) return -ENOMEM; if (addr) { addr = PAGE_ALIGN(addr); vma = find_vma(mm, addr); if (end - len \u003e= addr \u0026\u0026 (!vma || addr + len \u003c= vm_start_gap(vma))) return addr; } info.flags = 0; info.length = len; info.low_limit = begin; info.high_limit = end; info.align_mask = 0; info.align_offset = pgoff \u003c\u003c PAGE_SHIFT; if (filp) { info.align_mask = get_align_mask(); info.align_offset += get_align_bits(); } return vm_unmapped_area(\u0026info); } 主要逻辑是vm_unmapped_area，在调用vm_unmapped_area之前，会获取虚拟内存的开始地址和结束地址，然后写入vm_unmapped_area_info再传入vm_unmapped_area。 下面是vm_unmapped_area的实现： unsigned long unmapped_area(struct vm_unmapped_area_info *info) { //...... vma = rb_entry(mm-\u003emm_rb.rb_node, struct vm_area_struct, vm_rb); if (vma-\u003erb_subtree_gap \u003c length) goto check_highest; //...... while (true) { /* Visit left subtree if it looks promising */ gap_end = vm_start_gap(vma); if (gap_end \u003e= low_limit \u0026\u0026 vma-\u003evm_rb.rb_left) { struct vm_area_struct *left = rb_entry(vma-\u003evm_rb.rb_left, struct vm_area_struct, vm_rb); if (left-\u003erb_subtree_gap \u003e= length) { vma = left; continue; } } //...... } found: /* We found a suitable gap. Clip it with the original low_limit. */ if (gap_start \u003c info-\u003elow_limit) gap_start = info-\u003elow_limit; /* Adjust gap address to the desired alignment */ gap_start += (info-\u003ealign_offset - gap_start) \u0026 info-\u003ealign_mask; VM_BUG_ON(gap_start + info-\u003elength \u003e info-\u003ehigh_limit); VM_BUG_ON(gap_start + info-\u003elength \u003e gap_end); return gap_start; } 这里的rb前缀是指红黑树，使用红黑树来管理VMA（Virtual Memory Area）。 先是判断当前进程的虚拟内存块是不是有一个大于或等于length大小的，只有满足这个条件，才会继续向下寻找。然后在VMA红黑树的左树找到最左侧的一个满足内存块gap大于或等于length的虚拟内存块，此时可以满足这个内存块是RB树里面最小的满足大于或等于length大小的内存块。 这里存在一些盲区： VMA红黑树怎么构建的？什么时候构建的？ 虚拟内存都是按块分配的吗？ 最后是mmap_region： addr = mmap_region(file, addr, l","date":"2022-02-28","objectID":"/202202/glibc-mmap/:2:4","tags":["Linux","glibc"],"title":"glibc-mmap源码阅读","uri":"/202202/glibc-mmap/"},{"categories":["操作系统","glibc"],"content":"遗留问题 VMA如何构建已经构建时机 现代一般架构下（比如X86，ARM等），CPU（加上Cache）可以直接操作硬盘吗？还是必须经过RAM？mmap可以虚拟地址直接映射到硬盘吗？还是必须经过RAM？ malloc等和mmap的关联和区别 ","date":"2022-02-28","objectID":"/202202/glibc-mmap/:3:0","tags":["Linux","glibc"],"title":"glibc-mmap源码阅读","uri":"/202202/glibc-mmap/"},{"categories":["操作系统","glibc"],"content":"番外 我最开始的疑问是，页表是如何构建以及怎么使用的？ 因为我们使用的是虚拟内存，并且已经知道进程的内存在mm_struct管理，但是mm_struct也是虚拟内存上的，也就是说，如果要找到某个进程的页表，首先得找到这个进程的mm_struct，因为虚拟内存的映射是不定的，那么得有一个先对固定的地址，使得内核可以找到进程的页表。 在mmap这一篇中，没能解答这个问题，但是查阅一些资料了解到： mm_struct结构体中的pgd_t * pgd;代表的是物理地址，pgd指向的就是当前进程的页表，是物理内存上的。那么，只要拿到了pgd，就可以拿到当前进程的也表了。又因为，task_struct是内核管理的，内核的也表是固定的/事先知道的（这一点没有疑问，不然内核启动不了），所以每个进程的task_struct又是可以在物理内存上找到的，进而每个进程的mm_struct也是在物理内存上可以找到的（通过内核可以找到）。 所以，进程也表加载流程可以是： 切换进程 找到pgd 通过pgd的物理地址，在内存上找到当前进程的页表 MMU工作等 ","date":"2022-02-28","objectID":"/202202/glibc-mmap/:4:0","tags":["Linux","glibc"],"title":"glibc-mmap源码阅读","uri":"/202202/glibc-mmap/"},{"categories":["操作系统","glibc"],"content":"总结 期望本文可以加深大家对虚拟内存的理解，以上内容加上《进程控制和通信(四) · PCB介绍 》，我有以下结论： 进程的页表储存在物理内存上，通过pgd代表的物理地址可以找到 mm_struct表示的是虚拟内存的地址，比如数据段/代码段等等，再通过页表映射到物理内存上 Linux内核使用红黑树管理了内存块，mmap是在这些内存块上映射的 mmap会有很多内存对齐的检查，在使用传入参数的时候，最好也要考虑对齐 mmap是会阻塞的，会有读写信号量 mmap分配的虚拟内存空间可能比实际需要的大 mmap可能会失败，比如内存不足 ","date":"2022-02-28","objectID":"/202202/glibc-mmap/:5:0","tags":["Linux","glibc"],"title":"glibc-mmap源码阅读","uri":"/202202/glibc-mmap/"},{"categories":["操作系统","glibc"],"content":"上一篇《glibc-fopen源码阅读》讲到了fopen是怎么工作的，以及FILE是怎么和文件关联起来的。但是再次阅读之后，发现还是有些细节存在疑问： 系统调用openat怎么就拿到了fd？ struct file怎么和文件内容关联起来的，什么时候关联起来的？ 带着以上疑问，继续阅读系统的open类函数。不过仅了解fopen也是可以的，并不影响对glibc的文件打开过程的理解。 ","date":"2022-02-22","objectID":"/202202/fopen-sys-open/:0:0","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读-补充篇-open系统调用","uri":"/202202/fopen-sys-open/"},{"categories":["操作系统","glibc"],"content":"系统调用open 上篇已经说到，fopen最终通过系统调用openat拿到了文件的fd，并且将fd放到了FILE的_fileno成员中： int __libc_open64 (const char *file, int oflag, ...) { int mode = 0; if (__OPEN_NEEDS_MODE (oflag)) { va_list arg; va_start (arg, oflag); mode = va_arg (arg, int); va_end (arg); } return SYSCALL_CANCEL (openat, AT_FDCWD, file, oflag | EXTRA_OPEN_FLAGS, mode); } ","date":"2022-02-22","objectID":"/202202/fopen-sys-open/:1:0","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读-补充篇-open系统调用","uri":"/202202/fopen-sys-open/"},{"categories":["操作系统","glibc"],"content":"openat fopen最终走到的系统调用是openat，openat调用的是do_sys_open，对fopen来说，调用openat和open是一样的： SYSCALL_DEFINE3(open, const char __user *, filename, int, flags, umode_t, mode) { if (force_o_largefile()) flags |= O_LARGEFILE; return do_sys_open(AT_FDCWD, filename, flags, mode); } SYSCALL_DEFINE4(openat, int, dfd, const char __user *, filename, int, flags, umode_t, mode) { if (force_o_largefile()) flags |= O_LARGEFILE; return do_sys_open(dfd, filename, flags, mode); } open和openat指向的都是do_sys_open这个函数，下面来看do_sys_open： long do_sys_open(int dfd, const char __user *filename, int flags, umode_t mode) { struct open_flags op; int fd = build_open_flags(flags, mode, \u0026op); struct filename *tmp; if (fd) return fd; tmp = getname(filename); if (IS_ERR(tmp)) return PTR_ERR(tmp); fd = get_unused_fd_flags(flags); if (fd \u003e= 0) { struct file *f = do_filp_open(dfd, tmp, \u0026op); if (IS_ERR(f)) { put_unused_fd(fd); fd = PTR_ERR(f); } else { fsnotify_open(f); fd_install(fd, f); } } putname(tmp); return fd; } 初看可以分为几个部分： 建立open flag 获取name（什么name？） 获取fd 打开文件 通知file system 将文件注册到进程 下面逐个分析。 ","date":"2022-02-22","objectID":"/202202/fopen-sys-open/:1:1","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读-补充篇-open系统调用","uri":"/202202/fopen-sys-open/"},{"categories":["操作系统","glibc"],"content":"build_open_flags 先是根据不同情况设置不同的open flag，我认为这里不是重点，稍微看看就好了，不过注意一下O_TMPFILE_MASK（因为最近用到了tmpfile这个函数…），有些情况是会直接返回一个错误码的。所以，fd相关的返回值，如果是负数则表示发生错误，可以从其返回值大致判断错误类型。 static inline int build_open_flags(int flags, umode_t mode, struct open_flags *op) { // ...... if (flags \u0026 __O_TMPFILE) { if ((flags \u0026 O_TMPFILE_MASK) != O_TMPFILE) return -EINVAL; if (!(acc_mode \u0026 MAY_WRITE)) return -EINVAL; } else if (flags \u0026 O_PATH) { /* * If we have O_PATH in the open flag. Then we * cannot have anything other than the below set of flags */ flags \u0026= O_DIRECTORY | O_NOFOLLOW | O_PATH; acc_mode = 0; } // ...... return 0; } ","date":"2022-02-22","objectID":"/202202/fopen-sys-open/:1:2","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读-补充篇-open系统调用","uri":"/202202/fopen-sys-open/"},{"categories":["操作系统","glibc"],"content":"getname getname会返回一个filename的结构体，所以先来看看filename结构体： struct filename { const char *name; /* pointer to actual string */ const __user char *uptr; /* original userland pointer */ int refcnt; struct audit_names *aname; const char iname[]; }; audit对应的是linux审计系统相关，就先不理它了。其余注意到filename结构体主要是存储了一些字符串，大概可以猜想到是存储的文件路径相关的字符串。但是为什么需要这么多成员来存储呢？ 再看getname函数指向的getname_flags，这里或许可以找到filename的一些原理： struct filename * getname_flags(const char __user *filename, int flags, int *empty) { //...... const size_t size = offsetof(struct filename, iname[1]); kname = (char *)result; /* * size is chosen that way we to guarantee that * result-\u003einame[0] is within the same object and that * kname can't be equal to result-\u003einame, no matter what. */ result = kzalloc(size, GFP_KERNEL); if (unlikely(!result)) { __putname(kname); return ERR_PTR(-ENOMEM); } result-\u003ename = kname; len = strncpy_from_user(kname, filename, PATH_MAX); //....... result-\u003erefcnt = 1; //...... result-\u003euptr = filename; result-\u003eaname = NULL; audit_getname(result); return result; } kname指向的是filename结构体的第一个成员，它会alloc一段空间，下面是关于kzalloc函数的描述： /* * kmalloc is the normal method of allocating memory * for objects smaller than page size in the kernel. */ static __always_inline void *kmalloc(size_t size, gfp_t flags); static inline void *kzalloc(size_t size, gfp_t flags) { return kmalloc(size, flags | __GFP_ZERO); } 现在可以知道，filename结构体的name成员指向了kmalloc申请的一块内存，这块内存的最大空间是1Page，这也就是为什么会有PATH_MAX这个系统宏了，其对应大小是4096，在我的系统上就是一个Page的大小。 len = strncpy_from_user(kname, filename, PATH_MAX); result-\u003erefcnt = 1; result-\u003euptr = filename; 以上，filename结构体的name成员指向了自己分配的一块内存，其内容是filename这个字符串的拷贝，uptr成员则指向了filename这个字符串，refcnt成员被置为1。但是，现在还没回答上面的问题，为什么filename结构体会有两个成员来存储同一个字符串？ 可以大概猜想一下，调用完open之后，filename字符串因为是用户申请的，所以可能被回收，如果后续还在使用的话就存在越界的可能，所以需要一块额外的空间存储filename字符串，所以就自己申请一块了。后续还会用到filename结构体的name成员。 ","date":"2022-02-22","objectID":"/202202/fopen-sys-open/:1:3","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读-补充篇-open系统调用","uri":"/202202/fopen-sys-open/"},{"categories":["操作系统","glibc"],"content":"get_unused_fd_flags get_unused_fd_flags调用的是__alloc_fd函数，这里注意到current，先前已经介绍过，代表当前的task_struct，所以这里拿到了当前进程的files，在《进程控制和通信(四) · PCB介绍 》中已经讲过task_struct和files的关系了。 int get_unused_fd_flags(unsigned flags) { return __alloc_fd(current-\u003efiles, 0, rlimit(RLIMIT_NOFILE), flags); } 下面是摘取自__alloc_fd的一些语句： fdt = files_fdtable(files); fd = start; if (fd \u003c files-\u003enext_fd) fd = files-\u003enext_fd; if (fd \u003c fdt-\u003emax_fds) fd = find_next_fd(fdt, fd); //...... error = expand_files(files, fd); /* * If we needed to expand the fs array we * might have blocked - try again. */ if (error) goto repeat; if (start \u003c= files-\u003enext_fd) files-\u003enext_fd = fd + 1; __set_open_fd(fd, fdt); // ...... 可以知道，__alloc_fd的大致过程： 获取fdtable 找到一个可用的fd 如果没有可用的fd，则尝试扩展fdtable（参考《进程控制和通信(四) · PCB介绍 》） 扩展后在尝试找一个可用的fd 找fd成功，设置fdtable对应bit位 目前为止，文件还是没有被打开，也没有对filename指向的文件做任何操作。不过，fd和filename结构体准备好后，就可以打开文件了。 ","date":"2022-02-22","objectID":"/202202/fopen-sys-open/:1:4","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读-补充篇-open系统调用","uri":"/202202/fopen-sys-open/"},{"categories":["操作系统","glibc"],"content":"do_filp_open 以下是do_filp_open函数： struct file *do_filp_open(int dfd, struct filename *pathname, const struct open_flags *op) { struct nameidata nd; int flags = op-\u003elookup_flags; struct file *filp; set_nameidata(\u0026nd, dfd, pathname); filp = path_openat(\u0026nd, op, flags | LOOKUP_RCU); if (unlikely(filp == ERR_PTR(-ECHILD))) filp = path_openat(\u0026nd, op, flags); if (unlikely(filp == ERR_PTR(-ESTALE))) filp = path_openat(\u0026nd, op, flags | LOOKUP_REVAL); restore_nameidata(); return filp; } 这个函数看着比较简单，大概是先通过filename得到一个nameidata的结构体，然后就用这个nameidata生成了一个struct file。 nameidata是什么？还是先来看看这个结构体的成员： struct nameidata { struct path path; struct qstr last; struct path root; struct inode *inode; /* path.dentry.d_inode */ unsigned int flags; unsigned seq, m_seq; int last_type; unsigned depth; int total_link_count; struct saved { struct path link; struct delayed_call done; const char *name; unsigned seq; } *stack, internal[EMBEDDED_LEVELS]; struct filename *name; struct nameidata *saved; struct inode *link_inode; unsigned root_seq; int dfd; } __randomize_layout; 我认为重要的就是两个inode，一个是dentry的inode，一个是link_inode。 set_nameidata只是大概填写nameidata的一些基础信息，关于inode的部分这里并没有填写。 static void set_nameidata(struct nameidata *p, int dfd, struct filename *name) { struct nameidata *old = current-\u003enameidata; p-\u003estack = p-\u003einternal; p-\u003edfd = dfd; p-\u003ename = name; p-\u003etotal_link_count = old ? old-\u003etotal_link_count : 0; p-\u003esaved = old; current-\u003enameidata = p; } 所以，接下来需要关注path_openat函数是怎么填写nameidata的： file = alloc_empty_file(op-\u003eopen_flag, current_cred()); error = do_o_path(nd, flags, file); 摘取了一些语句，大致过程如上，先是申请了一个空的struct file，根据alloc_empty_file的输入参数，也大概可以看出，alloc_empty_file只是申请了一个结构体之类的内存，不会真正打开文件（因为没有路径等信息输入）。然后是do_o_path（这里有多个类似的函数入口，仅挑选do_o_path追踪）： static int do_o_path(struct nameidata *nd, unsigned flags, struct file *file) { struct path path; int error = path_lookupat(nd, flags, \u0026path); if (!error) { audit_inode(nd-\u003ename, path.dentry, 0); error = vfs_open(\u0026path, file); path_put(\u0026path); } return error; } 大概是两步： int error = path_lookupat(nd, flags, \u0026path); error = vfs_open(\u0026path, file); 在path_lookupat的时候会填写nameidata的inode等成员，因此，path_lookupat之后可以通过nameidata拿到文件的dentry信息了，在dentry的inode表里就可以找到文件对应的inode。 然后通过vfs_open打开文件，拿到文件的inode等信息填写到struct file结构体中。不同的vfs会有对应的open方法，vfs_open指向的do_dentry_open方法中，就会使用文件所在vfs的open方法来打开文件。 到目前为止，已经打开文件，拿到文件的inode等信息，并且写入struct file了。 do_filp_open过程 ","date":"2022-02-22","objectID":"/202202/fopen-sys-open/:1:5","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读-补充篇-open系统调用","uri":"/202202/fopen-sys-open/"},{"categories":["操作系统","glibc"],"content":"fsnotify_open 略。（这部分有机会单独讲，关于Linux文件事件） fsnotify_open过程 ","date":"2022-02-22","objectID":"/202202/fopen-sys-open/:1:6","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读-补充篇-open系统调用","uri":"/202202/fopen-sys-open/"},{"categories":["操作系统","glibc"],"content":"fd_install 文件已经打开了，怎么让进程拥有这个文件呢？并且我们已经知道，文件可以通过一个fd就能打开了。关键是fd_install函数： void fd_install(unsigned int fd, struct file *file) { __fd_install(current-\u003efiles, fd, file); } 通过current可以获得当前task_struct的files_struct，进而可以获得fdtable。然后将fdtable的第fd个元素指向file这个struct file结构体。此时通过task_struct就可以找到对应的文件了，并且通过fd就能准确在fdtable中找到对应的struct file。 ","date":"2022-02-22","objectID":"/202202/fopen-sys-open/:1:7","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读-补充篇-open系统调用","uri":"/202202/fopen-sys-open/"},{"categories":["操作系统"],"content":"在《glibc-exit源码阅读》和《《UCB CS61a SICP Python 中文》一周目笔记(一)》中我们提到了栈帧的概念，但是我对这个概念越来越模糊，栈帧是什么？栈帧是不是包含了程序的执行指令？ 本文的说法或者结果可能因为不同平台或不同编译器而产生差别，但是本文的目的不是为了搞清楚某一个平台/编译器下的栈帧，而是为了搞清楚栈帧整体的概念，因此即使不同平台/编译器下，也应该不会有很大差别。 ","date":"2022-01-26","objectID":"/202201/framestack/:0:0","tags":["Linux","栈"],"title":"程序的栈帧","uri":"/202201/framestack/"},{"categories":["操作系统"],"content":"栈帧 按照约定，以下rbp表示栈底，rsp表示栈顶，栈向低地址方向增长。 来看一段代码，以下使用x86-64 clang 13.0.0版本编译，需要开启O0优化： int func(int v1, int v2, int v3, int v4, int v5, int v6, int v7, int v8, int v9, int v10) { int n1 = v1 + 1; int n10 = v10 + 1; int nv = v1 + v2 + v3 + v4 + v5 + v6 + v7 + v8 + v9 + v10; int vv[100]{1}; int vv10 = vv[10]; char cv[10] = \"hello\"; return nv; } int main() { int a = 1; int b = 10; int c = 11; func(a, 2, 3, 4, 5, 6, 7, 8, 9, b); return 1; } 得到main和func的汇编结果如下，下面来分析汇编流程。 首先看main函数的汇编： main: push rbp mov rbp,rsp sub rsp,0x30 mov DWORD PTR [rbp-0x4],0x0 mov DWORD PTR [rbp-0x8],0x1 mov DWORD PTR [rbp-0xc],0xa mov DWORD PTR [rbp-0x10],0xb mov edi,DWORD PTR [rbp-0x8] mov eax,DWORD PTR [rbp-0xc] mov esi,0x2 mov edx,0x3 mov ecx,0x4 mov r8d,0x5 mov r9d,0x6 mov DWORD PTR [rsp],0x7 mov DWORD PTR [rsp+0x8],0x8 mov DWORD PTR [rsp+0x10],0x9 mov DWORD PTR [rsp+0x18],eax call 401130 \u003cfunc(int, int, int, int, int, int, int, int, int, int)\u003e mov eax,0x1 add rsp,0x30 pop rbp ret ","date":"2022-01-26","objectID":"/202201/framestack/:1:0","tags":["Linux","栈"],"title":"程序的栈帧","uri":"/202201/framestack/"},{"categories":["操作系统"],"content":"保存栈底和扩展栈 第一步是准备操作： push rbp mov rbp,rsp sub rsp,0x30 把上一次的rbp入栈，然后把rbp的值置为rsp，也就是说，目前为止，栈底就是上一次的栈顶，然后将栈顶寄存器rsp下移0x30个字节，这里约定了，64位机上，rsp偏移需要是16的整数倍。 第一步操作就是把上一次的栈顶作为现在的栈底，然后把栈顶下移一段距离，以增加当前栈的长度。 ","date":"2022-01-26","objectID":"/202201/framestack/:1:1","tags":["Linux","栈"],"title":"程序的栈帧","uri":"/202201/framestack/"},{"categories":["操作系统"],"content":"局部变量 第二步操作初始化了一些局部变量： mov DWORD PTR [rbp-0x4],0x0 mov DWORD PTR [rbp-0x8],0x1 mov DWORD PTR [rbp-0xc],0xa mov DWORD PTR [rbp-0x10],0xb 如上，按照代码顺序，局部变量按照从高地址到低地址排列，比如rbp-0x8代表变量a，rbp-0xc代表变量b。但是也有一个问题，rbp-0x4代表的是什么？这里存在疑问，不像是为了内存对齐，因为即使我让main函数中的变量8B对齐了，这个rbp-0x4还是存在，但是使用gcc编译的话就不存在了，所以也可以暂时猜想为编译器的某优化目的。 ","date":"2022-01-26","objectID":"/202201/framestack/:1:2","tags":["Linux","栈"],"title":"程序的栈帧","uri":"/202201/framestack/"},{"categories":["操作系统"],"content":"函数入参准备 第三步是准备函数入参，准备好后就要调用函数了： mov edi,DWORD PTR [rbp-0x8] mov eax,DWORD PTR [rbp-0xc] mov esi,0x2 mov edx,0x3 mov ecx,0x4 mov r8d,0x5 mov r9d,0x6 mov DWORD PTR [rsp],0x7 mov DWORD PTR [rsp+0x8],0x8 mov DWORD PTR [rsp+0x10],0x9 mov DWORD PTR [rsp+0x18],eax 这里的计算顺序是从左往右，如果是gcc编译器，计算顺序则是从右往左，计算顺序和入参顺序在《i++和++i在函数入参时的一些问题》和《《UCB CS61a SICP Python 中文》一周目笔记(一)》有讲过。 这里还需要注意的就是这几句： mov edi,DWORD PTR [rbp-0x8] mov eax,DWORD PTR [rbp-0xc] ##... mov DWORD PTR [rsp+0x18],eax 在开始的时候就拿到了a(rbp-0x8)和b(rbp-0xc)两个变量，但是这里入参准备阶段实际只用到a，b在最后才准备好，被写入了rsp+0x18。 这里的地址也是值得关注的： mov DWORD PTR [rsp],0x7 mov DWORD PTR [rsp+0x8],0x8 mov DWORD PTR [rsp+0x10],0x9 mov DWORD PTR [rsp+0x18],eax 注意到，这部分都是用的rsp加一个偏移得到的地址，而不是rbp减偏移得到的地址，并且这些参数是被写入了内存，而前6个参数是被写入的寄存器。这里的共识是，如果函数参数个数少于6个，则使用寄存器传递，如果大于6个，则多余的参数会使用内存传递，是不是所有情况都这样，暂时不必要追究，大部分情况都是这样的。 至于为什么用rsp加一个偏移来传递参数，我认为这是编译器的优化问题，使用gcc编译器的话，就是使用push指令，相当于是使用rsp减一个偏移来传递参数。为什么说是编译器优化问题呢？看这一段： sub rsp,0x30 在开头已经分析过了，这是移动了栈顶指针，现在栈的大小是48B（如果是gcc的话，分配的是16B），对于4个int参数，3个int变量，和上述说的4B的未知空间，48B \u003e (4 * 4 + 3 * 4 + 4)B是满足要求的，所以为了利用好空间，这样操作是可能的。 ","date":"2022-01-26","objectID":"/202201/framestack/:1:3","tags":["Linux","栈"],"title":"程序的栈帧","uri":"/202201/framestack/"},{"categories":["操作系统"],"content":"函数调用 第四步就是函数调用了： call 401130 \u003cfunc(int, int, int, int, int, int, int, int, int, int)\u003e 这里call指令需要拆解一下，方便后续分析，call指令相当于： push ip jmp 401130 \u003cfunc(int, int, int, int, int, int, int, int, int, int)\u003e ","date":"2022-01-26","objectID":"/202201/framestack/:1:4","tags":["Linux","栈"],"title":"程序的栈帧","uri":"/202201/framestack/"},{"categories":["操作系统"],"content":"子函数 现在我们进入到了函数内部，回忆在这之前我们做了什么工作？ 保存了调用者的ip指针（或者叫pc指针），这里对应就是main函数中call的后一句，所以我们可以方便的恢复到jmp之后。下面来看子函数： func(int, int, int, int, int, int, int, int, int, int): push rbp mov rbp,rsp sub rsp,0x1d0 mov eax,DWORD PTR [rbp+0x28] mov eax,DWORD PTR [rbp+0x20] mov eax,DWORD PTR [rbp+0x18] mov eax,DWORD PTR [rbp+0x10] mov DWORD PTR [rbp-0x4],edi mov DWORD PTR [rbp-0x8],esi mov DWORD PTR [rbp-0xc],edx mov DWORD PTR [rbp-0x10],ecx mov DWORD PTR [rbp-0x14],r8d mov DWORD PTR [rbp-0x18],r9d mov eax,DWORD PTR [rbp-0x4] add eax,0x1 mov DWORD PTR [rbp-0x1c],eax mov eax,DWORD PTR [rbp+0x28] add eax,0x1 mov DWORD PTR [rbp-0x20],eax mov eax,DWORD PTR [rbp-0x4] add eax,DWORD PTR [rbp-0x8] add eax,DWORD PTR [rbp-0xc] add eax,DWORD PTR [rbp-0x10] add eax,DWORD PTR [rbp-0x14] add eax,DWORD PTR [rbp-0x18] add eax,DWORD PTR [rbp+0x10] add eax,DWORD PTR [rbp+0x18] add eax,DWORD PTR [rbp+0x20] add eax,DWORD PTR [rbp+0x28] mov DWORD PTR [rbp-0x24],eax lea rdi,[rbp-0x1c0] xor esi,esi mov edx,0x190 call 401030 \u003cmemset@plt\u003e mov DWORD PTR [rbp-0x1c0],0x1 mov eax,DWORD PTR [rbp-0x198] mov DWORD PTR [rbp-0x1c4],eax mov rax,QWORD PTR ds:0x402004 mov QWORD PTR [rbp-0x1ce],rax mov ax,WORD PTR ds:0x40200c mov WORD PTR [rbp-0x1c6],ax mov eax,DWORD PTR [rbp-0x24] add rsp,0x1d0 pop rbp ret cs nop WORD PTR [rax+rax*1+0x0] nop DWORD PTR [rax+rax*1+0x0] 第一步我们保存了rbp寄存器，这里的rbp寄存器保存了什么值？就是调用者的栈底指针，这里对应的就是main的栈底指针。所以目前为止，我们保存了main的栈底和pc指针，已经只要恢复这两个指针，我们又可以回到main工作了！ 第二步把func帧的栈底设置为了main的栈顶，所以这两个栈连续了～，然后扩展了func函数的栈，大小是0x1d0。 第三步是入参： mov eax,DWORD PTR [rbp+0x28] mov eax,DWORD PTR [rbp+0x20] mov eax,DWORD PTR [rbp+0x18] mov eax,DWORD PTR [rbp+0x10] mov DWORD PTR [rbp-0x4],edi mov DWORD PTR [rbp-0x8],esi mov DWORD PTR [rbp-0xc],edx mov DWORD PTR [rbp-0x10],ecx mov DWORD PTR [rbp-0x14],r8d mov DWORD PTR [rbp-0x18],r9d 对照入参准备阶段，参数计算是从左往右，这里入参是从右往左。现在我们观察到了函数入参的结论了。另外，这几个地址可以关注一下： mov eax,DWORD PTR [rbp+0x28] mov eax,DWORD PTR [rbp+0x20] mov eax,DWORD PTR [rbp+0x18] mov eax,DWORD PTR [rbp+0x10] 和main参数准备的地址相比，还偏移了0x10个字节，为什么？因为call指令的时候保存了pc指针，进入到func函数的时候又保存了rbp指针，一共是16B，对应就是增加了0x10。 总之，目前为止，我们将main函数传入的参数都保存在了func函数栈帧里面。后续的赋值语句我们就不分析了，不过需要关在下面两部分： lea rdi,[rbp-0x1c0] xor esi,esi mov edx,0x190 call 401030 \u003cmemset@plt\u003e mov DWORD PTR [rbp-0x1c0],0x1 这里用于分配和初始化vv[100]这个数组，调用memset初始化为0,然后给第一个元素初始化为1，是否调用memset初始化是编译器行为，并不是所有编译器都会帮助你初始化一个数组，这是需要注意的。 mov rax,QWORD PTR ds:0x402004 mov QWORD PTR [rbp-0x1ce],rax mov ax,WORD PTR ds:0x40200c mov WORD PTR [rbp-0x1c6],ax 这部分用于给cv[10]初始化为\"hello\"，可以看到\"hello\"对应在了ds区，并且发现这里是有复制操作的，怎么复制的就先不关心了，这也能给我们提醒，如果非必要的话，可以直接使用指针指向\"hello\"，而不是用一个数组。 最后就是func的退出，这部分是和main类似的，就不介绍了。 函数调用的栈帧 ","date":"2022-01-26","objectID":"/202201/framestack/:1:5","tags":["Linux","栈"],"title":"程序的栈帧","uri":"/202201/framestack/"},{"categories":["操作系统"],"content":"函数退出 上述函数调用之后，就需要退出main函数了： mov eax,0x1 add rsp,0x30 pop rbp ret 我开始比较疑惑，为什么会把0x1赋值给eax寄存器？原来是main函数返回了1，所以返回值先给了eax寄存器。赋值完返回值后，会把栈顶寄存器移动到栈底，这里对应的就是add rsp,0x30，然后恢复调用者的栈底，main的调用者就是__libc_start_main，在《glibc-exit源码阅读》已经介绍过了。ret指令则会pop出ip寄存器，相当于恢复到调用者上次执行的位置。 函数退出的栈帧 ","date":"2022-01-26","objectID":"/202201/framestack/:1:6","tags":["Linux","栈"],"title":"程序的栈帧","uri":"/202201/framestack/"},{"categories":["操作系统"],"content":"黑魔法 通过上面的分析，可以知道，函数在调用子函数后，栈会向下增长，子函数返回后，栈会减小，栈底和栈顶又会回到调用者的位置，但是并没有清空子函数的栈记录。 因此，我们可以实现一个黑魔法，在main函数里面获得func函数中的局部变量！如下就是我们的攻击函数： #include \u003cstdio.h\u003e int func(int v1, int v2, int v3, int v4, int v5, int v6, int v7, int v8, int v9, int v10) { int n1 = v1 + 1; int n10 = v10 + 1; int nv = v1 + v2 + v3 + v4 + v5 + v6 + v7 + v8 + v9 + v10; int vv[100]{1}; int vv10 = vv[10]; char cv[10] = \"hello\"; return nv; } int main() { int a = 1; int b = 10; int c = 11; func(a, 2, 3, 4, 5, 6, 7, 8, 9, b); printf(\"%s\\n\", (reinterpret_cast\u003cchar *\u003e(\u0026a) + 4 + 4 - 16 * 3 - 8 - 8 - 462)); return 1; } 关键部分是： (reinterpret_cast\u003cchar *\u003e(\u0026a) + 4 + 4 - 16 * 3 - 8 - 8 - 462) 我们来分析每个数字的含义： 第一个+ 4，因为变量a占4B，为了回到main的栈底，我们先上移4B 第二个+ 4，暂时没找到原因，通过分析clang的汇编才能找到这多出来的4B，总之，还需要上移4B - 16 * 3，以上我们回到了main的栈底，现在需要到main的栈顶，所以下移16 * 3 - 8 - 8， 现在走到了main的栈顶，调用func还有两个push操作，分别是push``ip和rbp，所以再下移两个8B - 462， 现在走到了func的栈底，为了得到cv的值，我们需要知道cv的偏移， cv的偏移是0x1ce对应就是462 所以，以上printf部分，可以在main函数打印func函数中的局部变量，这里就会打印\"hello\"。 不过，还是有疑问，- 462是怎么来的，如果只分析func的局部变量的大小，计算出来的不是462，而是(100 + 4 + 6) × 4 + 10 = 450，通过汇编分析，多出来的12B是在vv[100]这个数组初始化过程中产生的，可以尝试增加另外一个数组，也会发现会多出来几个字节的空间，这里就不追究了。 假想攻击： 通过以上分析，我们知道程序执行过程中会在程序栈中留下痕迹。如果某软件会把用户密码明文地临时保存在一个局部变量中，是不是可以通过hook一些基础函数，比如hook glibc的某些函数来入侵软件的进程栈呢？入侵之后就可以获取到整个进程栈（一般也就8MB），然后通过实时分析（比如关键词匹配等等）进程栈来猜解用户密码。不过，如果多线程的话，线程栈可能会和进程栈有区别，会增加数据量。 ","date":"2022-01-26","objectID":"/202201/framestack/:2:0","tags":["Linux","栈"],"title":"程序的栈帧","uri":"/202201/framestack/"},{"categories":["操作系统"],"content":"结论 现在来回答一下我的疑问：栈帧是什么？栈帧是不是包含了程序的执行指令？ 栈帧是栈，是保存程序运行局部变量的栈，是程序栈的一部分，动态增长。栈帧不包含程序的执行指令，但是包含执行指令的地址。 ","date":"2022-01-26","objectID":"/202201/framestack/:3:0","tags":["Linux","栈"],"title":"程序的栈帧","uri":"/202201/framestack/"},{"categories":["操作系统","glibc"],"content":"glibc调用 exit 在exit.c可以找到exit的实现。 void exit (int status) { __run_exit_handlers (status, \u0026__exit_funcs, true, true); } libc_hidden_def (exit) 调用glibc的exit相当于调用了__run_exit_handlers， 下面来看看__run_exit_handlers的实现。 先看定义： void attribute_hidden __run_exit_handlers (int status, struct exit_function_list **listp, bool run_list_atexit, bool run_dtors) 由此知道，调用exit的时候run_list_atexit和run_dtors被设置为了true， exit_function_list被设置为了__exit_funcs； ","date":"2022-01-24","objectID":"/202201/glibc-exit/:1:0","tags":["Linux","glibc"],"title":"glibc-exit源码阅读","uri":"/202201/glibc-exit/"},{"categories":["操作系统","glibc"],"content":"第一阶段 这个函数执行的时候，首先会判断run_dtors然后调用__call_tls_dtors： /* First, call the TLS destructors. */ #ifndef SHARED if (\u0026__call_tls_dtors != NULL) #endif if (run_dtors) __call_tls_dtors (); 什么是TLS？网上查到一些资料说这是一种通信协议，进入__call_tls_dtors阅读，可以发现这里的TLS并不指代TLS协议，阅读这篇文章-《TLS–线程局部存储》-可以对TLS有大概的了解，TLS会与写时复制（COW）比较类似，是一个全局变量，每个线程有自己的副本，从而可以保证每个线程自己修改自己的TLS变量，而不会影响其他线程的TLS变量。 __call_tls_dtors会做什么？注释说的比较清楚了，会调用TLS的析构函数，这个析构函数负责析构thread_local中声明的TLS变量。 /* Call the destructors. This is called either when a thread returns from the initial function or when the process exits via the exit function. */ void __call_tls_dtors (void) { while (tls_dtor_list) { struct dtor_list *cur = tls_dtor_list; dtor_func func = cur-\u003efunc; #ifdef PTR_DEMANGLE PTR_DEMANGLE (func); #endif tls_dtor_list = tls_dtor_list-\u003enext; func (cur-\u003eobj); /* Ensure that the MAP dereference happens before l_tls_dtor_count decrement. That way, we protect this access from a potential DSO unload in _dl_close_worker, which happens when l_tls_dtor_count is 0. See CONCURRENCY NOTES for more detail. */ atomic_fetch_add_release (\u0026cur-\u003emap-\u003el_tls_dtor_count, -1); free (cur); } } TLS析构函数是通过一个全局链表tls_dtor_list调用的，tls_dtor_list是什么时候初始化的呢？通过下面这个函数__cxa_thread_atexit_impl，并且__cxa_thread_atexit_impl是只被编译器调用的。（编译器什么时候会调用就暂不追踪了。） /* Register a destructor for TLS variables declared with the 'thread_local' keyword. This function is only called from code generated by the C++ compiler. FUNC is the destructor function and OBJ is the object to be passed to the destructor. DSO_SYMBOL is the __dso_handle symbol that each DSO has at a unique address in its map, added from crtbegin.o during the linking phase. */ int __cxa_thread_atexit_impl (dtor_func func, void *obj, void *dso_symbol) 以上总结就是，在调用glibc-exit的时候，首先会析构所有的TLS变量。 ","date":"2022-01-24","objectID":"/202201/glibc-exit/:1:1","tags":["Linux","glibc"],"title":"glibc-exit源码阅读","uri":"/202201/glibc-exit/"},{"categories":["操作系统","glibc"],"content":"第二阶段 然后是处理listp，会根据每个节点不同的属性调用不同函数。 while (true) { restart: cur = *listp; while (cur-\u003eidx \u003e 0) { struct exit_function *const f = \u0026cur-\u003efns[--cur-\u003eidx]; const uint64_t new_exitfn_called = __new_exitfn_called; /* Unlock the list while we call a foreign function. */ __libc_lock_unlock (__exit_funcs_lock); switch (f-\u003eflavor) { //... case ef_free: case ef_us: break; case ef_on: onfct = f-\u003efunc.on.fn; #ifdef PTR_DEMANGLE PTR_DEMANGLE (onfct); #endif onfct (status, f-\u003efunc.on.arg); break; case ef_at: atfct = f-\u003efunc.at; #ifdef PTR_DEMANGLE PTR_DEMANGLE (atfct); #endif atfct (); break; case ef_cxa: /* To avoid dlclose/exit race calling cxafct twice (BZ 22180), we must mark this function as ef_free. */ f-\u003eflavor = ef_free; cxafct = f-\u003efunc.cxa.fn; #ifdef PTR_DEMANGLE PTR_DEMANGLE (cxafct); #endif cxafct (f-\u003efunc.cxa.arg, status); break; } /* Re-lock again before looking at global state. */ __libc_lock_lock (__exit_funcs_lock); if (__glibc_unlikely (new_exitfn_called != __new_exitfn_called)) /* The last exit function, or another thread, has registered more exit functions. Start the loop over. */ goto restart; } //... } 这里需要关注的是__exit_funcs，__exit_funcs是怎么初始化的？ 在cxa_atexit.c可以找到对__exit_funcs的初始化。 /* Register a function to be called by exit or when a shared library is unloaded. This function is only called from code generated by the C++ compiler. */ int __cxa_atexit (void (*func) (void *), void *arg, void *d) { return __internal_atexit (func, arg, d, \u0026__exit_funcs); } libc_hidden_def (__cxa_atexit) 和第一阶段类似，__exit_funcs初始化也是编译器的行为，具体会把哪些函数串在这个链表上呢？暂时不追踪了。 同时，也提供了用户接口，用户可以自定义一些在exit时执行的函数，下面这一段在on_exit.c: /* Register a function to be called by exit. */ int __on_exit (void (*func) (int status, void *arg), void *arg) { struct exit_function *new; /* As a QoI issue we detect NULL early with an assertion instead of a SIGSEGV at program exit when the handler is run (bug 20544). */ assert (func != NULL); __libc_lock_lock (__exit_funcs_lock); new = __new_exitfn (\u0026__exit_funcs); if (new == NULL) { __libc_lock_unlock (__exit_funcs_lock); return -1; } #ifdef PTR_MANGLE PTR_MANGLE (func); #endif new-\u003efunc.on.fn = func; new-\u003efunc.on.arg = arg; new-\u003eflavor = ef_on; __libc_lock_unlock (__exit_funcs_lock); return 0; } weak_alias (__on_exit, on_exit) 总之，第二阶段也是会执行一些编译器或用户注册的函数。 ","date":"2022-01-24","objectID":"/202201/glibc-exit/:1:2","tags":["Linux","glibc"],"title":"glibc-exit源码阅读","uri":"/202201/glibc-exit/"},{"categories":["操作系统","glibc"],"content":"第三阶段 最后判断run_list_atexit调用__libc_atexit和_exit： if (run_list_atexit) RUN_HOOK (__libc_atexit, ()); _exit (status); 这里关注两个函数__libc_atexit和_exit。 在genops.c可以找到对__libc_atexit的说明。 text_set_element(__libc_atexit, _IO_cleanup); 原来__libc_atexit绑定的是一个叫_IO_cleanup的函数，这里就可以猜到，此时会做一些IO清理相关的工作。 int _IO_cleanup (void) { /* We do *not* want locking. Some threads might use streams but that is their problem, we flush them underneath them. */ int result = _IO_flush_all_lockp (0); /* We currently don't have a reliable mechanism for making sure that C++ static destructors are executed in the correct order. So it is possible that other static destructors might want to write to cout - and they're supposed to be able to do so. The following will make the standard streambufs be unbuffered, which forces any output from late destructors to be written out. */ _IO_unbuffer_all (); return result; } 什么是IO清理相关的工作？比如使用glibc标准stream函数，一般是有IO缓存的，比如读写文件或者标准输入输出，因为需要考虑IO性能和CPU性能的差距，会缓存一段buffer，这段buffer满或者外部触发时就可以出发写入或者读出操作了。 在调用exit的时候相当于手动将这些缓存buffer输出了。 _exit则是系统调用，会引导退出进程。 ","date":"2022-01-24","objectID":"/202201/glibc-exit/:1:3","tags":["Linux","glibc"],"title":"glibc-exit源码阅读","uri":"/202201/glibc-exit/"},{"categories":["操作系统","glibc"],"content":"系统调用 _exit _exit源码大概在_exit.S，但是看不太懂…可以另外关注man7的说明： _exit() terminates the calling process “immediately”. Any open file descriptors belonging to the process are closed. Any children of the process are inherited by init(1) (or by the nearest “subreaper” process as defined through the use of the prctl(2) PR_SET_CHILD_SUBREAPER operation). The process’s parent is sent a SIGCHLD signal. The value status \u0026 0xFF is returned to the parent process as the process’s exit status, and can be collected by the parent using one of the wait(2) family of calls. The function _Exit() is equivalent to _exit(). 意思是： _exit会立刻中断当前进程 关闭所有属于该进程的文件 将该进程的所有子进程移交给init进程，这里可以看到例子《进程控制和通信(一) · 进程控制》 给该进程的父进程发送SIGCHLD信号 _exit的参数status会被返回给父进程，可以被父进程的wait函数接收。 In glibc up to version 2.3, the _exit() wrapper function invoked the kernel system call of the same name. Since glibc 2.3, the wrapper function invokes exit_group(2), in order to terminate all of the threads in a process. The raw _exit() system call terminates only the calling thread, and actions such as reparenting child processes or sending SIGCHLD to the parent process are performed only if this is the last thread in the thread group. glibc调用的_exit会被映射到exit_group，exit_group会中断进程的所有线程，这里和group id有关，在这篇文章中《进程控制和通信(四) · PCB介绍》已经介绍过了，在当前多任务Linux系统中，进程ID指task_struct中的tgid（thread group id），线程id则指pid（process id），有一点区别，主要是为了兼容。 原生的系统调用_exit只会中断当前的线程，并且仅当当前线程是进程的最后一个线程的时候才会有上述诸如发送SIGCHLD的操作。 ","date":"2022-01-24","objectID":"/202201/glibc-exit/:2:0","tags":["Linux","glibc"],"title":"glibc-exit源码阅读","uri":"/202201/glibc-exit/"},{"categories":["操作系统","glibc"],"content":"return和exit的区别 ","date":"2022-01-24","objectID":"/202201/glibc-exit/:3:0","tags":["Linux","glibc"],"title":"glibc-exit源码阅读","uri":"/202201/glibc-exit/"},{"categories":["操作系统","glibc"],"content":"栈桢 先看一段关于return的代码： void func1() { return; } int func2() { return 1; } int func3(int v) { v++; return v; } int main() { func1(); func2(); func3(1); return 1; } func1翻译成汇编是： push rbp mov rbp,rsp pop rbp ret cs nop WORD PTR [rax+rax*1+0x0] 函数入口处是保存上一个栈帧rbp，然后将当前栈地址赋值给栈帧寄存器rbp。函数退出时会将父栈帧地址pop给栈帧寄存器rbp。 func2翻译成汇编是： push rbp mov rbp,rsp mov eax,0x1 pop rbp ret nop DWORD PTR [rax+rax*1+0x0] 函数入口处是保存上一个栈帧rbp，然后将当前栈地址赋值给栈帧寄存器rbp。函数退出时，会将返回值赋值给寄存器eax，再将父栈帧地址pop给栈帧寄存器rbp。 func3翻译成汇编是： push rbp mov rbp,rsp mov DWORD PTR [rbp-0x4],edi mov eax,DWORD PTR [rbp-0x4] add eax,0x1 mov DWORD PTR [rbp-0x4],eax mov eax,DWORD PTR [rbp-0x4] pop rbp ret cs nop WORD PTR [rax+rax*1+0x0] nop 函数入口处是保存上一个栈帧rbp，然后将当前栈地址赋值给栈帧寄存器rbp，然后将函数入参赋值给[rbp-0x4]，因为只有一个参数，所以对应的是栈帧的前4个字节。函数执行时，从[rbp-0x4]取出值给累加器eax，然后累加器eax做+1操作，再将结果返回给[rbp-0x4]。函数退出时，从[rbp-0x4]取值，将返回值赋值给寄存器eax，再将父栈帧地址pop给栈帧寄存器rbp。 所以return是什么？ return可以将返回值保存在某寄存器，然后将父栈帧弹出，对应的就是赋值/出栈操作。这里介绍的不太仔细，但是对我们目前的问题够用了，不过也算是查漏补缺了（TODO：函数栈帧具体过程，如果只需要大概了解，也可以参考《《UCB CS61a SICP Python 中文》一周目笔记(一)》）。此外，本节内容还参考了： 《x86-64 下函数调用及栈帧原理》 《手撕虚拟内存（8）——函数栈桢原理》 所以，return和exit的区别之一： return负责了一些栈桢的退出操作，exit负责程序/进程方面的退出操作。 ","date":"2022-01-24","objectID":"/202201/glibc-exit/:3:1","tags":["Linux","glibc"],"title":"glibc-exit源码阅读","uri":"/202201/glibc-exit/"},{"categories":["操作系统","glibc"],"content":"main函数 再说到return和exit区别的时候，还想到一个问题，main的return就是进程的退出吗？要回答这个问题得先了解main是怎么执行的。 程序的入口函数是哪里？是main吗？ 不是的，程序的入口函数是_start，这是glibc约定的入口，可以参考这里what-is-the-use-of-start-in-c。 入口函数的定义看start.S，这里就不贴代码了，在_start开始会做一些初始化工作，比如初始化栈帧，其他的也看不太懂了，不过在_start最后会调用一个函数call *__libc_start_main@GOTPCREL(%rip)，这个函数指向libc-start.c。在__libc_start_main会做一些准备工作，比如收集输入参数argc和argv，然后会调用用户定义的main函数，最后会用main的返回值调用exit函数。 /* Nothing fancy, just call the function. */ result = main (argc, argv, __environ MAIN_AUXVEC_PARAM); exit (result); 这里有几点启发： 在main函数调用return和exit没有太大区别 正常情况main函数最好返回0（因为C语言一般用0表示Success）, 而不是1（我大部分时候喜欢返回1） ","date":"2022-01-24","objectID":"/202201/glibc-exit/:3:2","tags":["Linux","glibc"],"title":"glibc-exit源码阅读","uri":"/202201/glibc-exit/"},{"categories":["工具"],"content":"！！以下说明或结论不构成任何建议，且难免有错误之处，仅是个人感兴趣点以及学习过程。 ","date":"2022-01-21","objectID":"/202201/fund-sim/:0:0","tags":["Python","仿真","基金"],"title":"几种定投策略的仿真比较","uri":"/202201/fund-sim/"},{"categories":["工具"],"content":"策略代码 生成随机涨跌趋势，这里假设是以周为单位，并且限定了涨跌最大幅度为10%，win_rate表示平均胜率，表示一个周期（周）中，有win_rate的概率是盈利的。 def rand_rate(win_rate : float, time_steps : int): import random return [(-1 if random.random() \u003e win_rate else 1) * random.random() / 10 for _ in range(time_steps)] sim是仿真执行函数，执行cases中的策略，并放回最终的收益率。 def sim(rates, cases): return [case(rates) for case in cases] 以下是模拟的三种策略。 策略一， 起始投入1000, 设定周定投500, 但是会根据上周的涨跌幅浮动，定投额度为500减去浮动金额。所以，如果上周上涨了，本周就少定投，上周下跌了，本周就多定投，上下限分别是0和1000。 def case1(rates): base = 1000 wadd = 500 wadd_max = 1000 nbase = base addon = 0 for ra in rates: base = base + addon nbase = nbase + addon fb = nbase * ra nbase = nbase + fb addon = max(wadd - fb, 0) addon = min(addon, wadd_max) return (nbase - base) / base 策略二，一次性全部投入。 def case2(rates): base = 1000 nbase = base for ra in rates: nbase = nbase + nbase * ra return (nbase - base) / base 策略三，类似策略一，但是是固定金额定投，不浮动。 def case3(rates): base = 1000 wadd = 500 nbase = base addon = 0 for ra in rates: base = base + addon nbase = nbase + addon fb = nbase * ra nbase = nbase + fb addon = wadd return (nbase - base) / base 仿真策略。模拟3年，市场盈利概率40%～60%的情况，每个盈利概率下模拟10000次，计算平均盈利率。 def rsim(): import numpy as np for r in range(40, 60, 1): win = [] rates = [] for _ in range(10000): rates = rand_rate(r / 100, 52 * 3) win.append(sim(rates, [case1, case2, case3])) win = np.array(win) for i in range(len(win[0])): for j in range(len(win), 0, -1): win[j - 1, i] = win[:j, i].mean() paint_rate(rates) paint( t = r, y=[ { 'data': win[:,0], 'color': 'r', }, { 'data': win[:,1], 'color': 'b', }, { 'data': win[:,2], 'color': 'y', }, ] ) ","date":"2022-01-21","objectID":"/202201/fund-sim/:1:0","tags":["Python","仿真","基金"],"title":"几种定投策略的仿真比较","uri":"/202201/fund-sim/"},{"categories":["工具"],"content":"结论 以上仿真的结果是： 一次性投入可以获得很高的盈利，但是亏损在这三者中也是最大的 浮动定投比定额定投可以获得更少的亏损，也比定额定投有更高的盈利 更具体的情况可以下载源码 ","date":"2022-01-21","objectID":"/202201/fund-sim/:2:0","tags":["Python","仿真","基金"],"title":"几种定投策略的仿真比较","uri":"/202201/fund-sim/"},{"categories":["Cpp","STL"],"content":"智能指针出现很多, 但是自己用得很少. 本文从源码层面来学习智能指针, 学习是怎么实现的, 以及如此实现可以实现如何的功能. ","date":"2021-12-29","objectID":"/202112/stl-smartpointers/:0:0","tags":["内存","Cpp","指针"],"title":"STL-智能指针三剑客源码阅读","uri":"/202112/stl-smartpointers/"},{"categories":["Cpp","STL"],"content":"unique_ptr 我认为unique_ptr是编译器强制人类某些行为的例子, 只允许人类这样做而不允许人类那样做. 可以参考explicit说明符的一些想法. 源码在这里. 其析构函数会释放内存资源: ~unique_ptr() noexcept { auto\u0026 __ptr = _M_t._M_ptr(); if (__ptr != nullptr) get_deleter()(__ptr); __ptr = pointer(); } 为了保证这一点, unique_ptr就不允许用户将一块内容\"多人\"使用, 所以需要限制用户的拷贝和赋值行为: // Disable copy from lvalue. unique_ptr(const unique_ptr\u0026) = delete; unique_ptr\u0026 operator=(const unique_ptr\u0026) = delete; 禁用了左值拷贝构造和赋值, 这样可以保证只有一个unique_ptr指向一块内存, 不会有多个unique_ptr指向一块内存. 但是允许了右值拷贝构造和赋值: unique_ptr(unique_ptr\u0026\u0026 __u) noexcept : _M_t(__u.release(), std::forward\u003cdeleter_type\u003e(__u.get_deleter())) { } unique_ptr\u0026 operator=(unique_ptr\u0026\u0026 __u) noexcept { reset(__u.release()); get_deleter() = std::forward\u003cdeleter_type\u003e(__u.get_deleter()); return *this; } 右值在构造结束后就会被销毁, 所以此处的右值构造可以保证只有一个unique_ptr指向一块内存. 在内存转移的时候使用的是release接口(和reset(__u._M_t)是有区别的), 因为内存转移时候需要保证原unique_ptr的数据指针为空, 不能指向需要转移的内存, 不然在临时变量析构的时候会释放这块内存. 所以release接口的作用就是提取数据内存的指针, 将本来数据指针置空, 返回数据内存指针: pointer release() noexcept { pointer __p = get(); _M_t._M_ptr() = pointer(); return __p; } unique_ptr有太多行为限制, 除了行为限制, 比较容易想到的是使用计数器形式实现RAII. ","date":"2021-12-29","objectID":"/202112/stl-smartpointers/:1:0","tags":["内存","Cpp","指针"],"title":"STL-智能指针三剑客源码阅读","uri":"/202112/stl-smartpointers/"},{"categories":["Cpp","STL"],"content":"shared_ptr shared_ptr是基于计数器的智能指针, 继承自__shared_ptr, 自身没有实现任何引用计数的功能. shared_ptr源码 template\u003ctypename _Tp\u003e class shared_ptr : public __shared_ptr\u003c_Tp\u003e __shared_ptr 继承自 __shared_ptr_access. template\u003ctypename _Tp, _Lock_policy _Lp\u003e class __shared_ptr : public __shared_ptr_access\u003c_Tp, _Lp\u003e __shared_ptr本身维护两个变量, 内容指针和引用计数器. element_type* _M_ptr; // Contained pointer. __shared_count\u003c_Lp\u003e _M_refcount; // Reference counter. ","date":"2021-12-29","objectID":"/202112/stl-smartpointers/:2:0","tags":["内存","Cpp","指针"],"title":"STL-智能指针三剑客源码阅读","uri":"/202112/stl-smartpointers/"},{"categories":["Cpp","STL"],"content":"计数器的使用 以下看看__shared_ptr实现了哪些需要借助引用计数的方法: 拷贝构造 拷贝构造数据和计数器, 而计数器的拷贝构造会使得计数器的值+1. __shared_ptr(const __shared_ptr\u0026) noexcept = default; 右值构造, 相当于右值的数据和计数器给了左值, 右值获得了空的数据和0计数器. 因为右值本身就只有一个引用, 所以交换是可以的. __shared_ptr(__shared_ptr\u0026\u0026 __r) noexcept : _M_ptr(__r._M_ptr), _M_refcount() { _M_refcount._M_swap(__r._M_refcount); __r._M_ptr = 0; } 复制操作 左值复制使用默认函数, 所以涉及到计数器的复制, 计数器复制操作也会设计+1操作. __shared_ptr\u0026 operator=(const __shared_ptr\u0026) noexcept = default; 右值复制同右值构造, 使用swap交换. __shared_ptr\u0026 operator=(__shared_ptr\u0026\u0026 __r) noexcept { __shared_ptr(std::move(__r)).swap(*this); return *this; } 以上, 可以知道shared_ptr在左值构造和左值复制操作时会涉及计数器+1的操作. ","date":"2021-12-29","objectID":"/202112/stl-smartpointers/:2:1","tags":["内存","Cpp","指针"],"title":"STL-智能指针三剑客源码阅读","uri":"/202112/stl-smartpointers/"},{"categories":["Cpp","STL"],"content":"计数器的实现 重点关注引用计数器的实现: template\u003c_Lock_policy _Lp\u003e class __shared_count { public: constexpr __shared_count() noexcept : _M_pi(0) { } __shared_count(const __shared_count\u0026 __r) noexcept : _M_pi(__r._M_pi) { if (_M_pi != 0) _M_pi-\u003e_M_add_ref_copy(); } __shared_count\u0026 operator=(const __shared_count\u0026 __r) noexcept { _Sp_counted_base\u003c_Lp\u003e* __tmp = __r._M_pi; if (__tmp != _M_pi) { if (__tmp != 0) __tmp-\u003e_M_add_ref_copy(); if (_M_pi != 0) _M_pi-\u003e_M_release(); _M_pi = __tmp; } return *this; } void _M_swap(__shared_count\u0026 __r) noexcept { _Sp_counted_base\u003c_Lp\u003e* __tmp = __r._M_pi; __r._M_pi = _M_pi; _M_pi = __tmp; } //... private: friend class __weak_count\u003c_Lp\u003e; _Sp_counted_base\u003c_Lp\u003e* _M_pi; } 引用计数器的拷贝构造和复制操作都涉及到了计数器的加减, 拷贝构造时计数器会默认+1, 而复制操作时可能会将=右边的计数器释放. 这里有个疑问, 为什么拷贝构造和复制操作的行为不一样呢? 因为拷贝构造时说明原本还没有构造计数器, 对应的就是shared_ptr的拷贝构造, 比如shared_ptr\u003cint\u003e p2(p1), 这时候p1和p2都没有被释放, 是能够正常使用的, 所以拷贝构造时只需要计数器+1就行了. 复制操作需要释放是因为原本指向一个数据的指针会指向另外一个数据, 比如p2 = p1, p2原本可能指向p, 这时候变成了指向p1, 所以原来p的计数器需要-1, p1的计数器就需要+1. 以上计数器操作来自于_Sp_counted_base, 那么_Sp_counted_base是怎么实现的? 源码 template\u003c_Lock_policy _Lp = __default_lock_policy\u003e class _Sp_counted_base : public _Mutex_base\u003c_Lp\u003e { public: _Sp_counted_base() noexcept virtual ~_Sp_counted_base() noexcept { } : _M_use_count(1), _M_weak_count(1) { } void _M_add_ref_copy() { __gnu_cxx::__atomic_add_dispatch(\u0026_M_use_count, 1); } //... private: _Sp_counted_base(_Sp_counted_base const\u0026) = delete; _Sp_counted_base\u0026 operator=(_Sp_counted_base const\u0026) = delete; _Atomic_word _M_use_count; // #shared _Atomic_word _M_weak_count; // #weak + (#shared != 0) }; _Sp_counted_base维护了两个计数器, 一个用于shared一个用于weak, 并且两个都是原子变量, 如果关注源码, 还可以发现add或者release操作也是原子的, 并且release操作时会涉及内存屏障(TODO:内存屏障还不太了解). 同时,_Sp_counted_base的析构函数什么都没有做, 所以如果需要析构release计数器, 就依赖于上层函数的接口, 对应的就是: __shared_count::~__shared_count() noexcept { if (_M_pi != nullptr) _M_pi-\u003e_M_release(); } ","date":"2021-12-29","objectID":"/202112/stl-smartpointers/:2:2","tags":["内存","Cpp","指针"],"title":"STL-智能指针三剑客源码阅读","uri":"/202112/stl-smartpointers/"},{"categories":["Cpp","STL"],"content":"什么时候删除 一般猜测是析构函数的时候会delete数据, 但是并没有很容易地找到对应的代码, 所以这部分会介绍数据的delete到底是在哪里. __shared_ptr的构造函数令人怀疑, 因为_M_refcount会需求一个__p参数来构造, 而__p代表了源数据. template\u003ctypename _Yp, typename _Deleter, typename = _SafeConv\u003c_Yp\u003e\u003e __shared_ptr(_Yp* __p, _Deleter __d) : _M_ptr(__p), _M_refcount(__p, std::move(__d)) { static_assert(__is_invocable\u003c_Deleter\u0026, _Yp*\u0026\u003e::value, \"deleter expression d(p) is well-formed\"); _M_enable_shared_from_this_with(__p); } 接下来看看__shared_count的构造函数, 一般会调用下面这个构造函数, 不一般的情况就不分析了… template\u003ctypename _Ptr, typename _Deleter, typename _Alloc\u003e __shared_count(_Ptr __p, _Deleter __d, _Alloc __a) : _M_pi(0) { typedef _Sp_counted_deleter\u003c_Ptr, _Deleter, _Alloc, _Lp\u003e _Sp_cd_type; __try { typename _Sp_cd_type::__allocator_type __a2(__a); auto __guard = std::__allocate_guarded(__a2); _Sp_cd_type* __mem = __guard.get(); ::new (__mem) _Sp_cd_type(__p, std::move(__d), std::move(__a)); _M_pi = __mem; __guard = nullptr; } __catch(...) { __d(__p); // Call _Deleter on __p. __throw_exception_again; } } 这部分构造函数中包含了数据指针: ::new (__mem) _Sp_cd_type(__p, std::move(__d), std::move(__a)); _Sp_cd_type对应的_Sp_counted_deleter比较令我注意, 它继承自_Sp_counted_base, 并且会将_Sp_counted_deleter类型的数据赋值给_M_pi. _Sp_counted_deleter的定义如下: // Support for custom deleter and/or allocator template\u003ctypename _Ptr, typename _Deleter, typename _Alloc, _Lock_policy _Lp\u003e class _Sp_counted_deleter final : public _Sp_counted_base\u003c_Lp\u003e 注意到, _M_pi对应的是如下: _Sp_counted_base\u003c_Lp\u003e* _M_pi; 在此之前我们分析了_Sp_counted_base的析构函数什么也没有做, 依赖于__shared_count的析构, 而__shared_count的析构会调用_M_release. void _M_release() noexcept { // Be race-detector-friendly. For more info see bits/c++config. _GLIBCXX_SYNCHRONIZATION_HAPPENS_BEFORE(\u0026_M_use_count); if (__gnu_cxx::__exchange_and_add_dispatch(\u0026_M_use_count, -1) == 1) { _GLIBCXX_SYNCHRONIZATION_HAPPENS_AFTER(\u0026_M_use_count); _M_dispose(); // There must be a memory barrier between dispose() and destroy() // to ensure that the effects of dispose() are observed in the // thread that runs destroy(). // See http://gcc.gnu.org/ml/libstdc++/2005-11/msg00136.html if (_Mutex_base\u003c_Lp\u003e::_S_need_barriers) { __atomic_thread_fence (__ATOMIC_ACQ_REL); } // Be race-detector-friendly. For more info see bits/c++config. _GLIBCXX_SYNCHRONIZATION_HAPPENS_BEFORE(\u0026_M_weak_count); if (__gnu_cxx::__exchange_and_add_dispatch(\u0026_M_weak_count, -1) == 1) { _GLIBCXX_SYNCHRONIZATION_HAPPENS_AFTER(\u0026_M_weak_count); _M_destroy(); } } } 我们只看shared引用部分, 计数器减少到0后会调用到_M_dispose, 这是一个虚函数, 所以会调用到子类的_M_dispose. 对应的则是_Sp_counted_deleter的_M_dispose. 其内容为: virtual void _M_dispose() noexcept { _M_impl._M_del()(_M_impl._M_ptr); } 原来是在这里delete源数据的! 比较令我困惑的是, 删除数据的操作是在计数器对象里面的进行的. ","date":"2021-12-29","objectID":"/202112/stl-smartpointers/:2:3","tags":["内存","Cpp","指针"],"title":"STL-智能指针三剑客源码阅读","uri":"/202112/stl-smartpointers/"},{"categories":["Cpp","STL"],"content":"循环引用 这是shared_ptr中谈论比较多的问题, 比如: #include \u003ciostream\u003e #include \u003cmemory\u003e using namespace std; class Father; class Son; class Father{ public: shared_ptr\u003cSon\u003e m_son; Father() { cout \u003c\u003c __func__ \u003c\u003c endl; }; ~Father() { cout \u003c\u003c __func__ \u003c\u003c endl; }; }; class Son{ public: shared_ptr\u003cFather\u003e m_father; Son() { cout \u003c\u003c __func__ \u003c\u003c endl; }; ~Son() { cout \u003c\u003c __func__ \u003c\u003c endl; }; }; int main(){ shared_ptr\u003cFather\u003e father(new Father); shared_ptr\u003cSon\u003e son(new Son); father-\u003em_son = son; son-\u003em_father = father; cout \u003c\u003c \"father count \" \u003c\u003c father.use_count() \u003c\u003c endl; cout \u003c\u003c \"son count \" \u003c\u003c son.use_count() \u003c\u003c endl; } 输出是: Father Son father count 2 son count 2 只有构造没有析构, 因为在函数退出时引用计数器时2, 这时候就需要我们手动release一遍, 但是这明显不符合RAII的原则, 会导致shared_ptr四不象. 为应对这个问题, 设计了weak_ptr类. ","date":"2021-12-29","objectID":"/202112/stl-smartpointers/:2:4","tags":["内存","Cpp","指针"],"title":"STL-智能指针三剑客源码阅读","uri":"/202112/stl-smartpointers/"},{"categories":["Cpp","STL"],"content":"weak_ptr 同shared_ptr, weak_ptr的主要实现在__weak_ptr: template\u003ctypename _Tp, _Lock_policy _Lp\u003e class __weak_ptr 没有发现__weak_ptr有任何基类. 关注__weak_ptr的构造可以发现, 是没有普通指针的构造接口的, 但是可以从weak_ptr或者shared_ptr构造. 这里关注两个常用的方法: __shared_ptr\u003c_Tp, _Lp\u003e lock() const noexcept { return __shared_ptr\u003celement_type, _Lp\u003e(*this, std::nothrow); } lock方法会将weak指针转换为shared指针, 从而可以访问数据内存, 并且weak指针是不提供方法直接访问数据内存的. long use_count() const noexcept { return _M_refcount._M_get_use_count(); } use_count方法返回数据内存的引用计数, _M_get_use_count实际返回的是shared计数, 而不是weak计数. 再来关注class __weak_count, 类似的, 在构造的时候会增加计数器: __weak_count(const __shared_count\u003c_Lp\u003e\u0026 __r) noexcept : _M_pi(__r._M_pi) { if (_M_pi != nullptr) _M_pi-\u003e_M_weak_add_ref(); } 析构的时候会减少计数器: ~__weak_count() noexcept { if (_M_pi != nullptr) _M_pi-\u003e_M_weak_release(); } 但是, 区别于shared指针的计数器, weak指针使用的是weak计数器, 目前来看weak计数器似乎没有用到, 仅在weak计数器为0的时候会释放weak_count自身. 以上, weak_ptr不会增加shared计数器, 会增加weak计数器, 不能直接访问weak_ptr指向的数据, 需要转换为share_ptr才能访问. weak_ptr的构造决定了它一般是和shared_ptr配合使用的, 更像是担任数据缓存的角色(或者说数据快照), 它自身不维护数据的生命周期, 如果源数据被释放无法访问了, 那weak_ptr也将无法访问源数据, 比如shared_ptr循环引用问题, 可以这样改写: #include \u003ciostream\u003e #include \u003cmemory\u003e using namespace std; class Father; class Son; class Father{ public: weak_ptr\u003cSon\u003e m_son; Father() { cout \u003c\u003c __func__ \u003c\u003c endl; }; ~Father() { cout \u003c\u003c __func__ \u003c\u003c endl; }; }; class Son{ public: weak_ptr\u003cFather\u003e m_father; Son() { cout \u003c\u003c __func__ \u003c\u003c endl; }; ~Son() { cout \u003c\u003c __func__ \u003c\u003c endl; }; }; int main(){ shared_ptr\u003cFather\u003e father(new Father); shared_ptr\u003cSon\u003e son(new Son); father-\u003em_son = son; son-\u003em_father = father; cout \u003c\u003c \"father count \" \u003c\u003c father.use_count() \u003c\u003c endl; cout \u003c\u003c \"son count \" \u003c\u003c son.use_count() \u003c\u003c endl; } 输出是: Father Son father count 1 son count 1 ~Son ~Father ","date":"2021-12-29","objectID":"/202112/stl-smartpointers/:3:0","tags":["内存","Cpp","指针"],"title":"STL-智能指针三剑客源码阅读","uri":"/202112/stl-smartpointers/"},{"categories":["Cpp","STL"],"content":"总结 unique_ptr通过限制用户行为实现了内存的RAII; shared_ptr通过引用计数实现了内存的RAII, 但是存在循环引用问题; shared_ptr通过扩展weak_ptr解决了循环引用的问题, 将weak_ptr当做是内存的缓存/快照. 还能总结一些方法: 设计一个工具类的时候, 不仅仅可以考虑其方法函数, 也可以在构造函数上做文章; 资源可以有访问接口和管理接口, 类比shared_ptr的资源, 资源会给_M_ptr用于访问, 也会给_M_refcount用于管理, 是分开的; ","date":"2021-12-29","objectID":"/202112/stl-smartpointers/:4:0","tags":["内存","Cpp","指针"],"title":"STL-智能指针三剑客源码阅读","uri":"/202112/stl-smartpointers/"},{"categories":["Cpp"],"content":"一直对explicit的认知比较模糊, 在准备智能指针内容的时候, 看到了这个内容, 所以索性认认真真学习一遍. 简单来说, explicit表达的是: 只允许显示行为, 不允许隐式行为. 要理解上面的解释, 就需要理解哪些是C++的显示行为, 哪些是隐式行为. ","date":"2021-12-23","objectID":"/202112/cpp-explicit/:0:0","tags":["Cpp"],"title":"explicit说明符","uri":"/202112/cpp-explicit/"},{"categories":["Cpp"],"content":"显示行为和隐式行为 以下是cppreference的demo源码: struct A { A(int) { } // converting constructor A(int, int) { } // converting constructor (C++11) operator bool() const { return true; } }; struct B { explicit B(int) { } explicit B(int, int) { } explicit operator bool() const { return true; } }; int main() { A a1 = 1; // OK: copy-initialization selects A::A(int) A a2(2); // OK: direct-initialization selects A::A(int) A a3 {4, 5}; // OK: direct-list-initialization selects A::A(int, int) A a4 = {4, 5}; // OK: copy-list-initialization selects A::A(int, int) A a5 = (A)1; // OK: explicit cast performs static_cast if (a1) ; // OK: A::operator bool() bool na1 = a1; // OK: copy-initialization selects A::operator bool() bool na2 = static_cast\u003cbool\u003e(a1); // OK: static_cast performs direct-initialization // B b1 = 1; // error: copy-initialization does not consider B::B(int) B b2(2); // OK: direct-initialization selects B::B(int) B b3 {4, 5}; // OK: direct-list-initialization selects B::B(int, int) // B b4 = {4, 5}; // error: copy-list-initialization does not consider B::B(int,int) B b5 = (B)1; // OK: explicit cast performs static_cast if (b2) ; // OK: B::operator bool() // bool nb1 = b2; // error: copy-initialization does not consider B::operator bool() bool nb2 = static_cast\u003cbool\u003e(b2); // OK: static_cast performs direct-initialization } 对类A来说, 以下是显示行为: A a2(2); // OK: direct-initialization selects A::A(int) A a3 {4, 5}; // OK: direct-list-initialization selects A::A(int, int) A a5 = (A)1; // OK: explicit cast performs static_cast if (a1) ; // OK: A::operator bool() bool na2 = static_cast\u003cbool\u003e(a1); // OK: static_cast performs direct-initialization a2和a3好理解, 因为就是直接调用A的构造函数, 这里不存在转换. A a5 = (A)1;存在转换, 但是是显示的, 这是用户明确需要转换的, 不是编译器的默认行为, 所以这里是显示转换. if (a1) ; 这里用户没有明确, 但是因为是if语句, 所以其expression是bool型的, 不存在编译器的隐式行为, 所以这里也可以认为是显示转换. bool na2 = static_cast\u003cbool\u003e(a1); 同上, 这是用户明确的行为, 不是编译器的行为, 所以是显示转换. 以下是隐式行为: A a1 = 1; // OK: copy-initialization selects A::A(int) A a4 = {4, 5}; // OK: copy-list-initialization selects A::A(int, int) bool na1 = a1; // OK: copy-initialization selects A::operator bool() a1和a4, 会转换为A(int)和A(int, int), 存在隐式转换. bool na1 = a1; 用户没有明确转换类型, 依赖于编译器的转换, 所以存在隐式转换. 以上分析了类A的行为, 对类B的构造和转换函数都加上了explicit说明, 所以对类B, 存在隐式行为的地方将不被允许. 在类B中以下是不被运行的隐式行为: B b1 = 1; // error: copy-initialization does not consider B::B(int) B b4 = {4, 5}; // error: copy-list-initialization does not consider B::B(int,int) bool nb1 = b2; // error: copy-initialization does not consider B::operator bool() 比如参考这篇文章中复数运算的例子: #include \u003ciostream\u003e using namespace std; class Complex { public: Complex( ){real=0;imag=0;} Complex(double r,double i){real=r;imag=i;} operator double( ) {return real;} //类型转换函数 private: double real; double imag; }; int main( ) { Complex c1(3,4),c2(5,-10),c3; double d; d=2.5+c1;//要求将一个double数据与Complex类数据相加 cout\u003c\u003cd\u003c\u003cendl; return 0; } d=2.5+c1;存在隐式行为. 所以如果我们给类型转换函数添加explicit说明后, 编译将不通过, 比如有如下错误: \u003csource\u003e:18:9: error: no match for 'operator+' (operand types are 'double' and 'Complex') 18 | d=2.5+c1;//要求将一个double数据与Complex类数据相加 | ~~~^~~ | | | | | Complex | double 这时候就需要将d=2.5+c1;修改为显示的, 这样做d=2.5+double(c1);就可以了. 添加explicit说明后, 如果改成d=2.5+float(c1);编译器也会报错: \u003csource\u003e:18:10: error: invalid cast from type 'Complex' to type 'float' 18 | d=2.5+float(c1);//要求将一个double数据与Complex类数据相加 | ^~~~~~~~~ 这是很好的, 至少可以规范用户的行为, 用户需要明确知道当前应该是什么数据类型, 因此不会出现因为数据类型导致的超出预期的问题(比如精度或值域). 我尝试在Rust中寻找关于隐式行为的内容(因为我始终认为在默认行为部分Rust比C++做得更安全), 找到了这部分中的一句话: 标准库中有一个函数std::mem::transmute，它可以将任意类型转换成其他类型。该函数是unsafe的，因为它不能保证输入类型的有效位可以表示为输出类型的有效位。确保这两种类型兼容由用户决定。 这句话对我的启发是: 所有代码的编译结果\"基本\"都一样, 那怎么保证代码的安全性? 可以交给人或者交给机器. 比如类型转换的功能, 如果交给人, 编译器就可以大量使用隐式转换, 但是用户就需要知道自己写的是什么, 是从什么转换成什么, 编译器对此会有什么样的行为, 不然就可能不安全. 如果交给机器, 机器是不相信人类的, 那么编译器就尽量不使用隐式转换, 用户就必须明确转换类型, 确保这些是编译器的允许行为, 不然编译器不允许通过. C++有不少的安全性是交由用户管理的, 所以我们可以写出很灵活的代码, 比如各种类型的隐式转换, 不容易被局限, 但是人也不总是那么可靠. 不要只局限于运行期, 编译期也能做很多事情, 不仅仅只有template. 比如可以在编译期做一些运算(判断/求和等等), 或者像类型检查一样做一些其他的检查等等, 这可能有点magic(元编程容易被这样认为), 但是需要有这种思维或者知识. ","date":"2021-12-23","objectID":"/202112/cpp-explicit/:1:0","tags":["Cpp"],"title":"explicit说明符","uri":"/202112/cpp-explicit/"},{"categories":["Cpp"],"content":"explicit is better than implicit 这小结的标题是Python禅宗中的格言, 曾经读过, 但是今天不学习explicit的话, 可能还回忆不起这句话. 在“如何理解 Explicit is Better than Implicit?”中, 作者谈到了自己的理解, 我认为和《UCB CS61a SICP Python 中文》一周目笔记(一) 中有部分观点是类似的: 用户不会惊讶于函数的返回 用户不会惊讶于函数的输入 显式行为就是我们通过代码就很容易理解的行为, 而不需要过多了解编译器将会怎么做, 这不仅仅局限于类型转换. 比如在\"如何理解…“这篇文章中, 作者举例的read_csv和read_json, 是很明显的显式行为, 输入文件名, 输出对应文件类型的内容/对象. 但是read也没那么差, 比如可以有两个类CSV和JSON, 那么他们各自有一个公共接口read, 通过这个接口可以返回对应文件类型的内容/对象, 这也是不错的, 我认为也是显式的. 怎么运用在自己的代码中? 我认为依赖于代码阅读量的积累. 需要阅读一些通用, 很多人使用过的代码(比如一些开源项目). 我自己写的时候, 也会考虑, 是不是见过类似的片段, 如果见过的, 我会大胆的写, 如果没见过的, 并且也没有其他想法的话, 我也会写下去. 想到围棋中的一个词描述: 定式. 代码也是有定式的. 比如写一个线程池, 会怎么写? 我刚开始会想需要什么接口, 比如add啊, start啊, 等等, 慢慢这东西就会变成某项目专用的工具, 迁移性不高了. 但是比如这个超过1k fork/5k star的ThreadPool, 接口很少, 这些是很值得学习的, 可以认为是定式, 代码量不大, 容易看懂. 我想起我们leader对我说的, 大概意思是: 写工具类先写一个通用的工具基类, 再根据项目需求添加功能更丰富的子类, 而不是一上来就根据项目需求开始动手了. 这种思想很有用, 再用线程池举例, 比如可以按照ThreadPool实现一个只有enqueue方法的基类, 再按照需求实现有start/stop/wait功能之类的子类. ","date":"2021-12-23","objectID":"/202112/cpp-explicit/:2:0","tags":["Cpp"],"title":"explicit说明符","uri":"/202112/cpp-explicit/"},{"categories":["工具"],"content":"rssblog最初版本: 在应用启动的时间检查一个rss list, 然后取抓取rss list的数据, 保存在内存中. (至于为什么要做rssblog, 可以参考这里.) 以上, 会有一些问题: 如果rss list比较大的时候, 会影响服务的性能; 不能做到缓存/保存历史数据; 不能进行更复杂的操作; 其他; 基于以上问题, 通过github action服务(白piao)为rssblog定制了数据源的服务-rssblog-source. 我们需要解决什么问题呢? 可以缓存历史数据; 有能力分析博文数据; ","date":"2021-12-20","objectID":"/202112/talk-rssblogsource/:0:0","tags":["flask","Python","博客"],"title":"rssblog的数据源-rssblog-source","uri":"/202112/talk-rssblogsource/"},{"categories":["工具"],"content":"获取数据 首先明确我们的设备, 是github action, 白piao的我们才有可能保证长久运行, 而不至于因为资金等问题中断. 同原始版本, 也有一个rss list, 用于存放需要拉取的rss链接, 如下: https://gist.githubusercontent.com/caibingcheng/adf8f300dc50a61a965bdcc6ef0aecb3/raw/rssblog-source-list.json 其内容如下: { \"bbing\": \"https://gist.githubusercontent.com/caibingcheng/adf8f300dc50a61a965bdcc6ef0aecb3/raw/friends.json\", \"addition\": \"https://gist.githubusercontent.com/caibingcheng/adf8f300dc50a61a965bdcc6ef0aecb3/raw/addition.json\" } rssblog-source-list.json会指向一个json, 这个json中存放用户的rss列表, 因此, 可以支持不同的用户接入. 这里用户可以指博主, 博主可以将友链的rss整理成一个list, 填入上述json中即可. 例如, https://gist.githubusercontent.com/caibingcheng/adf8f300dc50a61a965bdcc6ef0aecb3/raw/friends.json会指向: [ \"https://bbing.com.cn/index.xml\", \"https://lewky.cn/index.xml\", \"https://www.insidentally.com/atom.xml\", \"https://www.hin.cool/atom.xml\", \"https://7bxing.com/atom.xml\", \"https://coonaa.cn/index.php/feed\", \"https://thrower.cc/feed/\" ] 这是我的博客中友链列表. 有了数据源后, 开始通过rss拉取文章列表和地址等信息. url_hash = hash_url(rss) df = pandas.json_normalize(rss_link) if len(df) \u003c= 0: print(\"fetching skip\", r, \"to\", url_hash, \"size\", len(rss_link), len(df)) continue rss_dir = rss_fetch_source_dir + url_hash + \"/\" if not os.path.isdir(rss_dir): os.makedirs(rss_dir) df.to_csv(rss_dir + \"new.csv\", index=False, sep=\",\", encoding=\"utf-8\") 计算rss链接的md5值, 作为本地保存的路径, 拉取数据保存为csv文件. 这里是原始数据, 还没有合并/去重/分类的操作. 拿到原始数据后, 可以先进行一些操作: 将以上的原始数据合并, 则可以得到所有的文章列表. 由此, 可以实现rssblog的基本功能, 预览所有文章的标题. 其次, 可以按照时间分类, 将Year-Month做成文件夹, 将对应的数据存在这些文件夹中. 由此, 可以实现rssblog的时间分类功能. 还可以按照博主分类, 可以实现rssblog的博主分类功能. 还可以按照数据源分类, 可以实现rssblog的源分类功能. 以上操作还不能保留以前拉取的数据, 并且上述都是临时数据(从rss list里面拉取和分类的).(对应fetch_*.py) 所以我们还需要一个地方保存最终的目标数据. 将以上数据按照对应目录保存在__tmp__, 然后merge到目标目录public, 对应merge_*.py. merge_source(rss_out_source_dir, rss_fetch_source_dir) merge_all(rss_out_all_dir, rss_fetch_all_dir) merge_member(rss_out_member_dir, rss_fetch_member_dir) merge_date(rss_out_date_dir, rss_fetch_date_dir) merge_user(rss_out_user_dir, rss_fetch_user_dir) 目前采用比较笨的merge方法, 读取__tmp__和public对应路径的所有数据, 然后合并, 去重, 排序, 再存入到public. 这样在未来数据量增加时会有性能问题. 不过目前也就\u003c10MB的数据, 数据增量也很小, 所以暂时不关心这个问题. 拉取和合并数据时, 每个独立分类下都有完整的数据, 比如源分类里面有所有的数据, 时间分类里面也有所有的数据, 如此会有很多的冗余, 能不能合并一起呢? 我认为是不行的, 因为没有高效的查找功能. 如果所有数据合并在一起, 我们就需要根据某个数据的index去这个合集里面查找, 对于vercel/github仓库来说, 这一点都不友好, 涉及太多IO. 所以, 当前设计是在每个分类下都有完整的数据, 因而在rssblog拉取数据时, 按照页为单位拉取, 比如第一页, 就是对应目录下的1.csv, 这样就可以只涉及一次IO操作, 尽管会有数据冗余, 也是可以接受的. 以上, 目前采取每天0/12/18点更新的策略. ","date":"2021-12-20","objectID":"/202112/talk-rssblogsource/:1:0","tags":["flask","Python","博客"],"title":"rssblog的数据源-rssblog-source","uri":"/202112/talk-rssblogsource/"},{"categories":["工具"],"content":"备份博文 有时候会担心某个博主突然关站了, 怎么办? 所以考虑到需要备份文章的原始数据. 这时候需要考虑后期的维护成本, 比如源数据可能很大, 也不要对站长造成流量上的困扰, 所以目前仅是get原文的数据, 如果站长有反爬策略, 则可能不会get到目标数据. 这部分后续还会更新, 可能会伪装一下, 但是…也不太好, 有些站长不知道会不会愿意. 源博文的其他数据, 例如图片/视频等暂时不会拉取. 不拉取媒体资源, 一是出于流量的考虑, 二是考虑维护成本, 三是考虑数据容量, 仅量避免github仓库溢出(其实可以考虑多个仓库的策略, 这样几乎就没有容量上限了). 文章数量太多时, 会触及github仓库的文件数量上限, 所以目前在action服务上拉取文章后, 会将所有文章归档, 保存为一个文件, 后续向其中更新/添加新文件即可. 当然, 这里也有其他解决方法, 比如参考git的blob保存策略, 将get下来的数据的文件名保存为md5值(实际上是按照文章链接和最后更新的timestamp计算的md5, 这样可以尽量保证保存的是最新的数据), 可以将md5分成三组(其他数量也行), 然后第一组作为一级目录, 第二组作为二级目录, 第三组作为文件名. 这样, 可以尽量减少每个目录下的文件数量. 这部分后续会更新. 另外, 在源仓库根目录下需要保存源文的一些信息, 比如文件地址/题目/作者等等, 这样就容易通过外部服务访问备份数据. 当然, 在rssblog上这部分接口还没有添加, 近期也不会考虑添加, 因为目前各位的博客看起来都很健康, 应该不会出现退网的情况.(其实就是懒.) 这部分对应的源码在backup_*.py, 以下是对应源文拉取的部分, 会尝试拉取3次, 以尽量避免网络波动等问题造成的拉取失败: @repeat(3) def download_article(backup_stats): keys = backup_stats.loc[backup_stats['path'] == '-', ['key', 'link']].to_numpy() if len(keys) == 0: return print(\"backup\", len(keys), \"links waiting for download\") def failed_backup(requests, exceptions): print(\"backup failed\", requests, exceptions) return None if not os.path.exists(BACKUP_PATH): os.makedirs(BACKUP_PATH) lens = len(keys) batch = 100 for s in range(0, lens, batch): keys_batch = keys[s: s + batch] reqs = [grequests.get(key[1], timeout=5.0) for key in keys_batch] print(\"backup request batch size: %d\" % len(reqs)) resp = grequests.map(reqs, exception_handler=failed_backup) for i, response in enumerate(resp): if not response: continue path = os.path.join(BACKUP_PATH, keys_batch[i][0] + \".html\") with open(path, 'w') as f: f.write(response.text) backup_stats.loc[(backup_stats['key'] == keys_batch[i][0]), 'path'] = '+' f.close() 可以看到, 文章被正常拉取并保存后, 会更新path的值, 这里的path表示当前文章的状态, 比如’+‘表示已经拉取并保存, ‘-‘表示还未拉取, 如果还有其他步骤的话, 可以继续添加, 这样可以减少一些重复的工作. 以上, 目前采取每周六4点更新的策略. ","date":"2021-12-20","objectID":"/202112/talk-rssblogsource/:2:0","tags":["flask","Python","博客"],"title":"rssblog的数据源-rssblog-source","uri":"/202112/talk-rssblogsource/"},{"categories":["工具"],"content":"分析数据 这部分是设想, 未来有时间会做的. 有了原始数据, 我们可以做更多的事情. 比如: 某些博主关站后, 我们还能访问他们原来的文章内容; (如果对方允许的话) 可以提取博文关键词, 自动生成rssblog的关键词云; 提供最新文章的接口, 这样可以应用在友链页面, 及时获取朋友们的最近更新; 其他; 目前在做的部分是关键词云, 但是关键词的准确性还有些问题. 解决完关键词问题后就可以按照关键词分类, 也可以实现搜索功能. ","date":"2021-12-20","objectID":"/202112/talk-rssblogsource/:3:0","tags":["flask","Python","博客"],"title":"rssblog的数据源-rssblog-source","uri":"/202112/talk-rssblogsource/"},{"categories":["Cpp"],"content":"问题 在提交代码的时候发现了代码中的一个问题: 大概意思是, 有一个pair类型的数据, 使用如下方式打印了pair的first的数据(实际上是代码写错了, 但是依然正常工作): using ps = pair\u003cuint64, float\u003e; ps p1(1, 1.1111); printf(\"%p\\n\", p1); 编译是正常的, 这时候怀疑打印的结果是不是正常的呢? ","date":"2021-12-14","objectID":"/202112/pair-memstruct/:1:0","tags":["内存","Cpp"],"title":"pair的内存结构","uri":"/202112/pair-memstruct/"},{"categories":["Cpp"],"content":"pair的实现 template\u003ctypename _U1, typename _U2\u003e class __pair_base { #if __cplusplus \u003e= 201103L template\u003ctypename _T1, typename _T2\u003e friend struct pair; __pair_base() = default; ~__pair_base() = default; __pair_base(const __pair_base\u0026) = default; __pair_base\u0026 operator=(const __pair_base\u0026) = delete; #endif // C++11 }; template\u003ctypename _T1, typename _T2\u003e struct pair : private __pair_base\u003c_T1, _T2\u003e { typedef _T1 first_type; /// @c first_type is the first bound type typedef _T2 second_type; /// @c second_type is the second bound type _T1 first; /// @c first is a copy of the first object _T2 second; /// @c second is a copy of the second object //................................................................ } 如上, pair的first和second两个数据是pair的成员变量, pair没有虚函数, pair继承自__pair_base, 且__pair_base中没有成员变量, 到这里就可以回答上面的问题, 问题中的输出是没问题的. 以上结论可以参考C++类的内存分布(二)和C++类的内存分布. ","date":"2021-12-14","objectID":"/202112/pair-memstruct/:2:0","tags":["内存","Cpp"],"title":"pair的内存结构","uri":"/202112/pair-memstruct/"},{"categories":["Cpp"],"content":"验证 我们使用一小段代码验证上述结论, 源码在这里: #include \u003ciostream\u003e #include \u003cvector\u003e using namespace std; using uint64 = unsigned long long int; using ps = pair\u003cuint64, float\u003e; int main() { ps p1(1, 1.1111); ps p2(2, 2.2222); vector\u003cps\u003e vp{p1, p2}; printf(\"%p\\n\", p1); printf(\"%p\\n\", p2); for (auto \u0026p : vp) { printf(\"%p\\n\", p); } } 可以得到期望的输出: 0x1 0x2 0x1 0x2 不过并不推荐这样写, 这种写法依赖对函数/结构的了解程度. 本文仅是复习之前学习的一些知识来解释一些看似不太自然的问题. ","date":"2021-12-14","objectID":"/202112/pair-memstruct/:3:0","tags":["内存","Cpp"],"title":"pair的内存结构","uri":"/202112/pair-memstruct/"},{"categories":["Cpp"],"content":"扩展验证 还是有些不放心, 因为pair是一个struct, 虽然我们学过struct基本可以等价为class, 但是总归没有真正看过是怎么等价的. 所以我们用下面的代码大概验证一下class和struct的内存结构是不是一样的, 下面的验证不全面, 仅初步了解, 源码在这里: #include \u003ciostream\u003e using namespace std; class A{ public: char a; int b; }; struct B{ char a; int b; }; int main() { A a; a.a = 1; a.b = 2; B b; b.a = 3; b.b = 4; printf(\"A.a = %d\\n\", a); printf(\"B.a = %d\\n\", b); printf(\"A.addr = %p\\n\", \u0026a); printf(\"B.addr = %p\\n\", \u0026b); printf(\"A.a.addr = %p\\n\", \u0026(a.a)); printf(\"B.a.addr = %p\\n\", \u0026(b.a)); } 以上输出很奇怪: A.a = 1 B.a = 174317315 A.addr = 0x7ffc0a63de28 B.addr = 0x7ffc0a63de20 A.a.addr = 0x7ffc0a63de28 B.a.addr = 0x7ffc0a63de20 我们本期望B.a输出是3, 但是我们得到了一个随机数, 所以可以观察后面的addr的输出, 这是符合预期的, class的基地址和第一个成员变量的地址一致, 那为什么B.a的输出不和期望呢? 考虑到是内存对齐的原因. 以上定义的成员a是一个char型, b是int型, 所以会向b对齐, 这时候按照%d解析基地址就可能有问题了, 我们改成这样的, 就能正常解析: A a; a.a = 65; a.b = 2; B b; b.a = 66; b.b = 4; printf(\"A.a = %c\\n\", a); //A.a = A printf(\"B.a = %c\\n\", b); //B.a = B printf(\"A.addr = %p\\n\", \u0026a); printf(\"B.addr = %p\\n\", \u0026b); printf(\"A.a.addr = %p\\n\", \u0026(a.a)); printf(\"B.a.addr = %p\\n\", \u0026(b.a)); 这小结偏题了, 但是也是在提醒我们需要注意内存对齐. ","date":"2021-12-14","objectID":"/202112/pair-memstruct/:3:1","tags":["内存","Cpp"],"title":"pair的内存结构","uri":"/202112/pair-memstruct/"},{"categories":["Cpp"],"content":"小结 pair的first成员的地址和基地址一致; 要注意class/struct的内存对齐; 仅量不要使用类的基地值访问类成员, 以免内存对齐/封装性等问题. ","date":"2021-12-14","objectID":"/202112/pair-memstruct/:4:0","tags":["内存","Cpp"],"title":"pair的内存结构","uri":"/202112/pair-memstruct/"},{"categories":["工具"],"content":"为应对blog的一些需求, 依托vercel搭建了一个webapi的服务, 考虑到vercel的性能以及自建难度, 部分api仅供个人使用. api.bbing.com.cn, 支持以下api. ","date":"2021-12-13","objectID":"/202112/webapi-descriptor/:0:0","tags":["vercel","Python","flask"],"title":"添加了一些WebAPI","uri":"/202112/webapi-descriptor/"},{"categories":["工具"],"content":"/dog 请求舔狗日记. 数据来源网络, 如有侵权请联系我删除. 参数 值域 作用 默认 method js|json|text 数据返回形式 text count 1-100 一次请求返回count条数据 1 identify Element ID 数据填写的Element ID \"\" /dog?method=js curl \"https://api.bbing.com.cn/dog?method=js\" document.write('我今天送了你一支口红，你拿到之后很开心，在他的嘴巴上亲了一下，或许他送你口红的时候，你也会在我的嘴巴上亲一下吧。'); /dog?method=js\u0026identify=dogdog curl \"https://api.bbing.com.cn/dog?method=js\u0026identify=dogdog\" document.getElementById('dogdog').innerText='小时候抓周抓了个方向盘 爸妈都以为我长大了会当赛车手 最差也是个司机 没想到我长大了当了你的备胎'; curl \"https://api.bbing.com.cn/dog?method=json\u0026count=2\" {\"data\": \"['你从来没说过爱我，聊天记录搜索了一下“爱”，唯一的一条是：你好像乡村爱情里的刘能啊。', '昨晚你终于回我信息了，你回了一句谢谢还加了一个爱心。当时我在工地上激动的差点把隔壁的吊塔阿姨给亲了。不过我想了想你笑起来的样子我还是忍住了。你给我发爱心，一定是已经爱上我了吧，放心，我连咱们的孩子名字都想好了。等我，我一定会继续努力挣钱，给你买更多的化妆品，发更多的红包！']\"} /dog?method=text curl \"https://api.bbing.com.cn/dog?method=text\" 昨天你把我拉黑了，我看着红色感叹号陷入了久久的沉思，我想这其中一定有什么含义？红色红色？我明白了！红色代表热情，你对我很热情，你想和我结婚，我愿意。 /dog?method=text\u0026count=2 curl \"https://api.bbing.com.cn/dog?method=text\u0026count=2\" ['你说你情头是一个人用的 空间上锁是因为你不喜欢玩空间 情侣空间是和闺蜜开的 找你连麦时你说你在忙工作 每次聊天你都说在忙 你真是一个上进的好女孩 你真好 我好喜欢你。', '昨天你把我拉黑了，我看着红色感叹号陷入了久久的沉思，我想这其中一定有什么含义？红色红色？我明白了！红色代表热情，你对我很热情，你想和我结婚，我愿意。'] ","date":"2021-12-13","objectID":"/202112/webapi-descriptor/:1:0","tags":["vercel","Python","flask"],"title":"添加了一些WebAPI","uri":"/202112/webapi-descriptor/"},{"categories":["工具"],"content":"/uptimerobot 自用. 返回uptimerobot的监视器, 300s更新一次, 用于自动判断blog友链的可访问性, 详细见友链. ","date":"2021-12-13","objectID":"/202112/webapi-descriptor/:2:0","tags":["vercel","Python","flask"],"title":"添加了一些WebAPI","uri":"/202112/webapi-descriptor/"},{"categories":["工具"],"content":"/gist 自用. 返回gist, 60s更新一次, 用于加速国内访问时获取blog友链列表, 详细见友链. ","date":"2021-12-13","objectID":"/202112/webapi-descriptor/:3:0","tags":["vercel","Python","flask"],"title":"添加了一些WebAPI","uri":"/202112/webapi-descriptor/"},{"categories":["操作系统","glibc"],"content":"问题 关于raise函数，有几个想调查的问题： raise是怎么实现的? raise的作用时机? ","date":"2021-11-16","objectID":"/202111/glibc-raise/:1:0","tags":["Linux","glibc"],"title":"glibc-raise源码阅读","uri":"/202111/glibc-raise/"},{"categories":["操作系统","glibc"],"content":"源码 先来看raise的实现, 代码比较简单, 我们也无需递归地去看每一个函数地实现. raise调用的就是tgkill. tgkill相比kill和tkill, 增加了多线程的保护, 通过tid和tgid基本保证信号传递到正确的线程, 而不会因为线程的消亡和构建而传递到错误的线程. int raise (int sig) { /* rt_sigprocmask may fail if: 1. sigsetsize != sizeof (sigset_t) (EINVAL) 2. a failure in copy from/to user space (EFAULT) 3. an invalid 'how' operation (EINVAL) The first case is already handle in glibc syscall call by using the arch defined _NSIG. Second case is handled by using a stack allocated mask. The last one should be handled by the block/unblock functions. */ sigset_t set; __libc_signal_block_app (\u0026set); INTERNAL_SYSCALL_DECL (err); pid_t pid = INTERNAL_SYSCALL (getpid, err, 0); pid_t tid = INTERNAL_SYSCALL (gettid, err, 0); int ret = INLINE_SYSCALL (tgkill, 3, pid, tid, sig); __libc_signal_restore_set (\u0026set); return ret; } raise看起来很简单, 我们也可以通过man raise来详细了解一下, 其说明的是: raise在单线程中等同于kill; raise在多线程中等同于pthread_kill; raise在信号处理函数处理结束后返回; raise是多线程安全的; glibc 2.3.3版本后raise调用的是tgkill.(本文即是tgkill) 所以我们可以解答开头的问题: raise是怎么实现的? 等同于tgkill, rasie发送信号给线程(进程), 然后调用对应的信号处理函数. 回忆上一篇《glibc-abort源码阅读》, 调用abort的时候就是调用raise发送SIGABRT信号, 会有SIG_DFL之类的处理函数绑定SIGABRT信号, 从而造成进程退出. raise的作用时机? 同信号处理, 参考《进程控制和通信(四) · PCB介绍》可以知道, raise是在用户陷入内核态再从内核态返回用户态的过程中会被处理. 所以, abort的作用时机也是等同于raise. 信号处理时机 ","date":"2021-11-16","objectID":"/202111/glibc-raise/:2:0","tags":["Linux","glibc"],"title":"glibc-raise源码阅读","uri":"/202111/glibc-raise/"},{"categories":["操作系统","glibc"],"content":"问题 关于abort函数，有几个想调查的问题： abort是退出当前线程还是退出当前进程? abort和raise/exit的区别是什么? 通过测试代码, 我们可以验证问题一, 通过阅读源码, 尽量来理解问题二. ","date":"2021-11-11","objectID":"/202111/glibc-abort/:1:0","tags":["Linux","glibc"],"title":"glibc-abort源码阅读","uri":"/202111/glibc-abort/"},{"categories":["操作系统","glibc"],"content":"测试 #include \u003cthread\u003e #include \u003ccstdlib\u003e #include \u003ciostream\u003e #include \u003cchrono\u003e #include \u003cexception\u003e using namespace std; int main() { thread t1([]() { int cnt = 20; while (cnt-- \u003e 0) { cout \u003c\u003c \"cnt=\" \u003c\u003c cnt \u003c\u003c endl; this_thread::sleep_for(std::chrono::seconds(1)); } }); thread t2([]() { this_thread::sleep_for(std::chrono::seconds(2)); cout \u003c\u003c \"t2 abort\" \u003c\u003c endl; try { abort(); } catch (exception \u0026e) { } }); if (t1.joinable()) t1.join(); if (t2.joinable()) t2.join(); return 1; } 开始编译: g++ main.cpp -o main --std=c++11 -lpthread 输出结果: cnt=19 cnt=18 t2 abort Aborted (core dumped) 通过这个测试可以直到, abort会导致进程的退出. ","date":"2021-11-11","objectID":"/202111/glibc-abort/:2:0","tags":["Linux","glibc"],"title":"glibc-abort源码阅读","uri":"/202111/glibc-abort/"},{"categories":["操作系统","glibc"],"content":"源码 首先是与abort相关的一些全局变量的定义, 如下, 有stage和lock, 并且此处的lock是递归lock. 这里可以看到递归锁是通过一个计数器实现的, 这里想到了信号量, 可以参考或对比《《UCB CS61a SICP Python 中文》一周目笔记(四)》和《进程控制和通信(三) · 消息、信号、共享内存》. 为什么使用递归锁? 有些系统调用函数也不太清楚, 所以不太好下结论. 不过, 这里的递归锁可以保护stage的状态, 至少是有这个用处的. 使用递归的目的, 也是因为abort确实可能存在递归调用(用户性为上的). 从这里我们也可以看到abort的行为是对进程的. /* We must avoid to run in circles. Therefore we remember how far we already got. */ static int stage; /* We should be prepared for multiple threads trying to run abort. */ __libc_lock_define_initialized_recursive (static, lock); 接下来是处理函数, 我们分为几个部分来看: 补充一个知识点: 信号掩码是对线程而言的. 第一部分是设置信号掩码, 允许SIGABRT信号. 尝试第一次raise SIGABRT信号, 用户可能绑定SIGABRT的信号处理函数, 这时候会去处理用户的信号函数. 这里考虑的问题是raise可能失败(去处理用户信号函数, 可能不引起SIGABRT退出), 所以会有后续操作. /* Cause an abnormal program termination with core-dump. */ void abort (void) { struct sigaction act; sigset_t sigs; /* First acquire the lock. */ __libc_lock_lock_recursive (lock); /* Now it's for sure we are alone. But recursive calls are possible. */ /* Unblock SIGABRT. */ if (stage == 0) { ++stage; __sigemptyset (\u0026sigs); __sigaddset (\u0026sigs, SIGABRT); __sigprocmask (SIG_UNBLOCK, \u0026sigs, 0); } /* Send signal which possibly calls a user handler. */ if (stage == 1) { /* This stage is special: we must allow repeated calls of `abort' when a user defined handler for SIGABRT is installed. This is risky since the `raise' implementation might also fail but I don't see another p ossibility. */ int save_stage = stage; stage = 0; __libc_lock_unlock_recursive (lock); raise (SIGABRT); __libc_lock_lock_recursive (lock); stage = save_stage + 1; } //... 执行用户绑定的信号函数后, 现在将SIG_DFL绑定到SIGABRT上, 然后raise SIGABRT信号. SIG_DFL是默认信号处理函数, 其值是0, 调用SIG_DFL相当于是访问0地址, 被禁止访问, 这时候就会退出进程了. /* There was a handler installed. Now remove it. */ if (stage == 2) { ++stage; memset (\u0026act, '\\0', sizeof (struct sigaction)); act.sa_handler = SIG_DFL; __sigfillset (\u0026act.sa_mask); act.sa_flags = 0; __sigaction (SIGABRT, \u0026act, NULL); } /* Try again. */ if (stage == 3) { ++stage; raise (SIGABRT); } 又担心raise失败, 这时候调用汇编的hlt命令(ABORT_INSTRUCTION调用的是htl命令), 使得逻辑CPU处于睡眠状态, 这时候相当于不再给当前进程CPU资源了. 如果hlt失败, 则又尝试exit退出. 如果exit失败, 则又不停地尝试hlt. /* Now try to abort using the system specific command. */ if (stage == 4) { ++stage; ABORT_INSTRUCTION; } /* If we can't signal ourselves and the abort instruction failed, exit. */ if (stage == 5) { ++stage; _exit (127); } /* If even this fails try to use the provided instruction to crash or otherwise make sure we never return. */ while (1) /* Try for ever and ever. */ ABORT_INSTRUCTION; } 现在我们知道abort是通过调用raise/exit/hlt这些命令使得进程退出的. 不过这里也有疑问, 为什么需要做这么多后备处理? raise/exit/hlt在哪些情况下会失败呢? (TODO) (这里的exit是指系统调用的_exit，可以关联《glibc-exit源码阅读》) ","date":"2021-11-11","objectID":"/202111/glibc-abort/:3:0","tags":["Linux","glibc"],"title":"glibc-abort源码阅读","uri":"/202111/glibc-abort/"},{"categories":["工具"],"content":"问题 在《使用Docker构建不同平台编译环境》中, 模拟了不同系统平台的编译环境, 使得我们可以在某一个系统平台编译其他系统平台的内容. 最近遇到一个问题: 从AOSP拿到的heap_trace工具是使用glibc2.28及以上库编译的, 我本地的机器是ubuntu18.04, 使用的是2.27版本, 所以不兼容heap_trace工具. 但是查到ubuntu20.04更新了glibc版本, 然后想到了使用docker模拟ubuntu20.04环境. ","date":"2021-11-10","objectID":"/202111/docker-build2/:1:0","tags":["Docker","平台"],"title":"使用Docker模拟软件运行环境","uri":"/202111/docker-build2/"},{"categories":["工具"],"content":"Dockerfile FROM ubuntu:20.04 WORKDIR /scripts RUN apt update \u0026\u0026 apt install -y python3 adb curl 使用ubuntu20.04镜像, 并且之后会将本地的测试脚本目录映射到容器的/scripts路径下. 镜像中也要记得安装脚本依赖. ","date":"2021-11-10","objectID":"/202111/docker-build2/:2:0","tags":["Docker","平台"],"title":"使用Docker模拟软件运行环境","uri":"/202111/docker-build2/"},{"categories":["工具"],"content":"构建镜像和容器 docker build -t heap_trace . docker create -it --name heap_trace --privileged --volume /dev/bus/usb/:/dev/bus/usb/ --volume **/scripts/heap_trace/:/scripts heap_trace /bin/bash /scripts/heap_recording_new.sh 构建容器时需要注意将本地的usb设备映射到容器对应的路径下, --volume /dev/bus/usb/:/dev/bus/usb/, 容器访问Android设备时, 本地需要断开adb连接, adb kill-server. 最后就可以运行容器了： docker start heap_trace -i ","date":"2021-11-10","objectID":"/202111/docker-build2/:3:0","tags":["Docker","平台"],"title":"使用Docker模拟软件运行环境","uri":"/202111/docker-build2/"},{"categories":["Cpp"],"content":"问题一: test(x++, x == 1) 以下函数的输出是什么? 本文源码参考: https://gcc.godbolt.org/z/veMohGYob void test(int x, bool bl) { cout \u003c\u003c x \u003c\u003c \" \" \u003c\u003c bl \u003c\u003c endl; } //... int x = 0; test(x++, x == 1); ","date":"2021-10-29","objectID":"/202110/ppi-ipp-func/:1:0","tags":["Cpp"],"title":"i++和++i在函数入参时的一些问题","uri":"/202110/ppi-ipp-func/"},{"categories":["Cpp"],"content":"参数计算顺序和入参顺序 首先, 毫无疑问, C/C++标准规定的函数参数入参顺序是从右往左. 按照上述说法, 问题一的数输出应该就是0 0. 使用gcc编译, 发现输出结果确实是0 0, 但是使用clang编译的输出结果是0 1. 不同编译器编译同一个函数, 居然会导致函数的输出不一样. 这是因为在函数参数入参之前还有参数的计算过程. 在《UCB CS61a SICP Python 中文》一周目笔记(一)中提到了函数参数的应用序和正则序, 按照我们的认知和经验, C/C++编译器使用的是应用序, 所以在函数入参之前需要计算参数的结果. 但是, 同入参顺序, 参数计算也有顺序. C/C++标准中没有规定函数参数的计算顺序, 所以导致不同的编译器可能定义了不同的参数计算顺序. 如上结果: gcc的参数计算顺序是从右往左; clang的参数计算顺序是从左往右; ","date":"2021-10-29","objectID":"/202110/ppi-ipp-func/:2:0","tags":["Cpp"],"title":"i++和++i在函数入参时的一些问题","uri":"/202110/ppi-ipp-func/"},{"categories":["Cpp"],"content":"问题二: test(m_idx++) 下面这个类Test, 调用test()方法的输出是什么? class Test{ public: Test() : m_idx(0) {} ~Test() {} void test() { test(m_idx++); } private: void test(int idx) { cout \u003c\u003c idx \u003c\u003c \" \" \u003c\u003c m_idx \u003c\u003c endl; } int m_idx; }; //... Test t; t.test(); 这里不涉及问题一的计算顺序了. 经过测试, test的输出结果是0 1, 这意为着m_idx++在入参时是传入的没有++的m_idx, 但是在调用函数之后, 有发现m_idx被++了, 也就是说, m_idx + 1的动作发生在入参前后. 这里涉及到的知识点是x++和++x的计算时机. ","date":"2021-10-29","objectID":"/202110/ppi-ipp-func/:3:0","tags":["Cpp"],"title":"i++和++i在函数入参时的一些问题","uri":"/202110/ppi-ipp-func/"},{"categories":["Cpp"],"content":"i++和++i的计算时机 先来看看汇编结果: Test::test(): mov QWORD PTR [rbp-0x8],rdi mov rdi,QWORD PTR [rbp-0x8] mov esi,DWORD PTR [rdi] mov eax,esi add eax,0x1 mov DWORD PTR [rdi],eax call 401350 \u003cTest::test(int)\u003e ## ... Test::test(int): mov DWORD PTR [rbp-0xc],esi mov rax,QWORD PTR [rbp-0x8] mov QWORD PTR [rbp-0x18],rax mov esi,DWORD PTR [rbp-0xc] 首先是拿到了m_idx, 然后将m_idx的值存入esi寄存器, 再将esi寄存器的值(这时候就是m_idx的值)存入eax寄存器, 然后eax+1, 再将eax寄存器加完后的结果存如m_idx, 然后调用test(int)函数. 在test(int)中会将esi寄存器的值作为入参参数. 所以我们可以得到一个结论: 执行test(m_idx++);时, 先将m_idx送入esi寄存器(源变址寄存器), 再复制到eax寄存器(累加寄存器), 再在eax寄存器执行++操作, 然后送入m_idx, 这时候m_idx已经执行完+1操作了. 参数入参时使用的是esi中的值, 所以入参的值是没有加一的值. 如果是test(++m_idx);呢? Test::test(): mov QWORD PTR [rbp-0x8],rdi mov rdi,QWORD PTR [rbp-0x8] mov esi,DWORD PTR [rdi] add esi,0x1 mov DWORD PTR [rdi],esi call 401350 \u003cTest::test(int)\u003e 可以发现, 没有使用临时寄存器了, 而是直接在esi寄存器上使用+1操作. 所以入参的值就是加完之后的值. ","date":"2021-10-29","objectID":"/202110/ppi-ipp-func/:4:0","tags":["Cpp"],"title":"i++和++i在函数入参时的一些问题","uri":"/202110/ppi-ipp-func/"},{"categories":["软件设计"],"content":"并行计算、序列和协程 锁、条件变量、死锁在译文中的描述符合我的认知，在此就不介绍了。以下是关于信号量的补充，在文章《进程控制和通信(三) · 消息、信号、共享内存》中描述过信号量，但是仅将信号量作为锁的一种实现方法。 ","date":"2021-09-17","objectID":"/202109/sicp-python-read4/:1:0","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(四)","uri":"/202109/sicp-python-read4/"},{"categories":["软件设计"],"content":"信号量 信号量是用于维持有限资源访问的信号。它们和锁类似，除了它们可以允许某个限制下的多个访问。它就像电梯一样只能够容纳几个人。一旦达到了限制，想要使用资源的进程就必须等待。其它进程释放了信号量之后，它才可以获得。 例如，假设有许多进程需要读取中心数据库服务器的数据。如果过多的进程同时访问它，它就会崩溃，所以限制连接数量就是个好主意。如果数据库只能同时支持N=2的连接，我们就可以以初始值N=2来创建信号量。 这里想到了socket里面的listen接口，可以监听N个连接，这里的实现可能就用到了值为N的信号量，不过目前还没找到源码。 \u003e\u003e\u003e from threading import Semaphore \u003e\u003e\u003e db_semaphore = Semaphore(2) # set up the semaphore \u003e\u003e\u003e database = [] \u003e\u003e\u003e def insert(data): db_semaphore.acquire() # try to acquire the semaphore database.append(data) # if successful, proceed db_semaphore.release() # release the semaphore \u003e\u003e\u003e insert(7) \u003e\u003e\u003e insert(8) \u003e\u003e\u003e insert(9) 信号量的工作机制是，所有进程只在获取了信号量之后才可以访问数据库。只有N=2个进程可以获取信号量，其它的进程都需要等到其中一个进程释放了信号量，之后在访问数据库之前尝试获取它。 P1 P2 P3 acquire db_semaphore: ok acquire db_semaphore: wait acquire db_semaphore: ok read data: 7 wait read data: 9 append 7 to database wait append 9 to database release db_semaphore: ok acquire db_semaphore: ok release db_semaphore: ok read data: 8 append 8 to database release db_semaphore: ok 值为 1 的信号量的行为和锁一样。 ","date":"2021-09-17","objectID":"/202109/sicp-python-read4/:1:1","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(四)","uri":"/202109/sicp-python-read4/"},{"categories":["软件设计"],"content":"协程 关于协程，之后再用一个篇幅来讲吧，大概会讲协程的原理和实现方法（TODO），本文仅是SICP的学习记录。 send和yield 此处并不是讲send和yield的实现原理或使用方法，而是为了记录从这两个方法中学习到的一种比较通用的范式，以便可以迁移到其他的学习中去。 协程可以通过(yield)语句来消耗值，向像下面这样： value = (yield) 使用这个语法，在带参数调用对象的send方法之前，执行流会停留在这条语句上。 coroutine.send(data) 之后，执行会恢复，value会被赋为data的值。为了发射计算终止的信号，我们需要使用close()方法来关闭协程。这会在协程内部产生GeneratorExit异常，它可以由try/except子句来捕获。 下面的例子展示了这些概念。它是一个协程，用于打印匹配所提供的模式串的字符串。 \u003e\u003e\u003e def match(pattern): print('Looking for ' + pattern) try: while True: s = (yield) if pattern in s: print(s) except GeneratorExit: print(\"=== Done ===\") 按照上述对yield和send的解释，match运行会停在yield处，直到有send调用才会继续向下执行，执行后又会回到yield等待。 如下调用： \u003e\u003e\u003e text = 'Commending spending is offending to people pending lending!' \u003e\u003e\u003e matcher = match('ending') \u003e\u003e\u003e matcher.__next__() Looking for ending \u003e\u003e\u003e read(text, matcher) Commending spending offending pending lending! === Done === read函数向协程matcher发送每个单词，协程打印出任何匹配pattern的输入。在matcher协程中，s = (yield)一行等待每个发送进来的单词，并且在执行到这一行之后将控制流交还给read。 send激活yield，下一次执行到yield时又将控制流交换给send之后的流程。 ","date":"2021-09-17","objectID":"/202109/sicp-python-read4/:1:2","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(四)","uri":"/202109/sicp-python-read4/"},{"categories":["软件设计"],"content":"尾声 本篇是“SICP笔记/读后感系列”的最后一篇，本篇大部分内容都是摘抄自原文的ch5，本系列文章名后面加了一周目，是因为我觉的这种读物是值得多次阅读的，不同的阶段肯定会有不同的收获、见解。至于什么时候开二周目，我也不知道，至少近期不会。 ","date":"2021-09-17","objectID":"/202109/sicp-python-read4/:1:3","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(四)","uri":"/202109/sicp-python-read4/"},{"categories":["工具"],"content":"本站原来使用lunr.js作为搜索引擎，在使用过程中发现一些问题： 客户端需要下载索引文件 会出现搜索失效的情况 故本站改为algolia搜索，使用hugo-algolia创建algolia索引文件时发现，hugo-algolia仅针对英文分词，并且会包含一些无用词。hugo-algolia项目master分支超过一年未更新，且issue也较长时间未作出回复，所以本项目hugo-algolia2 clone自hugo-algolia，在其ISC许可下作为单独项目开发。 本项目持续更新中，如有问题欢迎反馈 ","date":"2021-09-10","objectID":"/202109/hugo-algolia2/:0:0","tags":["hugo","algolia","搜索"],"title":"Hugo搜索工具hugo-algolia2","uri":"/202109/hugo-algolia2/"},{"categories":["工具"],"content":"hugo-algolia2 项目改编自hugo-algolia, 用于hugo静态内容的搜索. ","date":"2021-09-10","objectID":"/202109/hugo-algolia2/:1:0","tags":["hugo","algolia","搜索"],"title":"Hugo搜索工具hugo-algolia2","uri":"/202109/hugo-algolia2/"},{"categories":["工具"],"content":"New Features 修复原项目的一些问题 支持自定义URI格式 支持按照文件后缀过滤 去除无用单词 添加中文分词 ","date":"2021-09-10","objectID":"/202109/hugo-algolia2/:1:1","tags":["hugo","algolia","搜索"],"title":"Hugo搜索工具hugo-algolia2","uri":"/202109/hugo-algolia2/"},{"categories":["工具"],"content":"Installation 从npm安装hugo-algolia2 npm install hugo-algolia2 或者 yarn add hugo-algolia2 ","date":"2021-09-10","objectID":"/202109/hugo-algolia2/:1:2","tags":["hugo","algolia","搜索"],"title":"Hugo搜索工具hugo-algolia2","uri":"/202109/hugo-algolia2/"},{"categories":["工具"],"content":"How does it work? 默认遍历hugo项目的/content路径下的文件, 并且按照[‘html’,‘md’]后缀过滤, 并且在/public下生成algolia.json. 具体配置参数可以使用hugo-algolia2 --help. ","date":"2021-09-10","objectID":"/202109/hugo-algolia2/:1:3","tags":["hugo","algolia","搜索"],"title":"Hugo搜索工具hugo-algolia2","uri":"/202109/hugo-algolia2/"},{"categories":["工具"],"content":"Sending to Algolia 在hugo项目根目录下添加配置文件config.yaml, 如下: --- baseURL: / uri: :year:month/:slug algolia: index: \"index-name\" key: \"[your API key]\" appID: \"[your app id]\" --- URI是访问路径, 需要和hugo的配置相同. key需要填写Admin API Key. 配置之后, hugo-algolia2 -s 可以上传algolia配置. ","date":"2021-09-10","objectID":"/202109/hugo-algolia2/:1:4","tags":["hugo","algolia","搜索"],"title":"Hugo搜索工具hugo-algolia2","uri":"/202109/hugo-algolia2/"},{"categories":["工具"],"content":"Github Action name: deploy on: push: workflow_dispatch: jobs: generate-algolia: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - uses: caibingcheng/hugo-algolia2@v1 with: input: \"./posts/**\" output: \"./algolia.json\" index: ${{ secrets.ALGOLIA_INDEX }} apikey: ${{ secrets.ALGOLIA_APIKEY }} appid: ${{ secrets.ALGOLIA_APPID }} ","date":"2021-09-10","objectID":"/202109/hugo-algolia2/:1:5","tags":["hugo","algolia","搜索"],"title":"Hugo搜索工具hugo-algolia2","uri":"/202109/hugo-algolia2/"},{"categories":["工具"],"content":"License 同hugo-algolia, 本项目也使用ISC License. ","date":"2021-09-10","objectID":"/202109/hugo-algolia2/:2:0","tags":["hugo","algolia","搜索"],"title":"Hugo搜索工具hugo-algolia2","uri":"/202109/hugo-algolia2/"},{"categories":["随笔"],"content":"起点 我的起点已经比很多人低了。 大概三年前，大部分同学都在刷题、看书准备找工作的时候，我却是悠哉悠哉，并不在意，完全沉浸在自己当时的工作中。或许很多人会有和我一样的想法：看这些没用的东西干嘛？太功利了，我不屑。 刷题、看八股文，正真工作的时候却是基本用不上，完全是为了面试准备的，太功利了。 当时的我觉得实用主义至上。这可能是大学养成的习惯。大学之前，我可能会好好做题，一步一步打好基础。但是到大学就变了，如果你志不在绩点，可能就没这么多时间一步一步从基础做起，基础部分过过就行了。技术太多，却学不完，跟不上。甚至有一段时间觉得不过尔尔。技术什么的，用的时候学学也来得及，用不上的也没必要深究。 加之找工作面试的时候，除了笔试，基本没有八股文问题，也不会聊数据结构和算法，聊聊大学项目就好了，就更加深了我对刷题和八股文行为的偏见。 ","date":"2021-09-03","objectID":"/202109/whyread-useless-content/:1:0","tags":["码农","碎碎念"],"title":"为什么看这么多“没用的”东西","uri":"/202109/whyread-useless-content/"},{"categories":["随笔"],"content":"面试 鄙视刷题、八股文，这是错的，我现在是这么认为的。 刷题、背八股文不是为了面试，虽然这件事带来的好处可以帮助你更容易通过面试，但是它的目的不应该是为了通过面试。 年初，我陷入了很长时间的一段迷茫期。我迫切地想知道自己的技术程度。工作圈子太小，自认为在圈子里做的是不错的，但是圈子外呢？我难道需要被迫在现在的圈子呆一辈子吗？ 我觉得是不可能的。加之当时对现在的小组也有一些不满，最终打算找个新工作试试，所以我尝试面试了两家公司。 面试第一家的时候毫无疑问的挂了。一上来面试都是八股文，非常反感。八股文面试完就是数据结构与算法，也是做不出来，只能说AC，但是不能做到最优解。 面试第二家的时候，初面通过了。初面基本就是聊项目，也会聊一些工作或者技术上的事情，没有问八股文和数据结构的问题。但是第一和第二面的时候挂了，反馈结构是数据结构和算法以及计算机基础只是扎实。 第二家面试失败之后我开始意识到有些地方我是有问题的。 ","date":"2021-09-03","objectID":"/202109/whyread-useless-content/:2:0","tags":["码农","碎碎念"],"title":"为什么看这么多“没用的”东西","uri":"/202109/whyread-useless-content/"},{"categories":["随笔"],"content":"内功 数据结构和算法以及计算机基础理论是一个程序员的内功。 这是面试之后在某平台看到有文章说刷题这件事。我记得结论是这样的： 数据结构和算法代表的是你的内功，外功是你的代码水平，很多人外功都不差，但是内功参差不齐。 学习了这么多编程语言，比较擅长的也有这么一两门，经常会有这样一种想法：编程语言学起来很简单，从零基础到能够上手写代码一个星期也就差不多了。确实是这样，会再多编程语言，编程语言掌握得再好，可替代性都很强。你的周围都是程序员，从编程语言上超过你只是时间的问题了。对于这件事，我的想法是，需要熟练掌握一两门语言的大部分特性，其他语言了解就行了，待需要用时，花个几天时间熟悉熟悉也是来得及的。所以，会很多编程语言虽然可能代表你比其他程序员更热爱技术，更喜欢折腾，但是并不代表你比其他成员更优秀。时间是有限的，可以将学习其他编程语言的时间花在更必要的事情上。 对于编程语言的研究，我放慢了脚步，对于刷题这件事，不排斥了。最近leetcode有人说刷题多了很自闭，别人可能一下子就看出解法了，我却需要很久，我仔细想了这个问题，这样回复了： 我也有这种感觉，但是应该换个角度想想。 这有点像我们的科目考试。比如数学考几何吧，假设你没有系统学习过几何，只在某些地方零零散散看过一点几何的内容，让你去考试你可能也能做出来，并且也可能会发明一些神奇的解法。 但是让系统学习过几何的人来考试，他们就会有系统的方法和思想。很多我们这些半吊子觉得很神奇的想法，对他们来说就是普普通通，甚至是本能。 所以，还是需要系统学习一些数据结构和算法的知识，也要用大量的题目来巩固，这点和高中刷题很像。 刷题这件事情就和高中疯狂刷题一样，只是为了巩固数据结构与算法的知识，刷题是方法不是目的。 大学之前十二年的学习，学到的知识真的都用上了吗？显然没有。这些知识对我的作用我认为有两个：一是让你考上了一个好大学，二是影响了你的世界观、思维方式。 学习数据结构和算法以及刷题这件事就和那十二年的学习一样，都能用上吗？不一定。但是这件事有两个作用：一是帮你找到好工作，二是影响作为程序员的你的思维方式和对事情谨慎的态度。 年初，我写了几篇计算机理论基础相关的博客，目的很明确，补充自己在这方面的知识，直到最近从朋友那里知道了SICP这本书，网上关于SICP的一条言论很影响我，改变了我对学习计算机理论基础的看法，大概是这么说的： SICP讲述的知识对于现代很多程序员可能很简单，但是很少有人会从这些知识点的角度去思考，仅仅是，书本告诉你了，你懂了，才觉得简单。SICP是一个程序员的内功。 SICP在编程语言上，这句话很启发我： 我们需要将自己看做语言的设计者，而不只是由他人设计的语言用户。 学习计算机理论基础也是这样，让我们有一定的能力、资格站在系统设计者的角度去思考编程这件事。说到这里，我想到的一句话就是：站得更高，看得更远。 仅仅站在代码编写者的角度去写代码，可能永远都是码农；站在语言设计者，系统设计者的角度去写代码，才能越站越高，越走越远。 ","date":"2021-09-03","objectID":"/202109/whyread-useless-content/:3:0","tags":["码农","碎碎念"],"title":"为什么看这么多“没用的”东西","uri":"/202109/whyread-useless-content/"},{"categories":["随笔"],"content":"总结 所以，我的总结如下： 不会数据结构的程序员就像不会高数的理工科生，可以干活，但是干不了大活； 刷题只是巩固数据结构和算法知识的方法； 学习理论是为了让你能站在更高的角度去思考和编写代码； ","date":"2021-09-03","objectID":"/202109/whyread-useless-content/:4:0","tags":["码农","碎碎念"],"title":"为什么看这么多“没用的”东西","uri":"/202109/whyread-useless-content/"},{"categories":["软件设计"],"content":" 我们需要将自己看做语言的设计者，而不只是由他人设计的语言用户。 ","date":"2021-09-02","objectID":"/202109/sicp-python-read3/:0:0","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(三)","uri":"/202109/sicp-python-read3/"},{"categories":["软件设计"],"content":"计算机程序的构造和解释 ","date":"2021-09-02","objectID":"/202109/sicp-python-read3/:1:0","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(三)","uri":"/202109/sicp-python-read3/"},{"categories":["软件设计"],"content":"递归 函数递归 一个将英文单词转换为它的 Pig Latin 等价形式的例子： def pig_latin(w): \"\"\"Return the Pig Latin equivalent of English word w.\"\"\" if starts_with_a_vowel(w): return w + 'ay' return pig_latin(w[1:] + w[0]) def starts_with_a_vowel(w): \"\"\"Return whether w begins with a vowel.\"\"\" return w[0].lower() in 'aeiou' 以上，将会产生函数的递归调用pig_latin-\u003epig_latin, 我们可以看下面的环境图示，每次递归调用都将产生新的递归环境，也就是产生新的内存消耗。这就至少说明，递归是有最大深度限制的，最大深度取决于每次递归的环境大小和总内存大小之间的关系。不过， 按照我的理解，如Python这种语言会在解释器层面限制最大递归深度。 从上图我们也可以看到一些别的东西， 如变量引用。两次递归都使用了同一个pun，而不是会复制一份。 递归也像一个数学归纳的过程，以下是计算阶乘的递归函数的一段说明： 我们不应该关心fact(n-1)如何在fact的函数体中实现；我们只需要相信它计算了n-1的阶乘。将递归调用看做函数抽象叫做递归的“信仰飞跃”（leap of faith）。 这看起来就是数学归纳的过程，所以我想，递归和动态规划应该是同一类问题吧？ 动态规划也是一个数学归纳过程。 这两种编程方法应该是可以互相转换的。下面有一个计算斐波那契数列的例子，使用了递归实现，但是也有状态转移方程，也存储了计算的中间结果。 一个使用记忆函数计算斐波那契数列的例子， 实现方式值得学习： def fib(n): if n == 1: return 0 if n == 2: return 1 return fib(n-2) + fib(n-1) def memo(f): \"\"\"Return a memoized version of single-argument function f.\"\"\" cache = {} def memoized(n): if n not in cache: cache[n] = f(n) return cache[n] return memoized fib = memo(fib) fib(40) 状态转移方程在fib函数中有体现，中间结果的保存过程则体现在memo函数中。初看这个实现方式时，着实令我眼前一新的感觉，代码很现代，值得学习。 数据递归 数据递归在数据抽象这一章出现了很多。我对数据递归的理解如下： 可以迭代 子集和全集结构相似 所以，以下数据结构一般都可以是递归结构： 列表（list，tuple，set，array等等） 树 ","date":"2021-09-02","objectID":"/202109/sicp-python-read3/:1:1","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(三)","uri":"/202109/sicp-python-read3/"},{"categories":["软件设计"],"content":"组合语言解释器 参考和补充原文，实现一个计算器语言： 支持四个运算符：add，sub，mul，div 计算器运算符可以接受任意数量参数 运算符可以组合 如： calc\u003e mul(add(2,3), sub(10,2), div(2,add(3,3,3))) 8.88888888888889 实现如下， 源码在github。 抽象表达式 class Exp(): \"\"\" 表达式抽象， 操作符和操作数 通过cal_apply调用， cal_apply(operator, operands) \"\"\" def __init__(self, operator, operands): self.operator = operator self.operands = operands def __repr__(self): return 'Exp({0}, {1})'.format(repr(self.operator), repr(self.operands)) def __str__(self): operand_strs = ', '.join(map(str, self.operands)) return '{0}({1})'.format(self.operator, operand_strs) 执行运算符 def cal_apply(op, args): \"\"\" 正式计算, 但是没有递归， 所以需要有别的模块解决递归计算问题 cal_apply(operator, operands) \"\"\" if op in (\"add\", \"+\"): return sum(args) if op in (\"sub\", \"-\"): if len(args) == 0: raise TypeError(\"{} require 1 argument at least\".format(op)) elif len(args) == 1: return -args[0] else: return sum(args[:1] + [-arg for arg in args[1:]]) if op in (\"mul\", \"*\"): return reduce(mul, args, 1) if op in (\"div\", \"/\"): if len(args) != 2: raise TypeError(\"{} require 2 argument\".format(op)) else: return args[0] / args[1] 解析表达式 def calc_parse(line): \"\"\" 解析表达式， 返回值是Exp 先将表达式的各个元素拆开， 再组合为Exp格式 \"\"\" tokens = tokenize(line) expression_tree = analyze(tokens) if len(tokens) \u003e 0: raise SyntaxError('Extra token(s): ' + ' '.join(tokens)) return expression_tree 词法分析 def tokenize(line): \"\"\" 拆分表示各个元素 \"\"\" spaced = line.replace('(', ' ( ').replace(')', ' ) ').replace(',', ' , ') return spaced.split() 语法分析 known_operators = ['add', 'sub', 'mul', 'div', '+', '-', '*', '/'] def analyze(tokens): \"\"\" 表达式元素组合，形成操作树 \"\"\" assert_non_empty(tokens) # 数字或者操作符 token = analyze_token(tokens.pop(0)) # 如果是数字，直接放回就好了，继续求下一个，因为数字是自求解的，本身就是解 if type(token) in (int, float): return token # 如果是操作符，则需要组合为Exp表达式 if token in known_operators: # 当前是操作符， 则需要检查后面有没有操作数 # 计算器的操作符后面是有操作数的 # 操作数递归组合即可 if len(tokens) == 0 or tokens.pop(0) != '(': raise SyntaxError('expected ( after ' + token) return Exp(token, analyze_operands(tokens)) else: raise SyntaxError('unexpected ' + token) def analyze_operands(tokens): \"\"\" 生成操作数 \"\"\" assert_non_empty(tokens) operands = [] # 直到闭括号 while tokens[0] != ')': if operands and tokens.pop(0) != ',': raise SyntaxError('expected ,') operands.append(analyze(tokens)) assert_non_empty(tokens) tokens.pop(0) # 移除闭括号‘）’ return operands def assert_non_empty(tokens): \"\"\"Raise an exception if tokens is empty.\"\"\" if len(tokens) == 0: raise SyntaxError('unexpected end of line') def analyze_token(token): \"\"\"Return the value of token if it can be analyzed as a number, or token.\"\"\" try: return int(token) except (TypeError, ValueError): try: return float(token) except (TypeError, ValueError): # 如果不是数字， 则可能是表达式， 先直接返回 return token 递归表达式 将表达式递归成执行器可以理解的。 def calc_eval(expression): \"\"\" 表达式递归求解， 从里到外依次求解 \"\"\" expression.operands = [calc_eval(operand) if type(operand) == type( expression) else operand for operand in expression.operands] cal_apply_result = cal_apply(expression.operator, expression.operands) return cal_apply_result 读取输入 def read_eval_print_loop(): \"\"\"Run a read-eval-print loop for calculator.\"\"\" while True: try: expression_tree = calc_parse(input('calc\u003e ')) print(calc_eval(expression_tree)) except (SyntaxError, TypeError, ZeroDivisionError) as err: print(type(err).__name__ + ':', err) except (KeyboardInterrupt, EOFError): print('Calculation completed.') return ","date":"2021-09-02","objectID":"/202109/sicp-python-read3/:1:2","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(三)","uri":"/202109/sicp-python-read3/"},{"categories":["软件设计"],"content":"在上一章中我们主要学习了函数. 关注了函数的调用过程, 也学习了高阶函数. 高阶函数实际上是比较\"古老\"的技术, 在Lisp原生支持. 但是C语言似乎并没有或者很难实现高阶函数, 不过这一点在C++中有所缓解. 这一篇主要关注程序的数据. ","date":"2021-08-26","objectID":"/202108/sicp-python-read2/:0:0","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(二)","uri":"/202108/sicp-python-read2/"},{"categories":["软件设计"],"content":"使用对象构建抽象 数据抽象的基本概念是构造操作抽象数据的程序。也就是说，我们的程序应该以一种方式来使用数据，对数据做出尽可能少的假设。 这句话引起了我对如何构建类或者结构体的思考。 通俗的说，抽象某个数据时，应该让用户对该数据做出尽可能少的思考，类似于上一篇函数抽象，数据抽象也应该让用户感觉起来非常的自然，而不会惊讶于数据抽象的某些表示。要做到这一点，我们确实需要考虑用户可能对这个数据抽象所进行的操作，并且可能需要删除一些没必要/意料之外的操作。 下面这句话比较好解释上面的思想： 复数有两种不同表示（平面坐标和极坐标），它们适用于不同的操作。然而，从一些人编写使用复数的程序的角度来看，数据抽象的原则表明，所有操作复数的运算都应该可用，无论计算机使用了哪个表示。 如果打算做复数的数据抽象，那么我们确实应该考虑用户可能的操作。有些用户可能使用平面坐标表示，有些用户可能使用极坐标表示。并且这两种表示确实是复数的常用表示方法。同时，平面表示的复数和极坐标表示的复数也不应该有明显的界限， 这一点表现在两者的运算操作上。想想在学校里学习的复数运算，经常也会涉及平面坐标和极坐标的相互转换和运算。 ","date":"2021-08-26","objectID":"/202108/sicp-python-read2/:1:0","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(二)","uri":"/202108/sicp-python-read2/"},{"categories":["软件设计"],"content":"构造器和选择器 构造器 构造器的概念类似于C++中的构造函数。通过SICP我的认知是：构造器只负责构造当前抽象的数据。 举个例子：文中的有理数构造， 就只构造有理数的分子和分母，其他无关的元素没有参与构造，也不应该参与构造。 在代码编写过程中，经常容易陷入的误区是，喜欢在构造函数里面做一些和构造无关的操作，比如某些初始化。这些初始化的工作应不应该放在构造函数中呢？没有见过有比较值得信赖的定论。但是目前来看，与数据抽象无关的元素不应该放在构造函数中构造（初始化）。 所以，即使抽象某个数据的时候，看似很简单，但是还是应该思考清楚哪些是这个数据本身的属性，哪些是额外的属性。本身的属性就需要在构造的时候初始化，额外的属性则不需要在构造的时候初始化。 选择器 以C++举例，和一般认知一样， 我们不应该把成员变量写在public可见性下，这样会误导用户，使用户直接取用或者修改成员变量的值， 这时候我们应该为运行用户操作的变量提供选择器。 为什么需要这样？ 下面一段例子很好： template\u003ctypename T\u003e class Math{ public: void set(const T\u0026); T get(); T sqrt(); T square(); //... private: T m_source; }; 如上，我们使用set和get方法来选择元素，而不是直接访问元素，这有什么好处呢？ 隔离用户和抽象的数据； 统一接口； 第1点比较好理解，通过选择器访问元素，我们可以在选择器函数中执行一些额外的操作，而用户不需要关心这些操作就能得到他们期望的结果。 关于第2点， 如果我们不使用选择器访问元素，而让用户有权直接访问到元素，则会造成接口的不统一。比如用户想访问元素本身时，可以直接访问元素： math.m_source; 用户甚至可以修改元素的值，而不用通知类。 如果用户想访问元素的平方根或者平方时，则需要访问： math.srqt(); math.square(); 这和对元素的访问是不一样的。所以，添加选择器方法后，可以规范用户对抽象数据的操作行为。 复数的例子很好： class ComplexRI(object): def __init__(self, real, imag): self.real = real self.imag = imag @property def magnitude(self): return (self.real ** 2 + self.imag ** 2) ** 0.5 @property def angle(self): return atan2(self.imag, self.real) def __repr__(self): return 'ComplexRI({0}, {1})'.format(self.real, self.imag) class ComplexMA(object): def __init__(self, magnitude, angle): self.magnitude = magnitude self.angle = angle @property def real(self): return self.magnitude * cos(self.angle) @property def imag(self): return self.magnitude * sin(self.angle) def __repr__(self): return 'ComplexMA({0}, {1})'.format(self.magnitude, self.angle) python有property这个修饰器，所以可以把需要被计算的量当做属性一样访问。比如上例，我们可以像访问实部虚部一样的访问模长和角度。对于C++这种类型的语言，都使用选择器方法可能就比较好了。 ","date":"2021-08-26","objectID":"/202108/sicp-python-read2/:1:1","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(二)","uri":"/202108/sicp-python-read2/"},{"categories":["软件设计"],"content":"约束传播 约束传播 上图是关于摄氏度和华氏度转换的约束网络，通过设置摄氏度的值可以得到华氏度的结果，设置华氏度的值可以得到摄氏度的结果，只需要通过这个网络传播即可。 参考原文，我实现了以下的约束传播，另外还可以参考这篇文章，这里对约束传播讲地更清楚。 定义连接器，需要的方法有： has_val: 判断值是否已知 set_val: 更新连接器的值 val: 获取连接器的值 connect: 关联连接器和其约束 forget: 让连接器丢弃现在的值 需要的容器有： value: 保存连接器的值，如果是None则代表没有值 constraints: 保存所有与该连接器相关的约束，如果连接器的值更新了，则需要通知其他约束更新 informant: 描述连接器的最后一次修改者，以防止连接器的值被不允许的对象修改 class connector(): def __init__(self, name=None): self._name = name self._value = None self._constraints = [] self._informant = None def _notify(self, source, message): notify = { 'new_val': lambda constraint : constraint.new_val(), 'forget': lambda constraint : constraint.forget(), } for constraint in self._constraints: if source != constraint: notify[message](constraint) @property def val(self): return self._value @property def has_val(self): return self._value is not None def set_val(self, source, val): if self._value is None: self._informant, self._value = source, val if self._name is not None: print(self._name, '=', val) self._notify(source, 'new_val') else: if self._value != val: print('Contradiction detected:', self._value, 'vs', val) def connect(self, constraint): self._constraints.append(constraint) def forget(self, source): if self._informant == source: self._informant, self._value = None, None self._notify(source, 'forget') 以下是构造约束条件，这里定义的是三元约束条件，其设计思想是，如果约束条件相关的某两个连接器的值已知，则可以更新另外一个连接器的值。 class ternary_constraint(): def __init__(self, a, b, c, ab, ca, cb): self._a = a self._b = b self._c = c self._ab = ab self._ca = ca self._cb = cb for connector in (self._a, self._b, self._c): connector.connect(self) def new_val(self): av, bv, cv = [connector.has_val for connector in (self._a, self._b, self._c)] if av and bv: self._c.set_val(self, self._ab(self._a.val, self._b.val)) elif av and cv: self._b.set_val(self, self._ca(self._c.val, self._a.val)) elif bv and cv: self._a.set_val(self, self._cb(self._c.val, self._b.val)) print(\"not satisfied\") def forget(self): for connector in (self._a, self._b, self._c): connector.forget(self) 按照华氏度和设置度转换的需求，构造以下几种约束条件： def adder(a, b, c): from operator import add, sub return ternary_constraint(a, b, c, add, sub, sub) def multiplier(a, b, c): from operator import mul, truediv return ternary_constraint(a, b, c, mul, truediv, truediv) def constant(connector, value): constraint = {} connector.set_val(constraint, value) return constraint 组合约束条件和连接器，实现华氏度和摄氏度转换的约束传播网络： def make_converter(c, f): \"\"\"Connect c to f with constraints to convert from Celsius to Fahrenheit.\"\"\" u, v, w, x, y = [connector() for _ in range(5)] multiplier(c, w, u) multiplier(v, x, u) adder(v, y, f) constant(w, 9) constant(x, 5) constant(y, 32) 只需要某个条件已知，就可以按照约束传播网络的约束，更新其他未知的值： celsius = connector('Celsius') fahrenheit = connector('Fahrenheit') make_converter(celsius, fahrenheit) celsius.set_val('c', 25) celsius.forget('c') celsius.set_val('c', 30) ","date":"2021-08-26","objectID":"/202108/sicp-python-read2/:1:2","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(二)","uri":"/202108/sicp-python-read2/"},{"categories":["软件设计"],"content":"函数和方法 【不重要的】操作对象或执行对象特定计算的函数叫做方法。 有以上的概念，需要思考的是，什么时候应该实现为函数， 什么时候应该实现为方法？ 这将有助于我们理解一个类里面应该包含什么，不应该包含什么。 我观察到的现象是，所有方法都会操作对象的数据，读或者写。如果某个操作需要读入某个对象的某个数据，但是并不会对其产生影响，输出也与这个类完全无关，那应该定义为一个方法吗？我认为是不应该的。 比如STL中的容器。 std::vector是一个容器，其作用是存储数据。其基本操作就是，添加数据，删除数据，统计数据长度。对数据排序，这算不算是容器的基本方法呢？目前可以看到，STL不认为这是容器的基本方法，所以STL实现的容器是很纯粹的。但是在Python里面，sort一般是可变容器的默认方法。 ","date":"2021-08-26","objectID":"/202108/sicp-python-read2/:1:3","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(二)","uri":"/202108/sicp-python-read2/"},{"categories":["软件设计"],"content":"通过字典实现类和对象 在Linux内核源码中，可以看到不少这样的操作： 将一系列函数指针包装为一个结构体operation，比如open、close等等，然后其他抽象数据类型的结构结构体（比如VFS，虚拟文件系统）就会包含operation这个结构体，这时候就像是VFS自身的结构体包含了operation里面的操作，是一个类。 在Python里面自定义一个类更现代： def make_instance(cls): \"\"\"Return a new object instance, which is a dispatch dictionary.\"\"\" def get_value(name): if name in attributes: return attributes[name] else: value = cls['get'](name) return bind_method(value, instance) def set_value(name, value): attributes[name] = value attributes = {} instance = {'get': get_value, 'set': set_value} return instance def bind_method(value, instance): \"\"\"Return a bound method if value is callable, or value otherwise.\"\"\" if callable(value): def method(*args): return value(instance, *args) return method else: return value def make_class(attributes, base_class=None): \"\"\"Return a new class, which is a dispatch dictionary.\"\"\" def get_value(name): if name in attributes: return attributes[name] elif base_class is not None: return base_class['get'](name) def set_value(name, value): attributes[name] = value def new(*args): return init_instance(cls, *args) cls = {'get': get_value, 'set': set_value, 'new': new} return cls def init_instance(cls, *args): \"\"\"Return a new object with type cls, initialized with args.\"\"\" instance = make_instance(cls) init = cls['get']('__init__') if init: init(instance, *args) return instance def make_account_class(): \"\"\"Return the Account class, which has deposit and withdraw methods.\"\"\" def __init__(self, account_holder): self['set']('holder', account_holder) self['set']('balance', 0) def deposit(self, amount): \"\"\"Increase the account balance by amount and return the new balance.\"\"\" new_balance = self['get']('balance') + amount self['set']('balance', new_balance) return self['get']('balance') def withdraw(self, amount): \"\"\"Decrease the account balance by amount and return the new balance.\"\"\" balance = self['get']('balance') if amount \u003e balance: return 'Insufficient funds' self['set']('balance', balance - amount) return self['get']('balance') return make_class({'__init__': __init__, 'deposit': deposit, 'withdraw': withdraw, 'interest': 0.02}) Account = make_account_class() jim_acct = Account['new']('Jim') jim_acct['get']('holder') jim_acct['get']('deposit')(20) jim_acct['set']('interest', 0.04) ","date":"2021-08-26","objectID":"/202108/sicp-python-read2/:1:4","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(二)","uri":"/202108/sicp-python-read2/"},{"categories":["Cpp"],"content":" 目录 1 通用安全指南 I. C/C++使用错误 1.1 不得直接使用无长度限制的字符拷贝函数 1.2 创建进程类的函数的安全规范 1.3 尽量减少使用 _alloca 和可变长度数组 1.4 printf系列参数必须对应 1.5 防止泄露指针（包括%p）的值 1.6 不应当把用户可修改的字符串作为printf系列函数的“format”参数 1.7 对数组delete时需要使用delete[] 1.8 注意隐式符号转换 1.9 注意八进制问题 II. 不推荐的编程习惯 2.1 switch中应有default 2.2 不应当在Debug或错误信息中提供过多内容 2.3 不应该在客户端代码中硬编码对称加密秘钥 2.4 返回栈上变量的地址 2.5 有逻辑联系的数组必须仔细检查 2.6 避免函数的声明和实现不同 2.7 检查复制粘贴的重复代码 2.8 左右一致的重复判断/永远为真或假的判断 2.9 函数每个分支都应有返回值 2.10 不得使用栈上未初始化的变量 2.11 不得直接使用刚分配的未初始化的内存（如realloc） 2.12 校验内存相关函数的返回值 2.13 不要在if里面赋值 2.14 确认if里面的按位操作 III. 多线程 3.1 变量应确保线程安全性 3.2 注意signal handler导致的条件竞争 3.3 注意Time-of-check Time-of-use条件竞争 IV. 加密解密 4.1 不得明文存储用户密码等敏感数据 4.2 内存中的用户密码等敏感数据应该安全抹除 4.3 rand() 类函数应正确初始化 4.4 在需要高强度安全加密时不应使用弱PRNG函数 4.5 自己实现的rand范围不应过小 V. 文件操作 5.1 避免路径穿越问题 5.2 避免相对路径导致的安全问题 5.3 文件权限控制 Ⅵ. 内存操作 6.1 防止各种越界写 6.2 防止任意地址写 Ⅶ. 数字操作 7.1 防止整数溢出 7.2 防止Off-By-One 7.3 避免大小端错误 7.4 检查除以零异常 7.5 防止数字类型的错误强转 7.6 比较数据大小时加上最小/最大值的校验 Ⅷ. 指针操作 8.1 检查在pointer上使用sizeof 8.2 检查直接将数组和0比较的代码 8.3 不应当向指针赋予写死的地址 8.4 检查空指针 8.5 释放完后置空指针 8.6 防止错误的类型转换 8.7 智能指针使用安全 ","date":"2021-08-19","objectID":"/202108/secguide_c_tc/:0:0","tags":["Cpp","C"],"title":"C,C++安全指南","uri":"/202108/secguide_c_tc/"},{"categories":["Cpp"],"content":"通用安全指南 ","date":"2021-08-19","objectID":"/202108/secguide_c_tc/:1:0","tags":["Cpp","C"],"title":"C,C++安全指南","uri":"/202108/secguide_c_tc/"},{"categories":["Cpp"],"content":"1 C/C++使用错误 1.1 【必须】不得直接使用无长度限制的字符拷贝函数 不应直接使用legacy的字符串拷贝、输入函数，如strcpy、strcat、sprintf、wcscpy、mbscpy等，这些函数的特征是：可以输出一长串字符串，而不限制长度。如果环境允许，应当使用其_s安全版本替代，或者使用n版本函数（如：snprintf，vsnprintf）。 若使用形如sscanf之类的函数时，在处理字符串输入时应当通过%10s这样的方式来严格限制字符串长度，同时确保字符串末尾有\\0。如果环境允许，应当使用_s安全版本。 但是注意，虽然MSVC 2015时默认引入结尾为0版本的snprintf（行为等同于C99定义的snprintf）。但更早期的版本中，MSVC的snprintf可能是_snprintf的宏。而_snprintf是不保证\\0结尾的（见本节后半部分）。 （MSVC） Beginning with the UCRT in Visual Studio 2015 and Windows 10, snprintf is no longer identical to _snprintf. The snprintf function behavior is now C99 standard compliant. 从Visual Studio 2015和Windows 10中的UCRT开始，snprintf不再与_snprintf相同。snprintf函数行为现在符合C99标准。 请参考：https://docs.microsoft.com/en-us/cpp/c-runtime-library/reference/snprintf-snprintf-snprintf-l-snwprintf-snwprintf-l?redirectedfrom=MSDN\u0026view=vs-2019 因此，在使用n系列拷贝函数时，要确保正确计算缓冲区长度，同时，如果你不确定是否代码在各个编译器下都能确保末尾有0时，建议可以适当增加1字节输入缓冲区，并将其置为\\0，以保证输出的字符串结尾一定有\\0。 // Good char buf[101] = {0}; snprintf(buf, sizeof(buf) - 1, \"foobar ...\", ...); 一些需要注意的函数，例如strncpy和_snprintf是不安全的。 strncpy不应当被视为strcpy的n系列函数，它只是恰巧与其他n系列函数名字很像而已。strncpy在复制时，如果复制的长度超过n，不会在结尾补\\0。 同样，MSVC _snprintf系列函数在超过或等于n时也不会以0结尾。如果后续使用非0结尾的字符串，可能泄露相邻的内容或者导致程序崩溃。 // Bad char a[4] = {0}; _snprintf(a, 4, \"%s\", \"AAAA\"); foo = strlen(a); 上述代码在MSVC中执行后， a[4] == ‘A’，因此字符串未以0结尾。a的内容是\"AAAA\"，调用strlen(a)则会越界访问。因此，正确的操作举例如下： // Good char a[4] = {0}; _snprintf(a, sizeof(a), \"%s\", \"AAAA\"); a[sizeof(a) - 1] = '\\0'; foo = strlen(a); 在 C++ 中，强烈建议用 string、vector 等更高封装层次的基础组件代替原始指针和动态数组，对提高代码的可读性和安全性都有很大的帮助。 关联漏洞: 中风险-信息泄露 低风险-拒绝服务 高风险-缓冲区溢出 1.2 【必须】创建进程类的函数的安全规范 system、WinExec、CreateProcess、ShellExecute等启动进程类的函数，需要严格检查其参数。 启动进程需要加上双引号，错误例子： // Bad WinExec(\"D:\\\\program files\\\\my folder\\\\foobar.exe\", SW_SHOW); 当存在D:\\program files\\my.exe的时候，my.exe会被启动。而foobar.exe不会启动。 // Good WinExec(\"\\\"D:\\\\program files\\\\my folder\\\\foobar.exe\\\"\", SW_SHOW); 另外，如果启动时从用户输入、环境变量读取组合命令行时，还需要注意是否可能存在命令注入。 // Bad std::string cmdline = \"calc \"; cmdline += user_input; system(cmdline.c_str()); 比如，当用户输入1+1 \u0026\u0026 ls时，执行的实际上是calc 1+1和ls 两个命令，导致命令注入。 需要检查用户输入是否含有非法数据。 // Good std::string cmdline = \"ls \"; cmdline += user_input; if(cmdline.find_first_not_of(\"1234567890.+-*/e \") == std::string::npos) system(cmdline.c_str()); else warning(...); 关联漏洞: 高风险-代码执行 高风险-权限提升 1.3 【必须】尽量减少使用 _alloca 和可变长度数组 _alloca 和可变长度数组使用的内存量在编译期间不可知。尤其是在循环中使用时，根据编译器的实现不同，可能会导致：（1）栈溢出，即拒绝服务； （2）缺少栈内存测试的编译器实现可能导致申请到非栈内存，并导致内存损坏。这在栈比较小的程序上，例如IoT设备固件上影响尤为大。对于 C++，可变长度数组也属于非标准扩展，在代码规范中禁止使用。 错误示例： // Bad for (int i = 0; i \u003c 100000; i++) { char* foo = (char *)_alloca(0x10000); ..do something with foo ..; } void Foo(int size) { char msg[size]; // 不可控的栈溢出风险！ } 正确示例： // Good // 改用动态分配的堆内存 for (int i = 0; i \u003c 100000; i++) { char * foo = (char *)malloc(0x10000); ..do something with foo ..; if (foo_is_no_longer_needed) { free(foo); foo = NULL; } } void Foo(int size) { std::string msg(size, '\\0'); // C++ char* msg = malloc(size); // C } 关联漏洞: 低风险-拒绝服务 高风险-内存破坏 1.4 【必须】printf系列参数必须对应 所有printf系列函数，如sprintf，snprintf，vprintf等必须对应控制符号和参数。 错误示例： // Bad const int buf_size = 1000; char buffer_send_to_remote_client[buf_size] = {0}; snprintf(buffer_send_to_remote_client, buf_size, \"%d: %p\", id, some_string); // %p 应为 %s buffer_send_to_remote_client[buf_size - 1] = '\\0'; send_to_remote(buffer_send_to_remote_client); 正确示例： // Good const int buf_size = 1000; char buffer_send_to_remote_client[buf_size] = {0}; snprintf(buffer_send_to_remote_client, buf_size, \"%d: %s\", id, some_string); buffer_send_to_remote_client[buf_size - 1] = '\\0'; send_to_remote(buffer_send_to_remote_client); 前者可能会让client的攻击者获取部分服务器的原始指针地址，可以用于破坏ASLR保护。 关联漏洞: 中风险-信息泄露 1.5 【必须】防止泄露指针（包括%p）的值 所有printf系列函数，要防止格式化完的字符串泄露程序布局信息。例如，如果将带有%p的字符串泄露给程序，则可能会破坏ASLR的防护效果。使得攻击者更容易攻破程序。 %p的值只应当在程序内使用，而不应当输出到外部或被外部以某种方式获取。 错误示例： // Bad // 如果这是暴露给客户的一个API： uint64_t GetUniqueObjectId(const Foo* pobject) { return (uint64_t)pobject; } 正确示例： // Good uint64_t g_object_id = 0; void Foo::Foo() { this-\u003eobject_id_ = g_object_id++; } // 如果这是暴露给客户的一个API： uint64_t GetUniqueObjectId(const Foo* object","date":"2021-08-19","objectID":"/202108/secguide_c_tc/:1:1","tags":["Cpp","C"],"title":"C,C++安全指南","uri":"/202108/secguide_c_tc/"},{"categories":["Cpp"],"content":"2 不推荐的编程习惯 2.1 【必须】switch中应有default switch中应该有default，以处理各种预期外的情况。这可以确保switch接受用户输入，或者后期在其他开发者修改函数后确保switch仍可以覆盖到所有情况，并确保逻辑正常运行。 // Bad int Foo(int bar) { switch (bar \u0026 7) { case 0: return Foobar(bar); break; case 1: return Foobar(bar * 2); break; } } 例如上述代码switch的取值可能从0～7，所以应当有default： // Good int Foo(int bar) { switch (bar \u0026 7) { case 0: return Foobar(bar); break; case 1: return Foobar(bar * 2); break; default: return -1; } } 关联漏洞: 中风险-逻辑漏洞 中风险-内存泄漏 2.2 【必须】不应当在Debug或错误信息中提供过多内容 包含过多信息的Debug消息不应当被用户获取到。Debug信息可能会泄露一些值，例如内存数据、内存地址等内容，这些内容可以帮助攻击者在初步控制程序后，更容易地攻击程序。 // Bad int Foo(int* bar) { if (bar \u0026\u0026 *bar == 5) { OutputDebugInfoToUser(\"Wrong value for bar %p = %d\\n\", bar, *bar); } } 而应该： // Good int foo(int* bar) { #ifdef DEBUG if (bar \u0026\u0026 *bar == 5) { OutputDebugInfo(\"Wrong value for bar.\\n\", bar, *bar); } #endif } 关联漏洞: 中风险-信息泄漏 2.3 【必须】不应该在客户端代码中硬编码对称加密秘钥 不应该在客户端代码中硬编码对称加密秘钥。例如：不应在客户端代码使用硬编码的 AES/ChaCha20-Poly1305/SM1 密钥，使用固定密钥的程序基本和没有加密一样。 如果业务需求是认证加密数据传输，应优先考虑直接用 HTTPS 协议。 如果是其它业务需求，可考虑由服务器端生成对称秘钥，客户端通过 HTTPS 等认证加密通信渠道从服务器拉取。 或者根据用户特定的会话信息，比如登录认证过程可以根据用户名用户密码业务上下文等信息，使用 HKDF 等算法衍生出对称秘钥。 又或者使用 RSA/ECDSA + ECDHE 等进行认证秘钥协商，生成对称秘钥。 // Bad char g_aes_key[] = {...}; void Foo() { .... AES_func(g_aes_key, input_data, output_data); } 可以考虑在线为每个用户获取不同的密钥： // Good char* g_aes_key; void Foo() { .... AES_encrypt(g_aes_key, input_data, output_data); } void Init() { g_aes_key = get_key_from_https(user_id, ...); } 关联漏洞: 中风险-信息泄露 2.4 【必须】返回栈上变量的地址 函数不可以返回栈上的变量的地址，其内容在函数返回后就会失效。 // Bad char* Foo(char* sz, int len){ char a[300] = {0}; if (len \u003e 100) { memcpy(a, sz, 100); } a[len] = '\\0'; return a; // WRONG } 而应当使用堆来传递非简单类型变量。 // Good char* Foo(char* sz, int len) { char* a = new char[300]; if (len \u003e 100) { memcpy(a, sz, 100); } a[len] = '\\0'; return a; // OK } 对于 C++ 程序来说，强烈建议返回 string、vector 等类型，会让代码更加简单和安全。 关联漏洞: 高风险-内存破坏 2.5 【必须】有逻辑联系的数组必须仔细检查 例如下列程序将字符串转换为week day，但是两个数组并不一样长，导致程序可能会越界读一个int。 // Bad int nWeekdays[] = {1, 2, 3, 4, 5, 6}; const char* sWeekdays[] = {\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"}; for (int x = 0; x \u003c ARRAY_SIZE(sWeekdays); x++) { if (strcmp(sWeekdays[x], input) == 0) return nWeekdays[x]; } 应当确保有关联的nWeekdays和sWeekdays数据统一。 // Good const int nWeekdays[] = {1, 2, 3, 4, 5, 6, 7}; const char* sWeekdays[] = {\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"}; assert(ARRAY_SIZE(nWeekdays) == ARRAY_SIZE(sWeekdays)); for (int x = 0; x \u003c ARRAY_SIZE(sWeekdays); x++) { if (strcmp(sWeekdays[x], input) == 0) { return nWeekdays[x]; } } 关联漏洞: 高风险-内存破坏 2.6 【必须】避免函数的声明和实现不同 在头文件、源代码、文档中列举的函数声明应当一致，不应当出现定义内容错位的情况。 错误： foo.h int CalcArea(int width, int height); foo.cc int CalcArea(int height, int width) { // Different from foo.h if (height \u003e real_height) { return 0; } return height * width; } 正确： foo.h int CalcArea(int height, int width); foo.cc int CalcArea (int height, int width) { if (height \u003e real_height) { return 0; } return height * width; } 关联漏洞: 中风险-逻辑问题 2.7 【必须】检查复制粘贴的重复代码（相同代码通常代表错误） 当开发中遇到较长的句子时，如果你选择了复制粘贴语句，请记得检查每一行代码，不要出现上下两句一模一样的情况，这通常代表代码哪里出现了错误： // Bad void Foobar(SomeStruct\u0026 foobase, SomeStruct\u0026 foo1, SomeStruct\u0026 foo2) { foo1.bar = (foo1.bar \u0026 0xffff) | (foobase.base \u0026 0xffff0000); foo1.bar = (foo1.bar \u0026 0xffff) | (foobase.base \u0026 0xffff0000); } 如上例，通常可能是： // Good void Foobar(SomeStruct\u0026 foobase, SomeStruct\u0026 foo1, SomeStruct\u0026 foo2) { foo1.bar = (foo1.bar \u0026 0xffff) | (foobase.base \u0026 0xffff0000); foo2.bar = (foo2.bar \u0026 0xffff) | (foobase.base \u0026 0xffff0000); } 最好是把重复的代码片段提取成函数，如果函数比较短，可以考虑定义为 inline 函数，在减少冗余的同时也能确保不会影响性能。 关联漏洞: 中风险-逻辑问题 2.8 【必须】左右一致的重复判断/永远为真或假的判断（通常代表错误） 这通常是由于自动完成或例如Visual Assistant X之类的补全插件导致的问题。 // Bad if (foo1.bar == foo1.bar) { … } 可能是： // Good if (foo1.bar == foo2.bar) { … } 关联漏洞: 中风险-逻辑问题 2.9 【必须】函数每个分支都应有返回值 函数的每个分支都应该有返回值，否则如果函数走到无返回值的分支，其结果是未知的。 // Bad int Foo(int bar) { if (bar \u003e 100) { return 10; } else if (bar \u003e 10) { return 1; } } 上述例子当bar\u003c10时，其结果是未知的值。 // Good int Foo(int bar) { if (bar \u003e 100) { return 10; } else if (bar \u003e 10) { return 1; } return 0; } 开启适当级别的警告（GCC 中为 -Wreturn-type ","date":"2021-08-19","objectID":"/202108/secguide_c_tc/:1:2","tags":["Cpp","C"],"title":"C,C++安全指南","uri":"/202108/secguide_c_tc/"},{"categories":["Cpp"],"content":"3 多线程 3.1 【必须】变量应确保线程安全性 当一个变量可能被多个线程使用时，应当使用原子操作或加锁操作。 // Bad char g_somechar; void foo_thread1() { g_somechar += 3; } void foo_thread2() { g_somechar += 1; } 对于可以使用原子操作的，应当使用一些可以确保内存安全的操作，如： // Good volatile char g_somechar; void foo_thread1() { __sync_fetch_and_add(\u0026g_somechar, 3); } void foo_thread2() { __sync_fetch_and_add(\u0026g_somechar, 1); } 对于 C 代码，C11 后推荐使用 atomic 标准库。 对于 C++代码，C++11 后，推荐使用 std::atomic。 关联漏洞: 高风险-内存破坏 中风险-逻辑问题 3.2 【必须】注意signal handler导致的条件竞争 竞争条件经常出现在信号处理程序中，因为信号处理程序支持异步操作。攻击者能够利用信号处理程序争用条件导致软件状态损坏，从而可能导致拒绝服务甚至代码执行。 当信号处理程序中发生不可重入函数或状态敏感操作时，就会出现这些问题。因为信号处理程序中随时可以被调用。比如，当在信号处理程序中调用free时，通常会出现另一个信号争用条件，从而导致双重释放。即使给定指针在释放后设置为NULL，在释放内存和将指针设置为NULL之间仍然存在竞争的可能。 为多个信号设置了相同的信号处理程序，这尤其有问题——因为这意味着信号处理程序本身可能会重新进入。例如，malloc()和free()是不可重入的，因为它们可能使用全局或静态数据结构来管理内存，并且它们被syslog()等看似无害的函数间接使用；这些函数可能会导致内存损坏和代码执行。 // Bad char *log_message; void Handler(int signum) { syslog(LOG_NOTICE, \"%s\\n\", log_m_essage); free(log_message); sleep(10); exit(0); } int main (int argc, char* argv[]) { log_message = strdup(argv[1]); signal(SIGHUP, Handler); signal(SIGTERM, Handler); sleep(10); } 可以借由下列操作规避问题： 避免在多个处理函数中共享某些变量。 在信号处理程序中使用同步操作。 屏蔽不相关的信号，从而提供原子性。 避免在信号处理函数中调用不满足异步信号安全的函数。 关联漏洞: 高风险-内存破坏 中风险-逻辑问题 3.3 【建议】注意Time-of-check Time-of-use (TOCTOU) 条件竞争 TOCTOU： 软件在使用某个资源之前检查该资源的状态，但是该资源的状态可以在检查和使用之间更改，从而使检查结果无效。当资源处于这种意外状态时，这可能会导致软件执行错误操作。 当攻击者可以影响检查和使用之间的资源状态时，此问题可能与安全相关。这可能发生在共享资源(如文件、内存，甚至多线程程序中的变量)上。在编程时需要注意避免出现TOCTOU问题。 例如，下面的例子中，该文件可能已经在检查和lstat之间进行了更新，特别是因为printf有延迟。 struct stat *st; lstat(\"...\", st); printf(\"foo\"); if (st-\u003est_mtimespec == ...) { printf(\"Now updating things\\n\"); UpdateThings(); } TOCTOU难以修复，但是有以下缓解方案： 限制对来自多个进程的文件的交叉操作。 如果必须在多个进程或线程之间共享对资源的访问，那么请尝试限制”检查“（CHECK）和”使用“（USE）资源之间的时间量，使他们相距尽量不要太远。这不会从根本上解决问题，但可能会使攻击更难成功。 在Use调用之后重新检查资源，以验证是否正确执行了操作。 确保一些环境锁定机制能够被用来有效保护资源。但要确保锁定是检查之前进行的，而不是在检查之后进行的，以便检查时的资源与使用时的资源相同。 关联漏洞: 高风险-内存破坏 中风险-逻辑问题 ","date":"2021-08-19","objectID":"/202108/secguide_c_tc/:1:3","tags":["Cpp","C"],"title":"C,C++安全指南","uri":"/202108/secguide_c_tc/"},{"categories":["Cpp"],"content":"4 加密解密 4.1 【必须】不得明文存储用户密码等敏感数据 用户密码应该使用 Argon2, scrypt, bcrypt, pbkdf2 等算法做哈希之后再存入存储系统, https://password-hashing.net/ https://libsodium.gitbook.io/doc/password_hashing/default_phf#example-2-password-storage 用户敏感数据，应该做到传输过程中加密，存储状态下加密 传输过程中加密，可以使用 HTTPS 等认证加密通信协议 存储状态下加密，可以使用 SQLCipher 等类似方案。 4.2 【必须】内存中的用户密码等敏感数据应该安全抹除 例如用户密码等，即使是临时使用，也应在使用完成后应当将内容彻底清空。 错误： #include \u003copenssl/crypto.h\u003e #include \u003cunistd.h\u003e { ... string user_password(100, '\\0'); snprintf(\u0026user_password, \"password: %s\", user_password.size(), password_from_input); ... } 正确： { ... string user_password(100, '\\0'); snprintf(\u0026user_password, \"password: %s\", user_password.size(), password_from_input); ... OPENSSL_cleanse(\u0026user_password[0], user_password.size()); } 关联漏洞: 高风险-敏感信息泄露 4.3 【必须】rand() 类函数应正确初始化 rand类函数的随机性并不高。而且在使用前需要使用srand()来初始化。未初始化的随机数可能导致某些内容可预测。 // Bad int main() { int foo = rand(); return 0; } 上述代码执行完成后，foo的值是固定的。它等效于 srand(1); rand();。 // Good int main() { srand(time(0)); int foo = rand(); return 0; } 关联漏洞: 高风险-逻辑漏洞 4.4 【必须】在需要高强度安全加密时不应使用弱PRNG函数 在需要生成 AES/SM1/HMAC 等算法的密钥/IV/Nonce， RSA/ECDSA/ECDH 等算法的私钥，这类需要高安全性的业务场景，必须使用密码学安全的随机数生成器 (Cryptographically Secure PseudoRandom Number Generator (CSPRNG) ), 不得使用 rand() 等无密码学安全性保证的普通随机数生成器。 推荐使用的 CSPRNG 有： OpenSSL 中的 RAND_bytes() 函数, https://www.openssl.org/docs/man1.1.1/man3/RAND_bytes.html libsodium 中的 randombytes_buf() 函数 Linux kernel 的 getrandom() 系统调用, https://man7.org/linux/man-pages/man2/getrandom.2.html . 或者读 /dev/urandom 文件, 或者 /dev/random 文件。 Apple IOS 的 SecRandomCopyBytes(), https://developer.apple.com/documentation/security/1399291-secrandomcopybytes Windows 下的 BCryptGenRandom(), CryptGenRandom(), RtlGenRandom() #include \u003copenssl/aes.h\u003e #include \u003copenssl/crypto.h\u003e #include \u003copenssl/rand.h\u003e #include \u003cunistd.h\u003e { unsigned char key[16]; if (1 != RAND_bytes(\u0026key[0], sizeof(key))) { //... 错误处理 return -1; } AES_KEY aes_key; if (0 != AES_set_encrypt_key(\u0026key[0], sizeof(key) * 8, \u0026aes_key)) { // ... 错误处理 return -1; } ... OPENSSL_cleanse(\u0026key[0], sizeof(key)); } rand()类函数的随机性并不高。敏感操作时，如设计加密算法时，不得使用rand()或者类似的简单线性同余伪随机数生成器来作为随机数发生器。符合该定义的比特序列的特点是，序列中“1”的数量约等于“0”的数量；同理，“01”、“00”、“10”、“11”的数量大致相同，以此类推。 例如 C 标准库中的 rand() 的实现只是简单的线性同余算法，生成的伪随机数具有较强的可预测性。 当需要实现高强度加密，例如涉及通信安全时，不应当使用 rand() 作为随机数发生器。 实际应用中， C++11 标准提供的random_device保证加密的安全性和随机性 但是 C++ 标准并不保证这一点。跨平台的代码可以考虑用 OpenSSL 等保证密码学安全的库里的随机数发生器。 关联漏洞: 高风险-敏感数据泄露 4.5 【必须】自己实现的rand范围不应过小 如果在弱安全场景相关的算法中自己实现了PRNG，请确保rand出来的随机数不会很小或可预测。 // Bad int32_t val = ((state[0] * 1103515245U) + 12345U) \u0026 999999; 上述例子可能想生成0~999999共100万种可能的随机数，但是999999的二进制是11110100001000111111，与\u0026运算后，0位一直是0，所以生成出的范围明显会小于100万种。 // Good int32_t val = ((state[0] * 1103515245U) + 12345U) % 1000000; // Good int32_t val = ((state[0] * 1103515245U) + 12345U) \u0026 0x7fffffff; 关联漏洞: 高风险-逻辑漏洞 ","date":"2021-08-19","objectID":"/202108/secguide_c_tc/:1:4","tags":["Cpp","C"],"title":"C,C++安全指南","uri":"/202108/secguide_c_tc/"},{"categories":["Cpp"],"content":"5 文件操作 5.1 【必须】避免路径穿越问题 在进行文件操作时，需要判断外部传入的文件名是否合法，如果文件名中包含 ../ 等特殊字符，则会造成路径穿越，导致任意文件的读写。 错误： void Foo() { char file_path[PATH_MAX] = \"/home/user/code/\"; // 如果传入的文件名包含../可导致路径穿越 // 例如\"../file.txt\"，则可以读取到上层目录的file.txt文件 char name[20] = \"../file.txt\"; memcpy(file_path + strlen(file_path), name, sizeof(name)); int fd = open(file_path, O_RDONLY); if (fd != -1) { char data[100] = {0}; int num = 0; memset(data, 0, sizeof(data)); num = read(fd, data, sizeof(data)); if (num \u003e 0) { write(STDOUT_FILENO, data, num); } close(fd); } } 正确： void Foo() { char file_path[PATH_MAX] = \"/home/user/code/\"; char name[20] = \"../file.txt\"; // 判断传入的文件名是否非法，例如\"../file.txt\"中包含非法字符../，直接返回 if (strstr(name, \"..\") != NULL){ // 包含非法字符 return; } memcpy(file_path + strlen(file_path), name, sizeof(name)); int fd = open(file_path, O_RDONLY); if (fd != -1) { char data[100] = {0}; int num = 0; memset(data, 0, sizeof(data)); num = read(fd, data, sizeof(data)); if (num \u003e 0) { write(STDOUT_FILENO, data, num); } close(fd); } } 关联漏洞: 高风险-逻辑漏洞 5.2 【必须】避免相对路径导致的安全问题（DLL、EXE劫持等问题） 在程序中，使用相对路径可能导致一些安全风险，例如DLL、EXE劫持等问题。 例如以下代码，可能存在劫持问题： int Foo() { // 传入的是dll文件名，如果当前目录下被写入了恶意的同名dll，则可能导致dll劫持 HINSTANCE hinst = ::LoadLibrary(\"dll_nolib.dll\"); if (hinst != NULL) { cout\u003c\u003c\"dll loaded!\" \u003c\u003c endl; } return 0; } 针对DLL劫持的安全编码的规范： 1）调用LoadLibrary，LoadLibraryEx，CreateProcess，ShellExecute等进行模块加载的函数时，指明模块的完整（全）路径，禁止使用相对路径，这样就可避免从其它目录加载DLL。 2）在应用程序的开头调用SetDllDirectory(TEXT(\"\")); 从而将当前目录从DLL的搜索列表中删除。结合SetDefaultDllDirectories，AddDllDirectory，RemoveDllDirectory这几个API配合使用，可以有效的规避DLL劫持问题。这些API只能在打了KB2533623补丁的Windows7，2008上使用。 关联漏洞: 中风险-逻辑漏洞 5.3 【必须】文件权限控制 在创建文件时，需要根据文件的敏感级别设置不同的访问权限，以防止敏感数据被其他恶意程序读取或写入。 错误： int Foo() { // 不要设置为777权限，以防止被其他恶意程序操作 if (creat(\"file.txt\", 0777) \u003c 0) { printf(\"文件创建失败！\\n\"); } else { printf(\"文件创建成功！\\n\"); } return 0; } 关联漏洞: 中风险-逻辑漏洞 ","date":"2021-08-19","objectID":"/202108/secguide_c_tc/:1:5","tags":["Cpp","C"],"title":"C,C++安全指南","uri":"/202108/secguide_c_tc/"},{"categories":["Cpp"],"content":"6 内存操作 6.1 【必须】防止各种越界写（向前/向后） 错误1： int a[5]; a[5] = 0; 错误2： int a[5]; int b = user_controlled_value; a[b] = 3; 关联漏洞: 高风险-内存破坏 6.2 【必须】防止任意地址写 任意地址写会导致严重的安全隐患，可能导致代码执行。因此，在编码时必须校验写入的地址。 错误： void Write(MyStruct dst_struct) { char payload[10] = { 0 }; memcpy(dst_struct.buf, payload, sizeof(payload)); } int main() { MyStruct dst_stuct; dst_stuct.buf = (char*)user_controlled_value; Write(dst_stuct); return 0; } 关联漏洞: 高风险-内存破坏 ","date":"2021-08-19","objectID":"/202108/secguide_c_tc/:1:6","tags":["Cpp","C"],"title":"C,C++安全指南","uri":"/202108/secguide_c_tc/"},{"categories":["Cpp"],"content":"7 数字操作 7.1 【必须】防止整数溢出 在计算时需要考虑整数溢出的可能，尤其在进行内存操作时，需要对分配、拷贝等大小进行合法校验，防止整数溢出导致的漏洞。 错误（该例子在计算时产生整数溢出） const int kMicLen = 4; // 整数溢出 void Foo() { int len = 1; char payload[10] = { 0 }; char dst[10] = { 0 }; // Bad, 由于len小于4，导致计算拷贝长度时，整数溢出 // len - kMicLen == 0xfffffffd memcpy(dst, payload, len - kMicLen); } 正确例子 void Foo() { int len = 1; char payload[10] = { 0 }; char dst[10] = { 0 }; int size = len - kMicLen; // 拷贝前对长度进行判断 if (size \u003e 0 \u0026\u0026 size \u003c 10) { memcpy(dst, payload, size); printf(\"memcpy good\\n\"); } } 关联漏洞: 高风险-内存破坏 7.2 【必须】防止Off-By-One 在进行计算或者操作时，如果使用的最大值或最小值不正确，使得该值比正确值多1或少1，可能导致安全风险。 错误： char firstname[20]; char lastname[20]; char fullname[40]; fullname[0] = '\\0'; strncat(fullname, firstname, 20); // 第二次调用strncat()可能会追加另外20个字符。如果这20个字符没有终止空字符，则存在安全问题 strncat(fullname, lastname, 20); 正确： char firstname[20]; char lastname[20]; char fullname[40]; fullname[0] = '\\0'; // 当使用像strncat()函数时，必须在缓冲区的末尾为终止空字符留下一个空字节，避免off-by-one strncat(fullname, firstname, sizeof(fullname) - strlen(fullname) - 1); strncat(fullname, lastname, sizeof(fullname) - strlen(fullname) - 1); 对于 C++ 代码，再次强烈建议使用 string、vector 等组件代替原始指针和数组操作。 关联漏洞: 高风险-内存破坏 7.3 【必须】避免大小端错误 在一些涉及大小端数据处理的场景，需要进行大小端判断，例如从大端设备取出的值，要以大端进行处理，避免端序错误使用。 关联漏洞: 中风险-逻辑漏洞 7.4 【必须】检查除以零异常 在进行除法运算时，需要判断被除数是否为零，以防导致程序不符合预期或者崩溃。 错误： int divide(int x, int y) { return x / y; } 正确： int divide(int x, int y) { if (y == 0) { throw DivideByZero; } return x / y; } 关联漏洞: 低风险-拒绝服务 7.5 【必须】防止数字类型的错误强转 在有符号和无符号数字参与的运算中，需要注意类型强转可能导致的逻辑错误，建议指定参与计算时数字的类型或者统一类型参与计算。 错误例子 int Foo() { int len = 1; unsigned int size = 9; // 1 \u003c 9 - 10 ? 由于运算中无符号和有符号混用，导致计算结果以无符号计算 if (len \u003c size - 10) { printf(\"Bad\\n\"); } else { printf(\"Good\\n\"); } } 正确例子 void Foo() { // 统一两者计算类型为有符号 int len = 1; int size = 9; if (len \u003c size - 10) { printf(\"Bad\\n\"); } else { printf(\"Good\\n\"); } } 关联漏洞: 高风险-内存破坏 中风险-逻辑漏洞 7.6 【必须】比较数据大小时加上最小/最大值的校验 在进行数据大小比较时，要合理地校验数据的区间范围，建议根据数字类型，对其进行最大和最小值的判断，以防止非预期错误。 错误： void Foo(int index) { int a[30] = {0}; // 此处index是int型，只考虑了index小于数组大小，但是并未判断是否大于等于0 if (index \u003c 30) { // 如果index为负数，则越界 a[index] = 1; } } 正确： void Foo(int index) { int a[30] = {0}; // 判断index的最大最小值 if (index \u003e= 0 \u0026\u0026 index \u003c 30) { a[index] = 1; } } 关联漏洞: 高风险-内存破坏 ","date":"2021-08-19","objectID":"/202108/secguide_c_tc/:1:7","tags":["Cpp","C"],"title":"C,C++安全指南","uri":"/202108/secguide_c_tc/"},{"categories":["Cpp"],"content":"8 指针操作 8.1 【建议】检查在pointer上使用sizeof 除了测试当前指针长度，否则一般不会在pointer上使用sizeof。 正确： size_t pointer_length = sizeof(void*); 可能错误： size_t structure_length = sizeof(Foo*); 可能是： size_t structure_length = sizeof(Foo); 关联漏洞: 中风险-逻辑漏洞 8.2 【必须】检查直接将数组和0比较的代码 错误： int a[3]; ...; if (a \u003e 0) ...; 该判断永远为真，等价于: int a[3]; ...; if (\u0026a[0]) ...; 可能是： int a[3]; ...; if(a[0] \u003e 0) ...; 开启足够的编译器警告（GCC 中为 -Waddress，并已包含在 -Wall 中），并设置为错误，可以在编译期间发现该问题。 关联漏洞: 中风险-逻辑漏洞 8.3 【必须】不应当向指针赋予写死的地址 特殊情况需要特殊对待（比如开发硬件固件时可能需要写死） 但是如果是系统驱动开发之类的，写死可能会导致后续的问题。 关联漏洞: 高风险-内存破坏 8.4 【必须】检查空指针 错误： *foo = 100; if (!foo) { ERROR(\"foobar\"); } 正确： if (!foo) { ERROR(\"foobar\"); } *foo = 100; 错误： void Foo(char* bar) { *bar = '\\0'; } 正确： void Foo(char* bar) { if(bar) *bar = '\\0'; else ...; } 关联漏洞: 低风险-拒绝服务 8.5 【必须】释放完后置空指针 在对指针进行释放后，需要将该指针设置为NULL，以防止后续free指针的误用，导致UAF等其他内存破坏问题。尤其是在结构体、类里面存储的原始指针。 错误： void foo() { char* p = (char*)malloc(100); memcpy(p, \"hello\", 6); printf(\"%s\\n\", p); free(p); // 此时p所指向的内存已被释放，但是p所指的地址仍然不变 // 未设置为NULL，可能导致UAF等内存错误 if (p != NULL) { // 没有起到防错作用 printf(\"%s\\n\", p); // 错误使用已经释放的内存 } } 正确： void foo() { char* p = (char*)malloc(100); memcpy(p, \"hello\", 6); // 此时p所指向的内存已被释放，但是p所指的地址仍然不变 printf(\"%s\\n\", p); free(p); //释放后将指针赋值为空 p = NULL; if (p != NULL) { // 没有起到防错作用 printf(\"%s\\n\", p); // 错误使用已经释放的内存 } } 对于 C++ 代码，使用 string、vector、智能指针等代替原始内存管理机制，可以大量减少这类错误。 关联漏洞: 高风险-内存破坏 8.6 【必须】防止错误的类型转换（type confusion） 在对指针、对象或变量进行操作时，需要能够正确判断所操作对象的原始类型。如果使用了与原始类型不兼容的类型进行访问，则存在安全隐患。 错误： const int NAME_TYPE = 1; const int ID_TYPE = 2; // 该类型根据 msg_type 进行区分，如果在对MessageBuffer进行操作时没有判断目标对象，则存在类型混淆 struct MessageBuffer { int msg_type; union { const char *name; int name_id; }; }; void Foo() { struct MessageBuffer buf; const char* default_message = \"Hello World\"; // 设置该消息类型为 NAME_TYPE，因此buf预期的类型为 msg_type + name buf.msg_type = NAME_TYPE; buf.name = default_message; printf(\"Pointer of buf.name is %p\\n\", buf.name); // 没有判断目标消息类型是否为ID_TYPE，直接修改nameID，导致类型混淆 buf.name_id = user_controlled_value; if (buf.msg_type == NAME_TYPE) { printf(\"Pointer of buf.name is now %p\\n\", buf.name); // 以NAME_TYPE作为类型操作，可能导致非法内存读写 printf(\"Message: %s\\n\", buf.name); } else { printf(\"Message: Use ID %d\\n\", buf.name_id); } } 正确（判断操作的目标是否是预期类型）： void Foo() { struct MessageBuffer buf; const char* default_message = \"Hello World\"; // 设置该消息类型为 NAME_TYPE，因此buf预期的类型为 msg_type + name buf.msg_type = NAME_TYPE; buf.name = default_msessage; printf(\"Pointer of buf.name is %p\\n\", buf.name); // 判断目标消息类型是否为 ID_TYPE，不是预期类型则做对应操作 if (buf.msg_type == ID_TYPE) buf.name_id = user_controlled_value; if (buf.msg_type == NAME_TYPE) { printf(\"Pointer of buf.name is now %p\\n\", buf.name); printf(\"Message: %s\\n\", buf.name); } else { printf(\"Message: Use ID %d\\n\", buf.name_id); } } 关联漏洞: 高风险-内存破坏 8.7 【必须】智能指针使用安全 在使用智能指针时，防止其和原始指针的混用，否则可能导致对象生命周期问题，例如 UAF 等安全风险。 错误例子： class Foo { public: explicit Foo(int num) { data_ = num; }; void Function() { printf(\"Obj is %p, data = %d\\n\", this, data_); }; private: int data_; }; std::unique_ptr\u003cFoo\u003e fool_u_ptr = nullptr; Foo* pfool_raw_ptr = nullptr; void Risk() { fool_u_ptr = make_unique\u003cFoo\u003e(1); // 从独占智能指针中获取原始指针,\u003cFoo\u003e(1) pfool_raw_ptr = fool_u_ptr.get(); // 调用\u003cFoo\u003e(1)的函数 pfool_raw_ptr-\u003eFunction(); // 独占智能指针重新赋值后会释放内存 fool_u_ptr = make_unique\u003cFoo\u003e(2); // 通过原始指针操作会导致UAF，pfool_raw_ptr指向的对象已经释放 pfool_raw_ptr-\u003eFunction(); } // 输出： // Obj is 0000027943087B80, data = 1 // Obj is 0000027943087B80, data = -572662307 正确，通过智能指针操作: void Safe() { fool_u_ptr = make_unique\u003cFoo\u003e(1); // 调用\u003cFoo\u003e(1)的函数 fool_u_ptr-\u003eFunction(); fool_u_ptr = make_unique\u003cFoo\u003e(2); // 调用\u003cFoo\u003e(2)的函数 fool_u_ptr-\u003eFunction(); } // 输出： // Obj is 000002C7BB550830, data = 1 // Obj is 000002C7BB557AF0, data = 2 关联漏洞: 高风险-内存破坏 ","date":"2021-08-19","objectID":"/202108/secguide_c_tc/:1:8","tags":["Cpp","C"],"title":"C,C++安全指南","uri":"/202108/secguide_c_tc/"},{"categories":["软件设计"],"content":"UCB SICP译文, 看这里. 令我印象深刻的是MIT SICP第一章中的例子题1.5:应用序和正则序. ","date":"2021-08-10","objectID":"/202108/sicp-python-read1/:0:0","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(一)","uri":"/202108/sicp-python-read1/"},{"categories":["软件设计"],"content":"使用函数构建抽象 第一大章初会觉得很简单, 但是仔细看还是可以看到很多忽略的知识点, 比如我印象最深的, 对调用栈的解释, 这里用的名词是环境(应该是一个意思). ","date":"2021-08-10","objectID":"/202108/sicp-python-read1/:1:0","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(一)","uri":"/202108/sicp-python-read1/"},{"categories":["软件设计"],"content":"中缀记号和函数 一个很容易观察到, 但是容易被忽略的问题: \u003e\u003e\u003e 2 + 3 5 \u003e\u003e\u003e add(2, 3) 5 在简短的表达式中, 2 + 3是很容易被使用的. 但是2 + 3和add(2, 3)的区别我却没有花心思去考虑过: 2 + 3仅适合两个元素; add可以适应任意多个元素; 当然, 并不是说都需要将中缀记号替换为函数, 这本来就是不合理的. 比如说: 对于简单的算术运算, Python 在惯例上倾向于运算符而不是调用表达式. 这里仅仅是让你注意到这一点. 在后面章节中会提到add函数的其他优点. ","date":"2021-08-10","objectID":"/202108/sicp-python-read1/:1:1","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(一)","uri":"/202108/sicp-python-read1/"},{"categories":["软件设计"],"content":"全局环境和局部环境 实参是怎么传入到形参的? 形参为什么可以重名? 全局环境(帧) 内建函数/用户定义的全局变量/用户定义的全局函数等等, 会作为全局环境的组成部分. 如上图, 表示一个全局环境, 其中pi/tau等变量是通过导入和赋值加入到全局环境中的. 赋值和导入语句会向当前环境的第一个帧添加条目 根据上面这个原理, 当前环境是全局环境, 所以导入和赋值引入的变量等名字将会导入到当前环境中, 也就是全局环境. 局部环境(帧) 比如这样一个函数: \u003e\u003e\u003e def square(x): return mul(x, x) 将会有自己的局部环境, square的环境和全局环境是不一样的, 但是全局环境可以指向这个局部环境. 比如下图, 虽然都有一个叫做x的东西, 但是他们在不同的局部环境, 所以不会互相干扰. 那么, 上述square函数的局部环境如何? 上述调用过程总结如下: 在全局环境中计算表达式-2的结果; 在全局环境中搜索square; 切换到square局部环境, 发现x, 将-2绑定到x; 在当前环境(square局部环境)计算x*x; 退出到全局环境, square计算结果输出到全局环境. 小结 关于环境, 看做是一个映射表, 全局环境或这局部环境都是key(名字), value(真正的内容)会指向其他地方, 在同一个环境中, 只需要关系key不一样就可以了, 不关心value是不是一样. 问题1: 实参是怎么传入到形参的? 实参在函数的局部环境中被绑定到形参上. 问题2: 形参为什么可以重名? 因为采用了局部环境, 在不同的环境中, 相同的名字不影响. ","date":"2021-08-10","objectID":"/202108/sicp-python-read1/:1:2","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(一)","uri":"/202108/sicp-python-read1/"},{"categories":["软件设计"],"content":"函数抽象 函数抽象举例. 为什么要做函数抽象? 黑盒 以下例子令我有种醍醐灌顶的感觉: def square(x): return mul(x, x) def square(x): return mul(x, x-1) + x 函数返回的结果一样, 但是里面实现不一样. 这就是黑盒. 实际上, 我认为我们确实应该把函数当做黑盒. 但是实现起来并没有那么容器. 举例C++的STL, 每个容器的实现都当做黑盒, 所以如果某某能知道各种STL函数, 但是不理解里面的实现, 也没什么了不起的啦. 黑盒确实没必要过分探究. 再说STL, 实际上我们也不是完全不需要关系黑盒内部. 比如vector/list等, 在某些需求下, 可以认为是对等关系的, 但是我们用户却需要考虑到这些容器的内部实现, 以做出更佳的选择, 比如遇到多线程问题时, vector可能需要被慎重考虑了. 所以STL在使用上, 也不是那么的\"无脑\". 这里给我的提示就是: 用户不应该需要知道如何实现来调用. 这句话是值得思考的, 我的理解是: 用户不需要知道内部实现(通俗的理解); 用户不会惊讶于函数的返回(黑盒函数的返回值是正常的可以理解的, 而不会放回一些意外的东西); 用户不会惊讶于函数的输入(类似2, 函数的输入是合乎常理的, 不会有意外的输入, 下面我会举一个真实的例子). 一个反例 某同事期望定制一个基类, 并且他将类定义为了模板类. 他的问题是, 模板并不能代表这个类的意义, 仅是为了其中某些成员函数而引入了模板. 将STL作为对比, 使用vector等容器的时候, 传入int等模板是有意义的, 它告诉你这是一个int容器. 或者放开想象, 可以直接将vector看成某种特殊的int, 因为这时候的vector\u003cint\u003e我们就是在当做一个int在做. 但是他的做法, 使用模板类, 但是模板类的模板只是指代类中某些个函数的输入类型, 和这个类完全没关系. 比如说: template \u003ctypename T\u003e class A{ public: //... T get(){ //... } void set(const T\u0026 t) { //... } private: _container\u003cT\u003e m_data; } 以上, 我认为是一个好的定义, 模板T代表这个类的类型, 用户操作这个类的时候, 就像在操作T一样, 因为get的返回和set的输入都是T, 并且其中主要参与作用的数据也是T(m_data, 当然底层数据是用户无需关心的.) template \u003ctypename T\u003e class A{ public: //... int get(){ //... } void set(const T\u0026 t) { //... } private: _container\u003cint\u003e m_data; } 以上, 引入了模板T, 但是这个的表现并不像T, 因为get的返回和T无关, set的输入虽然是T, 但是和这个类无关, 因为这个类的主要数据m_data的类型是int. 这就是不好的做法, 为了用模板而用模板. 这就不是一个黑盒! 什么应该抽象为函数 这个应该好好想想. 我以及我周围很多人都做不好. 要不是抽象的部分太大, 要不是抽象的部分太特殊以至于只有写的人自己用了. 这个例子我认为挺好的: \u003e\u003e\u003e def pressure(v, t, n): \"\"\"Compute the pressure in pascals of an ideal gas. Applies the ideal gas law: http://en.wikipedia.org/wiki/Ideal_gas_law v -- volume of gas, in cubic meters t -- absolute temperature in degrees kelvin n -- particles of gas \"\"\" k = 1.38e-23 # Boltzmann's constant return n * k * t / v 可以看出来, 这里是某个公式. 如果直接把公式写出来, 外行人非常容易疑惑, 但是抽象为函数, 则容易理解多了. 这也是一个黑盒. 另外不仅仅是抽象为函数, 也可以是一个变量: pressure = #... 变量做法我在一些判断式中经常用. 比如: if( exp1 \u0026\u0026 exp2 \u0026\u0026 exp3 ){ // ... } 这里的exp*应该抽象出来, 指代每一个exp的具体含义, 比如: is_range_ok = //... is_size_ok = //... is_empty = //... if (!is_empty \u0026\u0026 is_range_ok \u0026\u0026 is_size_ok) { // ... } 这时候会容易理解多了. 其实还没有解答我的问题, 可能这是一个经验性的问题吧~ 以上例子仅做参考, 不同的人可能有不同的想法. 小结 怎么写黑盒? 就是让黑盒的行为不超出用户的意外, 输入输出看起来都很自然. 函数抽象也应该像黑盒一样, 不仅仅是将一段重复使用的代码写成函数就好了. ","date":"2021-08-10","objectID":"/202108/sicp-python-read1/:1:3","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(一)","uri":"/202108/sicp-python-read1/"},{"categories":["软件设计"],"content":"高阶函数 高阶函数概念. 高阶函数举例. 第一小节我们提到了add函数, 实际上add是一个很宽泛的行为. 我们可以直接add, 也可以是绝对值add, 平方值add等等. 这里就涉及到了高阶函数. 推荐阅读MIT的SICP(我还没看完…), 在LISP里面使用高阶函数看起来太自然了, 在Python中多多少少有点别扭… 我们需要思考的问题是: 为什么要使用高阶函数? 什么时候应该用高阶函数? 参数是函数 摘抄原文的三个求和的例子: \u003e\u003e\u003e def sum_naturals(n): total, k = 0, 1 while k \u003c= n: total, k = total + k, k + 1 return total \u003e\u003e\u003e sum_naturals(100) 5050 \u003e\u003e\u003e def sum_cubes(n): total, k = 0, 1 while k \u003c= n: total, k = total + pow(k, 3), k + 1 return total \u003e\u003e\u003e sum_cubes(100) 25502500 \u003e\u003e\u003e def pi_sum(n): total, k = 0, 1 while k \u003c= n: total, k = total + 8 / (k * (k + 2)), k + 4 return total \u003e\u003e\u003e pi_sum(100) 3.121594652591009 以上三个函数实现了不同的功能, 但是仔细观察可以发现, 函数的抽象功能是一样的. 总结就是: def \u003cname\u003e(n): total, k = 0, 1 while k \u003c= n: total, k = total + \u003cterm\u003e(k), \u003cnext\u003e(k) return total 不同的仅仅是term和next, 一个用于计算部分结果, 一个用于返回下一个值. 最外层函数也是有意义的, 它的作用是计算 $$ s(N) = \\sum_{i=1, k=f(i)}^{N}{g(k)} $$ 所以, 这三个例子相当于是三个函数的组合, 最外层的$s$, 以及内层的$f$和$g$. 返回是函数 例子: \u003e\u003e\u003e def compose1(f, g): def h(x): return f(g(x)) return h \u003e\u003e\u003e add_one_and_square = compose1(square, successor) \u003e\u003e\u003e add_one_and_square(12) 169 读懂例子并不难, 但是要好好理解. 那上三个例子举例, 如果计算某函数的sum, 按照上述例子, 需要三个参数, $n$/$f$/$g$, 返回值是求某上限是$n$的$f$|$s$的和的值. 如果将函数作为返回值, 此处值需要两个参数, 返回值代表求某$f$|$g$的和的方法, 意义是不一样的. 修饰器等相当于是语言的语法糖, 这里不就记述了. 小结 什么时候用到高阶函数? 当我们在函数内部还能抽象出某些函数的时候, 就应该使用高阶函数了. ","date":"2021-08-10","objectID":"/202108/sicp-python-read1/:1:4","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(一)","uri":"/202108/sicp-python-read1/"},{"categories":["软件设计"],"content":"总结 注意中缀记号和函数调用的优缺点, 一个简洁, 一个扩展性高; 程序运行依赖于环境, 有全局环境和对每个函数的局部环境; 黑盒应该让用户用起来很自然, 没有任何意外的输入或输出; 当函数内部还能抽象出一些通用方法是, 应该考虑考虑高阶函数; ","date":"2021-08-10","objectID":"/202108/sicp-python-read1/:1:5","tags":["SICP","Python"],"title":"《UCB CS61a SICP Python 中文》一周目笔记(一)","uri":"/202108/sicp-python-read1/"},{"categories":["Cpp"],"content":"持续更新中…主要来源在这里, 仅摘抄部分个人不常用或者不太理解的知识点． ","date":"2021-07-30","objectID":"/202107/cpp-modern-feature/:0:0","tags":["Cpp"],"title":"现代C++容易忽略的一些特性","uri":"/202107/cpp-modern-feature/"},{"categories":["Cpp"],"content":"语言 if/switch 变量声明强化[C++17] C++17 使得我们可以在 if（或 switch）中使用局部变量: // 将临时变量放到 if 语句内 if (const std::vector\u003cint\u003e::iterator itr = std::find(vec.begin(), vec.end(), 3); itr != vec.end()) { *itr = 4; } 初始化列表[C++11] C++11 首先把初始化列表的概念绑定到了类型上，并将其称之为std::initializer_list，允许构造函数或其他函数像参数一样使用初始化列表，这就为类对象的初始化与普通数组和 POD 的初始化方法提供了统一的桥梁，例如： #include \u003cinitializer_list\u003e #include \u003cvector\u003e class MagicFoo { public: std::vector\u003cint\u003e vec; MagicFoo(std::initializer_list\u003cint\u003e list) { for (std::initializer_list\u003cint\u003e::iterator it = list.begin(); it != list.end(); ++it) vec.push_back(*it); } }; int main() { // after C++11 MagicFoo magicFoo = {1, 2, 3, 4, 5}; std::cout \u003c\u003c \"magicFoo: \"; for (std::vector\u003cint\u003e::iterator it = magicFoo.vec.begin(); it != magicFoo.vec.end(); ++it) std::cout \u003c\u003c *it \u003c\u003c std::endl; } 初始化列表除了用在对象构造上，还能将其作为普通函数的形参，例如： public: void foo(std::initializer_list\u003cint\u003e list) { for (std::initializer_list\u003cint\u003e::iterator it = list.begin(); it != list.end(); ++it) vec.push_back(*it); } magicFoo.foo({6,7,8,9}); 其次，C++11 还提供了统一的语法来初始化任意的对象，例如： Foo foo2 {3, 4}; std::initializer_list和std::vector区别: std::initializer_list一般是在栈上的, 不可修改, std::vector在堆上, 详细 结构化绑定[C++17] #include \u003ciostream\u003e #include \u003ctuple\u003e std::tuple\u003cint, double, std::string\u003e f() { return std::make_tuple(1, 2.3, \"456\"); } int main() { auto [x, y, z] = f(); std::cout \u003c\u003c x \u003c\u003c \", \" \u003c\u003c y \u003c\u003c \", \" \u003c\u003c z \u003c\u003c std::endl; return 0; } 返回值推导[C++14] 不用后缀decltype了. C++14 开始是可以直接让普通函数具备返回值推导: template\u003ctypename T, typename U\u003e auto add3(T x, U y){ return x + y; } 外部模板[C++11] 在没有外部模板时可能会产生多个相同的实例, 带来冗余. 外部模板允许只有一个实例化了. template class std::vector\u003cbool\u003e; // 强行实例化 extern template class std::vector\u003cdouble\u003e; // 不在该当前编译文件中实例化模板 类型别名模板[C++11] 使用using完全代替typedef. typedef int (*process)(void *); using NewProcess = int(*)(void *); template\u003ctypename T\u003e using TrueDarkMagic = MagicType\u003cstd::vector\u003cT\u003e, std::string\u003e; int main() { TrueDarkMagic\u003cbool\u003e you; } 折叠表达式[C++17] #include \u003ciostream\u003e template\u003ctypename ... T\u003e auto sum(T ... t) { return (t + ...); } int main() { std::cout \u003c\u003c sum(1, 2, 3, 4, 5, 6, 7, 8, 9, 10) \u003c\u003c std::endl; } 非类型模板推导auto[C++17] template \u003cauto value\u003e void foo() { std::cout \u003c\u003c value \u003c\u003c std::endl; return; } int main() { foo\u003c10\u003e(); // value 被推导为 int 类型 } 委托构造[C++11] #include \u003ciostream\u003e class Base { public: int value1; int value2; Base() { value1 = 1; } Base(int value) : Base() { // 委托 Base() 构造函数 value2 = value; } }; int main() { Base b(2); std::cout \u003c\u003c b.value1 \u003c\u003c std::endl; std::cout \u003c\u003c b.value2 \u003c\u003c std::endl; } 继承构造[C++11] #include \u003ciostream\u003e class Base { public: int value1; int value2; Base() { value1 = 1; } Base(int value) : Base() { // 委托 Base() 构造函数 value2 = value; } }; class Subclass : public Base { public: using Base::Base; // 继承构造 }; int main() { Subclass s(3); std::cout \u003c\u003c s.value1 \u003c\u003c std::endl; std::cout \u003c\u003c s.value2 \u003c\u003c std::endl; } 右值引用[C++11] TODO 字面量[C++11] C++11 提供了原始字符串字面量的写法, 可以在一个字符串前方使用 R 来修饰这个字符串, 同时, 将原始字符串使用括号包裹, 例如: #include \u003ciostream\u003e #include \u003cstring\u003e int main() { std::string str = R\"(C:\\File\\To\\Path)\"; //不需要转义了 std::cout \u003c\u003c str \u003c\u003c std::endl; return 0; } 自定义字面量[C++11] C++11 引进了自定义字面量的能力, 通过重载双引号后缀运算符实现: // 字符串字面量自定义必须设置如下的参数列表 std::string operator\"\" _wow1(const char *wow1, size_t len) { return std::string(wow1)+\"woooooooooow, amazing\"; } std::string operator\"\" _wow2 (unsigned long long i) { return std::to_string(i)+\"woooooooooow, amazing\"; } int main() { auto str = \"abc\"_wow1; auto num = 1_wow2; std::cout \u003c\u003c str \u003c\u003c std::endl; std::cout \u003c\u003c num \u003c\u003c std::endl; return 0; } 自定义字面量支持四种字面量： 整型字面量: 重载时必须使用 unsigned long long/const char *模板字面量算符参数, 在上面的代码中使用的是前者; 浮点型字面量: 重载时必须使用 long double/const char */模板字面量算符; 字符串字面量: 必须使用 (const char *, size_t) 形式的参数表; 字符字面量: 参数只能是 char, wchar_t, char16_t, char32_t 这几种类型. 内存对齐[C++11] TODO ","date":"2021-07-30","objectID":"/202107/cpp-modern-feature/:0:1","tags":["Cpp"],"title":"现代C++容易忽略的一些特性","uri":"/202107/cpp-modern-feature/"},{"categories":["Cpp"],"content":"容器 std::array[C++11] 注意和std::vector的区别. 如果是已知并且固定大小的数组, 可以考虑使用std::array. 与 std::vector 不同，std::array 对象的大小是固定的; std::vector执行clear()方法后, 需要使用释放内存, std::array则自动释放内存; 提供data()方法, 从而可以兼容C风格指针访问. std::forward_list[C++11] 类似std::list, 但是std::forward_list指单向列表, 不提供size()方法. 运行时获取std::tuple元素[C++17] std::get\u003c\u003e()方法只可以在编译期获取元素, 使用std::variant\u003c\u003e可以在运行时获取元素: #include \u003cvariant\u003e template \u003csize_t n, typename... T\u003e constexpr std::variant\u003cT...\u003e _tuple_index(const std::tuple\u003cT...\u003e\u0026 tpl, size_t i) { if constexpr (n \u003e= sizeof...(T)) throw std::out_of_range(\"越界.\"); if (i == n) return std::variant\u003cT...\u003e{ std::in_place_index\u003cn\u003e, std::get\u003cn\u003e(tpl) }; return _tuple_index\u003c(n \u003c sizeof...(T)-1 ? n+1 : 0)\u003e(tpl, i); } template \u003ctypename... T\u003e constexpr std::variant\u003cT...\u003e tuple_index(const std::tuple\u003cT...\u003e\u0026 tpl, size_t i) { return _tuple_index\u003c0\u003e(tpl, i); } template \u003ctypename T0, typename ... Ts\u003e std::ostream \u0026 operator\u003c\u003c (std::ostream \u0026 s, std::variant\u003cT0, Ts...\u003e const \u0026 v) { std::visit([\u0026](auto \u0026\u0026 x){ s \u003c\u003c x;}, v); return s; } ","date":"2021-07-30","objectID":"/202107/cpp-modern-feature/:0:2","tags":["Cpp"],"title":"现代C++容易忽略的一些特性","uri":"/202107/cpp-modern-feature/"},{"categories":["Cpp"],"content":"并行与并发 C++11内存顺序模型[C++11] TODO ","date":"2021-07-30","objectID":"/202107/cpp-modern-feature/:0:3","tags":["Cpp"],"title":"现代C++容易忽略的一些特性","uri":"/202107/cpp-modern-feature/"},{"categories":["工具"],"content":"RSSBlog RSSBlog 是一个基于RSS的博客内容聚合站. 想法来源: https://github.com/volfclub/travellings 及 https://front-end-rss.vercel.app/ ","date":"2021-07-19","objectID":"/202107/rss-rssblog/:1:0","tags":["RSS","vercel","flask"],"title":"博文聚合站-RSSBlog","uri":"/202107/rss-rssblog/"},{"categories":["工具"],"content":"定位 这是一个值得一直思考的问题. 当初打算写RSSBlog是因为在个人博客添加友链时遇到了一些问题: 被关注的友链, 如何才能比较及时的知道对方有没有更新博文呢? 或许可以通过爬虫或者其他RSS订阅, 但是最终还是期望把友链的最新内容可以通过博客本站访问到, 所以就搭建了RSSBlog. 所以在最初的版本中, 一直只维护部分友链中的RSS订阅, 再到后来偏移了最初的方向. 最近做了一次更新, 保持原来的url不变, 原始链接依然可以访问所有的订阅. 添加了新的访问方式/uid/, 通过uid访问, 可以定制不同的RSS列表. 比如可以将我的博客友链列表做成一个json文件, 然后接入到RSSBlog, 假设uid是bbing, 那么就可以通过https://rssblog.cn/bbing访问到我定制的RSS列表, 将这个链接接入到个人博客, 就可以比较及时的获取友链更新的情况. ","date":"2021-07-19","objectID":"/202107/rss-rssblog/:1:1","tags":["RSS","vercel","flask"],"title":"博文聚合站-RSSBlog","uri":"/202107/rss-rssblog/"},{"categories":["工具"],"content":"接入规则 加入RSSBlog的博客应满足 愿为开放的网络做出贡献(如乐于分享知识经验等) 没有违法以及影响体验的内容(如侵入式广告等) 正常更新维护中(国内无法正常访问会被移除) 网页已有较多内容 启用https 提交issue 如果满足RSSBlog的接入条件, 且期望接入RSSBlog, 需要按照以下格式提交issue: { \"uid\" :　\"gist json link\", } 例如: { \"bbing\": \"https://gist.githubusercontent.com/caibingcheng/adf8f300dc50a61a965bdcc6ef0aecb3/raw/friends.json\", } 提交的issue将经过人工筛选, 以保证内容干净. json的格式可以参考此处. RSS接力 目前还没有非常确定的定义RSSBlog的接力规则, 所以目前可以您的博客网站中无需有指向RSSBlog的链接, 当然有的话最好了. 您可以在底部或者其他地方接入: \u003ca href=\"https://rssblog.cn/[uid]\" target=\"_blank\" rel=\"noopener\" title=\"RSSBlog\"\u003e \u003ci class='fas fa-fw fa-inbox'\u003e\u003c/i\u003eRSSBlog \u003c/a\u003e fa-inbox看起来像一个盒子, 比较贴近RSS聚合的定义. TODOLIST 搜索 ","date":"2021-07-19","objectID":"/202107/rss-rssblog/:1:2","tags":["RSS","vercel","flask"],"title":"博文聚合站-RSSBlog","uri":"/202107/rss-rssblog/"},{"categories":["工具"],"content":"UPDATE LIST 2021-08-18: 从RSSBlog-Source获取数据 ","date":"2021-07-19","objectID":"/202107/rss-rssblog/:1:3","tags":["RSS","vercel","flask"],"title":"博文聚合站-RSSBlog","uri":"/202107/rss-rssblog/"},{"categories":["Cpp"],"content":"在《C++类的内存分布》中, 我们使用gdb大概了解了C++类的内存结构, 并得到了以下结论: 类成员函数只有一份，所有实例共享 类的成员变量有多份，不同实例维护不同的成员变量 即使是继承关系，派生类的成员变量也只是基类的复制体，而不是指向同一块内存 派生类会把从基类继承过来的成员变量当做自己的普通成员变量一样看待 类的虚表只有一份，所有实例共享 编译器在编译的时候, 通过给类添加__vptr指针指向虚表而得到虚表地址. 本文主要目的是扩展vptr和vtable部分, 深入了解C++多态的实现原理. 以下环境基于x86-64架构下的gcc 11.1编译器. 测试代码在这里. ","date":"2021-07-06","objectID":"/202107/cpp-class-mem2/:0:0","tags":["Cpp","内存"],"title":"C++类的内存分布(二)","uri":"/202107/cpp-class-mem2/"},{"categories":["Cpp"],"content":"带virtual的类的内存结构 上文中, 我们得到了这样的类内存结构: 结构图 在这里有两个疑问: 类是怎么指向虚表的? 虚表怎么指向函数的? 我们先来看结论, 再一起研究怎么得到这个结论: vptr和vtable ","date":"2021-07-06","objectID":"/202107/cpp-class-mem2/:1:0","tags":["Cpp","内存"],"title":"C++类的内存分布(二)","uri":"/202107/cpp-class-mem2/"},{"categories":["Cpp"],"content":"问题1: 类是怎么指向虚表的? 我们可以验证下面一段代码, 输出的值是多少? #include \u003ciostream\u003e using namespace std; class Base { public: Base(){} virtual ~Base(){ cout \u003c\u003c \"release Base\" \u003c\u003c endl; } virtual void vfunc1(){ int a = 1; cout \u003c\u003c \"hello vfunc1 \" \u003c\u003c a \u003c\u003c endl; } virtual void vfunc2(){ double a = 1.111; cout \u003c\u003c \"hello vfunc2 \" \u003c\u003c a \u003c\u003c endl; } virtual void vfunc3(){ char a =64; cout \u003c\u003c \"hello vfunc3 \" \u003c\u003c a \u003c\u003c endl; } void func_s1() { int a = 1; cout \u003c\u003c \"hello func_s1 \" \u003c\u003c a \u003c\u003c endl; } }; int main() { cout \u003c\u003c sizeof(Base) \u003c\u003c endl; return 1; } 编译运行, 可以看到输出值是8. 根据上文的结论, 我们知道, 如果类里面有virtual关键词, 则会生成一个vptr变量指向虚表. 现在可以断定, 这里的8, 就是vptr指针的占位. 一般, 我们可以直接通过类头指针直接拿到vptr. 看下面一段代码: Base *base = new Base(); using uint64 = unsigned long long; using func_type = void*(void); uint64 vptr_base_v = *reinterpret_cast\u003cuint64 *\u003e(base); uint64 *vptr_base = reinterpret_cast\u003cuint64 *\u003e(vptr_base_v); 我们把base指针重新解释为uint64*, 因为按照Base*的内存结构不是我们想要的, 所以要把\"地址解释为地址\", 换句话说, 并解引用得到vptr_base_v. 这里用uint64是为了方便我们后续查看和重新解释指针. 现在vptr_base_v就是vtable地址的值了. 接下来, 对vptr_base_v重新解释, 将uint64解释为uint64*得到vptr_base. 现在vptr_base真正是C++编译器可以认识的地址, 并且指向vtable. 现在可以知道类怎么得到vptr, vptr又是怎么指向vtable的了: vptr到vtable ","date":"2021-07-06","objectID":"/202107/cpp-class-mem2/:1:1","tags":["Cpp","内存"],"title":"C++类的内存分布(二)","uri":"/202107/cpp-class-mem2/"},{"categories":["Cpp"],"content":"问题2: 虚表怎么指向函数的? 以上, 我们拿到了vtable. table类设计一般都比较容易猜想, 虚函数指针会\"一列一列\"的排列在vtable上. 首先, 直接打印函数地址, 作为参照: void *base_vfunc1_void = reinterpret_cast\u003cvoid *\u003e(\u0026Base::vfunc1); uint64 base_vfunc1 = reinterpret_cast\u003cuint64\u003e(base_vfunc1_void); void *base_vfunc2_void = reinterpret_cast\u003cvoid *\u003e(\u0026Base::vfunc2); uint64 base_vfunc2 = reinterpret_cast\u003cuint64\u003e(base_vfunc2_void); void *base_vfunc3_void = reinterpret_cast\u003cvoid *\u003e(\u0026Base::vfunc3); uint64 base_vfunc3 = reinterpret_cast\u003cuint64\u003e(base_vfunc3_void); 这几个输出是: base::vfunc* vfunc1 0x401aca vfunc2 0x401b0c vfunc3 0x401b58 再来尝试分析虚函数在虚表中的定位: //*reinterpret_cast\u003cuint64 *\u003e(vptr_base + 0) //*reinterpret_cast\u003cuint64 *\u003e(vptr_base + 1) uint64 vptr_base_vfunc1 = *reinterpret_cast\u003cuint64 *\u003e(vptr_base + 2); uint64 vptr_base_vfunc2 = *reinterpret_cast\u003cuint64 *\u003e(vptr_base + 3); uint64 vptr_base_vfunc3 = *reinterpret_cast\u003cuint64 *\u003e(vptr_base + 4); 第0和1是对不上的, 尝试2-4, 可以得到以下地址: base vptr base::vfunc* vfunc1 0x401aca 0x401aca vfunc2 0x401b0c 0x401b0c vfunc3 0x401b58 0x401b58 和函数地址是匹配的, 但是0和1是什么? 我们可以打印0和1的地址: uint64 vptr_base_v0 = *reinterpret_cast\u003cuint64 *\u003e(vptr_base + 0); uint64 vptr_base_v1 = *reinterpret_cast\u003cuint64 *\u003e(vptr_base + 1); 得到: base vptr 0 0x401a66 1 0x401a9e 再看汇编, 可以知道0和1分别对应两个虚析构函数: # Base::~Base(): 0x401a66: push rbp mov rbp,rsp sub rsp,0x10 mov QWORD PTR [rbp-0x8],rdi mov edx,0x402370 mov rax,QWORD PTR [rbp-0x8] mov QWORD PTR [rax],rdx mov esi,0x402008 mov edi,0x4040c0 call 401080 \u003cstd::basic_ostream\u003cchar, std::char_traits\u003cchar\u003e \u003e\u0026 std::operator\u003c\u003c \u003cstd::char_traits\u003cchar\u003e \u003e(std::basic_ostream\u003cchar, std::char_traits\u003cchar\u003e \u003e\u0026, char const*)@plt\u003e mov esi,0x401050 mov rdi,rax call 4010b0 \u003cstd::ostream::operator\u003c\u003c(std::ostream\u0026 (*)(std::ostream\u0026))@plt\u003e nop leave ret nop # Base::~Base(): 0x401a9e: push rbp mov rbp,rsp sub rsp,0x10 mov QWORD PTR [rbp-0x8],rdi mov rax,QWORD PTR [rbp-0x8] mov rdi,rax call 401a66 \u003cBase::~Base()\u003e mov rax,QWORD PTR [rbp-0x8] mov esi,0x8 mov rdi,rax call 4010a0 \u003coperator delete(void*, unsigned long)@plt\u003e leave ret nop # ... 以上, 我们知道怎么从vtable指向函数了: vtable到vfunc ","date":"2021-07-06","objectID":"/202107/cpp-class-mem2/:1:2","tags":["Cpp","内存"],"title":"C++类的内存分布(二)","uri":"/202107/cpp-class-mem2/"},{"categories":["Cpp"],"content":"问题3: 怎么调用虚函数的？ （本小结2022年3月11日更新） 参考以上示例代码： Base *base = new Base(); D1 *d1 = new D1(); base-\u003evfunc1(); d1-\u003evfunc1(); 其汇编代码是： mov edi,0x8 call 401090 \u003coperator new(unsigned long)@plt\u003e mov rbx,rax mov rdi,rbx call 401a4e \u003cBase::Base()\u003e mov QWORD PTR [rbp-0x18],rbx mov edi,0x8 call 401090 \u003coperator new(unsigned long)@plt\u003e mov rbx,rax mov rdi,rbx call 401c20 \u003cD1::D1()\u003e mov QWORD PTR [rbp-0x20],rbx mov rax,QWORD PTR [rbp-0x18] mov rax,QWORD PTR [rax] add rax,0x10 mov rdx,QWORD PTR [rax] mov rax,QWORD PTR [rbp-0x18] mov rdi,rax call rdx 按照我们的代码顺序，先后构造了两个类Base和D1。然后在汇编的第三小节，开始执行函数base-\u003evfunc1();，其流程是： 拿到Base的地址，其实对应的就是vptr： mov rax,QWORD PTR [rbp-0x18] mov rax,QWORD PTR [rax] 计算vfunc1的偏移，增加16B相当于跳过了虚函数表开头的两个析构函数地址，所以得到了vfunc1的地址： add rax,0x10 mov rdx,QWORD PTR [rax] 调用函数vfunc1，和常规调用一样，这里也需要保存当前的环境，然后call rdx： mov rax,QWORD PTR [rbp-0x18] mov rdi,rax call rdx ","date":"2021-07-06","objectID":"/202107/cpp-class-mem2/:1:3","tags":["Cpp","内存"],"title":"C++类的内存分布(二)","uri":"/202107/cpp-class-mem2/"},{"categories":["Cpp"],"content":"单继承 以上, 我们知道了一个基类的内存分布, 如果是单继承的子类呢? class D1 : public Base{ public: D1(){} virtual ~D1(){ cout \u003c\u003c \"release D1\" \u003c\u003c endl; } }; 类比第一节, 可以拿到子类的vtable: D1 *d1 = new D1(); uint64 vptr_d1_v = *reinterpret_cast\u003cuint64 *\u003e(d1); uint64 *vptr_d1 = reinterpret_cast\u003cuint64 *\u003e(vptr_d1_v); 以及子类的vtable的指向: uint64 vptr_base_vfunc1 = *reinterpret_cast\u003cuint64 *\u003e(vptr_base + 2); uint64 vptr_base_vfunc2 = *reinterpret_cast\u003cuint64 *\u003e(vptr_base + 3); uint64 vptr_base_vfunc3 = *reinterpret_cast\u003cuint64 *\u003e(vptr_base + 4); 可以得到输出: d1 vptr base vptr base::vfunc* vfunc1 0x401aca 0x401aca 0x401aca vfunc2 0x401b0c 0x401b0c 0x401b0c vfunc3 0x401b58 0x401b58 0x401b58 子类相对于复制了父类的vtable, 但是需要注意这是两个不同的vtable: base d1 0x402370 0x402310 再来观察子类vtable的0和1号元素: uint64 vptr_d1_v0 = *reinterpret_cast\u003cuint64 *\u003e(vptr_d1 + 0); uint64 vptr_d1_v1 = *reinterpret_cast\u003cuint64 *\u003e(vptr_d1 + 1); 得到: d1 vptr base vptr 0 0x401c48 0x401a66 1 0x401c8c 0x401a9e 子类vtable的0号元素和1号元素和父类指向不同, 继续观察汇编结果, 可以发现子类vtable的0号和1号元素指向的是子类的两个析构函数: # D1::~D1(): 0x401c48 push rbp mov rbp,rsp sub rsp,0x10 mov QWORD PTR [rbp-0x8],rdi mov edx,0x402310 mov rax,QWORD PTR [rbp-0x8] mov QWORD PTR [rax],rdx mov esi,0x40204d mov edi,0x4040c0 call 401080 \u003cstd::basic_ostream\u003cchar, std::char_traits\u003cchar\u003e \u003e\u0026 std::operator\u003c\u003c \u003cstd::char_traits\u003cchar\u003e \u003e(std::basic_ostream\u003cchar, std::char_traits\u003cchar\u003e \u003e\u0026, char const*)@plt\u003e mov esi,0x401050 mov rdi,rax call 4010b0 \u003cstd::ostream::operator\u003c\u003c(std::ostream\u0026 (*)(std::ostream\u0026))@plt\u003e mov rax,QWORD PTR [rbp-0x8] mov rdi,rax call 401a66 \u003cBase::~Base()\u003e nop leave ret nop # D1::~D1(): 0x401c8c push rbp mov rbp,rsp sub rsp,0x10 mov QWORD PTR [rbp-0x8],rdi mov rax,QWORD PTR [rbp-0x8] mov rdi,rax call 401c48 \u003cD1::~D1()\u003e mov rax,QWORD PTR [rbp-0x8] mov esi,0x8 mov rdi,rax call 4010a0 \u003coperator delete(void*, unsigned long)@plt\u003e leave ret nop 类比Base类的析构, 可以发现子类的析构会调用Base类的析构, 所以, 现在我们可以得到一个教科书上的结论: 在堆上分配的子类, 执行子类析构会先调用子类的析构函数, 然后再调用父类的析构函数, 最后对子类资源正真执行delete. (尽管这是很多教科书上已有的结论, 但是现在我们从根源观察到了这个执行流程.) 现在, 我们可以得到单继承的类的内存分布的关系图: 单继承 ","date":"2021-07-06","objectID":"/202107/cpp-class-mem2/:2:0","tags":["Cpp","内存"],"title":"C++类的内存分布(二)","uri":"/202107/cpp-class-mem2/"},{"categories":["Cpp"],"content":"两个析构函数? 以上, 我们发现虚析构函数在汇编的时候会生成两个析构函数, 有点奇怪.(实际上, 上文中已经给出一些结论了:D) 我们继续拿D1来讲: # D1::~D1(): 0x401c48 push rbp mov rbp,rsp sub rsp,0x10 mov QWORD PTR [rbp-0x8],rdi mov edx,0x402310 mov rax,QWORD PTR [rbp-0x8] mov QWORD PTR [rax],rdx mov esi,0x40204d mov edi,0x4040c0 call 401080 \u003cstd::basic_ostream\u003cchar, std::char_traits\u003cchar\u003e \u003e\u0026 std::operator\u003c\u003c \u003cstd::char_traits\u003cchar\u003e \u003e(std::basic_ostream\u003cchar, std::char_traits\u003cchar\u003e \u003e\u0026, char const*)@plt\u003e mov esi,0x401050 mov rdi,rax call 4010b0 \u003cstd::ostream::operator\u003c\u003c(std::ostream\u0026 (*)(std::ostream\u0026))@plt\u003e mov rax,QWORD PTR [rbp-0x8] mov rdi,rax call 401a66 \u003cBase::~Base()\u003e nop leave ret nop # D1::~D1(): 0x401c8c push rbp mov rbp,rsp sub rsp,0x10 mov QWORD PTR [rbp-0x8],rdi mov rax,QWORD PTR [rbp-0x8] mov rdi,rax call 401c48 \u003cD1::~D1()\u003e mov rax,QWORD PTR [rbp-0x8] mov esi,0x8 mov rdi,rax call 4010a0 \u003coperator delete(void*, unsigned long)@plt\u003e leave ret nop 因为父类的析构函数是virtual的, 所以子类\"继承了\"父类的析构函数, 这里可以类比普通的虚函数. 又因为析构函数有默认函数, 所以必然会重写父类的析构函数. 先看第一个析构函数0x401c48, 它的作用一部分是执行了用户自定义的析构函数, 然后再调用基类的析构函数~Base(). 再看第二个析构函数0x401c8c, 它会先调用第一个析构函数, 然后再调用delete. 我们执行delele的时候调用的是第二个析构函数, 因此可以保证会析构子类和父类, 并且delete子类的资源. 如果我们测试以下代码: D1 nd1 = D1(); 可以发现调用的会是第一个析构函数: call 401c48 \u003cD1::~D1()\u003e 因为资源在栈上分配, 所以也无需关心资源分配的问题了. 现在, 我们可得到关于为什么要有两个析构函数的结论: 两个析构函数可以解决堆上分配和栈上分配的问题, 如果是堆分配则调用第二个析构函数, 如果是栈分配则调用第一个析构函数 ","date":"2021-07-06","objectID":"/202107/cpp-class-mem2/:2:1","tags":["Cpp","内存"],"title":"C++类的内存分布(二)","uri":"/202107/cpp-class-mem2/"},{"categories":["Cpp"],"content":"多继承 多继承和单继承是类似的. 多继承可能包含多个vptr和vtable. 多继承 ","date":"2021-07-06","objectID":"/202107/cpp-class-mem2/:3:0","tags":["Cpp","内存"],"title":"C++类的内存分布(二)","uri":"/202107/cpp-class-mem2/"},{"categories":["Cpp"],"content":"总结 本文可以得到的几个结论: vptr一般在类内存的头部(和编译器相关) 如果基类析构函数是虚函数, 则vtable的前两项会指向析构函数 (有点累…过两天继续) ","date":"2021-07-06","objectID":"/202107/cpp-class-mem2/:4:0","tags":["Cpp","内存"],"title":"C++类的内存分布(二)","uri":"/202107/cpp-class-mem2/"},{"categories":["Cpp"],"content":"这是在学习风云的协程库时, 在他的博文里提到了这种写法. glibc或者linux源码里面也能见到, 但是没有仔细想想为什么. ","date":"2021-06-25","objectID":"/202106/array-heap-stack/:0:0","tags":["Cpp","数组","指针"],"title":"用数组[1]替代堆分配","uri":"/202106/array-heap-stack/"},{"categories":["Cpp"],"content":"基本写法 typedef struct __A__{ // some members }A; A a[1]; 平常见到这种写法也可能很少注意, 有什么用呢? ","date":"2021-06-25","objectID":"/202106/array-heap-stack/:1:0","tags":["Cpp","数组","指针"],"title":"用数组[1]替代堆分配","uri":"/202106/array-heap-stack/"},{"categories":["Cpp"],"content":"作用 方便使用地址访问; 减少拷贝操作(由于1的特性); 使用栈分配而不是堆分配得到类似指针的结果. 这有点像是RAII了. ","date":"2021-06-25","objectID":"/202106/array-heap-stack/:2:0","tags":["Cpp","数组","指针"],"title":"用数组[1]替代堆分配","uri":"/202106/array-heap-stack/"},{"categories":["工具"],"content":"本文会推荐一套用于tmux保存会话的插件，这样在重启电脑重新登录的时候，也可以恢复上一次的tmux环境。（主要指tmux的状态环境。） ","date":"2021-06-21","objectID":"/202106/tmux-plugin-ssesion/:0:0","tags":["tmux","插件"],"title":"tmux插件-保存会话","uri":"/202106/tmux-plugin-ssesion/"},{"categories":["工具"],"content":"下载插件 git clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm git clone https://github.com/tmux-plugins/tmux-resurrect ~/.tmux/plugins/tmux-resurrect git clone https://github.com/tmux-plugins/tmux-continuum ~/.tmux/plugins/tmux-continuum ","date":"2021-06-21","objectID":"/202106/tmux-plugin-ssesion/:1:0","tags":["tmux","插件"],"title":"tmux插件-保存会话","uri":"/202106/tmux-plugin-ssesion/"},{"categories":["工具"],"content":"配置文件 在~/.tmux.conf添加: # plugins set -g @plugin 'tmux-plugins/tpm' set -g @plugin 'tmux-plugins/tmux-resurrect' set -g @plugin 'tmux-plugins/tmux-continuum' set -g @continuum-save-interval '15' set -g @continuum-restore 'on' set -g @resurrect-capture-pane-contents 'on' run -b '~/.tmux/plugins/tpm/tpm' ","date":"2021-06-21","objectID":"/202106/tmux-plugin-ssesion/:2:0","tags":["tmux","插件"],"title":"tmux插件-保存会话","uri":"/202106/tmux-plugin-ssesion/"},{"categories":["工具"],"content":"重新加载 按照个人配置不同, 前缀可能有差异. Ctrl+b r ","date":"2021-06-21","objectID":"/202106/tmux-plugin-ssesion/:3:0","tags":["tmux","插件"],"title":"tmux插件-保存会话","uri":"/202106/tmux-plugin-ssesion/"},{"categories":["工具"],"content":"手动保存和加载 Ctrl+b Ctrl+s ## 保存 Ctrl+b Ctrl+r ## 加载 ","date":"2021-06-21","objectID":"/202106/tmux-plugin-ssesion/:4:0","tags":["tmux","插件"],"title":"tmux插件-保存会话","uri":"/202106/tmux-plugin-ssesion/"},{"categories":["数据结构与算法"],"content":"RC4是一种对称加密算法，本文尝试使用这种加密算法来加密图片和文件。 ","date":"2021-06-18","objectID":"/202106/algo-encrypter-rc4/:0:0","tags":["Python","vercel","flask"],"title":"RC4加密算法","uri":"/202106/algo-encrypter-rc4/"},{"categories":["数据结构与算法"],"content":"Demo 在线demo 文件内容加密 图片内容加密 ","date":"2021-06-18","objectID":"/202106/algo-encrypter-rc4/:1:0","tags":["Python","vercel","flask"],"title":"RC4加密算法","uri":"/202106/algo-encrypter-rc4/"},{"categories":["数据结构与算法"],"content":"Code class RC4(): ''' 初始化部分，s盒初始化为0-255，k是秘钥流 ''' def __init__(self): self.s_box = [i for i in range(256)] self.k = [0 for i in range(256)] ''' 参数： key 秘钥， 长度为1-256 --- 用于打乱s盒，新的s盒将与秘钥有关 ''' def init(self, key): key_len = len(key) if (key_len \u003e 256) or (key_len \u003c 1): raise Exception(\"Keys length between 1-256!\") # 秘钥流生成 k = [ord(key[i % key_len]) for i in range(256)] # 开始打乱s盒 j = 0 for i in range(256): j = (j + self.s_box[i] + k[i]) % 256 self.s_box[i], self.s_box[j] = self.s_box[j], self.s_box[i] return self.s_box ''' 参数： data 待加密数据 --- 用于加密数据，该方法使用前必须初始化，init与start分开有助于RC4加密的灵活使用 ''' def start(self, data, skip=False): i, j = 0, 0 for k in range(len(data)): # 降低计算量, 可选 if skip and ((k + i + j) % 7 \u003e 0): continue i = (i + 1) % 256 j = (j + self.s_box[i]) % 256 self.s_box[i], self.s_box[j] = self.s_box[j], self.s_box[i] t = (self.s_box[i] + self.s_box[j]) % 256 data[k] ^= self.s_box[t] return data ","date":"2021-06-18","objectID":"/202106/algo-encrypter-rc4/:2:0","tags":["Python","vercel","flask"],"title":"RC4加密算法","uri":"/202106/algo-encrypter-rc4/"},{"categories":["操作系统"],"content":"socket通信应用 这是进程通信的最后一节. socket可以实现不同进程间的通信, 可以是相同机器的不同进程, 也可以是不同机器的不同进程. 本文的目的是简要学习socket通信的应用, 并且结合前几篇的内容, 学习socket通信的部分底层实现. 涉及到的一些api因为网上参考内容很多, 这里就不会介绍api的使用了. ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:1:0","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"utils utils封装了init/bind和connet调用. // utils.h #include \u003cstdio.h\u003e #include \u003cstring.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e #include \u003carpa/inet.h\u003e #include \u003csys/socket.h\u003e #include \u003cnetinet/in.h\u003e void init_socket(int *sock, struct sockaddr_in *serv_addr, const char* ip, const int \u0026port) { *sock = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP); memset(serv_addr, 0, sizeof(struct sockaddr_in)); serv_addr-\u003esin_family = AF_INET; serv_addr-\u003esin_addr.s_addr = inet_addr(ip); serv_addr-\u003esin_port = htons(port); } int bind_socket(const char* ip, const int \u0026port) { int sock; struct sockaddr_in serv_addr; init_socket(\u0026sock, \u0026serv_addr, ip, port); bind(sock, (struct sockaddr *)\u0026serv_addr, sizeof(serv_addr)); return sock; } int connect_socket(const char* ip, const int \u0026port) { int sock; struct sockaddr_in serv_addr; init_socket(\u0026sock, \u0026serv_addr, ip, port); connect(sock, (struct sockaddr *)\u0026serv_addr, sizeof(serv_addr)); return sock; } ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:1:1","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"server server主要是监听端口, 收到客户端请求并且返回后, 继续监听. // server.cpp #include \u003cstdio.h\u003e #include \u003cstring.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e #include \u003carpa/inet.h\u003e #include \u003csys/socket.h\u003e #include \u003cnetinet/in.h\u003e #include \"utils.h\" int main(int argc, char **argv){ int serv_sock = bind_socket(argv[1], atoi(argv[2])); listen(serv_sock, 1024); struct sockaddr_in clnt_addr; socklen_t clnt_addr_size = sizeof(clnt_addr); char say[1024]; while(1) { int clnt_sock = accept(serv_sock, (struct sockaddr*)\u0026clnt_addr, \u0026clnt_addr_size); memset(say, 0, sizeof(say)); read(clnt_sock, say, sizeof(say)); printf(\"%s say: %s\\n\", inet_ntoa(clnt_addr.sin_addr), say); memset(say, 0, sizeof(say)); printf(\"you say: \"); char *s = fgets(say, sizeof(say), stdin); say[strlen(s) - 1] = '\\0'; write(clnt_sock, say, sizeof(say)); close(clnt_sock); } close(serv_sock); return 0; } ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:1:2","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"client 客户端尝试连接服务端, 给服务端发送请求并且收到服务端的返回后, 则尝试下一次连接. // client.cpp #include \u003cstdio.h\u003e #include \u003cstring.h\u003e #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e #include \u003carpa/inet.h\u003e #include \u003csys/socket.h\u003e #include \"utils.h\" int main(int argc, char **argv) { char say[1024]; while (1) { int serv_sock = connect_socket(argv[1], atoi(argv[2])); memset(say, 0, sizeof(say)); printf(\"you say: \"); char *s = fgets(say, sizeof(say), stdin); say[strlen(s) - 1] = '\\0'; if (strcmp(say, \"q\") == 0) { break; } write(serv_sock, say, sizeof(say)); memset(say, 0, sizeof(say)); read(serv_sock, say, sizeof(say)); printf(\"%s say: %s\\n\", argv[1], say); close(serv_sock); } return 0; } ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:1:3","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"输出 首先启动server端 $ ./server 127.0.0.1 7777 127.0.0.1 say: hi you say: hi, i got you 127.0.0.1 say: bye you say: byebye 然后启动client端 $ ./client 127.0.0.1 7777 you say: hi 127.0.0.1 say: hi, i got you you say: bye 127.0.0.1 say: byebye you say: q 如果是同一局域网下的不同机器, 只要知道服务端的ip和监听端口就可以实现同一局域网不同机器之间的通信. ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:1:4","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"socket socket函数返回的是一个int型, 一般可以知道这大概是一个fd, 下面我们来挖一挖socket函数. glibc给我们提供的socket函数调用的是__sys_socket. SYSCALL_DEFINE3(socket, int, family, int, type, int, protocol) { return __sys_socket(family, type, protocol); } __sys_socket大致可以分为三个部分: 处理flag 创建sock sock和file关联 如下, 将处理flag部分暂时省略了, 这部分主要是一些mask的操作. int __sys_socket(int family, int type, int protocol) { int retval; struct socket *sock; int flags; /* Check the SOCK_* constants for consistency. */ //...... retval = sock_create(family, type, protocol, \u0026sock); if (retval \u003c 0) return retval; return sock_map_fd(sock, flags \u0026 (O_CLOEXEC | O_NONBLOCK)); } sock_create创建了sock, 然后用sock和file关联, 并且返回一个fd. 下面继续看看sock_create和sock_map_fd. ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:2:0","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"sock_create sock_create会调用一个更复杂的__sock_create, __sock_create可以区分是否是kernel的调用, 根据是否是kernel调用在创建sock的时候也会有区别. __sock_create __sock_create大概可以分为两部分, security_socket_create和sock_alloc. security_socket_create会关联一个hook函数, 这里就没有继续追踪下去了(TODO). sock_alloc则会让sock和inode关联起来, 继续往下看. // __sock_create err = security_socket_create(family, type, protocol, kern); if (err) return err; /* * Allocate the socket and allow the family to set things up. if * the protocol is 0, the family is instructed to select an appropriate * default. */ sock = sock_alloc(); // ...... rcu_read_lock(); pf = rcu_dereference(net_families[family]); // ...... /* Now protected by module ref count */ rcu_read_unlock(); err = pf-\u003ecreate(net, sock, protocol, kern); sock_alloc sock_alloc大概分为三部分: 在vfs的super block创建一个新的inode 将新的inode扩展为一个sock(这部分比较有意思) 对inode做一些初始化 对inode的初始化以下就省略了. // struct socket *sock_alloc(void) inode = new_inode_pseudo(sock_mnt-\u003emnt_sb); if (!inode) return NULL; sock = SOCKET_I(inode); new_inode_pseudo暂且认为通过vfs根结点申请了一个inode, 并且返回. 接下来将这个inode输入给SOCKET_I. static inline struct socket *SOCKET_I(struct inode *inode) { return \u0026container_of(inode, struct socket_alloc, vfs_inode)-\u003esocket; /***** * ({ * void *__mptr = (void *)(socket); * ((struct socket_alloc *)(__mptr - __builtin_offsetof(struct socket_alloc, socket))); * }) *****/ } SOCKET_I大概意思就是可以通过inode的地址得到socket的地址. 在这里socket和inode被放在同一个结构体socket_alloc下面, 所以可以通过inode找到socket是可以理解的. 目前遗留的问题是, 如果通过inode可以找到socket并且不发生内存越界, 这就意为着socket事先就已经分配好, 并且和inode放在一起了. 那么, socket是什么时候分配的呢? (TODO) struct socket_alloc { struct socket socket; struct inode vfs_inode; }; 以上, 我们拿到了socket结构体, socket里面包含了什么? 如下: struct socket { socket_state state; short type; unsigned long flags; struct socket_wq *wq; struct file *file; struct sock *sk; const struct proto_ops *ops; }; 比较有意思的成员有三个: file/sk和ops. file怎么和socket关联起来可以看下面的sock_map_fd. sk指向了一个更复杂的struct sock结构体. ops是sock的操作表, 规范了一些操作函数, 这种写法在最近的学习中已经见过很多次了. 如下是部分ops函数: const struct proto_ops inet_stream_ops = { .family = PF_INET, .owner = THIS_MODULE, .release = inet_release, .bind = inet_bind, .connect = inet_stream_connect, .socketpair = sock_no_socketpair, .accept = inet_accept, .getname = inet_getname, .poll = tcp_poll, .ioctl = inet_ioctl, .listen = inet_listen, .shutdown = inet_shutdown, // ...... }; ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:2:1","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"sock_map_fd sock_map_fd大概分为两部分: 找到一个空闲的fd 生成一个新的file, 并且将fd和file关联 static int sock_map_fd(struct socket *sock, int flags) { struct file *newfile; int fd = get_unused_fd_flags(flags); if (unlikely(fd \u003c 0)) { sock_release(sock); return fd; } newfile = sock_alloc_file(sock, flags, NULL); if (likely(!IS_ERR(newfile))) { fd_install(fd, newfile); return fd; } put_unused_fd(fd); return PTR_ERR(newfile); } sock_alloc_file sock_alloc_file会创建一个新的file, 并且将file和socket关联: sock-\u003efile = file; file-\u003eprivate_data = sock; struct file *sock_alloc_file(struct socket *sock, int flags, const char *dname) { struct file *file; if (!dname) dname = sock-\u003esk ? sock-\u003esk-\u003esk_prot_creator-\u003ename : \"\"; file = alloc_file_pseudo(SOCK_INODE(sock), sock_mnt, dname, O_RDWR | (flags \u0026 O_NONBLOCK), \u0026socket_file_ops); if (IS_ERR(file)) { sock_release(sock); return file; } sock-\u003efile = file; file-\u003eprivate_data = sock; return file; } 将sock和file关联, 就可以通过file找到对应的sock. struct socket *sock_from_file(struct file *file, int *err) { if (file-\u003ef_op == \u0026socket_file_ops) return file-\u003eprivate_data; /* set in sock_map_fd */ *err = -ENOTSOCK; return NULL; } ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:2:2","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"小结 在创建socket的时候, 同时会创建inode和file, 将socket和inode以及file关联. 这样, 通过fd就可以找到file, 进而找到对应的socket. 由此, 我们也可以说, 对socket的操作就是对文件的操作. ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:2:3","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"bind bind调用的是__sys_bind. SYSCALL_DEFINE3(bind, int, fd, struct sockaddr __user *, umyaddr, int, addrlen) { return __sys_bind(fd, umyaddr, addrlen); } __sys_bind大致可以分为三个部分: 通过fd拿到sock 将用户空间的参数移动到内核空间 hook调用监听bind int __sys_bind(int fd, struct sockaddr __user *umyaddr, int addrlen) { struct socket *sock; struct sockaddr_storage address; int err, fput_needed; sock = sockfd_lookup_light(fd, \u0026err, \u0026fput_needed); if (sock) { err = move_addr_to_kernel(umyaddr, addrlen, \u0026address); if (!err) { err = security_socket_bind(sock, (struct sockaddr *)\u0026address, addrlen); if (!err) err = sock-\u003eops-\u003ebind(sock, (struct sockaddr *) \u0026address, addrlen); } fput_light(sock-\u003efile, fput_needed); } return err; } ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:3:0","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"sockfd_lookup_light sockfd_lookup_light可以通过fd找到sock, 在进程控制和进程通信(四)中, 我们已经学习了通过fd可以找到进程的struct file. 在上一节中, 我们又知道在创建socket的时候, socket和file已经关联起来, 所以通过file又可以找到socket. 下面就是通过fd找到socket的函数. static struct socket *sockfd_lookup_light(int fd, int *err, int *fput_needed) { struct fd f = fdget(fd); struct socket *sock; *err = -EBADF; if (f.file) { sock = sock_from_file(f.file, err); if (likely(sock)) { *fput_needed = f.flags; return sock; } fdput(f); } return NULL; } 通过file找到socket, 在上一节已经看过这个函数了. struct socket *sock_from_file(struct file *file, int *err) { if (file-\u003ef_op == \u0026socket_file_ops) return file-\u003eprivate_data; /* set in sock_map_fd */ *err = -ENOTSOCK; return NULL; } ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:3:1","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"move_addr_to_kernel 将用户空间参数移动到内核空间, 如果参数长度太大, 则会报错. 为什么需要从用户空间移动到内核空间呢? 可以参考下一节listen. 我认为是因为listen是在内核空间的, 为了减少频繁的用户/内核的切换, 所以在bind的时候就将用户空间的参数先复制到内核空间了. /** * move_addr_to_kernel - copy a socket address into kernel space * @uaddr: Address in user space * @kaddr: Address in kernel space * @ulen: Length in user space * * The address is copied into kernel space. If the provided address is * too long an error code of -EINVAL is returned. If the copy gives * invalid addresses -EFAULT is returned. On a success 0 is returned. */ int move_addr_to_kernel(void __user *uaddr, int ulen, struct sockaddr_storage *kaddr) { if (ulen \u003c 0 || ulen \u003e sizeof(struct sockaddr_storage)) return -EINVAL; if (ulen == 0) return 0; if (copy_from_user(kaddr, uaddr, ulen)) return -EFAULT; return audit_sockaddr(ulen, kaddr); } ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:3:2","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"inet_bind bind入参struct sockaddr *uaddr, 虽然写的是用户addr, 但是在上一小节的转换中, 这里的uaddr已经是内核空间的addr了. int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len) { // ...... /* If the socket has its own bind function then use it. (RAW) */ if (sk-\u003esk_prot-\u003ebind) { return sk-\u003esk_prot-\u003ebind(sk, uaddr, addr_len); } // ...... return __inet_bind(sk, uaddr, addr_len, false, true); } __inet_bind __inet_bind大概可以分为两个部分: 校验 绑定 int __inet_bind(struct sock *sk, struct sockaddr *uaddr, int addr_len, bool force_bind_address_no_port, bool with_lock) { struct sockaddr_in *addr = (struct sockaddr_in *)uaddr; struct inet_sock *inet = inet_sk(sk); struct net *net = sock_net(sk); unsigned short snum; int chk_addr_ret; u32 tb_id = RT_TABLE_LOCAL; // ...... // 端口校验 snum = ntohs(addr-\u003esin_port); err = -EACCES; if (snum \u0026\u0026 snum \u003c inet_prot_sock(net) \u0026\u0026 !ns_capable(net-\u003euser_ns, CAP_NET_BIND_SERVICE)) goto out; // ...... // 检查是否重复绑定 if (sk-\u003esk_state != TCP_CLOSE || inet-\u003einet_num) goto out_release_sock; // ...... // 开始绑定 /* Make sure we are allowed to bind here. */ if (snum || !(inet-\u003ebind_address_no_port || force_bind_address_no_port)) { if (sk-\u003esk_prot-\u003eget_port(sk, snum)) { inet-\u003einet_saddr = inet-\u003einet_rcv_saddr = 0; err = -EADDRINUSE; goto out_release_sock; } err = BPF_CGROUP_RUN_PROG_INET4_POST_BIND(sk); if (err) { inet-\u003einet_saddr = inet-\u003einet_rcv_saddr = 0; goto out_release_sock; } } // ...... } 如上, 校验部分, 一是校验端口权限(端口ID很小时)和是否和法, 二是检查是否已经绑定过. 校验成功之后就开始执行绑定部分, 调用的是get_port函数. get_port根据不同的协议簇会调用不同的绑定函数, 大体是将socket信息加入到一个hash表. (TODO: 端口绑定到底是怎么回事?) ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:3:3","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"小结 bind将ip地址和端口与socket绑定, 不同的协议簇会执行不同绑定函数. 在绑定之前, 会将绑定参数从用户空间移动到内核空间, 然后会检查绑定参数, 比如ip地址是否合法(支持), 端口是否合且是否有对应的权限可以操作, 也会检查是否是重复绑定. 检查过后就会将端口和socket绑定, 端口绑定会将参数送入内核空间的一个hash表. 端口可以重复绑定, 需要修改hash表对应value的值, 也可以实现自动绑定, 内核可以随机一个可以绑定的端口给socket实现绑定. ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:3:4","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"listen listen调用的是__sys_listen. SYSCALL_DEFINE2(listen, int, fd, int, backlog) { return __sys_listen(fd, backlog); } __sys_listen大概可以分为三部分: 通过fd找到sock 设置sock连接的最大数 hook调用监听sock int __sys_listen(int fd, int backlog) { struct socket *sock; int err, fput_needed; int somaxconn; sock = sockfd_lookup_light(fd, \u0026err, \u0026fput_needed); if (sock) { somaxconn = sock_net(sock-\u003esk)-\u003ecore.sysctl_somaxconn; if ((unsigned int)backlog \u003e somaxconn) backlog = somaxconn; err = security_socket_listen(sock, backlog); if (!err) err = sock-\u003eops-\u003elisten(sock, backlog); fput_light(sock-\u003efile, fput_needed); } return err; } ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:4:0","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"inet_listen listen最终调用到inet_listen. 大致分为两部分: 准备 开始监听 int inet_listen(struct socket *sock, int backlog) { struct sock *sk = sock-\u003esk; // ...... sk-\u003esk_max_ack_backlog = backlog; /* Really, if the socket is already in listen state * we can only allow the backlog to be adjusted. */ if (old_state != TCP_LISTEN) { /* Enable TFO w/o requiring TCP_FASTOPEN socket option. * Note that only TCP sockets (SOCK_STREAM) will reach here. * Also fastopen backlog may already been set via the option * because the socket was in TCP_LISTEN state previously but * was shutdown() rather than close(). */ tcp_fastopen = sock_net(sk)-\u003eipv4.sysctl_tcp_fastopen; if ((tcp_fastopen \u0026 TFO_SERVER_WO_SOCKOPT1) \u0026\u0026 (tcp_fastopen \u0026 TFO_SERVER_ENABLE) \u0026\u0026 !inet_csk(sk)-\u003eicsk_accept_queue.fastopenq.max_qlen) { fastopen_queue_tune(sk, backlog); tcp_fastopen_init_key_once(sock_net(sk)); } err = inet_csk_listen_start(sk, backlog); if (err) goto out; tcp_call_bpf(sk, BPF_SOCK_OPS_TCP_LISTEN_CB, 0, NULL); } err = 0; out: release_sock(sk); return err; } inet_csk_listen_start 开始监听时, 可以看到, 会将sock加入到一个hash表中. 后续调用不再追踪下去, 根据我们的socket应用可以看到, listen是不阻塞的, 所以listen在将sock塞入到hash表中之后, 就会返回. 那么结合上一节的结论, 我们基本可以知道, 监听hash表被系统内核维护了. int inet_csk_listen_start(struct sock *sk, int backlog) { struct inet_connection_sock *icsk = inet_csk(sk); struct inet_sock *inet = inet_sk(sk); int err = -EADDRINUSE; reqsk_queue_alloc(\u0026icsk-\u003eicsk_accept_queue); sk-\u003esk_ack_backlog = 0; inet_csk_delack_init(sk); // ...... inet_sk_state_store(sk, TCP_LISTEN); if (!sk-\u003esk_prot-\u003eget_port(sk, inet-\u003einet_num)) { inet-\u003einet_sport = htons(inet-\u003einet_num); sk_dst_reset(sk); err = sk-\u003esk_prot-\u003ehash(sk); if (likely(!err)) return 0; } inet_sk_set_state(sk, TCP_CLOSE); return err; } ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:4:1","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"小结 listen首先通过fd拿到sock, 然后会根据系统设置以及用户设置确定连接的最大数. 根据sock的状态会决定是否进入监听, 以避免重复监听. 在监听时, 会将sock加入到一个监听hash表中, 并被内核维护. ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:4:2","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"accept accept会调用__sys_accept SYSCALL_DEFINE3(accept, int, fd, struct sockaddr __user *, upeer_sockaddr, int __user *, upeer_addrlen) { return __sys_accept4(fd, upeer_sockaddr, upeer_addrlen, 0); } __sys_accept先是通过fd拿到sock, 然后创建一个新的sock并且创建一个struct file与之关联, 最后调用accept. 分为三步: 通过fd拿到sock 创建新的sock和struct file, 并且关联两者 调用accept // __sys_accept4 sock = sockfd_lookup_light(fd, \u0026err, \u0026fput_needed); // ...... newsock = sock_alloc(); if (!newsock) goto out_put; newsock-\u003etype = sock-\u003etype; newsock-\u003eops = sock-\u003eops; // ...... newfile = sock_alloc_file(newsock, flags, sock-\u003esk-\u003esk_prot_creator-\u003ename); // ...... err = security_socket_accept(sock, newsock); if (err) goto out_fd; err = sock-\u003eops-\u003eaccept(sock, newsock, sock-\u003efile-\u003ef_flags, false); if (err \u003c 0) goto out_fd; // ...... out_put: fput_light(sock-\u003efile, fput_needed); out: return err; out_fd: fput(newfile); put_unused_fd(newfd); goto out_put; ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:5:0","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"inet_accept accept指向的是inet_accept函数. int inet_accept(struct socket *sock, struct socket *newsock, int flags, bool kern) { struct sock *sk1 = sock-\u003esk; int err = -EINVAL; struct sock *sk2 = sk1-\u003esk_prot-\u003eaccept(sk1, flags, \u0026err, kern); if (!sk2) goto do_err; lock_sock(sk2); sock_rps_record_flow(sk2); WARN_ON(!((1 \u003c\u003c sk2-\u003esk_state) \u0026 (TCPF_ESTABLISHED | TCPF_SYN_RECV | TCPF_CLOSE_WAIT | TCPF_CLOSE))); sock_graft(sk2, newsock); newsock-\u003estate = SS_CONNECTED; err = 0; release_sock(sk2); do_err: return err; } ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:5:1","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"小结 accept会创建一个新的sock和struct file, 并且让两个关联起来. 尽管没有继续追踪下去, 但是也可以知道, accept返回的与之连接的sock就是这里创建的sock. 这里我甚至猜想会涉及到一些信号函数, 继续往下看. ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:5:2","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"connect connect调用的是__sys_connect. SYSCALL_DEFINE3(connect, int, fd, struct sockaddr __user *, uservaddr, int, addrlen) { return __sys_connect(fd, uservaddr, addrlen); } __sys_connect基本可以分为三步: 通过fd拿到sock 将用户参数用用户空间复制到内核空间 调用connect int __sys_connect(int fd, struct sockaddr __user *uservaddr, int addrlen) { struct socket *sock; struct sockaddr_storage address; int err, fput_needed; sock = sockfd_lookup_light(fd, \u0026err, \u0026fput_needed); if (!sock) goto out; err = move_addr_to_kernel(uservaddr, addrlen, \u0026address); if (err \u003c 0) goto out_put; err = security_socket_connect(sock, (struct sockaddr *)\u0026address, addrlen); if (err) goto out_put; err = sock-\u003eops-\u003econnect(sock, (struct sockaddr *)\u0026address, addrlen, sock-\u003efile-\u003ef_flags); out_put: fput_light(sock-\u003efile, fput_needed); out: return err; } ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:6:0","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"inet_stream_connect connect会调用到inet_stream_connect最终到__inet_stream_connect. 不同的协议簇有不同的connect实现, 这里是公共调用部分, 大概分为以下几步: 预连接, 不同协议簇有不同实现 等待连接 int __inet_stream_connect(struct socket *sock, struct sockaddr *uaddr, int addr_len, int flags, int is_sendmsg) { struct sock *sk = sock-\u003esk; // ...... switch (sock-\u003estate) { // ...... case SS_UNCONNECTED: err = -EISCONN; if (sk-\u003esk_state != TCP_CLOSE) goto out; if (BPF_CGROUP_PRE_CONNECT_ENABLED(sk)) { err = sk-\u003esk_prot-\u003epre_connect(sk, uaddr, addr_len); if (err) goto out; } err = sk-\u003esk_prot-\u003econnect(sk, uaddr, addr_len); if (err \u003c 0) goto out; sock-\u003estate = SS_CONNECTING; // ...... } timeo = sock_sndtimeo(sk, flags \u0026 O_NONBLOCK); if ((1 \u003c\u003c sk-\u003esk_state) \u0026 (TCPF_SYN_SENT | TCPF_SYN_RECV)) { int writebias = (sk-\u003esk_protocol == IPPROTO_TCP) \u0026\u0026 tcp_sk(sk)-\u003efastopen_req \u0026\u0026 tcp_sk(sk)-\u003efastopen_req-\u003edata ? 1 : 0; /* Error code is set above */ if (!timeo || !inet_wait_for_connect(sk, timeo, writebias)) goto out; err = sock_intr_errno(timeo); if (signal_pending(current)) goto out; } /* Connection was closed by RST, timeout, ICMP error * or another process disconnected us. */ if (sk-\u003esk_state == TCP_CLOSE) goto sock_error; // ...... } ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:6:1","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"小结 connect和bind有点像, 在demo部分我们也可以看到, conncet和bind是在相同的顺序下调用, 即创建socket之后调用. 但是connect是用来连接服务端, 也会将用户参数从用户空间复制到内核空间, 然后根据不同的协议簇调用不同的连接参数. 通过函数名inet_wait_for_connect, 也大概可以知道, connect是阻塞的, 直到连接成功. 此外, connect中可以看到几处signal_pending调用, 猜测是因为connect是阻塞的以及timeout的存在, 所以可能需要临时处理一些信号函数. ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:6:2","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统"],"content":"总结 这篇文章的内容比较浅, 主要目的还是补齐进程通信的最后一个方法, socket通信. 不过总归是有收获的. 对于我这种非科班人员, 是第一次接触socket编程, 通过学习和撰写这篇文章, 大概可以了解socket编程的大概方式: 服务端需要绑定和监听 客户端则需要连接服务端 通过尽量的接触源码, 一是习惯了这种学习方式, 虽然源码挖的不是很深, 但是基本会养成看源码的习惯. 二是看这些源码, 也学习到了linux编程的一些思路, 比如操作表. 三是养成举证的习惯, 下的一些结论尽量在代码里找到证据, 当然有一些结论基本也可以通过已知条件推断出来. 本文以及进程通信系列的文章还遗留了很多TODO, 这些都还是需要我去了解的, 但是优先级不是很高. 最近的目的还是先了解全貌, 再去看看一些细节. ","date":"2021-06-03","objectID":"/202106/process-ctracon5/:7:0","tags":["进程","进程通信","socket","Linux"],"title":"进程控制和通信(五)","uri":"/202106/process-ctracon5/"},{"categories":["操作系统","glibc"],"content":"FILE fopen返回值是FILE结构体, 先来看看FILE结构体的内容: struct _IO_FILE; typedef struct _IO_FILE FILE; struct _IO_FILE { int _flags; /* High-order word is _IO_MAGIC; rest is flags. */ /* The following pointers correspond to the C++ streambuf protocol. */ char *_IO_read_ptr; /* Current read pointer */ char *_IO_read_end; /* End of get area. */ char *_IO_read_base; /* Start of putback+get area. */ char *_IO_write_base; /* Start of put area. */ char *_IO_write_ptr; /* Current put pointer. */ char *_IO_write_end; /* End of put area. */ char *_IO_buf_base; /* Start of reserve area. */ char *_IO_buf_end; /* End of reserve area. */ /* The following fields are used to support backing up and undo. */ char *_IO_save_base; /* Pointer to start of non-current get area. */ char *_IO_backup_base; /* Pointer to first valid character of backup area */ char *_IO_save_end; /* Pointer to end of non-current get area. */ struct _IO_marker *_markers; struct _IO_FILE *_chain; int _fileno; int _flags2; __off_t _old_offset; /* This used to be _offset but it's too small. */ /* 1+column number of pbase(); 0 is unknown. */ unsigned short _cur_column; signed char _vtable_offset; char _shortbuf[1]; _IO_lock_t *_lock; __off64_t _offset; /* Wide character stream stuff. */ struct _IO_codecvt *_codecvt; struct _IO_wide_data *_wide_data; //...... int _mode; /* Make sure we don't get into trouble again. */ // 最后这个成员_unused2比较有意思, 给的解释是这个成员可以保证不会再出错. char _unused2[15 * sizeof (int) - 4 * sizeof (void *) - sizeof (size_t)]; }; 首先, FILE结构体中包含了缓存区(fopen是有缓存区域的)读写指针的位置, 如_IO_read_ptr/_IO_write_ptr, 也会有指向缓存区头尾的指针, 如_IO_backup_base. 还有_fileno成员, 会指向文件的fd, 通过_fileno可以真正的拿到文件. ","date":"2021-06-01","objectID":"/202106/fopen-deep/:1:0","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读","uri":"/202106/fopen-deep/"},{"categories":["操作系统","glibc"],"content":"缓存区 一般来说读写指针都是指向的缓存区, 如下图是可能的两种关系: 情况一 情况二 ","date":"2021-06-01","objectID":"/202106/fopen-deep/:1:1","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读","uri":"/202106/fopen-deep/"},{"categories":["操作系统","glibc"],"content":"wide data 同时注意到, 上述读写等指针都是char*型的, 应对ascii的字符没问题, 但是文件不仅只有ascii, 会有其他更复杂的格式, 这时候怎么办呢? 针对字符编码格式问题, glibc提供了宽字符流. 在FILE中, _codecvt指向的是_IO_codecvt, 这是针对字符编码转换的函数表, _wide_data指向_IO_wide_data, 这是针对宽字符的读写指针, 如下: struct _IO_wide_data { wchar_t *_IO_read_ptr; /* Current read pointer */ wchar_t *_IO_read_end; /* End of get area. */ wchar_t *_IO_read_base; /* Start of putback+get area. */ wchar_t *_IO_write_base; /* Start of put area. */ wchar_t *_IO_write_ptr; /* Current put pointer. */ wchar_t *_IO_write_end; /* End of put area. */ wchar_t *_IO_buf_base; /* Start of reserve area. */ wchar_t *_IO_buf_end; /* End of reserve area. */ /* The following fields are used to support backing up and undo. */ wchar_t *_IO_save_base; /* Pointer to start of non-current get area. */ wchar_t *_IO_backup_base; /* Pointer to first valid character of backup area */ wchar_t *_IO_save_end; /* Pointer to end of non-current get area. */ __mbstate_t _IO_state; __mbstate_t _IO_last_state; struct _IO_codecvt _codecvt; wchar_t _shortbuf[1]; const struct _IO_jump_t *_wide_vtable; }; 区别于_IO_FILE自带的指针, 宽字符的读写指针是wchar_t*. 还会有_wide_vtable, 这是指向_IO_jump_t的指针, _IO_jump_t可以看作是一个操作表, 包含了类似于read/write等操作. ","date":"2021-06-01","objectID":"/202106/fopen-deep/:1:2","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读","uri":"/202106/fopen-deep/"},{"categories":["操作系统","glibc"],"content":"sturct file fd是什么, 见进程控制和进程通信(四), 进程task_struct会有指向进程打开的文件的列表的指针(struct file), 如下图. 本文的fd就是指向这个文件列表的下标. fd和files_struct struct file如下: struct file { union { struct llist_node fu_llist; struct rcu_head fu_rcuhead; } f_u; struct path f_path; struct inode *f_inode; /* cached value */ const struct file_operations *f_op; /* * Protects f_ep_links, f_flags. * Must not be taken from IRQ context. */ spinlock_t f_lock; enum rw_hint f_write_hint; atomic_long_t f_count; unsigned int f_flags; fmode_t f_mode; struct mutex f_pos_lock; loff_t f_pos; struct fown_struct f_owner; const struct cred *f_cred; struct file_ra_state f_ra; u64 f_version; #ifdef CONFIG_SECURITY void *f_security; #endif /* needed for tty driver, and maybe others */ void *private_data; #ifdef CONFIG_EPOLL /* Used by fs/eventpoll.c to link all the hooks to this file */ struct list_head f_ep_links; struct list_head f_tfile_llink; #endif /* #ifdef CONFIG_EPOLL */ struct address_space *f_mapping; errseq_t f_wb_err; } __randomize_layout __attribute__((aligned(4))); /* lest something weird decides that 2 is OK */ struct file会有成员f_inode指向文件的inode, 这时候就可以找到文件对应的内容了. (TODO: vfs inode如何对应文件系统inode依然没有找到很好的资料…所以暂且认为有一个表指向吧~) f_op包含了文件的基本操作(这里是指Linux广义的文件), 如open/read/write等等, 本文就不再探究这些操作的具体内容了. 综上所述, fopen返回的FILE结构体可以通过fd找到struct file, 最终找到对应的inode. 那么fopen是如何找到fd的呢? 下面来追踪一下fopen的实现方式. ","date":"2021-06-01","objectID":"/202106/fopen-deep/:2:0","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读","uri":"/202106/fopen-deep/"},{"categories":["操作系统","glibc"],"content":"fopen fopen是glibc提供的用户态的api, 不同操作系统对fopen的实现方式是不同的, 这里采用64位Linux的实现方式(__USE_FILE_OFFSET64 \u0026 __USE_LARGEFILE64) #define fopen fopen64 在stdio.h可以找到fopen64和fopen的接口是一样的. #ifdef __USE_LARGEFILE64 extern FILE *fopen64 (const char *__restrict __filename, const char *__restrict __modes) __wur; #endif 在iofopen.c, fopen会被绑定到__fopen_internal: FILE * __fopen_internal (const char *filename, const char *mode, int is32) { struct locked_FILE { struct _IO_FILE_plus fp; #ifdef _IO_MTSAFE_IO _IO_lock_t lock; #endif struct _IO_wide_data wd; } *new_f = (struct locked_FILE *) malloc (sizeof (struct locked_FILE)); if (new_f == NULL) return NULL; #ifdef _IO_MTSAFE_IO new_f-\u003efp.file._lock = \u0026new_f-\u003elock; #endif _IO_no_init (\u0026new_f-\u003efp.file, 0, 0, \u0026new_f-\u003ewd, \u0026_IO_wfile_jumps); _IO_JUMPS (\u0026new_f-\u003efp) = \u0026_IO_file_jumps; _IO_new_file_init_internal (\u0026new_f-\u003efp); if (_IO_file_fopen ((FILE *) new_f, filename, mode, is32) != NULL) return __fopen_maybe_mmap (\u0026new_f-\u003efp.file); _IO_un_link (\u0026new_f-\u003efp); free (new_f); return NULL; } FILE * _IO_new_fopen (const char *filename, const char *mode) { return __fopen_internal (filename, mode, 1); } weak_alias (_IO_new_fopen, fopen64) 关注第20行的_IO_file_fopen, 在正常情况下, 会调用_IO_file_fopen ","date":"2021-06-01","objectID":"/202106/fopen-deep/:3:0","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读","uri":"/202106/fopen-deep/"},{"categories":["操作系统","glibc"],"content":"解析mode versioned_symbol (libc, _IO_new_file_fopen, _IO_file_fopen, GLIBC_2_1); glibc中将_IO_file_fopen绑定到_IO_new_file_fopen, 下面看_IO_new_file_fopen的实现: FILE *_IO_new_file_fopen (FILE *fp, const char *filename, const char *mode, int is32not64) { //...... int oprot = 0666; FILE *result; //...... switch (*mode) { case 'r': omode = O_RDONLY; read_write = _IO_NO_WRITES; break; case 'w': omode = O_WRONLY; oflags = O_CREAT|O_TRUNC; read_write = _IO_NO_READS; break; //...... } last_recognized = mode; for (i = 1; i \u003c 7; ++i) { switch (*++mode) { case '\\0': break; case '+': omode = O_RDWR; read_write \u0026= _IO_IS_APPENDING; last_recognized = mode; continue; case 'x': oflags |= O_EXCL; last_recognized = mode; continue; case 'b': last_recognized = mode; continue; //...... } break; } result = _IO_file_open (fp, filename, omode|oflags, oprot, read_write, is32not64); if (result != NULL) //...... 这里主要处理宽字符情况, 会修改一些字符指针和操作表 return result; } ","date":"2021-06-01","objectID":"/202106/fopen-deep/:3:1","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读","uri":"/202106/fopen-deep/"},{"categories":["操作系统","glibc"],"content":"获取fd 在_IO_new_file_fopen处理了fopen指定的文件权限和打开模式, 然后调用_IO_file_open打开文件: FILE * _IO_file_open (FILE *fp, const char *filename, int posix_mode, int prot, int read_write, int is32not64) { int fdesc; if (__glibc_unlikely (fp-\u003e_flags2 \u0026 _IO_FLAGS2_NOTCANCEL)) fdesc = __open_nocancel (filename, posix_mode | (is32not64 ? 0 : O_LARGEFILE), prot); else fdesc = __open (filename, posix_mode | (is32not64 ? 0 : O_LARGEFILE), prot); if (fdesc \u003c 0) return NULL; fp-\u003e_fileno = fdesc; //...... _IO_link_in ((struct _IO_FILE_plus *) fp); return fp; } 这里主要关注__open函数, 这依然是glibc的函数调用, 但是glibc会把__open绑定到__libc_open64 strong_alias (__libc_open64, __open) __libc_open64则会执行系统调用. int __libc_open64 (const char *file, int oflag, ...) { int mode = 0; if (__OPEN_NEEDS_MODE (oflag)) { va_list arg; va_start (arg, oflag); mode = va_arg (arg, int); va_end (arg); } return SYSCALL_CANCEL (openat, AT_FDCWD, file, oflag | EXTRA_OPEN_FLAGS, mode); } 抛开__libc_open64继续关注__open, 可以看到__open返回的是文件的fd, 会保存在FILE结构体的_fileno中. ","date":"2021-06-01","objectID":"/202106/fopen-deep/:3:2","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读","uri":"/202106/fopen-deep/"},{"categories":["操作系统","glibc"],"content":"总结 fopen如何打开文件, 可以见下图: fopen到inode ","date":"2021-06-01","objectID":"/202106/fopen-deep/:4:0","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读","uri":"/202106/fopen-deep/"},{"categories":["操作系统","glibc"],"content":"参考链接 FILE: https://code.woboq.org/userspace/glibc/libio/bits/types/struct_FILE.h.html struct file: https://code.woboq.org/linux/linux/include/linux/fs.h.html fopen: https://code.woboq.org/userspace/glibc/libio/stdio.h.html iofopen: https://code.woboq.org/userspace/glibc/libio/iofopen.c.html fileops: https://code.woboq.org/userspace/glibc/libio/fileops.c.html open64: https://code.woboq.org/userspace/glibc/sysdeps/unix/sysv/linux/open64.c.html ","date":"2021-06-01","objectID":"/202106/fopen-deep/:5:0","tags":["Linux","文件系统","glibc"],"title":"glibc-fopen源码阅读","uri":"/202106/fopen-deep/"},{"categories":["前后端笔记"],"content":"普通的锚点滚动方式是直来直去的，不太平滑，我们可以借助scrollIntoView实现平滑滚动。 ","date":"2021-06-01","objectID":"/202106/html5-maodian-scroll/:0:0","tags":["html5"],"title":"html5锚点滚动","uri":"/202106/html5-maodian-scroll/"},{"categories":["前后端笔记"],"content":"原始方案 \u003cdiv class=\"fixedbox\"\u003e \u003ca class=\"actiongithub\" href=\"https://github.com/caibingcheng/rssblog\" title=\"GitHub\" target=\"_blank\" rel=\"noopener noreffer me\"\u003e\u003c/a\u003e \u003ca class=\"actiontop\" href=\"#top-header\"\u003e\u003c/a\u003e \u003ca class=\"actionbottom\" href=\"#bottom-footer\"\u003e\u003c/a\u003e \u003c/div\u003e 一般会按照上述方案实现锚点滚动, 但是这种方案的问题有两点: 会改变url 滚动动画不平滑 ","date":"2021-06-01","objectID":"/202106/html5-maodian-scroll/:1:0","tags":["html5"],"title":"html5锚点滚动","uri":"/202106/html5-maodian-scroll/"},{"categories":["前后端笔记"],"content":"scrollIntoView 采用scrollIntoView可以使用很少的代码实现平滑滚动, 并且不会改变url. \u003cdiv class=\"fixedbox\"\u003e \u003ca class=\"actiongithub\" href=\"https://github.com/caibingcheng/rssblog\" title=\"GitHub\" target=\"_blank\" rel=\"noopener noreffer me\"\u003e\u003c/a\u003e \u003ca class=\"actiontop\" onclick=\"javascript:document.getElementById('top-header').scrollIntoView({block: 'start', behavior: 'smooth', inline: 'center'})\"\u003e\u003c/a\u003e \u003ca class=\"actionbottom\" onclick=\"javascript:document.getElementById('bottom-footer').scrollIntoView({block: 'start', behavior: 'smooth', inline: 'center'})\"\u003e\u003c/a\u003e \u003c/div\u003e scrollIntoView可以接收三个参数: behavior: 定义动画过渡效果, “auto\"或 “smooth” 之一. 默认为 “auto”. block: 定义垂直方向的对齐, “start”, “center”, “end”, 或 “nearest\"之一. 默认为 “start”. inline: 定义水平方向的对齐, “start”, “center”, “end”, 或 “nearest\"之一. 默认为 “nearest”. 注意: Safari桌面和移动端都不支持scrollIntoView参数, 仅可以使用默认配置, 这时候是没有平滑滚动效果的. ","date":"2021-06-01","objectID":"/202106/html5-maodian-scroll/:2:0","tags":["html5"],"title":"html5锚点滚动","uri":"/202106/html5-maodian-scroll/"},{"categories":["前后端笔记"],"content":"问题 我有以下模板: \u003cdiv class=\"grid\"\u003e {% for item in data.data %} \u003ca href={{ item.link }} class=\"card\"\u003e \u003cspan class=\"cardindex\"\u003e{{ loop.index }}. \u0026nbsp;\u0026nbsp;\u003c/span\u003e \u003cspan class=\"cardtitle\"\u003e{{ item.title }}\u003c/span\u003e \u003cdiv class=\"carddetail\"\u003e \u003cspan class=\"cardate\"\u003e{{ item.date }}\u003c/span\u003e \u003ca href={{ item.home }} class=\"cardhome\"\u003e \u003cspan class=\"cardauthor\"\u003e{{ item.author }}\u003c/span\u003e \u003c/a\u003e \u003c/div\u003e \u003c/a\u003e {% endfor %} \u003c/div\u003e 渲染之后看到浏览器显示是: \u003ca href=\"******\" class=\"card\"\u003e \u003cspan class=\"cardindex\"\u003e1. \u0026nbsp;\u0026nbsp;\u003c/span\u003e \u003cspan class=\"cardtitle\"\u003e******\u003c/span\u003e \u003c/a\u003e \u003cdiv class=\"carddetail\"\u003e \u003ca href=\"******\" class=\"card\"\u003e \u003cspan class=\"cardate\"\u003e******\u003c/span\u003e \u003c/a\u003e \u003ca href=\"******\" class=\"cardhome\"\u003e \u003cspan class=\"cardauthor\"\u003e******\u003c/span\u003e \u003c/a\u003e \u003c/div\u003e 明显不符合要求, 按照模板的结构carddetail应该是card的child. ","date":"2021-06-01","objectID":"/202106/jinja2-error-div/:1:0","tags":["jinja2","flask"],"title":"jinja2模板错位问题","uri":"/202106/jinja2-error-div/"},{"categories":["前后端笔记"],"content":"解决 通过渲染结果可以大概分析出是a标签嵌套导致的错位(TODO: 为什么嵌套a标签会导致错位?), 注释第二个a标签可以正确渲染. 那么, 解决方案如下: \u003cdiv class=\"grid\"\u003e {% for item in data.data %} \u003ca href=\"{{ item.link }}\" target=\"blank\" class=\"card\"\u003e \u003cspan class=\"cardindex\"\u003e{{ loop.index }}. \u003c/span\u003e \u003cspan class=\"cardtitle\"\u003e{{ item.title }}\u003c/span\u003e \u003cdiv class=\"carddetail\"\u003e \u003cspan class=\"cardate\"\u003e{{ item.date }}\u003c/span\u003e \u003cspan class=\"cardauthor cardhome\" onclick=\"javascript:window.open('{{ item.home }}')\"\u003e{{ item.author }}\u003c/span\u003e \u003c/div\u003e \u003c/a\u003e {% endfor %} \u003c/div\u003e 移除了a标签, 并且使用onclick事件来实现跳转. ","date":"2021-06-01","objectID":"/202106/jinja2-error-div/:2:0","tags":["jinja2","flask"],"title":"jinja2模板错位问题","uri":"/202106/jinja2-error-div/"},{"categories":["工具"],"content":"OrLike 使用LeanCloud, 部署在vercel的博客点赞插件, 保障安全. 当前功能: 分离APPID/APPKEY, 保护账号安全 使用随机用户ID, 不保存用户其他信息, 保障用户隐私 支持设置用户过期时间 支持取消点赞/踩 将orlike发布为pipy包, 方便自动升级 加载动画 自定义图标和CDN ","date":"2021-05-27","objectID":"/202105/blog-orlike/:1:0","tags":["vercel","flask","cors","博客"],"title":"使用OrLike为博文添加点赞系统","uri":"/202105/blog-orlike/"},{"categories":["工具"],"content":"Branch server: server端代码 client: client端代码 master: demo ","date":"2021-05-27","objectID":"/202105/blog-orlike/:2:0","tags":["vercel","flask","cors","博客"],"title":"使用OrLike为博文添加点赞系统","uri":"/202105/blog-orlike/"},{"categories":["工具"],"content":"Deployment 在这里可以将OrLike部署到你的Vercel账户上. 我们更推荐使用这个零配置的例子. ","date":"2021-05-27","objectID":"/202105/blog-orlike/:3:0","tags":["vercel","flask","cors","博客"],"title":"使用OrLike为博文添加点赞系统","uri":"/202105/blog-orlike/"},{"categories":["工具"],"content":"Usage 在你期望嵌入OrLike的页面加入以下链接: \u003cscript src=\"https://cdn.jsdelivr.net/gh/caibingcheng/orlike@client/orlike.min.js\"\u003e\u003c/script\u003e 当然, 也可以使用自己的CDN. 本项目也依赖JQuery, 所以别忘记引用JQuery: \u003cscript src=\"https://cdn.bootcdn.net/ajax/libs/jquery/3.5.1/jquery.min.js\"\u003e\u003c/script\u003e 接下来, 在你期望嵌入OrLike的位置加上一个div标签, 并且加上class或者id: \u003cdiv class=\"orlike-box\"\u003e\u003c/div\u003e 然后在合适的地方初始化OrLike: \u003cscript\u003e new OrLike({ serverUrl: \"https://orlike.vercel.app/\", el: \".orlike-box\", days: 30, icon: {like: \"fa fa-heart\", dislike: false}, style: \"https://cdn.jsdelivr.net/gh/caibingcheng/orlike@client/orlike.min.css\", }); \u003c/script\u003e 尽管可以使用公共的serverUrl, 但是更推荐使用私有的serverUrl, 这样更容易保证数据安全. 目前初始化需要的参数: serverUrl: 必填, Vercel服务地址 el: 必填, 放orlike的div名字(class或id) days: 可选, 用户id保存的时间, 默认是30天 icon: 可选, 自定义点赞和踩的图标, 不填写这是默认, 如果是false, 则不显示对应的按扭 style: 可选, 可自定义样式, 如果不填写, 则使用默认CDN ifont: 可选, 可自定义font-awesome CDN, 如果不填写, 则使用默认CDN 到此为止, 本地工作已经做完了, 现在需要创建LeanCloud账户, 可以参考Valine的配置方法. 创建账户并且新建应用之后， 需要给应用添加一个名为OrLike的class, 并且设置读写权限为所有用户, 然后再拿到LeanCloud的APP ID 和 APP Key填入到Vercel的环境变量. APPID 对应 APP ID APPKEY 对应 APP Key 然后部署OrLike就可以正常工作了. ","date":"2021-05-27","objectID":"/202105/blog-orlike/:4:0","tags":["vercel","flask","cors","博客"],"title":"使用OrLike为博文添加点赞系统","uri":"/202105/blog-orlike/"},{"categories":["工具"],"content":"Todo \u0026 Contributes 项目初期, 还有很多想象空间, 加油↖(^ω^)↗ 提供点赞/踩排名 ","date":"2021-05-27","objectID":"/202105/blog-orlike/:5:0","tags":["vercel","flask","cors","博客"],"title":"使用OrLike为博文添加点赞系统","uri":"/202105/blog-orlike/"},{"categories":["工具"],"content":"为hugo添加orlike 添加文件layouts/partials/single/orlike.html: \u003cscript src=\"https://cdn.jsdelivr.net/gh/caibingcheng/orlike@client/orlike.min.js\"\u003e\u003c/script\u003e \u003cscript src=\"https://cdn.bootcdn.net/ajax/libs/jquery/3.5.1/jquery.min.js\"\u003e\u003c/script\u003e \u003cdiv class=\"orlike-box\"\u003e\u003c/div\u003e \u003cscript\u003e new OrLike({ serverUrl: \"https://orlike-vercel.vercel.app/\", el: \".orlike-box\", days: 30, }); \u003c/script\u003e 要记得引用jquery, 如果已经引用过了并且jquery可以工作, 那么这里就不需要重复引用了. 在layouts/posts/single.html合适的位置引用以上文件, 例如在content末尾: {{- /* Content */ -}} \u003cdiv class=\"content\" id=\"content\"\u003e {{- dict \"Content\" .Content \"Ruby\" $params.ruby \"Fraction\" $params.fraction \"Fontawesome\" $params.fontawesome | partial \"function/content.html\" | safeHTML -}} {{- /* OrLike */ -}} {{- partial \"single/orlike.html\" . -}} {{- /* Reward */ -}} {{- partial \"single/reward.html\" . -}} {{- /* Notice */ -}} {{- partial \"single/notice.html\" . -}} \u003c/div\u003e 现在可以刷新页面试试是否有效. ","date":"2021-05-27","objectID":"/202105/blog-orlike/:6:0","tags":["vercel","flask","cors","博客"],"title":"使用OrLike为博文添加点赞系统","uri":"/202105/blog-orlike/"},{"categories":["操作系统"],"content":"在前面的文章中, 我们学习了进程通信的几种方式, 并且也接触到了内核控制进程的结构块task_struct, task_struct的内容主要会分为以下几个部分, 通过这一篇文章可以学习这些部分的大体内容. ","date":"2021-05-19","objectID":"/202105/process-ctracon4/:0:0","tags":["进程","进程资源","task_struct","PCB"],"title":"进程控制和通信(四)","uri":"/202105/process-ctracon4/"},{"categories":["操作系统"],"content":"task_struct task_struct 任务ID: 用于区分进程, 是进程的身份证, 比如pid就属于任务ID 亲缘关系: 包含兄弟进程, 父子进程的信息 任务状态: 用于标识当前进程的运行状态, 比如running, runable, stop, wait等; 权限: 进程权限信息, 包括本进程对外以及外对本进程的权限 运行统计: 包括启动时间, cpu占用时间等信息 调度相关: 包含进程优先级, 调度策略等信息 信号处理: 阻塞/等待等信息, 以及信号处理函数(见进程控制和进程通信三) 内存管理: 进程虚拟内存空间 文件与文件系统: 进程文件 内核栈: 内核栈地址 ","date":"2021-05-19","objectID":"/202105/process-ctracon4/:1:0","tags":["进程","进程资源","task_struct","PCB"],"title":"进程控制和通信(四)","uri":"/202105/process-ctracon4/"},{"categories":["操作系统"],"content":"任务ID 和任务ID相关的成员大概有以下: pid_t pid; // 进程id pid_t tgid; // 线程group id struct task_struct *group_leader; // 线程group leader group_leader是指向线程group第一个task的指针. 比如在setpgid函数中会用到. Linux将current包装为了一个宏, 用来获取在当前CPU上运行的task_struct地址. DECLARE_PER_CPU(struct task_struct *, current_task); static __always_inline struct task_struct *get_current(void) { return this_cpu_read_stable(current_task); } #define current get_current() 一般, 我们可以调用getpid获取进程的进程id, 实际上getpid返回的是task_struct的tgid. (当然这个函数的调用栈不是这么简单的, 还涉及到了Linux的namespace概念, 这里就先简单处理了, 以下的接口同样简单处理) SYSCALL_DEFINE0(getpid) { return task_tgid_vnr(current); } 同样, 我们也可以用gettid获取当前线程的线程id, 实际上gettid返回的是task_struct的pid. SYSCALL_DEFINE0(gettid) { return task_pid_vnr(current); } 另外, 也可以通过getppid获取父进程的进程id, 实际上getppid返回的是task_struct的real_parent的tgid. SYSCALL_DEFINE0(getppid) { int pid; rcu_read_lock(); pid = task_tgid_vnr(rcu_dereference(current-\u003ereal_parent)); rcu_read_unlock(); return pid; } 对内核来说, 没有区分进程和线程的概念, 在内核中, 这两种概念都叫task, 由task_struct结构体管理. 所以, 怎么来区分进程和线程呢? 内核会用pid和tgid两个成员区分, pid表示的当前task_struct的id, 可以认为是task_struct的标识符, 每个task都不一样. 如果某个进程/线程创建了一个子线程, 那么就会生成一个新的pid, 但是会继承父结点的tgid. pid和tgid 为什么有这两个概念? 我猜是因为从单核单进程时代到多进程时代迁移的遗留问题. ","date":"2021-05-19","objectID":"/202105/process-ctracon4/:2:0","tags":["进程","进程资源","task_struct","PCB"],"title":"进程控制和通信(四)","uri":"/202105/process-ctracon4/"},{"categories":["操作系统"],"content":"亲缘关系 与task亲缘关系相关的成员如下: /* Real parent process: */ struct task_struct __rcu *real_parent; /* Recipient of SIGCHLD, wait4() reports: */ struct task_struct __rcu *parent; /* Children/sibling form the list of natural children: */ struct list_head children; struct list_head sibling; real_parent指向的是真正的parent进程, 如下是进程clone时的一段代码, 可以看到real_parent是指向子(新)进程的父进程. 如果创建的是thread, 则和父进程的real_parent相同. /* CLONE_PARENT re-uses the old parent */ if (clone_flags \u0026 (CLONE_PARENT|CLONE_THREAD)) { p-\u003ereal_parent = current-\u003ereal_parent; p-\u003eparent_exec_id = current-\u003eparent_exec_id; } else { p-\u003ereal_parent = current; p-\u003eparent_exec_id = current-\u003eself_exec_id; } parent指向的是给当前进程传递SIGCHLD信号的进程, 这个进程一般是debug进程, 比如GDB调试进程, 这时候parent就是指向的GDB进程. 比如ptrace的link阶段, 就会更新parent的指向. void __ptrace_link(struct task_struct *child, struct task_struct *new_parent, const struct cred *ptracer_cred) { BUG_ON(!list_empty(\u0026child-\u003eptrace_entry)); list_add(\u0026child-\u003eptrace_entry, \u0026new_parent-\u003eptraced); child-\u003eparent = new_parent; child-\u003eptracer_cred = get_cred(ptracer_cred); } 关于parent的参考信息可见kernelnewbies:parent和real_parent. children用于存放子进程指针, sibling存放兄弟进程指针; ","date":"2021-05-19","objectID":"/202105/process-ctracon4/:3:0","tags":["进程","进程资源","task_struct","PCB"],"title":"进程控制和通信(四)","uri":"/202105/process-ctracon4/"},{"categories":["操作系统"],"content":"任务状态 与任务状态相关的一些成员如下: /* -1 unrunnable, 0 runnable, \u003e0 stopped: */ volatile long state; /* Per task flags (PF_*), defined further below: */ unsigned int flags; int exit_state; 以下是关于state的描述: /* Used in tsk-\u003estate: */ #define TASK_RUNNING 0x0000 #define TASK_INTERRUPTIBLE 0x0001 #define TASK_UNINTERRUPTIBLE 0x0002 #define __TASK_STOPPED 0x0004 #define __TASK_TRACED 0x0008 /* Used in tsk-\u003eexit_state: */ #define EXIT_DEAD 0x0010 #define EXIT_ZOMBIE 0x0020 #define EXIT_TRACE (EXIT_ZOMBIE | EXIT_DEAD) /* Used in tsk-\u003estate again: */ #define TASK_PARKED 0x0040 #define TASK_DEAD 0x0080 #define TASK_WAKEKILL 0x0100 #define TASK_WAKING 0x0200 #define TASK_NOLOAD 0x0400 #define TASK_NEW 0x0800 #define TASK_STATE_MAX 0x1000 /* Convenience macros for the sake of set_current_state: */ #define TASK_KILLABLE (TASK_WAKEKILL | TASK_UNINTERRUPTIBLE) #define TASK_STOPPED (TASK_WAKEKILL | __TASK_STOPPED) #define TASK_TRACED (TASK_WAKEKILL | __TASK_TRACED) #define TASK_IDLE (TASK_UNINTERRUPTIBLE | TASK_NOLOAD) /* Convenience macros for the sake of wake_up(): */ #define TASK_NORMAL (TASK_INTERRUPTIBLE | TASK_UNINTERRUPTIBLE) /* get_task_state(): */ #define TASK_REPORT (TASK_RUNNING | TASK_INTERRUPTIBLE | \\ TASK_UNINTERRUPTIBLE | __TASK_STOPPED | \\ __TASK_TRACED | EXIT_DEAD | EXIT_ZOMBIE | \\ TASK_PARKED) 总的来说, 进程状态可以分为以下几种: 可运行, 等待(中断/不可中断), 退出(僵死/销毁), 暂停. 这些对应的状态通过ps aux命令也可以查看, 基本是对应的. TASK_RUNNING表示是可运行的状态, 可运行不仅仅是runable的意思, 也表示running. 实际上处于TASK_RUNNING状态的task会被安排进runqueue, 那么其状态可能是等待执行或者正在执行. 如下一段代码是计算task运行时间的, 如果task状态是TASK_RUNNING就被塞进runqueue. /* * Called when a process ceases being the active-running process involuntarily * due, typically, to expiring its time slice (this may also be called when * switching to the idle task). Now we can calculate how long we ran. * Also, if the process is still in the TASK_RUNNING state, call * sched_info_queued() to mark that it has now again started waiting on * the runqueue. */ static inline void sched_info_depart(struct rq *rq, struct task_struct *t) { unsigned long long delta = rq_clock(rq) - t-\u003esched_info.last_arrival; rq_sched_info_depart(rq, delta); if (t-\u003estate == TASK_RUNNING) sched_info_queued(rq, t); } TASK_INTERRUPTIBLE和TASK_UNINTERRUPTIBLE可以表示task的两种等待状态. 在task运行时, 如果需要等待一些IO设备的返回, 就会处于等待状态. 处于TASK_INTERRUPTIBLE状态的task可以被一些信号唤醒, 转而去执行信号处理函数; 处于TASK_UNINTERRUPTIBLE状态的task则不可被信号唤醒, 只能一直等待当前IO返回, 此时一般只能通过重启电脑来杀死这个进程. 通过一些状态的组合, 就可以生成一些更复杂的状态, 比如TASK_KILLABLE, 就表示task不可被一般信号唤醒, 但是可以被系统的kill信号唤醒, 这个状态在控制一些重要进程时是很有用的. TASK_DEAD和EXIT_ZOMBIE表示进程的僵死状态. 在task处于退出状态时, 会处于TASK_DEAD状态, 此时exit_state工作. task退出会清空task资源, 但是task_struct这个结构体资源还在保留, 需要父进程清理(调用wait). 为什么需要父进程清理? 因为task_struct中保留了task的退出状态码, 这是需要返回给父进程的, 所以需要被父进程清理. 如果父进程没有清理task_struct, 那么这个只有一个空壳task_struct的task就会占用内核task队列中的资源, 这种就叫僵尸进程. 如果系统中充斥了大量的僵尸进程, 就会占满task队列, 导致不能有新的进程产生. 如果僵尸进程的父进程退出了, 但是没有清理僵尸进程呢? 这时候僵尸进程就被init进程接管, 此时init进程会自动清理僵尸进程. TASK_DEAD和EXIT_DEAD表示进程的正常退出状态. 比如用detach分离一个线程, 那么线程退出时直接就是EXIT_DEAD状态. 其他例子不再叙述, 但是也有一个问题(TODO): task正常退出时, 是先处于EXIT_ZOMBIE然后再处于EXIT_DEAD吗? TASK_STOPPED和TASK_TRACED可以表示进程的暂停状态. TASK_STOPPED状态是在task收到SIGSTOP/SIGTTIN/SIGTSTP/SIGTTOU信号后进入的状态. TASK_TRACED是调试进程监控当前task时, 如果调试进程暂停了当前进程则会进入该状态. 关于state的状态转换, 可以参考如下: state状态机 以下是task的flag: /* * Per process flags */ #define PF_IDLE 0x00000002 /* I am an IDLE thread */ #define PF_EXITING 0x00000004 /* Getting shut down */ #define PF_EXITPIDONE 0x00000008 /* PI exit done on shut down */ #define PF_VCPU 0x00000010 /* I'm a virtual CPU */ #define PF_WQ_WORKER 0x00000020 /* I'm a workqueue worker */ #define PF_FORKNOEXEC 0x00000040 /* Forked but didn't exec */ #define PF_MCE_PROCESS 0x00000080 /* Process policy on mce errors */ #define PF_SUPERPRIV 0x00000100 /* Used super-user privileges */ #define PF_DUMPCORE 0x00000200 /* Dumped core */ #define PF_SIGNALED 0x00000400 /* Killed by a signal */ #define PF_MEMALLOC 0x00000800 /* Allocating memory */ #define PF_NPROC_EXCEEDED 0x00001000 /* set_user() noticed that RLIMIT_NPROC was exceeded */ #define PF_USED_MATH 0x0000","date":"2021-05-19","objectID":"/202105/process-ctracon4/:4:0","tags":["进程","进程资源","task_struct","PCB"],"title":"进程控制和通信(四)","uri":"/202105/process-ctracon4/"},{"categories":["操作系统"],"content":"权限 和权限相关的成员如下: /* Process credentials: */ /* Tracer's credentials at attach: */ const struct cred __rcu *ptracer_cred; /* Objective and real subjective task credentials (COW): */ const struct cred __rcu *real_cred; /* Effective (overridable) subjective task credentials (COW): */ const struct cred __rcu *cred; 对一个task的权限管理分为了三类: trace的权限, 其他task的权限, 当前task的权限. 要了解权限的大体内容, 需要关注cred结构体: struct cred { atomic_t usage; #ifdef CONFIG_DEBUG_CREDENTIALS atomic_t subscribers; /* number of processes subscribed */ void *put_addr; unsigned magic; #define CRED_MAGIC 0x43736564 #define CRED_MAGIC_DEAD 0x44656144 #endif kuid_t uid; /* real UID of the task */ kgid_t gid; /* real GID of the task */ kuid_t suid; /* saved UID of the task */ kgid_t sgid; /* saved GID of the task */ kuid_t euid; /* effective UID of the task */ kgid_t egid; /* effective GID of the task */ kuid_t fsuid; /* UID for VFS ops */ kgid_t fsgid; /* GID for VFS ops */ // ....... kernel_cap_t cap_inheritable; /* caps our children can inherit */ kernel_cap_t cap_permitted; /* caps we're permitted */ kernel_cap_t cap_effective; /* caps we can actually use */ kernel_cap_t cap_bset; /* capability bounding set */ kernel_cap_t cap_ambient; /* Ambient capability set */ // ....... } __randomize_layout; 可以看到一个cred主要储存了一些user id和group id以及表示能力的cap. uid/gid表示当前task的id, 一般是谁启动这个task那么就表示谁. suid/sgid让本来没有相应权限的用户运行这个程序时, 可以访问他没有权限访问的资.passwd就是一个很鲜明的例子.(linux：SUID、SGID详解) euid/egid表示当前task可以操作的一些资源的权限, 比如共享内存/管道等等, 这时候就可以比较这个用户和用户组是否有权限可以操作. fsuid/fsgid表示当前task可以操作的文件系统的权限, 比如文件打开/读写时, 就会比较这个用户和用户组是否有对应的权限. 以上的*id都是对用户和用户组授权, 权限粒度比较大, 比如某些task期望给普通用户运行, 但是又期望可以得到一些更高级的权限. 如果只使用*id来区分, 则可能需要赋予root之类高级用户的权限, 相对是不安全的. 这时候kernel_cap_t就起到作用了. kernel_cap_t相当于是一个mask, 通过这个mask可以控制用户的权限粒度, 达到更精细的权限控制的目的. 这样就算是普通用户也可以得到高级用户某些必要权限, 而不污染其他权限. 关于cred和real_cred在源码中有以下解释: /* * The security context of a task * * The parts of the context break down into two categories: * * (1) The objective context of a task. These parts are used when some other * task is attempting to affect this one. * * (2) The subjective context. These details are used when the task is acting * upon another object, be that a file, a task, a key or whatever. * * Note that some members of this structure belong to both categories - the * LSM security pointer for instance. * * A task has two security pointers. task-\u003ereal_cred points to the objective * context that defines that task's actual details. The objective part of this * context is used whenever that task is acted upon. * * task-\u003ecred points to the subjective context that defines the details of how * that task is going to act upon another object. This may be overridden * temporarily to point to another security context, but normally points to the * same context as task-\u003ereal_cred. */ ","date":"2021-05-19","objectID":"/202105/process-ctracon4/:5:0","tags":["进程","进程资源","task_struct","PCB"],"title":"进程控制和通信(四)","uri":"/202105/process-ctracon4/"},{"categories":["操作系统"],"content":"运行统计 主要是task的一些时间相关的状态信息. u64 utime; //用户态消耗的CPU时间 u64 stime; //内核态消耗的CPU时间 /* Context switch counts: */ unsigned long nvcsw; //自愿的上下文切换计数 unsigned long nivcsw; //非自愿的上下文切换计数 /* Monotonic time in nsecs: */ u64 start_time; //进程启动时间, 不包含睡眠时间 /* Boot based time in nsecs: */ u64 real_start_time; //进程启动时间, 包含睡眠时间 ","date":"2021-05-19","objectID":"/202105/process-ctracon4/:6:0","tags":["进程","进程资源","task_struct","PCB"],"title":"进程控制和通信(四)","uri":"/202105/process-ctracon4/"},{"categories":["操作系统"],"content":"调度相关 调度相关成员如下: int prio; int static_prio; int normal_prio; unsigned int rt_priority; const struct sched_class *sched_class; struct sched_entity se; struct sched_rt_entity rt; 这里在看相关资料的时候发现task的优先级还是比较复杂的, 涉及到了不同的调度器, 不同的调度策略等等. 所以调度相关的内容还需要额外一个篇幅来说明的(TODO). 这里就简单介绍一下吧~ 首先我们可以在prio.h中找到一些和prio相关的定义. #define MAX_NICE 19 #define MIN_NICE -20 #define MAX_USER_RT_PRIO 100 #define MAX_RT_PRIO MAX_USER_RT_PRIO // 100 #define MAX_PRIO (MAX_RT_PRIO + NICE_WIDTH) // 140 #define DEFAULT_PRIO (MAX_RT_PRIO + NICE_WIDTH / 2) // 120 优先级的值越低这表示优先级越高. *_NICE决定了用户可以设置的task的优先级范围, 比如是[-19, 20]. 通过nice -n和renice -n N -p PID命令, 我们可以对某个程序或者对当前的某个进程设置其nice值. nice值越低则表示优先级越高. nice的结果是会作用在*_prio成员上的, 所以nice也只能部分控制task的优先级. 比如参考如下的计算方法: #define NICE_TO_PRIO(nice) ((nice) + DEFAULT_PRIO) #define PRIO_TO_NICE(prio) ((prio) - DEFAULT_PRIO) 系统也规定了优先级的范围, 最大范围是[0, 139]. 但是会将这个范围分成几个部分: [0, MAX_RT_PRIO-1]表示RT的task的优先级范围. [MAX_RT_PRIO, MAX_PRIO-1]表示SCHED_NORMAL/SCHED_BATCH的task的优先级范围. 比如查看系统进程信息: $ ps -la F S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD 4 S 1000 16697 8335 0 80 0 - 537617 futex_ pts/4 00:01:19 hugo 可以看到hugo对应的NI(nice)值是0, PRI(prio)是80, 可以尝试设置hugo的nice值. $ renice -n 20 -p 16697 \u0026\u0026 ps -la | grep hugo 16697 (process ID) old priority 0, new priority 19 4 S 1000 16697 8335 0 99 19 - 537617 ep_pol pts/4 00:01:20 hugo 我们设置了nice为20, 但是实际应用的只有19, priority也只能到99. 这是因为hugo这个进程是RT的, 最大优先级也只能到99. 如果再设置nice值\u003c=0就会发现, 这时候需要root权限才可以设置了, 这是因为如果设置高优先级的话, 就可能会抢占其他进程的资源, 这一般是内核不愿意看到的, 所以会需要更高的权限. ","date":"2021-05-19","objectID":"/202105/process-ctracon4/:7:0","tags":["进程","进程资源","task_struct","PCB"],"title":"进程控制和通信(四)","uri":"/202105/process-ctracon4/"},{"categories":["操作系统"],"content":"信号处理 和信号处理相关的部分成员如下: /* Signal handlers: */ struct signal_struct *signal; struct sighand_struct *sighand; sigset_t blocked; sigset_t real_blocked; /* Restored if set_restore_sigmask() was used: */ sigset_t saved_sigmask; struct sigpending pending; unsigned long sas_ss_sp; size_t sas_ss_size; unsigned int sas_ss_flags; pending用于缓存当前task收到的信号, 这些信号还未被处理, 只有在task从内核态跳到用户态的过程中, 才会检查pending中的信号. 而内核进程一般都在内核态运行, 所以无法通过这种方法相应信号, 因此对内核进程我们一般无法使用kill等指令杀死. 对处于TASK_INTERRUPTIBLE状态的进程, 信号发送函数会直接唤醒当前task, 让当前task有机会从内核态转换到用户态, 从而响应信号处理函数. 对处于TASK_UNINTERRUPTIBLE状态的进程, 信号就只被添加进pending队列, 无法响应对应的信号. sighand用来指向信号处理函数. 信号处理时机可以参考下图: 信号处理时机 get_signal函数中会获取当前task的sighand. saved_sigmask也是在这个时间段会被用到. 如下在kernel/signal.c中可以找到: // bool get_signal(struct ksignal *ksig) struct sighand_struct *sighand = current-\u003esighand; struct signal_struct *signal = current-\u003esignal; 关于进程信号的使用, 可以参考进程控制和进程通信三. 查看当前系统支持64种不同的信号, 如下: $ kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 2) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR1 1) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM 2) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP 3) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ 4) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR 5) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+3 6) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+8 7) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13 8) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12 9) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-7 10) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-2 11) SIGRTMAX-1 64) SIGRTMAX ","date":"2021-05-19","objectID":"/202105/process-ctracon4/:8:0","tags":["进程","进程资源","task_struct","PCB"],"title":"进程控制和通信(四)","uri":"/202105/process-ctracon4/"},{"categories":["操作系统"],"content":"内存管理 与内存管理相关的部分成员如下: struct mm_struct *mm; struct mm_struct *active_mm; 主要关注mm_struct结构体, 其中会包含一些segment的分段信息: unsigned long start_code, end_code, start_data, end_data; unsigned long start_brk, brk, start_stack; unsigned long arg_start, arg_end, env_start, env_end; Segment指向 进程从task_struct如何映射到物理内存的, 大概可以知道是以下流程了: 进程到物理内存 当然, 现在依然存在一些盲区, mm_struct怎么指向页表的? 页表在哪里? 页表的工作流程是怎样的? mm和active_mm有什么区别呢? 这封1999-07-30的邮件(和现在的一些表述可能有点区别)中有详细的说明: 邮件中描述, 内存空间有\"real address spaces\"和\"anonymous address spaces\", 这里可以理解为\"real address spaces\"是指用户空间, “anonymous address spaces\"指内核空间(The obvious use for a “anonymous address space” is any thread that doesn’t need any user mappings), 因为内核空间是不需要映射关系就可以找到的. mm用来指向\"real address spaces”, active_mm用来指向\"real address spaces\". 那么linux内核设计了以下规则: 如果当前进程(一般是内核进程)空间指向\"anonymous address spaces\", 则mm的值为NULL, active_mm指向当前空间; 如果当前进程空间指向\"real address spaces\", 则active_mm的值和mm的值保持一致. 所以, 现在一般也可以通过mm的值判断当前是内核进程还是用户进程. ","date":"2021-05-19","objectID":"/202105/process-ctracon4/:9:0","tags":["进程","进程资源","task_struct","PCB"],"title":"进程控制和通信(四)","uri":"/202105/process-ctracon4/"},{"categories":["操作系统"],"content":"文件与文件系统 与文件与文件系统相关的成员如下: /* Filesystem information: */ struct fs_struct *fs; /* Open file information: */ struct files_struct *files; 通过fs_struct, 可以拿到文件系统的root路径, 和当前进程的工作路径pwd. struct fs_struct { int users; spinlock_t lock; seqcount_t seq; int umask; int in_exec; struct path root, pwd; } __randomize_layout; files_struct表示当前进程打开的文件. /* * Open file table structure */ struct files_struct { /* read mostly part */ atomic_t count; bool resize_in_progress; wait_queue_head_t resize_wait; struct fdtable __rcu *fdt; struct fdtable fdtab; /* written part on a separate cache line in SMP */ spinlock_t file_lock ____cacheline_aligned_in_smp; unsigned int next_fd; unsigned long close_on_exec_init[1]; unsigned long open_fds_init[1]; unsigned long full_fds_bits_init[1]; struct file __rcu * fd_array[NR_OPEN_DEFAULT]; }; 首先可以关注fd_array这个成员, NR_OPEN_DEFAULT默认值是操作系统的位数, 比如是32或者64, 这表示这个进程可以打开32/64个文件, 如果超过了这个值, 则系统会继续增大这个数组, 但是file数组的大小是有限制的: #define INR_OPEN_MAX 4096 /* Hard limit for nfile rlimits */ 比如说操作系统限制一个进程最多可以大概4096个文件, 通过root权限可以更改这个最大值. 再关注fdtable所指的两个成员, 可以先看看files_struct的结构: struct fdtable { unsigned int max_fds; struct file __rcu **fd; /* current fd array */ unsigned long *close_on_exec; unsigned long *open_fds; unsigned long *full_fds_bits; struct rcu_head rcu; }; fdtable和files_struct看起来会有冲突的地方, 比如都可以表示打开文件的组数. 对应关系如下: fdtable和files_struct 实际上fdtable在打开文件数量扩充中是有用的, 初始化files_struct最多可以打开NR_OPEN_DEFAULT个文件, 如果超过了则会申请一个新的fdtable内存, 由*fdt指向这块新的内存, 并且不再和fd_array关联(相当于有两块内存存储文件列表), 这时候就可以继续扩充打开文件的数量而不受NR_OPEN_DEFAULT大小限制了. fdtable扩充 文件系统的内容还需要进一步学习. ","date":"2021-05-19","objectID":"/202105/process-ctracon4/:10:0","tags":["进程","进程资源","task_struct","PCB"],"title":"进程控制和通信(四)","uri":"/202105/process-ctracon4/"},{"categories":["操作系统"],"content":"内核栈 struct thread_info thread_info; // 必须是task_struct的第一个成员 void *stack; // 内核栈 stack是指内核栈, 因为如果是用户态的进程, 某些情况(系统调用/异常触发等)会陷入内核态, 这时候在内核态执行指令同样需要栈空间, 如果使用用户态的栈可能会导致内核不安全, 这时候就需要给内核额外的分配栈, 就是这里的内核栈. 所以在用户进程切换到内核态的时候, 栈也会从用户栈切换到内核栈. 为什么thread_info必须是第一个成员? 可以看下面的函数: #define current_thread_info() ((struct thread_info *)current) current_thread_info可以把current(上文讲过, 这就是当前的task_struct)转换为thread_info, 所以thread_info需要是第一个成员保证转换正确. thread_info是干什么用的? 首先task_struct是一种通用的task描述, 和平台架构无关, 但是linux是支持不同平台架构的, 怎么区分这些平台架构, 这时候就是通过thread_info来体现这些差异了. 也可以通过以下的方式拿到thread_info: #ifdef CONFIG_THREAD_INFO_IN_TASK static inline struct thread_info *task_thread_info(struct task_struct *task) { return \u0026task-\u003ethread_info; } #elif !defined(__HAVE_THREAD_FUNCTIONS) # define task_thread_info(task) ((struct thread_info *)(task)-\u003estack) #endif 注意到task_thread_info宏, 可以通过task的stack拿到thread_info, 这也说明stack和thread_info是在同一块内存的. 通过thread_union可以得到stack的大小是4Pages Size(16KB, 不同架构上可能不一样). 以下是thread_union的定义: #ifdef CONFIG_KASAN #define KASAN_STACK_ORDER 1 #else #define KASAN_STACK_ORDER 0 #endif #define THREAD_SIZE_ORDER (2 + KASAN_STACK_ORDER) #define THREAD_SIZE (PAGE_SIZE \u003c\u003c THREAD_SIZE_ORDER) union thread_union { #ifndef CONFIG_ARCH_TASK_STRUCT_ON_STACK struct task_struct task; #endif #ifndef CONFIG_THREAD_INFO_IN_TASK struct thread_info thread_info; #endif unsigned long stack[THREAD_SIZE/sizeof(long)]; }; 在thread_info结构体中, task_struct/thread_info/stack之间的关系如下图: thread_info和stack 为什么将进程内核栈和task_struct放一起? 一个解释是, 为了方便内核快速的获取当前进程的描述符. 如此, 可以通过进程内核栈的栈顶指针esp快速计算得到task_struct的地址. 如果内核栈增长过多, 就可能踩踏thread_info, 导致task崩溃. 实际上内核提供了一些接口用于查询是否踩踏以保证task的安全. ","date":"2021-05-19","objectID":"/202105/process-ctracon4/:11:0","tags":["进程","进程资源","task_struct","PCB"],"title":"进程控制和通信(四)","uri":"/202105/process-ctracon4/"},{"categories":["Cpp"],"content":"访问private成员 我们知道, C++的priavte关键词可以保证成员的不可见性, 约束了代码维护者之间的一些行为, 但是private并不是安全的, 可以通过指针偏移的方式访问不可见的成员. 如下案例: #include \u003ciostream\u003e using namespace std; class A{ public: A() { cout \u003c\u003c \"create A\" \u003c\u003c endl; } ~A() { cout \u003c\u003c \"delete A\" \u003c\u003c endl; } A(const int \u0026size, const float \u0026val) : m_size(size), m_val(val) { cout \u003c\u003c \"create A \" \u003c\u003c this \u003c\u003c \" -\u003e \" \u003c\u003c \u0026m_size \u003c\u003c \": \" \u003c\u003c size \u003c\u003c \", \" \u003c\u003c \u0026m_val \u003c\u003c \": \" \u003c\u003c val \u003c\u003c endl; } private: int m_size; float m_val; }; int main() { A a(1, 3.0); void *pb = reinterpret_cast\u003cvoid *\u003e(\u0026a); cout \u003c\u003c \"private m_size \" \u003c\u003c *reinterpret_cast\u003cint *\u003e(pb) \u003c\u003c endl; cout \u003c\u003c \"private m_val \" \u003c\u003c *(reinterpret_cast\u003cfloat *\u003e(pb) + 1) \u003c\u003c endl; } 可以得到输出: create A 0x7ffe320d0318 -\u003e 0x7ffe320d0318: 1, 0x7ffe320d031c: 3 private m_size 1 private m_val 3 delete A 成功窃取了private的成员内容. 当然通过指针修改private内容也是可以的: *reinterpret_cast\u003cint *\u003e(pb) = 10; cout \u003c\u003c \"private m_size \" \u003c\u003c *reinterpret_cast\u003cint *\u003e(pb) \u003c\u003c endl; 现在输出就是10了. ","date":"2021-05-17","objectID":"/202105/priavte-bypointer/:1:0","tags":["Cpp"],"title":"private不保证安全","uri":"/202105/priavte-bypointer/"},{"categories":["数据结构与算法","Cpp"],"content":"问题 假设有一个数字流, 值域是[0, 4294967295], 每个值等概率随机出现, 现在需要设计一个算法判断某个数字有没有出现过. 解决这个问题有几种思路: 申请一个大小为4294967296的数组A, 初始化所有值为0, 每来一个数字n, 就给对应下标+1, 即A[n]++; 如果这个数组是bool类型, 那么将占用4GB内存空间. 使用文件操作, 每来一个数字就去文件中查找是否存在, 如果不存在就将数字写入文件. 这样磁盘足够大, 但是会涉及到很多IO操作. 可以稍微优化一下, 比如用一个想对比较小的buffer作为缓存, 先将数字和buffer中的数字比较, 如果不存在就再和文件中的数字比较, 如果还是不存在, 就维护buffer长度, 将buffer的最后一个数字写入文件, 最新的数字加到buffer头. 优化方案1, 如果可以将数字类型设置为bit, 那么就可以减少为1/8的空间, 这时候只需要512MB内存, 想对还可以接受. 方案3就是这里要介绍的位图. 可以认为位图就是一块buffer, 以bit为单位操作. 如果来一个新的数字, 比如n, 我们就需要计算n在位图中的下标, 这个下标可以用二维表示, 一个是所在的Byte下标, 一个是在Byte的偏移, 所以下标可以计算为(n / 8, n % 8). ","date":"2021-05-14","objectID":"/202105/cpp-bitmap/:1:0","tags":["Cpp","位图"],"title":"数据结构与算法之位图","uri":"/202105/cpp-bitmap/"},{"categories":["数据结构与算法","Cpp"],"content":"bitset C++为我们提供了bitset的结构用于表示位图. 来看一段例子: #include \u003ciostream\u003e #include \u003cbitset\u003e using namespace std; int main() { bitset\u003c8\u003e bits; bits.set(); //11111111 cout \u003c\u003c bits \u003c\u003c endl; bits.reset(); //00000000 cout \u003c\u003c bits \u003c\u003c endl; bits[0] = 1; //00000001 bits[1] = 2; //00000011 cout \u003c\u003c bits \u003c\u003c endl; bits.flip(); //11111100 cout \u003c\u003c bits \u003c\u003c endl; bits ^= 0xF1; //00001101 cout \u003c\u003c bits \u003c\u003c endl; bitset\u003c65\u003e bits1; cout \u003c\u003c sizeof(bits) \u003c\u003c endl; //8 cout \u003c\u003c sizeof(bits1) \u003c\u003c endl; //16 return 1; } API手册 了解这个结构即可, bitset还可以支持常规的位运算, 当做一个普通的类型处理即可. 需要注意的是, bitset以64b为单位申请内存, 比如声明bitset\u003c8\u003e时, bitset内部申请了64bits的内存, 声明bitset\u003c65\u003e时, bitset内部申请了128bits的内存. ","date":"2021-05-14","objectID":"/202105/cpp-bitmap/:2:0","tags":["Cpp","位图"],"title":"数据结构与算法之位图","uri":"/202105/cpp-bitmap/"},{"categories":["操作系统"],"content":"前面的文章讲了进程控制和进程通信的内容, 在学习和准备这些内容的过程中, 发现对Linux文件系统并不是很熟悉. 此前对Linux文件系统的理解非常肤浅, 嘴上会说\"万物皆是文件\"的话, 但是并不是很理解Linux的文件系统. 这里插入一篇文章, 学习和整理一下Linux文件系统的内容. ","date":"2021-05-14","objectID":"/202105/linux-filesystem/:0:0","tags":["Linux","文件系统"],"title":"初探Linux文件和文件系统","uri":"/202105/linux-filesystem/"},{"categories":["操作系统"],"content":"文件 这一节作为引言, 先看看我们日常操作的一些结果在深入内核去看会更容易理解. ","date":"2021-05-14","objectID":"/202105/linux-filesystem/:1:0","tags":["Linux","文件系统"],"title":"初探Linux文件和文件系统","uri":"/202105/linux-filesystem/"},{"categories":["操作系统"],"content":"ls 在Linux上可以使用ls命令查看对应路径下的文件, 比如ls -la查看当前路径下的文件: drwxrwxr-x 3 mi mi 4096 4月 27 19:32 . drwxrwxr-x 7 mi mi 4096 4月 26 10:02 .. -rw-rw-r-- 1 mi mi 0 4月 26 10:03 file_attr drwxrwxr-x 2 mi mi 4096 4月 27 19:32 file_dic 每一行代表一个文件或者一个目录, 一行大概可以分成七块区域, 以文件file_attr为例: -rw-rw-r--, 1, mi, mi, 0, 4月 26 10:03, file_attr. 首先可以理解, 4月 26 10:03, file_attr代表的是时间和文件名, 且时间是在每次写入文件时才会改变, 打开文件时这个时间是不变的, 所以这里的时间就是最后修改的时间. 其他的部分是什么意思呢? -rw-rw-r--代表文件的权限, 在Linux系统中, 一切操作都有比较严格的权限控制, 对一个文件来说, 它可以读/写/执行, 所以Linux使用rwx三个字符分别表示文件的读写和执行权限, 实际上是一个mask, 用3bits表示, 从高到底分别是读写和执行, 所以可以用7表示读写执行权限, 6表示读写权限, 1表示执行权限等等. 针对当前用户, 当前用户组, 其他用户组可以设置不同的读/写/执行权限. 数字1则表示有几个文件link了这个文件, 表示的是硬链接. mi mi两项代表这个文件的拥有者和拥有者的用户组. 数字0则代表文件内容的大小, 因为没有向文件中添加内容, 所以大小为0. 注意到当前目录表示.和上一级目录表示..都被ls打印出来了, 其是这两种目录都是文件. 在Linux中目录和文件都被当做文件, 只是属于不同的文件类型. ","date":"2021-05-14","objectID":"/202105/linux-filesystem/:1:1","tags":["Linux","文件系统"],"title":"初探Linux文件和文件系统","uri":"/202105/linux-filesystem/"},{"categories":["操作系统"],"content":"文件权限 普通文件的文件权限比较好理解, 这里就不再验证了. 目录文件的文件权限如何理解呢? 对某个目录./filesystem/, 向关闭所有权限: chmod 000 ./filesystem/ 这时候再查看就会报错: $ ls ./filesystem/ ls: cannot open directory './filesystem/': Permission denied 添加读写权限: chmod 600 ./filesystem/ 这时候再查看依然会有一些错误: $ ls ./filesystem/ ls: cannot access './filesystem/file_attr': Permission denied ls: cannot access './filesystem/file_dic': Permission denied file_attr file_dic 列举除了目录下的文件, 但是对目录下的文件没有访问权限(继续往下看)? 如果添加读写执行权限, 这一切都正常了: $ ls -la filesystem/ total 12 drwxrwxrwx 3 mi mi 4096 5月 11 20:36 . drwxrwxrwx 11 mi mi 4096 5月 8 20:32 .. -rw-rw-r-- 1 mi mi 0 5月 8 20:32 file_attr drwxrwxr-x 2 mi mi 4096 5月 11 20:36 file_dic 可以继续类似实验, 总的来说, 目录同样需要读写执行权限, 如果权限不对, 可以会有无法打开文件, 无法ls文件, 无法添加文件, 无法cd到目录等问题. ","date":"2021-05-14","objectID":"/202105/linux-filesystem/:1:2","tags":["Linux","文件系统"],"title":"初探Linux文件和文件系统","uri":"/202105/linux-filesystem/"},{"categories":["操作系统"],"content":"stat 可以使用stat查看文件的详细信息, 比如下面两段: 当前目录的信息: $ stat . File: . Size: 4096 Blocks: 8 IO Block: 4096 directory Device: 802h/2050d Inode: 136185988 Links: 3 Access: (0775/drwxrwxr-x) Uid: ( 1000/ mi) Gid: ( 1000/ mi) Access: 2021-05-11 20:36:13.625994262 +0800 Modify: 2021-05-11 20:36:12.533997328 +0800 Change: 2021-05-11 20:36:12.533997328 +0800 Birth: - 某个普通文件的信息: $ stat ./file_attr File: ./file_attr Size: 0 Blocks: 0 IO Block: 4096 regular empty file Device: 802h/2050d Inode: 136185989 Links: 1 Access: (0664/-rw-rw-r--) Uid: ( 1000/ mi) Gid: ( 1000/ mi) Access: 2021-05-12 13:04:02.996823303 +0800 Modify: 2021-05-08 20:32:55.623371621 +0800 Change: 2021-05-08 20:32:55.623371621 +0800 Birth: - 两段信息结构相同, 包含了名称, 大小, link, 日期, 权限等信息. Inode项是inode的id, inode是实际存储文件信息和内容的结构体, 对操作系统来说, 文件名是陌生的, 操作系统看文件是看的inode. 通过ls -i也可以查看文件的inode id. 目录和文件都有inode. ","date":"2021-05-14","objectID":"/202105/linux-filesystem/:1:3","tags":["Linux","文件系统"],"title":"初探Linux文件和文件系统","uri":"/202105/linux-filesystem/"},{"categories":["操作系统"],"content":"文件系统 问题: 文件是怎么储存在磁盘上, 又是如何加载进内存的? 如果让我们自己设计磁盘存储文件的方式, 可能会想到两种: 文件存储在磁盘连续的空间上; 文件分片存储在磁盘连续的空间上; 如果是第一种存储方式, 那么可能会遇到一些问题, 比如磁盘上存储了很多很小的文件, 假设只有1KB, 之后我们删除其中的一些文件, 那么在磁盘上就会有很多坑坑洼洼的小碎片, 如果这时候我们要存储一个比较大文件, 但是没有连续的空间了, 该怎么办呢? 这时候我们可以\"整理\"一下磁盘, 把分散的文件移动到一起, 这样就会有大的连续的存储空间了. 但是, 这样必然会设计大量的搬运操作, 大大提高系统功耗, 降低系统的效率, 且容易损坏磁盘. 第二种方式这是类比链表(或者类比内存RAM), 将磁盘分成很多很多的小块, 比如每块只有1KB, 那么文件就存储在这些小块上. 比如, 文件小于1KB, 则一块空间就行了, 文件大于1KB, 则每1KB都存储在一小块空间上, 不需要连续. 相比于第一种方法, 第二种方法原生地就把磁盘分割成了很多小块, 就算有超大文件需要存储也用担心有没有足够大小的连续空间的问题. 但是第二种方法就需要存储每个小块的地址, 并且需要知道小块的顺序关系, 而第一种方法一般只需要存储一个地址和文件大小就行了. 一般使用的是第二种存储方式, 按照映射关系又可以分为不同的文件系统, 有的类似树状结构存储, 有的类似链表结构存储. 链式存储: 链式存储 树状存储: 树状存储 ","date":"2021-05-14","objectID":"/202105/linux-filesystem/:2:0","tags":["Linux","文件系统"],"title":"初探Linux文件和文件系统","uri":"/202105/linux-filesystem/"},{"categories":["操作系统"],"content":"inode inode可以认为是操作系统眼中的文件, 磁盘或者内存上都会有inode, 这里是内存上(VFS)的inode, 是一个结构体. inode在Linux上是已经分配好的, 磁盘上会有一块固定区域存放inode的bitmap, 这也意味着inode的数量是有限的, 在硬盘格式化的时候就已经确定好了. 通过df -i可以看到系统各个分区的inode总数和使用数. 所以我们可能会遇到的一个问题是, 硬盘空间明明还有很多, 但是已经无法创建新的文件了, 这时候就可以考虑是不是inode没有了. 在线看inode结构 /* * Keep mostly read-only and often accessed (especially for * the RCU path lookup and 'stat' data) fields at the beginning * of the 'struct inode' */ struct inode { umode_t i_mode; // 文件权限, rwx等 unsigned short i_opflags; kuid_t i_uid; // 文件所属用户id, ls可以看到 kgid_t i_gid; // 文件所属用户组id, ls可以看到 unsigned int i_flags; #ifdef CONFIG_FS_POSIX_ACL struct posix_acl *i_acl; struct posix_acl *i_default_acl; #endif const struct inode_operations *i_op; struct super_block *i_sb; // 指向了super block, 对同一个文件系统是唯一的 struct address_space *i_mapping; //...... /* Stat data, not accessed from path walking */ unsigned long i_ino; /* * Filesystems may only read i_nlink directly. They shall use the * following functions for modification: * * (set|clear|inc|drop)_nlink * inode_(inc|dec)_link_count */ union { const unsigned int i_nlink; unsigned int __i_nlink; }; dev_t i_rdev; loff_t i_size; // 文件大小 struct timespec64 i_atime; // 操作时间相关 struct timespec64 i_mtime; // 操作时间相关 struct timespec64 i_ctime; // 操作时间相关 spinlock_t i_lock; /* i_blocks, i_bytes, maybe i_size */ unsigned short i_bytes; u8 i_blkbits; u8 i_write_hint; blkcnt_t i_blocks; //...... union { struct pipe_inode_info *i_pipe; struct block_device *i_bdev; struct cdev *i_cdev; char *i_link; unsigned i_dir_seq; }; // inode的类型, 比如可以是一个pipe或者link等, 这时候可以不需要磁盘上具体的文件内容, 仅inode结构就可以了 //...... } __randomize_layout; 从这个结构体中我们可以看到, inode基本包含一个文件的所有信息, 文件大小, 访问时间, 文件权限等等, 但是不包括文件名. 结构体用一个union表示了文件的类型, 比如是pipe文件(i_pipe)还是link的文件(i_link)等等, 因为一个文件同时只能属于一种类型, 不可能既是link有时pipe等等, 所以只需要使用union表示即可. 我们使用的ls和stat等命令就可以打印inode的基本信息. 以下是文件系统的inode, 是在磁盘上的结构, 比如ext4文件系统: /* * Structure of an inode on the disk */ struct ext4_inode { __le16 i_mode; /* File mode */ __le16 i_uid; /* Low 16 bits of Owner Uid */ __le32 i_size_lo; /* Size in bytes */ __le32 i_atime; /* Access time */ __le32 i_ctime; /* Inode Change time */ __le32 i_mtime; /* Modification time */ __le32 i_dtime; /* Deletion Time */ __le16 i_gid; /* Low 16 bits of Group Id */ __le16 i_links_count; /* Links count */ __le32 i_blocks_lo; /* Blocks count */ __le32 i_flags; /* File flags */ //....... __le32 i_block[EXT4_N_BLOCKS];/* Pointers to blocks */ __le32 i_generation; /* File version (for NFS) */ __le32 i_file_acl_lo; /* File ACL */ __le32 i_size_high; __le32 i_obso_faddr; /* Obsoleted fragment address */ //...... }; 在这里也保存了和文件相关的一些基本信息, 比如mode/时间等等, 同时文件系统的inode也包含i_block这个成员, i_block就可以指向磁盘上真正的block. TODO: 虚拟文件系统的inode是如何与文件系统inode关联的. pipe 以下展示的是inode如何描述一个pipe: pipe 前面的文章说过: Linux管道是一个文件, 但是没有具体的文件内容, 在struct inode中就可以看到inode会有一个成员指向pipe_inode_info. pipe_inode_info结构体如下, 这里会关注tmp_page和bufs, 分别指向了page缓存和pipe的环形缓存队列. 并且这两者都是以page为单位的, 所以这里可以看到, pipe的最小单位是page, 并且pipe结构体中有一个锁, 所以可以猜测, pipe的原子操作是以page(已缓存的tmp_page)为单位(之前的文章中已经有过这个结论). /** * struct pipe_inode_info - a linux kernel pipe * @mutex: mutex protecting the whole thing * @wait: reader/writer wait point in case of empty/full pipe * @nrbufs: the number of non-empty pipe buffers in this pipe * @buffers: total number of buffers (should be a power of 2) * @curbuf: the current pipe buffer entry * @tmp_page: cached released page * @readers: number of current readers of this pipe * @writers: number of current writers of this pipe * @files: number of struct file referring this pipe (protected by -\u003ei_lock) * @waiting_writers: number of writers blocked waiting for room * @r_counter: reader counter * @w_counter: writer counter * @fasync_readers: reader side fasync * @fasync_writers: writer side fasync * @bufs: the circular array of pipe buffers * @user: the user who created this pipe **/ struct pipe_inode_info { struct mutex mutex; wait_queue_head_t wait; unsigned int nrbufs, curbuf, buffers; unsigned int readers; unsigned int writers; unsigned int files;","date":"2021-05-14","objectID":"/202105/linux-filesystem/:2:1","tags":["Linux","文件系统"],"title":"初探Linux文件和文件系统","uri":"/202105/linux-filesystem/"},{"categories":["操作系统"],"content":"block TODO: inode如何访问到block的需要再确认. block是磁盘存储内容的最小单位, 计算机按照block为单位读取磁盘内容. (类比内存按照page为最小单位读写.) 每次读写一个block都会触发一个IO操作. 这里说明的是, inode可以直接将内容存储在block中, 这样一次跳转就可以访问到磁盘的内容, 但是如果直接指向block就会导致文件的最大大小受到限制. 所以inode会有多种机制, 可以直接指向保存内容的block, 也可以指向一个中间block, 这个中间block会指向多个保存有文件内容的block, 或者这个中间block再指向多个次中间block, 这些block再指向保存有文件内容的block. 这样的好处就是不需要过大的inode, inode只需极少数的block指针, 就可以存储很大的文件. 坏处是多级指向会降低对大文件读写的效率, 因为计算机按照block读取文件内容, 多级指向就会增加IO访问次数, 降低读写效率. 以下是文件系统inode到block的多级指向结构: inode-block 通过inode和block的指向关系, 我们可以大概算出系统支持的最大文件大小. 假设block大小是4KB, 那么通过inode直接指向block, 一个文件最大大概是4KB. 通过一级指向, 那么一个文件最大大概是$(4KB / 64b) * 4KB = 256MB$. 通过二级指向, 一个文件最大大概有$((4KB / 64b) * 4KB / 64b) * 4KB = 16GB$. 上述是比较简单的计算, 但是计算方式基本如此, 供参考. ","date":"2021-05-14","objectID":"/202105/linux-filesystem/:2:2","tags":["Linux","文件系统"],"title":"初探Linux文件和文件系统","uri":"/202105/linux-filesystem/"},{"categories":["操作系统"],"content":"super_block super block是内核直接管理的block, 内核可以直接拿到这个block的内容. 一个文件系统负责操作一个super block. 在线看super_block: struct super_block { struct list_head s_list; /* Keep this first */ dev_t s_dev; /* search index; _not_ kdev_t */ unsigned char s_blocksize_bits; unsigned long s_blocksize; loff_t s_maxbytes; /* Max file size */ struct file_system_type *s_type; const struct super_operations *s_op; const struct dquot_operations *dq_op; const struct quotactl_ops *s_qcop; const struct export_operations *s_export_op; unsigned long s_flags; unsigned long s_iflags; /* internal SB_I_* flags */ unsigned long s_magic; struct dentry *s_root; // 根结点dentry struct rw_semaphore s_umount; int s_count; atomic_t s_active; //...... struct hlist_bl_head s_roots; /* alternate root dentries for NFS */ struct list_head s_mounts; /* list of mounts; _not_ for fs use */ struct block_device *s_bdev; struct backing_dev_info *s_bdi; struct mtd_info *s_mtd; struct hlist_node s_instances; unsigned int s_quota_types; /* Bitmask of supported quota types */ struct quota_info s_dquot; /* Diskquota specific options */ struct sb_writers s_writers; //...... char s_id[32]; /* Informational name */ uuid_t s_uuid; /* UUID */ unsigned int s_max_links; fmode_t s_mode; /* * The next field is for VFS *only*. No filesystems have any business * even looking at it. You had been warned. */ struct mutex s_vfs_rename_mutex; /* Kludge */ /* * Filesystem subtype. If non-empty the filesystem type field * in /proc/mounts will be \"type.subtype\" */ const char *s_subtype; const struct dentry_operations *s_d_op; /* default d_op for dentries */ /* * Saved pool identifier for cleancache (-1 means none) */ int cleancache_poolid; struct shrinker s_shrink; /* per-sb shrinker handle */ /* Number of inodes with nlink == 0 but still referenced */ atomic_long_t s_remove_count; /* Pending fsnotify inode refs */ atomic_long_t s_fsnotify_inode_refs; /* Being remounted read-only */ int s_readonly_remount; /* AIO completions deferred from interrupt context */ struct workqueue_struct *s_dio_done_wq; struct hlist_head s_pins; /* * Owning user namespace and default context in which to * interpret filesystem uids, gids, quotas, device nodes, * xattrs and security labels. */ struct user_namespace *s_user_ns; /* * The list_lru structure is essentially just a pointer to a table * of per-node lru lists, each of which has its own spinlock. * There is no need to put them into separate cachelines. */ struct list_lru s_dentry_lru; struct list_lru s_inode_lru; struct rcu_head rcu; struct work_struct destroy_work; struct mutex s_sync_lock; /* sync serialisation lock */ /* * Indicates how deep in a filesystem stack this SB is */ int s_stack_depth; /* s_inode_list_lock protects s_inodes */ spinlock_t s_inode_list_lock ____cacheline_aligned_in_smp; struct list_head s_inodes; /* all inodes */ spinlock_t s_inode_wblist_lock; struct list_head s_inodes_wb; /* writeback inodes */ } __randomize_layout; 很多成员不太懂什么意思, 这里先关注s_root这个成员, s_root指向的是一个dentry, 从名字也可以看出是指向的根结点的dentry, 也就是/目录. 因为每个inode都有一个指向super block的指针, 所以每个inode都可以间接访问到根结点, 这也为文件系统的访问奠定了基础. inode-super_block 下面来看dentry的结构. ","date":"2021-05-14","objectID":"/202105/linux-filesystem/:2:3","tags":["Linux","文件系统"],"title":"初探Linux文件和文件系统","uri":"/202105/linux-filesystem/"},{"categories":["操作系统"],"content":"dentry dentry是一个目录的结构表示: struct dentry { /* RCU lookup touched fields */ unsigned int d_flags; /* protected by d_lock */ seqcount_t d_seq; /* per dentry seqlock */ struct hlist_bl_node d_hash; /* lookup hash list */ struct dentry *d_parent; /* parent directory */ struct qstr d_name; struct inode *d_inode; /* Where the name belongs to - NULL is * negative */ unsigned char d_iname[DNAME_INLINE_LEN]; /* small names */ /* Ref lookup also touches following */ struct lockref d_lockref; /* per-dentry lock and refcount */ const struct dentry_operations *d_op; struct super_block *d_sb; /* The root of the dentry tree */ unsigned long d_time; /* used by d_revalidate */ void *d_fsdata; /* fs-specific data */ union { struct list_head d_lru; /* LRU list */ wait_queue_head_t *d_wait; /* in-lookup ones only */ }; struct list_head d_child; /* child of parent list */ struct list_head d_subdirs; /* our children */ /* * d_alias and d_rcu can share memory */ union { struct hlist_node d_alias; /* inode alias list */ struct hlist_bl_node d_in_lookup_hash; /* only for in-lookup ones */ struct rcu_head d_rcu; } d_u; } __randomize_layout; 每个dentry都会有指向父结点的指针d_parent, 目录名d_name也存在dentry的结构体中, 还会有一个指向inode的指针d_inode, 这也说明目录和文件之间存在一定的关系. 除此之外, dentry也可以之间访问到自己的兄弟结点d_child和孩子结点d_subdirs, 有了这两个指向关系, 系统就可以做一些缓存操作, 不需要每次都从根结点一层一层访问到当前结点(这里是个人猜测的). 比如我们要访问某个文件, 一般会按照以下顺序, 先是解析路径, 找到根结点, 一层一层查找, 直到当前结点. open ","date":"2021-05-14","objectID":"/202105/linux-filesystem/:2:4","tags":["Linux","文件系统"],"title":"初探Linux文件和文件系统","uri":"/202105/linux-filesystem/"},{"categories":["操作系统"],"content":"小结 这一篇主要是学习一些概念, 很多知识我也是第一次接触, 不是科班出身. 我们所理解的文件对操作系统来说就是inode, inode存储了文件的基本信息, 包括权限和访问时间等等, 但是inode不包括文件名. inode可以直接访问到文件内容的block, 也可以通过多级跳转访问到文件内容的block, 具体看文件的大小和block大小的关系. 之前学习过的pipe也是一个inode, 并且没有实际的block, 只是系统内存上的一个inode结构体. 通过pipe结构体, 我们也可以看到pipe缓存是以页为基本单位, 并且会给之加锁, 所以pipe对一个page的读写是原子操作的. 目录会和dentry关联, dentry也会有指向inode的指针, 所以目录的一些基本信息也会存储在inode中, 这也可以认为目录也是文件. inode可以直接访问到super block, 进而访问到根结点的dentry, 一般来说我们访问一个文件, 系统会从根结点一层一层的追溯到被访问文件的inode. 文件名和inode的对应关系会存在一个表中, 但是存在哪, 如何存的还需进一步学习. ","date":"2021-05-14","objectID":"/202105/linux-filesystem/:3:0","tags":["Linux","文件系统"],"title":"初探Linux文件和文件系统","uri":"/202105/linux-filesystem/"},{"categories":["操作系统"],"content":"遗留问题(TODO) 查看根目录inode信息, 有几项特殊的内容: ls -ia / 2 . 2 .. 2 dev 2 run 1 proc 1 sys . .. dev和run的inode id相同; proc和sys的inode id相同; 为什么他们的inode id相同但是内容会不同? inode如何找到block的? 是那个成员指向? dentry找到inode的具体过程如何? 是哪些成员参与指向? ","date":"2021-05-14","objectID":"/202105/linux-filesystem/:4:0","tags":["Linux","文件系统"],"title":"初探Linux文件和文件系统","uri":"/202105/linux-filesystem/"},{"categories":["操作系统"],"content":"参考链接 Linux中的任务和调度[一] Linux的进程地址空间[一] If threads share the same PID, how can they be identified? 从内核角度看Linux 线程和进程的区别 linux/include/linux/fs.h Overview of the Linux Virtual File System Index Nodes Overlay Filesystem 这一篇知识很浅, 通过写这篇文章对文件系统也有一些粗浅的了解了, 后续还会写一个文件系统的专题. ","date":"2021-05-14","objectID":"/202105/linux-filesystem/:5:0","tags":["Linux","文件系统"],"title":"初探Linux文件和文件系统","uri":"/202105/linux-filesystem/"},{"categories":["Android"],"content":" 需求: 用CMake构建和编译生成的算法库, 作为动态共享库link到Android项目. ","date":"2021-05-12","objectID":"/202105/cmake-ndk-crosscomplie/:0:0","tags":["cmake","ndk","android"],"title":"cmake链接ndk交叉编译","uri":"/202105/cmake-ndk-crosscomplie/"},{"categories":["Android"],"content":"配置 在Android项目的Android.mk中添加: include $(CLEAR_VARS) LOCAL_PATH := $(XXXX_PATH) LOCAL_MODULE := libxxx LOCAL_MULTILIB := 64 LOCAL_SRC_FILES_64 := ./algo/libxxx.so LOCAL_MODULE_SUFFIX := .so LOCAL_MODULE_TAGS := optional LOCAL_MODULE_CLASS := SHARED_LIBRARIES LOCAL_PROPRIETARY_MODULE := true include $(BUILD_PREBUILT) include $(CLEAR_VARS) 算法库的CMakeLists.txt中添加一下编译项和宏: CMAKE_MINIMUM_REQUIRED(VERSION 3.5) ADD_DEFINITIONS(\"-Wall\") ADD_DEFINITIONS(\"-fPIC\") ADD_DEFINITIONS(\"-Wl,-lm\") ADD_DEFINITIONS(\"-Wl,--whole-archive\") SET(CMAKE_CXX_FLAGS \"-std=c++17 -pthread -Wall -pie -fPIC -Wl,-Bsymbolic -lz -lc -ldl -lm -D__STDINT_LIMITS -D__STDINT_MACROS -D__ANDROID__ -DANDROID\") SET(EXECUTABLE_OUTPUT_PATH ${PROJECT_SOURCE_DIR}) ADD_EXECUTABLE(xxx xxx.cpp) 算法库的build.sh编译脚本如下: function build() { export ANDROID_NDK=$HOME/android-ndk-r21e export PATH=$ANDROID_NDK:$PATH rm -r .build mkdir .build \u0026\u0026 cd .build cmake -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake \\ -DANDROID_ABI=arm64-v8a \\ -DANDROID_NDK=$ANDROID_NDK \\ -DANDROID_PLATFORM=latest \\ -DANDROID_LD=lld \\ .. make -j12 \u0026\u0026 make cd .. rm -r .build/ } build 需要注意的是: 设置环境变量, 添加ndk路径到环境变量 cmake配置参数, 按照如上填写 DANDROID_ABI要与link库索声明的类型匹配, 比如Android.mk中link库声明的是64位, 则这里填写arm64-v8a ","date":"2021-05-12","objectID":"/202105/cmake-ndk-crosscomplie/:1:0","tags":["cmake","ndk","android"],"title":"cmake链接ndk交叉编译","uri":"/202105/cmake-ndk-crosscomplie/"},{"categories":["Android"],"content":"链接 ndk下载 cmake和ndk交叉编译 ","date":"2021-05-12","objectID":"/202105/cmake-ndk-crosscomplie/:2:0","tags":["cmake","ndk","android"],"title":"cmake链接ndk交叉编译","uri":"/202105/cmake-ndk-crosscomplie/"},{"categories":["工具"],"content":"本站同时部署到了阿里云oss和vercel, 境内ip一般访问的是阿里云, 境外ip一般访问的是vercel, 经过测试, 境外ip访问会有较大速度提升(最快从几百ms可以到几十ms). 部署到vercel是将vercel项目和github page的仓库链接, 所以本站的源码或者博客内容提交后, 第一是会触发github action实现自动编译, 第二是将自动编译后的结果./public发布到阿里云oss和github page仓库, 此时会更新github page并会生成新的commit, 所以会触发vercel的自动部署函数. 内容推送到github page仓库需要使用deploy key, 源码仓库添加screte保存密钥, github page仓库添加deploy key保存公钥, 密钥对可以使用ssh-keygen生成. 为什么要使用github page触发vercel? 因为本站源码采用的是git submodule组织的形式, 内容/主题/插件/配置分别在不同的仓库或者分支, 目前使用vercel没有发现有很好的方法可以将这些内容组织起来, 所以曲线救国, 使用github page触发. 如果源码都在一个仓库的同一个分支, 则可以直接使用vercel部署, 不需要引入github page这一中间变量. ","date":"2021-05-11","objectID":"/202105/blog2vercel/:0:0","tags":["vercel","博客"],"title":"博客部署到vercel","uri":"/202105/blog2vercel/"},{"categories":["操作系统"],"content":"消息队列 消息队列是在内核空间开辟的一块共享内存, 类似于以下结构: 内核提供共享区域做IPC 类似于具名管道, 消息队列也有一个标识符MSG_KEY, 用来标识不同的消息队列. 只要知道某个消息队列的标识符, 并且拥有相应的权限, 就可以使用相应的消息队列. 所以, 消息队列可以在没有亲缘关系的进程间使用. Linux系统调用为我们提供了几个C接口用于消息队列, 在sys/msg.h可以找到定义. 主要是以下4个函数: /* Message queue control operation. */ extern int msgctl (int __msqid, int __cmd, struct msqid_ds *__buf) __THROW; /* Get messages queue. */ extern int msgget (key_t __key, int __msgflg) __THROW; /* Receive message from message queue. This function is a cancellation point and therefore not marked with __THROW. */ extern ssize_t msgrcv (int __msqid, void *__msgp, size_t __msgsz, long int __msgtyp, int __msgflg); /* Send message to message queue. This function is a cancellation point and therefore not marked with __THROW. */ extern int msgsnd (int __msqid, const void *__msgp, size_t __msgsz, int __msgflg); msgget接收MSG_KEY和权限flag, 用于创建或者打开一个消息队列. msgsnd接收msg_id和消息内容以及消息控制flag, 用于发送消息. msgrcv接收msg_id和接收消息的容器以及消息控制flag, 用于接收消息. msgctl接收msg_id和控制命令, 用于控制消息队列. 在bits/ipc.h可以找到各种flag: /* Mode bits for `msgget', `semget', and `shmget'. */ #define IPC_CREAT 01000 /* Create key if key does not exist. */ #define IPC_EXCL 02000 /* Fail if key exists. */ #define IPC_NOWAIT 04000 /* Return error on wait. */ /* Control commands for `msgctl', `semctl', and `shmctl'. */ #define IPC_RMID 0 /* Remove identifier. */ #define IPC_SET 1 /* Set `ipc_perm' options. */ #define IPC_STAT 2 /* Get `ipc_perm' options. */ #ifdef __USE_GNU # define IPC_INFO 3 /* See ipcs. */ #endif 接下来, 我们开启两个进程, 使用消息队列实现进程间通信, 一个用于发送消息, 一个用于接收消息. ","date":"2021-05-07","objectID":"/202105/process-ctracon3/:1:0","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(三)","uri":"/202105/process-ctracon3/"},{"categories":["操作系统"],"content":"发送端 #include \u003cstdio.h\u003e #include \u003cstring.h\u003e #include \u003cstdlib.h\u003e #include \u003cerrno.h\u003e #include \u003csys/types.h\u003e #include \u003csys/ipc.h\u003e #include \u003csys/msg.h\u003e #define MSG_KEY 7777 struct MSG { long type; char msg[1024]; }; int main() { int msg_id = msgget(MSG_KEY, IPC_EXCL); if (msg_id \u003c 0) { msg_id = msgget(MSG_KEY, IPC_CREAT | 0666); } if (msg_id \u003c 0) { printf(\"get msg queue failed!\"); return -1; } printf(\"msq key %d id %d\\n\", MSG_KEY, msg_id); while(1) { struct MSG msg; printf(\"msg type: \"); scanf(\"%ld\", \u0026msg.type); printf(\"msg info: \"); scanf(\"%s\", \u0026msg.msg); int snd_id = msgsnd(msg_id, \u0026msg, sizeof(msg.msg), IPC_NOWAIT); if (snd_id \u003c 0) { printf(\"send msg failed with errno=%d[%s]\\n\", errno, strerror(errno)); msgctl(msg_id, IPC_RMID, 0); return -1; } } } 发送端定义了#define MSG_KEY 7777, MSG_KEY可以是任意的KEY, 不要和已有的混淆即可. 在创建消息队列的时候加了额外的权限, msgget(MSG_KEY, IPC_CREAT | 0666);, 6对应的是0110表示read和write. 在发送消息的时候, 如果发送失败, 则会移除对应的消息队列msgctl(msg_id, IPC_RMID, 0);. 此外, 我们还定义了一个结构体用来作为消息容器: struct MSG { long type; char msg[1024]; }; 第一个成员是long型, 作为消息的ID, 这意为着在同一个消息队列中, 每条消息都可以拥有不同的消息ID. 所以仅使用一个消息队列, 也可以在多个进程间实现通信, 且多个进程可以互不干扰.(关于这一点, 继续看后面的接收端就清楚了) 启动发送端程序, 输入消息ID和消息内容: msq key 7777 id 1 msg type: 1 msg info: hello msg type: 2 msg info: helloworld ","date":"2021-05-07","objectID":"/202105/process-ctracon3/:1:1","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(三)","uri":"/202105/process-ctracon3/"},{"categories":["操作系统"],"content":"接收端 #include \u003cstdio.h\u003e #include \u003cstring.h\u003e #include \u003cstdlib.h\u003e #include \u003csys/types.h\u003e #include \u003csys/ipc.h\u003e #include \u003csys/msg.h\u003e #define MSG_KEY 7777 struct MSG { long type; char msg[1024]; }; int main() { int msg_id = msgget(MSG_KEY, IPC_EXCL); if (msg_id \u003c 0) { msg_id = msgget(MSG_KEY, IPC_CREAT | 0666); } if (msg_id \u003c 0) { printf(\"get msg queue failed!\"); return -1; } printf(\"msq key %d id %d\\n\", MSG_KEY, msg_id); while(1) { struct MSG msg; for (int id = 0; id \u003c 100; id++) { msg.type = id; int rev_id = msgrcv(msg_id, \u0026msg, sizeof(msg.msg), msg.type, IPC_NOWAIT); if (rev_id \u003e 0) { printf(\"rev msg[%ld]: %s\\n\", msg.type, msg.msg); } } } } 接收端类似于发送端, 拥有相同的MSG_KEY和相同的struct MSG定义. 区别在与, 接收的时候不仅要有消息队列的ID, 还需要有消息的ID, 比如msg.type. 这意为着只有消息队列ID和消息ID都匹配时, 才可以读取到对应的消息. 所以接收端可以通过不同的消息ID, 区分不同发送端发送过来的消息, 当然最好要事先约定好消息ID. 如果没有事先约定消息ID, 则需要发送额外的消息来通知接收端以区分消息ID. 启动接收端程序, 可以收到: msq key 7777 id 1 rev msg[1]: hello rev msg[2]: helloworld ","date":"2021-05-07","objectID":"/202105/process-ctracon3/:1:2","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(三)","uri":"/202105/process-ctracon3/"},{"categories":["操作系统"],"content":"小结 使用msgget创建消息队列, 创建消息队列要注意权限控制, 如果异常可以使用errno查看错误信息, msgsnd用来发送消息, msgrcv用来接收消息. 如果发现消息队列异常时, 比如发送失败或者接收失败, 则最好使用msgctl移除对应的消息队列. 一个消息队列里面的每条消息都有对应的消息ID, 所以在消息队列ID相同的情况下, 不同进程可以通过区分消息ID以区分不同的消息发送端. 如果没有清空消息队列, 则发送的消息会缓存在消息队列中, 直到读出或者移除. ","date":"2021-05-07","objectID":"/202105/process-ctracon3/:1:3","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(三)","uri":"/202105/process-ctracon3/"},{"categories":["操作系统"],"content":"信号 进程间的信号通信有点类似于中断机制. 大概意思是, 当某个进程收到某个信号时, 就可以暂停进程当前的操作, 转而根据信号的类型做相应的操作(函数). 信号可以认为是一个整形的数, 所以信号的数量存在一个上限. 信号通信 Linux为我们提供了C的接口用于信号通信, 在include/signal.h可以找到: /* Send signal SIG to process number PID. If PID is zero, send SIG to all processes in the current process's process group. If PID is \u003c -1, send SIG to all processes in process group - PID. */ #ifdef __USE_POSIX extern int kill (__pid_t __pid, int __sig) __THROW; #endif /* Use POSIX. */ /* Set the handler for the signal SIG to HANDLER, returning the old handler, or SIG_ERR on error. By default `signal' has the BSD semantic. */ extern __sighandler_t signal (int __sig, __sighandler_t __handler) __THROW; 这里简单介绍两个, kill用于发送信号, signal用于处理信号. ","date":"2021-05-07","objectID":"/202105/process-ctracon3/:2:0","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(三)","uri":"/202105/process-ctracon3/"},{"categories":["操作系统"],"content":"发送信号 #include \u003cstdio.h\u003e #include \u003csignal.h\u003e #include \u003cstdlib.h\u003e int main(int argc, char *argv[]) { int signo = SIGUSR1; int pid = atoi(argv[1]); kill(pid, signo); printf(\"send sig %d to pid %d\\n\", signo, pid); } 我们要输入进程PID, 然后调用kill函数将信号发送给对应PID的进程: $ ./kill 15273 send sig 10 to pid 15273 则看起来很麻烦, 如果结合上述几种进程间通信方法, 就可以先使用具名管道或者消息队列通信, 告知PID, 然后再通过发送信号的方式, 处理对应的信号. ","date":"2021-05-07","objectID":"/202105/process-ctracon3/:2:1","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(三)","uri":"/202105/process-ctracon3/"},{"categories":["操作系统"],"content":"处理信号 #include \u003cstdio.h\u003e #include \u003csignal.h\u003e #include \u003cstdlib.h\u003e void signalPorcessor(int signo) { printf(\"process %d receive signal %d\\n\", getpid(), signo); } int main() { printf(\"current pid %d\\n\", getpid()); signal(SIGUSR1, signalPorcessor); while(1) { printf(\"process %d doing something\\n\", getpid()); sleep(1); } } 接收端的信号处理函数和接收端是在同一个进程: current pid 15273 process 15273 doing something process 15273 doing something process 15273 doing something process 15273 doing something process 15273 doing something process 15273 receive signal -1943753024 process 15273 doing something process 15273 doing something ","date":"2021-05-07","objectID":"/202105/process-ctracon3/:2:2","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(三)","uri":"/202105/process-ctracon3/"},{"categories":["操作系统"],"content":"小结 信号类似于软件中断, 进程在收到信号的时候, 可以转而去处理对应的信号处理函数, 处理完成之后, 回到被中断的地方继续执行. 因为信号传递需要知道对方PID, 所以可以通过其他进程通信的方式, 事先告知PID, 再使用信号传递通信. 操作系统会有很多信号, 比如Ctrl+C中断程序会触发信号, 进程越界会触发信号, 等等. 有些信号尽量不要随意使用, 它们可能负责系统的安全. 有些信号可能不能直接被使用, 比如SIGKILL和SIGSTOP, 他们用来保证进程可以被系统管理员正常杀死, 如果改写这两个进程, 则可以让进程一直存在系统中, 不被销毁. ","date":"2021-05-07","objectID":"/202105/process-ctracon3/:2:3","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(三)","uri":"/202105/process-ctracon3/"},{"categories":["操作系统"],"content":"共享内存 在此之前, 进程间的通信基本都在内核空间进行, 我们是否可以在用户空间进行进程间的通信呢? 这就是共享内存. 共享内存 我们知道, 进程的虚拟内存空间到实际的物理内存空间会有内存映射表. 如果将不同进程的映射表的某个地址映射到同一块物理内存, 那么这些进程之间就可以通过共享这块内存而实现通信. Linux在sys/shm.h为我们提供了操作共享内存的方法. 类比消息队列: /* The following System V style IPC functions implement a shared memory facility. The definition is found in XPG4.2. */ /* Shared memory control operation. */ extern int shmctl (int __shmid, int __cmd, struct shmid_ds *__buf) __THROW; /* Get shared memory segment. */ extern int shmget (key_t __key, size_t __size, int __shmflg) __THROW; /* Attach shared memory segment. */ extern void *shmat (int __shmid, const void *__shmaddr, int __shmflg) __THROW; /* Detach shared memory segment. */ extern int shmdt (const void *__shmaddr) __THROW; shmget接收SHM_KEY和buffer大小以及权限flag, 用于创建或者打开一个共享内存. shmat接收shm_id, 用于获得共享内存的地址. shmdt接收共享内存地址, 用于将共享内存和当前进程分离. shmctl接收shm_id和控制命令, 用于控制共享内存. 下面使用两个进程, 一个向共享内存写入数据, 一个从共享内存读出数据. ","date":"2021-05-07","objectID":"/202105/process-ctracon3/:3:0","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(三)","uri":"/202105/process-ctracon3/"},{"categories":["操作系统"],"content":"写入内存 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cstring.h\u003e #include \u003cunistd.h\u003e #include \u003ctime.h\u003e #include \u003csys/types.h\u003e #include \u003csys/ipc.h\u003e #include \u003csys/shm.h\u003e #define SHM_KEY 7777 #define BUF_SIZ 1024 int main() { time_t t; srand((unsigned) time(\u0026t)); int shm_id = shmget(SHM_KEY, BUF_SIZ, IPC_EXCL); if (shm_id \u003c 0) { shm_id = shmget(SHM_KEY, BUF_SIZ, IPC_CREAT | 0666); } if (shm_id \u003c 0) { printf(\"get shm failed!\"); return -1; } printf(\"shm key %d id %d\\n\", SHM_KEY, shm_id); char* shmem = shmat(shm_id, NULL, 0); for (int i = 0; i \u003c 3; i++) { char msg[512] = {0}; for (int j = 0; j \u003c 20; j++) { msg[j] = rand() % 26 + 65; } memcpy(shmem, msg, BUF_SIZ); printf(\"[%d]write msg: %s\\n\", getpid(), shmem); sleep(2); } // shmdt(shmem); // shmctl(shm_id, IPC_RMID, NULL); } 操作类似消息队列, 在写入数据时, 用时随机生成的长度20的字符串. 大概每间隔2秒向共享内存写入数据. 比如向内存写入: shm key 7777 id 1802301 [24105]write msg: HAHCIUYUHCWKPKOTMWGA [24105]write msg: VUMRNYOLVFJDHSFRPDOY [24105]write msg: HKIWVWQHSWJPQYIFYZST 代码最后两句, 用于分离共享内存和当前进程, 并且移除共享内存, 这样的话, 下次再次执行时, 可能会指向不同的共享内存块: shmdt(shmem); shmctl(shm_id, IPC_RMID, NULL); ","date":"2021-05-07","objectID":"/202105/process-ctracon3/:3:1","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(三)","uri":"/202105/process-ctracon3/"},{"categories":["操作系统"],"content":"读出内存 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cstring.h\u003e #include \u003cunistd.h\u003e #include \u003csys/types.h\u003e #include \u003csys/ipc.h\u003e #include \u003csys/shm.h\u003e #define SHM_KEY 7777 #define BUF_SIZ 1024 int main() { int shm_id = shmget(SHM_KEY, BUF_SIZ, IPC_EXCL); if (shm_id \u003c 0) { shm_id = shmget(SHM_KEY, BUF_SIZ, IPC_CREAT | 0666); } if (shm_id \u003c 0) { printf(\"get shm failed!\"); return -1; } printf(\"shm key %d id %d\\n\", SHM_KEY, shm_id); char* shmem = shmat(shm_id, NULL, 0); while(1) { printf(\"[%d]get msg: %s\\n\", getpid(), shmem); sleep(1); } } 间隔1秒从共享内存读取数据: shm key 7777 id 1802301 [24096]get msg: OPVCCQHLNBRVUNOZLNWD [24096]get msg: OPVCCQHLNBRVUNOZLNWD [24096]get msg: HAHCIUYUHCWKPKOTMWGA [24096]get msg: HAHCIUYUHCWKPKOTMWGA [24096]get msg: VUMRNYOLVFJDHSFRPDOY [24096]get msg: VUMRNYOLVFJDHSFRPDOY [24096]get msg: HKIWVWQHSWJPQYIFYZST [24096]get msg: HKIWVWQHSWJPQYIFYZST [24096]get msg: HKIWVWQHSWJPQYIFYZST [24096]get msg: HKIWVWQHSWJPQYIFYZST [24096]get msg: HKIWVWQHSWJPQYIFYZST 会读到本次没有写入的数据OPVCCQHLNBRVUNOZLNWD, 这是写入进程在上次写入的数据, 依然保存在共享内存中, 因为没有调用shmctl移除对应内存. 同时也发现每条数据会读到多次, 因为共享内存并没有提供同步机制. 所以单独使用共享内存时, 可能会遇到一些问题: 多次读取同一个数据(读比写快) 丢失数据(写比读快) 乱序(读到一半时, 又重新写) 为了解决这些问题, 我们可以使用其他的进程通信方式以达到同步的目的. 比如使用信号, 写入进程写完数据后, 发送信号, 读取进程捕获信号, 进入相应函数读取数据, 同时发送信号给写入进程, 表示已经读完数据, 可以继续写入. 当然, 有很多方式可以保证共享内存的同步, 接下来要介绍的信号量也可以用来解决共享内存的同步问题. ","date":"2021-05-07","objectID":"/202105/process-ctracon3/:3:2","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(三)","uri":"/202105/process-ctracon3/"},{"categories":["操作系统"],"content":"小结 使用shmget创建或者打开共享内存, 通过shmat获取共享内存的地址, 拿到地址后就可以像一块普通内存一样操作它, 通过shmdt和shmctl可以分离当前进程和共享内存然后移除它. 如果写端移除了共享内存, 读端还在继续读的话, 读端依然可以正常工作, 但是其数据不再更新. 共享内存会有同步问题, 因为共享内存的相关操作都不是原子操作, 所以需要搭配其他的IPC方式以解决共享内存的同步问题. ","date":"2021-05-07","objectID":"/202105/process-ctracon3/:3:3","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(三)","uri":"/202105/process-ctracon3/"},{"categories":["操作系统"],"content":"信号量 可以认为信号量是一个计数器, 并且对信号量的操作是原子操作. 信号量维护了一个计数器sv, 可以对sv进行+1和-1的操作. 那么, 有如下规定: 执行-1操作(P操作), 如果计数器sv大于0, 则sv减1, 否则, 如果sv等于0, 则挂起调用进程 执行+1操作(V操作), 如果有其他进程因为sv等于0被挂起, 则回复对应进程, 否则, 计数器sv加1 如果我们定义一个信号量, 其值只有0和1, 那么就可以实现简单的互斥锁. 这时可能有以下流程: 初始化信号量sv的值为1 进程1调用信号量, 试图执行-1操作, 由于sv大于0, 则执行-1操作, 继续往下执行 此时, 如果进程2调用信号量, 试图执行-1操作, 由于sv等于0, 则进程2被挂起 进程1处理完, 调用信号量, 试图执行+1操作, 由于进程2因为sv等于0被挂起, 则回复进程2, 此时sv等于0 进程2执行, 进程1再次执行到信号量时, 也会被挂起, 只能等待其他进程试图执行+1操作是, 进程1才会被回复 以上, 我们来实现简单的互斥锁, 信号量-1时对应lock操作, 信号量+1时对应unlock操作. Linux为我们提供了对信号的基本操作: /* Semaphore control operation. */ extern int semctl (int __semid, int __semnum, int __cmd, ...) __THROW; /* Get semaphore. */ extern int semget (key_t __key, int __nsems, int __semflg) __THROW; /* Operate on semaphore. */ extern int semop (int __semid, struct sembuf *__sops, size_t __nsops) __THROW; semget 用于获取或者创建信号量, 输入SEM_KEY参数和信号量数目以及权限flag semop 用于对信号量的基本操作, 可以执行+1或者-1操作 semctl 用于对信号量的基本控制, 包括初始化, 移除等 semop中的sembuf定义如下: struct sembuf { unsigned short int sem_num; /* semaphore number */ short int sem_op; /* semaphore operation */ short int sem_flg; /* operation flag */ }; ","date":"2021-05-07","objectID":"/202105/process-ctracon3/:4:0","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(三)","uri":"/202105/process-ctracon3/"},{"categories":["操作系统"],"content":"实现互斥锁 将信号量的操作抽象为lock和unlock函数, lock函数表示当前进程正在操作资源, 只它进程访问到lock时会被挂起, unlock这表示当前进程已经访问完资源, 其他进程可以竞争抢占这个资源. 定义utils.h文件: #include \u003csys/types.h\u003e #include \u003csys/ipc.h\u003e #include \u003csys/shm.h\u003e #include \u003csys/sem.h\u003e struct sembuf sem; union semun { int val; struct semid_ds *buf; unsigned short int *array; struct seminfo *__buf; }; void init(int sem_id) { union semun sem_union; sem_union.val = 1; semctl(sem_id, 0, SETVAL, sem_union); } void uinit(int sem_id) { union semun sem_union; semctl(sem_id, 0, IPC_RMID, sem_union); } void lock(int sem_id) { sem.sem_num = 0; sem.sem_op = -1; sem.sem_flg = SEM_UNDO; semop(sem_id, \u0026sem, 1); } void unlock(int sem_id) { sem.sem_num = 0; sem.sem_op = 1; sem.sem_flg = SEM_UNDO; semop(sem_id, \u0026sem, 1); } 结构体union semun在semctl有用, Linux现在没有定义这个结构体, 需要用户自行定义. bits/sem.h中解释如下: /* The user should define a union like the following to use it for arguments for `semctl'. union semun { int val; \u003c= value for SETVAL struct semid_ds *buf; \u003c= buffer for IPC_STAT \u0026 IPC_SET unsigned short int *array; \u003c= array for GETALL \u0026 SETALL struct seminfo *__buf; \u003c= buffer for IPC_INFO }; Previous versions of this file used to define this union but this is incorrect. One can test the macro _SEM_SEMUN_UNDEFINED to see whether one must define the union or not. */ #define _SEM_SEMUN_UNDEFINED 1 可以使用宏_SEM_SEMUN_UNDEFINED判断是否需要自定义. 可以看注释, val用于set值, 其他成员的用法暂不清楚. init函数用于初始化, 将信号量的值初始化为0. uinit则用于移除信号量. ","date":"2021-05-07","objectID":"/202105/process-ctracon3/:4:1","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(三)","uri":"/202105/process-ctracon3/"},{"categories":["操作系统"],"content":"结合共享内存实现写入端 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cstring.h\u003e #include \u003cunistd.h\u003e #include \u003ctime.h\u003e #include \u003csys/types.h\u003e #include \u003csys/ipc.h\u003e #include \u003csys/shm.h\u003e #include \u003csys/sem.h\u003e #include \"utils.h\" #define SHM_KEY 7777 #define SEM_KEY 8888 #define BUF_SIZ 1024 int main(int argc, char **argv) { time_t t; srand((unsigned) time(\u0026t)); if (argc \u003e 1) { srand(atoi(argv[1])); } int shm_id = shmget(SHM_KEY, BUF_SIZ, IPC_CREAT | 0666); int sem_id = semget(SEM_KEY, 1, IPC_CREAT | 0666); init(sem_id); printf(\"shm key %d id %d, sem key %d id %d\\n\", SHM_KEY, shm_id, SEM_KEY, sem_id); char* shmem = shmat(shm_id, NULL, 0); for (int i = 0; i \u003c 3; i++) { char msg[512] = {0}; for (int j = 0; j \u003c 20; j++) { msg[j] = rand() % 26 + 65; } lock(sem_id); memcpy(shmem, msg, BUF_SIZ); unlock(sem_id); printf(\"[%d]write msg: %s\\n\", getpid(), shmem); sleep(1); } uinit(sem_id); printf(\"[%d]write done\\n\", getpid()); } 正常情况下, 可以看到以下输出: $ ./write \u0026 ./write 1 \u0026 ./write 2 \u0026 ./write 3 [1] 16970 [2] 16971 [3] 16973 shm key 7777 id 1867816, sem key 8888 id 10 [16970]write msg: NUHUWAWMIXYSWZZLVBED shm key 7777 id 1867816, sem key 8888 id 10 [16971]write msg: NWLRBBMQBHCDARZOWKKY shm key 7777 id 1867816, sem key 8888 id 10 [16973]write msg: EBGNHAMDHNUXBVZLUFPK shm key 7777 id 1867816, sem key 8888 id 10 [16976]write msg: GVWQTYSKRGSEDLWPMVFX [16970]write msg: ZHFMVCTSCFVPBCKYDIMN [16971]write msg: HIDDQSCDXRJMOWFRXSJY [16973]write msg: KSNBVDSSSJDWKKJUMXXT [16976]write msg: RAEATJRJUUYASWSLVKYO [16970]write msg: HLGEMFRJIYMIHRWCVPUX [16971]write msg: BLDBEFSARCBYNECDYGGX [16973]write msg: NTSOORAIYRSLLIMGNHAF [16976]write msg: SQSVCRNOMSNFSRGLCZWW [16970]write done [16973]write done [16971]write done [16976]write done [1] Done ./write [2]- Done ./write 1 [3]+ Done ./write 2 这是符合预期的, 如果我们删除unlock操作, 则会发现, 进程会卡住: $ ./write \u0026 ./write 1 \u0026 ./write 2 \u0026 ./write 3 [1] 20832 [2] 20833 [3] 20834 shm key 7777 id 1867816, sem key 8888 id 11 [20832]write msg: EXOIWWVYGLJNJUAKPSLZ shm key 7777 id 1867816, sem key 8888 id 11 [20833]write msg: NWLRBBMQBHCDARZOWKKY shm key 7777 id 1867816, sem key 8888 id 11 [20834]write msg: EBGNHAMDHNUXBVZLUFPK shm key 7777 id 1867816, sem key 8888 id 11 [20835]write msg: GVWQTYSKRGSEDLWPMVFX // 卡在这 这是因为触发了sv等于0的情况, 进程都被挂起了. 并且, 因为每个进程都会做一个init操作, 使得被减为0的sv也会被初始化为1, 所以可能的情况是: 所有进程都会执行一次, 然后都被卡在第二次lock函数处 反复调用程序, 可能会解开一些lock住的进程 ","date":"2021-05-07","objectID":"/202105/process-ctracon3/:4:2","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(三)","uri":"/202105/process-ctracon3/"},{"categories":["操作系统"],"content":"结合共享内存实现读取端 #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cstring.h\u003e #include \u003cunistd.h\u003e #include \u003csys/types.h\u003e #include \u003csys/ipc.h\u003e #include \u003csys/shm.h\u003e #include \u003csys/sem.h\u003e #include \"utils.h\" #define SHM_KEY 7777 #define SEM_KEY 8888 #define BUF_SIZ 1024 int main() { int shm_id = shmget(SHM_KEY, BUF_SIZ, IPC_CREAT | 0666); int sem_id = semget(SEM_KEY, 1, IPC_CREAT | 0666); init(sem_id); printf(\"shm key %d id %d, sem key %d id %d\\n\", SHM_KEY, shm_id, SEM_KEY, sem_id); char* shmem = shmat(shm_id, NULL, 0); while(1) { lock(sem_id); printf(\"[%d]get msg: %s\\n\", getpid(), shmem); unlock(sem_id); // sleep(1); } uinit(sem_id); } 读取端比较简单, 添加信号量保证读取是原子的就好. ","date":"2021-05-07","objectID":"/202105/process-ctracon3/:4:3","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(三)","uri":"/202105/process-ctracon3/"},{"categories":["操作系统"],"content":"小结 信号量操作类似于消息队列和共享内存, 通过semget打开或者创建, 通过semop操作, 通过semctl初始化或者删除. 要区分信号量和信号, 可以将信号量类比于互斥锁, 将信号类比与中断, 两者是不同的. 信号量保证不同进程对共享资源的同步, 信号则是让不同进程可以根据不同信号执行相应操作. 操作信号量要考虑清楚, 也可能会出现死锁的情况. ","date":"2021-05-07","objectID":"/202105/process-ctracon3/:4:4","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(三)","uri":"/202105/process-ctracon3/"},{"categories":["工具"],"content":"最近做了一个博客内容聚合的网站RSSBlog, 写入rss链接, 就会定时触发, 获取rss文章列表. 如下: RSSBlog 开发的时候遇到了一个问题, 如何做到定时拉取呢? 这里用到了vercel和easycron. ","date":"2021-04-27","objectID":"/202104/autodeploy-vercel-easycron/:0:0","tags":["vercel","easycron","博客"],"title":"使用vercel和easycron实现自动部署","uri":"/202104/autodeploy-vercel-easycron/"},{"categories":["工具"],"content":"vercel vercel用于部署RSSBlog, 这里不赘述如何部署. 在vercel进入对应的项目页面, 在Setting-\u003eGit-\u003eDeploy Hooks中,输入Hook Name和Git Branch Name. Hook Name指Hook链接的名字, 好区分即可. Git Branch Name是待部署的Git分支, 每次访问Hook链接都会根据这个分支重新部署. 可以使用curl访问Hook链接: curl -X POST https://api.vercel.com/v1/integrations/deploy/QmcwKGEbAyFtfybXBxvuSjFT54dc5dRLmAYNB5jxxXsbeZ/hUg65Lj4CV POST 和 GET 请求都可以触发. 可能得到输出: { \"job\": { \"id\": \"A7OcAEEgNRh61p1VZXE1\", \"state\": \"PENDING\", \"createdAt\": 1564399503217 } } 尽量使用自己的Hook触发, 以免给他人带来不便. 手动访问这个链接太过麻烦, 这时候可以使用easycron. ","date":"2021-04-27","objectID":"/202104/autodeploy-vercel-easycron/:1:0","tags":["vercel","easycron","博客"],"title":"使用vercel和easycron实现自动部署","uri":"/202104/autodeploy-vercel-easycron/"},{"categories":["工具"],"content":"EasyCron 进入vercel个人页面, 在Integrations-\u003eMarketplace可以找到EasyCron这个工具. 添加工具, 并注册个人账号, 在EasyCron页面可以设置访问链接和定时. 在EasyCron页面点击Cron Job就可以方便的添加定时了. ","date":"2021-04-27","objectID":"/202104/autodeploy-vercel-easycron/:2:0","tags":["vercel","easycron","博客"],"title":"使用vercel和easycron实现自动部署","uri":"/202104/autodeploy-vercel-easycron/"},{"categories":["工具"],"content":"github webhooks 除了easycron的定时触发, 我们也可以使用github的webhooks实现事件触发. 在github仓库settings-\u003ewebhooks目录下, 可以给仓库添加webhooks, 可以实现在某些事件(比如push/star等)发生的情况下, 给某个url发送post请求. 这样我们就可以实现在blog内容更新的时候, 可以给vercel的waline项目的hook连接发送请求, 重新部署评论系统, 以达到更新评论系统的目的. ","date":"2021-04-27","objectID":"/202104/autodeploy-vercel-easycron/:3:0","tags":["vercel","easycron","博客"],"title":"使用vercel和easycron实现自动部署","uri":"/202104/autodeploy-vercel-easycron/"},{"categories":["工具"],"content":"总结 以上是简单记录, 开始刚接触vercel和easycron, 主要还是看看官网说明: Deploy Hooks. 如果接触过Linux上的cron则对easycron就很容易理解了. 不过刚开始对Hook理解错了, 认为访问Hook链接之后vercel会更新一笔到github上, 实际上不是的, vercel只做重新部署, 可以理解为重新从github上拉取代码然后部署. ","date":"2021-04-27","objectID":"/202104/autodeploy-vercel-easycron/:4:0","tags":["vercel","easycron","博客"],"title":"使用vercel和easycron实现自动部署","uri":"/202104/autodeploy-vercel-easycron/"},{"categories":["操作系统"],"content":"我们经常可以看到, 诸如Chrome/VSCode之类的程序打开运行的时候, 可以在后台看到会有多个相关进程启动. 同一个程序启动的不同进程间, 必然存在合作关系, 那么这些进程之间是如何合作的呢? ","date":"2021-04-23","objectID":"/202104/process-ctracon2/:0:0","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(二)","uri":"/202104/process-ctracon2/"},{"categories":["操作系统"],"content":"IPC 进程间通信也叫做IPC(InterPorcess Communication). 进程间通信可以让不同的进程共同合作完成某些任务. 不同进程的虚拟内存空间可能会映射到不同的物理内存空间, 但是虚拟内存空间中的虚拟内核空间都会映射到相同的物理内核空间, 因为一般认为系统的内核只有一个. 不同进程映射到相同物理内核空间 所以, 为了剔除用户空间映射不一致的影响, 可以在内核空间操作, 只要在内核空间中开辟相同的物理内存, 供不同进程访问, 那么就可以做到IPC. 内核提供共享区域做IPC 或者, 可以使用文件做IPC. 不同进程只要能够指向相同的文件, 再加上对文件的访问控制, 就可以在不同进程间通过文件系统通信. 使用文件系统做IPC 再或者, 可以通过我们熟知的网络链接做IPC. 通过网络做IPC ","date":"2021-04-23","objectID":"/202104/process-ctracon2/:1:0","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(二)","uri":"/202104/process-ctracon2/"},{"categories":["操作系统"],"content":"匿名管道 C提供了pipe函数用于创建管道. pipe是内核在内核空间提供的一段缓存区. ","date":"2021-04-23","objectID":"/202104/process-ctracon2/:2:0","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(二)","uri":"/202104/process-ctracon2/"},{"categories":["操作系统"],"content":"pipe /* Create a one-way communication channel (pipe). If successful, two file descriptors are stored in PIPEDES; bytes written on PIPEDES[1] can be read from PIPEDES[0]. Returns 0 if successful, -1 if not. */ extern int pipe (int __pipedes[2]) __THROW __wur; pipe输入参数是包含两个pipe描述符的二元数组. pipe执行失败返回-1, 执行成功则返回0, 同时第一个pipe描述符PIPEDES[0]指向pipe的读端, 第二个pipe描述符PIPEDES[1]指向pipe的写端. 调用pipe之后我们拿到了读写端口, 然后再调用fork函数, 现在父子进程都拿到了pipe的读写端口. 父子进程都拿到了pipe的读写端口 Create a one-way communication channel (pipe). 函数注释中已经说明, pipe是一个one-way communication channel, 只能一个通路, 也就是说只能从一端进一端出, 所以在父子进程必须确定谁来发送, 谁来接收, 不用的端口需要关闭. 下面的例子使用子进程写, 父进程读: #include\u003cstdio.h\u003e #include\u003cunistd.h\u003e #include\u003cstdlib.h\u003e #include\u003cstring.h\u003e int main() { int pipef[2] = {0, 0}; int ret = pipe(pipef); if (ret \u003c 0) { printf(\"create pipe error\\n\"); return -1; } printf(\"pipef[0] %d, pipef[1] %d\\n\", pipef[0], pipef[1]); int pid = fork(); if (pid \u003c 0) { printf(\"fork error\\n\"); return -1; } else if (pid == 0) { //close read close(pipef[0]); char msg[128] = \"pipe message.\"; int count = 5; while(count-- \u003e 0) { strcat(msg, \"+\"); int write_stat = write(pipef[1], msg, sizeof(msg)); printf(\"child send[%d]: %s\\n\", write_stat, msg); // sleep(1); } printf(\"write complete\\n\"); close(pipef[1]); } else { //close write close(pipef[1]); char msg[1024] = {0}; int count = 5; while(count-- \u003e 0) { int read_stat = read(pipef[0], msg, sizeof(msg)); if (read_stat \u003e 0) { printf(\"parent get[%d]: \", read_stat); for (int i = 0; i \u003c read_stat; i++) { printf(\"%c\", msg[i]); } printf(\"\\n\"); } } printf(\"read complete\\n\"); close(pipef[0]); } } 运行这段代码, 得到输出: pipef[0] 6, pipef[1] 7 child send[128]: pipe message.+ child send[128]: pipe message.++ child send[128]: pipe message.+++ child send[128]: pipe message.++++ child send[128]: pipe message.+++++ write complete parent get[640]: pipe message.+pipe message.++pipe message.+++pipe message.++++pipe message.+++++ read complete 并不符合预期, 子进程已经成功发送了五条信息, 但是父进程一口气全部读出来了, 为什么呢? 实际上这段程序每次执行的结果可能都不同. 这是因为pipe被设计为了循环队列, write负责从一端写, read负责从一端读. 上述问题在与, 还没开始读的时候, 写操作就完成了, 所以读的时候会将所有的数据读出(读的大小设置的1024B, 大于5次写128B共计640B). 所以, 将每次read的size改为每次写的size(=128), 就可以正常读出数据了: pipef[0] 6, pipef[1] 7 parent get[128]: pipe message.+ child send[128]: pipe message.+ child send[128]: pipe message.++ child send[128]: pipe message.+++ parent get[128]: pipe message.++ child send[128]: pipe message.++++ child send[128]: pipe message.+++++ parent get[128]: pipe message.+++ write complete parent get[128]: pipe message.++++ parent get[128]: pipe message.+++++ read complete 所有数据都正常写入和读出, 并且可见是异步的, 符合预期. 从上述信息中我们可以看到, 要使用pipe最好要在读写端约定写入的大小, 以保证可以按此大小读取. 一般来说, pipe读写可能会遇到四个问题: 读端和写端都是打开的, 但是还没有读, 这时候写端正常, 直到pipe被写满, 这会阻塞, 直到read将pipe里面的数据读出, pipe有空闲位置; 读端和写端都是打开的, 但是还没有写, 这时候如果pipe中有数据, 这正常读, 如果没有数据, 则阻塞, 直到往pipe里写入数据; 读端打开, 写端关闭, 这时候读端正常工作, 不阻塞, read返回值标识读到的数据大小, 为0则标识没有数据了; 读端关闭, 写端打开, 这时候会触发SIGPIPE信号, 此时往往是异常状态; ","date":"2021-04-23","objectID":"/202104/process-ctracon2/:2:1","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(二)","uri":"/202104/process-ctracon2/"},{"categories":["操作系统"],"content":"pipe全双工 使用两个pipe可以实现全双工通信. #include\u003cstdio.h\u003e #include\u003cunistd.h\u003e #include\u003cstdlib.h\u003e #include\u003cstring.h\u003e int main() { int pipef[2] = {0, 0}; int pipes[2] = {0, 0}; int ret = pipe(pipef); if (ret \u003c 0) { printf(\"create pipe error\\n\"); return -1; } ret = pipe(pipes); if (ret \u003c 0) { printf(\"create pipe error\\n\"); return -1; } printf(\"pipef[0] %d, pipef[1] %d\\n\", pipef[0], pipef[1]); printf(\"pipes[0] %d, pipes[1] %d\\n\", pipes[0], pipes[1]); int pid = fork(); if (pid \u003c 0) { printf(\"fork error\\n\"); return -1; } else if (pid == 0) { //close read close(pipef[0]); //close write close(pipes[1]); char msg[128] = \"child message.\"; int count = 5; while(count-- \u003e 0) { strcat(msg, \"+\"); int write_stat = write(pipef[1], msg, sizeof(msg)); printf(\"child send[%d]: %s\\n\", write_stat, msg); char read_msg[1024] = {0}; int read_stat = read(pipes[0], read_msg, sizeof(read_msg)); if (read_stat \u003e 0) { printf(\"get from parent: %s\\n\", read_msg); } } printf(\"child complete\\n\"); close(pipef[1]); close(pipes[0]); } else { //close write close(pipef[1]); //close read close(pipes[0]); char msg[128] = \"parent message.\"; int count = 5; while(count-- \u003e 0) { strcat(msg, \"+\"); int write_stat = write(pipes[1], msg, sizeof(msg)); printf(\"parent send[%d]: %s\\n\", write_stat, msg); char read_msg[1024] = {0}; int read_stat = read(pipef[0], read_msg, sizeof(read_msg)); if (read_stat \u003e 0) { printf(\"get from child: %s\\n\", msg); } } printf(\"parent complete\\n\"); close(pipef[0]); close(pipes[1]); } } 输出可能是: pipef[0] 6, pipef[1] 7 pipes[0] 8, pipes[1] 9 parent send[128]: parent message.+ child send[128]: child message.+ get from parent: parent message.+ child send[128]: child message.++ get from child: parent message.+ parent send[128]: parent message.++ get from parent: parent message.++ child send[128]: child message.+++ get from child: parent message.++ parent send[128]: parent message.+++ get from parent: parent message.+++ child send[128]: child message.++++ get from child: parent message.+++ parent send[128]: parent message.++++ get from parent: parent message.++++ child send[128]: child message.+++++ get from child: parent message.++++ parent send[128]: parent message.+++++ get from parent: parent message.+++++ child complete parent complete 可以看到, 读取的时候并没有和写入端约定大小, 但是这时候是可以正常读的, 为什么呢? 分析一下代码可能的逻辑: 子进程先走, 正常write, read的时候, pipe中没有数据, 则阻塞; 父进程走, 正常write, 子进程的read读到了数据, 退出阻塞, 父进程可以正常读到子进程write的数据; 父进程先走, 正常write, read的时候, pipe中没有数据, 则阻塞; 子进程走, 正常write, 父进程的read读到了数据, 退出阻塞, 子进程可以正常读到父进程write的数据; 所以, 无论父子进程怎么走, 都可以保证父子进程的正常读写. ","date":"2021-04-23","objectID":"/202104/process-ctracon2/:2:2","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(二)","uri":"/202104/process-ctracon2/"},{"categories":["操作系统"],"content":"pipe的容量和原子性 上面的例子都没有填满pipe, 也都默认了pipe的读写都是原子的. 到这里又想到了两个问题: pipe什么时候写满? pipe读写怎么保证是原子操作(读写一致性)? 使用man查看pipe的描述: man 7 pipe 关于pipe容量的. Pipe capacity In Linux versions before 2.6.11, the capacity of a pipe was the same as the system page size (e.g., 4096 bytes on i386). Since Linux 2.6.11, the pipe capacity is 16 pages (i.e., 65,536 bytes in a system with a page size of 4096 bytes). Since Linux 2.6.35, the default pipe capacity is 16 pages, but the capacity can be queried and set using the fcntl(2) F_GETPIPE_SZ and F_SETPIPE_SZ operations. See fcntl(2) for more information. pipe容量在不同的linux版本中不同, 从Linux 2.6.11开始是16Pages, 所以是$4096 Bytes \\times 16 Pages = 65535 Bytes$. 关于pipe如何保证一致性的. PIPE_BUF POSIX.1 says that write(2)s of less than PIPE_BUF bytes must be atomic: the output data is written to the pipe as a contiguous sequence. Writes of more than PIPE_BUF bytes may be nonatomic: the kernel may interleave the data with data written by other processes. POSIX.1 requires PIPE_BUF to be at least 512 bytes. (On Linux, PIPE_BUF is 4096 bytes.) 当写入的字节流大小不大PIPE_BUF时, pipe可以保证写入的原子性(读写一致性), 如果写入字节流大于PIPE_BUF则无法保证写入的原子性. PIPE_BUF至少时512Bytes, 在Linux上PIPE_BUF时$4096Bytes = 1Page$. ","date":"2021-04-23","objectID":"/202104/process-ctracon2/:2:3","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(二)","uri":"/202104/process-ctracon2/"},{"categories":["操作系统"],"content":"pipe源码 /* * sys_pipe() is the normal C calling standard for creating * a pipe. It's not the way Unix traditionally does this, though. */ static int do_pipe2(int __user *fildes, int flags) { struct file *files[2]; int fd[2]; int error; error = __do_pipe_flags(fd, files, flags); if (!error) { if (unlikely(copy_to_user(fildes, fd, sizeof(fd)))) { fput(files[0]); fput(files[1]); put_unused_fd(fd[0]); put_unused_fd(fd[1]); error = -EFAULT; } else { fd_install(fd[0], files[0]); fd_install(fd[1], files[1]); } } return error; } 基本可以看出来pipe涉及到了文件操作struct file *files[2];, pipe和pipe2函数是对do_pipe2的封装. 匿名管道不属于任何文件系统，只存在于内存中，它是无名无形的，但是可以把它看作一种特殊的文件，通过使用普通文件的read(), write()函数对管道进行操作. static int __do_pipe_flags(int *fd, struct file **files, int flags) { int error; int fdw, fdr; if (flags \u0026 ~(O_CLOEXEC | O_NONBLOCK | O_DIRECT)) return -EINVAL; error = create_pipe_files(files, flags); if (error) return error; error = get_unused_fd_flags(flags); if (error \u003c 0) goto err_read_pipe; fdr = error; error = get_unused_fd_flags(flags); if (error \u003c 0) goto err_fdr; fdw = error; audit_fd_pair(fdr, fdw); fd[0] = fdr; fd[1] = fdw; return 0; err_fdr: put_unused_fd(fdr); err_read_pipe: fput(files[0]); fput(files[1]); return error; } 创建pipe的时候会查找可用fd, 如果fd不够了, 则会创建pipe失败. 在日常开发中, fd如果没有正常释放, 则可能会导致fd不够. ","date":"2021-04-23","objectID":"/202104/process-ctracon2/:2:4","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(二)","uri":"/202104/process-ctracon2/"},{"categories":["操作系统"],"content":"小结 综上所述: pipe是半双工; 两个pipe可以实现全双工; pipe只能在具有亲缘关系的进程间通信; 读写端都存在时, pipe满则阻塞写端, pipe空则阻塞读端; 读端不存在, 则写时触发SIGPIPE信号, 写端不存在时, 读正常, 但是不阻塞; pipe传输的是字节流; pipe的最大容量一般是64Pages, 写入小于1Page的字节流可以保证读写一致性; Linux系统中的命令, 如ls | grep txt中的|就是匿名管道, 实现两个进程中的通信. ","date":"2021-04-23","objectID":"/202104/process-ctracon2/:2:5","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(二)","uri":"/202104/process-ctracon2/"},{"categories":["操作系统"],"content":"具名管道 上述讲了匿名管道, 没有一个标识符(名字)指向的管道, 所以一般只能用在亲缘进程中(创建时共享了内存). 试想, 如果给管道加上了名字, 是不是就可以在不同的进程间通信了呢? 这就是具名管道. 具名管道可以认为是pipe加上了名字. Linux中将这种具名管道叫做fifo. fifo和pipe类似, 但是可以在文件系统中找到fifo的管道文件, fifo文件是存在系统中的文件. 进程可以根据fifo的名字打开fifo, 并对其读写, 但是进程会将fifo的数据缓存在内核中(类比pipe), 并不会将数据写入文件, 所以在fifo文件中也无法找到对fifo写入的数据. 我们可以使用ls -lh命令, 看到系统中的fifo文件, 如: prwxrwxr-x 1 ** ** 0 4月 25 17:37 ./fifo_pipe 权限一栏的p就标识这是一个pipe(管道, 要和上述的pipe函数区分一下)文件. 如果ll看的话, 会有类似以下输出: prwxrwxr-x 1 ** ** 0 4月 25 17:37 fifo_pipe| -rwxrwxr-x 1 ** ** 8616 4月 25 17:17 fifo_read* -rw-rw-r-- 1 ** ** 704 4月 25 17:42 fifo_read.c -rwxrwxr-x 1 ** ** 8744 4月 25 17:18 fifo_write* -rw-rw-r-- 1 ** ** 1630 4月 25 17:35 fifo_write.c fifo_pipe作为一个管道文件, 会有p字符标识, 文件名后也有|标识. 同pipe, fifo也可以使用open, write等IO接口函数对其操作. 人如其名, fifo的结构如下, 是内核中的一个先进先出的队列, 比如只能在尾部写入, 那么就只能在头部读出, 所以, 如果对应多个进程读写时, 就要约定写入的size和标识符规则. FIFO管道结构 关于fifo跟官方的内容可以: man fifo C提供了mkfifo函数用于创建fifo(创建, 不是打开). ","date":"2021-04-23","objectID":"/202104/process-ctracon2/:3:0","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(二)","uri":"/202104/process-ctracon2/"},{"categories":["操作系统"],"content":"mkfifo mkfifo需要传入fifo的路径和fifo打开模式. /* Create a new FIFO named PATH, with permission bits MODE. */ extern int mkfifo (const char *__path, __mode_t __mode) __THROW __nonnull ((1)); 如果fifo文件路径已经存在, 则mkfifo会报错, 如果fifo文件不存在, 则mkfifo会根据fifo路径创建fifo文件. 所以在调用mkfifo的时候, 需要判断fifo路径是否已经存在: if(access(fifo_name, F_OK) == -1) { printf(\"[%d] make fifo...\\n\", getpid()); int stats = mkfifo(fifo_name, 0777); if (stats != 0) { printf(\"[%d] make fifo error.\\n\", getpid()); return -1; } } ","date":"2021-04-23","objectID":"/202104/process-ctracon2/:3:1","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(二)","uri":"/202104/process-ctracon2/"},{"categories":["操作系统"],"content":"fifo读写 如果fifo管道文件已经存在, 可以通过open打开, 通过write写入. // fifo_write.c #include \u003cunistd.h\u003e #include \u003cstdlib.h\u003e #include \u003cstdio.h\u003e #include \u003cfcntl.h\u003e #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e #include \u003climits.h\u003e #include \u003cstring.h\u003e static const char* fifo_name = \"./fifo_pipe\"; int main() { if(access(fifo_name, F_OK) == -1) { printf(\"[%d] make fifo...\\n\", getpid()); int stats = mkfifo(fifo_name, 0777); if (stats != 0) { printf(\"[%d] make fifo error.\\n\", getpid()); return -1; } } int fifo_fd = open(fifo_name, O_WRONLY); printf(\"[%d] writer open fifo fd %d\\n\", getpid(), fifo_fd); if (fifo_fd != -1) { char msg[128] = \"fifo write.\"; int write_stat = write(fifo_fd, msg, sizeof(msg)); printf(\"[%d] fifo write[%d]: '%s'\\n\", getpid(), write_stat, msg); } close(fifo_fd); return 1; } 如果fifo管道文件已经存在, 可以通过open打开, 通过read读出. // fifo_read.c #include \u003cunistd.h\u003e #include \u003cstdlib.h\u003e #include \u003cstdio.h\u003e #include \u003cfcntl.h\u003e #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e #include \u003climits.h\u003e #include \u003cstring.h\u003e static const char* fifo_name = \"./fifo_pipe\"; int main() { if(access(fifo_name, F_OK) == -1) { printf(\"[%d] reader get fifo error.\\n\", getpid()); return -1; } printf(\"[%d] read prepare open fifo.\\n\", getpid()); int fifo_fd = open(fifo_name, O_RDONLY); printf(\"[%d] open fifo fd %d\\n\", getpid(), fifo_fd); if (fifo_fd != -1) { char msg[128]; int read_stat = read(fifo_fd, msg, sizeof(msg)); printf(\"[%d] fifo read[%d]: '%s'\\n\", getpid(), read_stat, msg); } close(fifo_fd); return 1; } 编译两个文件: gcc -o fifo_read ./fifo_read.c gcc -o fifo_write ./fifo_write.c 如果我们先执行fifo_write再执行fifo_read, fifo_write正常执行和退出, 但是fifo_read会阻塞不退出. 如果我们先执行fifo_read再执行fifo_write, 则fifo_read会先阻塞不退出, 待执行fifo_write并写入fifo后, fifo_read从fifo读取成功, 并退出. 关于fifo的read和write阻塞操作, 可以有以下结论: 以O_RDONLY读和O_WRONLY写时, 如果只有进程读, 没有进程写, 则读端会阻塞, 直到有进程写; 以O_RDONLY读和O_WRONLY写时, 如果只有进程写, 没有进程读, 写端不会阻塞(网上查了几份资料的结论时会阻塞, 但是实验代码是不会阻塞的(TODO:官方说法待查证)); 可以验证, 如果以O_RDONLY|O_WRONLY打开, 依然正常工作, 但是无法保证fifo的时序, 这时候A进程write的数据也可能从A进程read出来. 所以如果要fifo实现全双工, 比较简单的方式同pipe, 使用两个fifo实现. ","date":"2021-04-23","objectID":"/202104/process-ctracon2/:3:2","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(二)","uri":"/202104/process-ctracon2/"},{"categories":["操作系统"],"content":"小结 我们简单使用mkfifo创建了fifo文件, 并且使用open, read, write实现了对fifo的操作, 以上总结: fifo是一个真实存在的文件, 可以在文件系统中找到; fifo数据存储在内核内存的缓存区中, 不会写入到fifo文件; 以O_RDONLY读时, 如果没有写端写入数据, 则open会阻塞; fifo可以全双工, 但是可以使用两个fifo解决时序问题; 同pipe, fifo也依赖pipe capacity和PIPE_BUF决定缓存上限和保证原子性的最大Size; ","date":"2021-04-23","objectID":"/202104/process-ctracon2/:3:3","tags":["进程","进程通信","虚拟内存","Linux"],"title":"进程控制和通信(二)","uri":"/202104/process-ctracon2/"},{"categories":["操作系统"],"content":"Linux系统的进程由PCB(Process Control Block)管理. ","date":"2021-04-21","objectID":"/202104/process-ctracon1/:0:0","tags":["进程","进程通信","虚拟内存","Linux","PCB","task_struct"],"title":"进程控制和通信(一)","uri":"/202104/process-ctracon1/"},{"categories":["操作系统"],"content":"PCB 推荐https://code.woboq.org/阅读linux源码. Linux PCB 可以在https://code.woboq.org/linux/linux/include/linux/sched.h.html#task_struct找到, 对应task_struct结构体. struct task_struct { #ifdef CONFIG_THREAD_INFO_IN_TASK /* * For reasons of header soup (see current_thread_info()), this * must be the first element of task_struct. */ struct thread_info thread_info; #endif /* -1 unrunnable, 0 runnable, \u003e0 stopped: */ volatile long state; /* * This begins the randomizable portion of task_struct. Only * scheduling-critical items should be added above here. */ randomized_struct_fields_start void *stack; refcount_t usage; /* Per task flags (PF_*), defined further below: */ unsigned int flags; unsigned int ptrace; #ifdef CONFIG_SMP struct llist_node wake_entry; int on_cpu; #ifdef CONFIG_THREAD_INFO_IN_TASK /* Current CPU: */ unsigned int cpu; #endif unsigned int wakee_flips; unsigned long wakee_flip_decay_ts; struct task_struct *last_wakee; /* * recent_used_cpu is initially set as the last CPU used by a task * that wakes affine another task. Waker/wakee relationships can * push tasks around a CPU where each wakeup moves to the next one. * Tracking a recently used CPU allows a quick search for a recently * used CPU that may be idle. */ int recent_used_cpu; int wake_cpu; #endif int on_rq; int prio; int static_prio; int normal_prio; unsigned int rt_priority; const struct sched_class *sched_class; struct sched_entity se; struct sched_rt_entity rt; #ifdef CONFIG_CGROUP_SCHED struct task_group *sched_task_group; #endif struct sched_dl_entity dl; #ifdef CONFIG_PREEMPT_NOTIFIERS /* List of struct preempt_notifier: */ struct hlist_head preempt_notifiers; #endif #ifdef CONFIG_BLK_DEV_IO_TRACE unsigned int btrace_seq; #endif unsigned int policy; int nr_cpus_allowed; cpumask_t cpus_allowed; #ifdef CONFIG_PREEMPT_RCU int rcu_read_lock_nesting; union rcu_special rcu_read_unlock_special; struct list_head rcu_node_entry; struct rcu_node *rcu_blocked_node; #endif /* #ifdef CONFIG_PREEMPT_RCU */ #ifdef CONFIG_TASKS_RCU unsigned long rcu_tasks_nvcsw; u8 rcu_tasks_holdout; u8 rcu_tasks_idx; int rcu_tasks_idle_cpu; struct list_head rcu_tasks_holdout_list; #endif /* #ifdef CONFIG_TASKS_RCU */ struct sched_info sched_info; struct list_head tasks; #ifdef CONFIG_SMP struct plist_node pushable_tasks; struct rb_node pushable_dl_tasks; #endif struct mm_struct *mm; struct mm_struct *active_mm; /* Per-thread vma caching: */ struct vmacache vmacache; #ifdef SPLIT_RSS_COUNTING struct task_rss_stat rss_stat; #endif int exit_state; int exit_code; int exit_signal; /* The signal sent when the parent dies: */ int pdeath_signal; /* JOBCTL_*, siglock protected: */ unsigned long jobctl; /* Used for emulating ABI behavior of previous Linux versions: */ unsigned int personality; /* Scheduler bits, serialized by scheduler locks: */ unsigned sched_reset_on_fork:1; unsigned sched_contributes_to_load:1; unsigned sched_migrated:1; unsigned sched_remote_wakeup:1; #ifdef CONFIG_PSI unsigned sched_psi_wake_requeue:1; #endif /* Force alignment to the next boundary: */ unsigned :0; /* Unserialized, strictly 'current' */ /* Bit to tell LSMs we're in execve(): */ unsigned in_execve:1; unsigned in_iowait:1; #ifndef TIF_RESTORE_SIGMASK unsigned restore_sigmask:1; #endif #ifdef CONFIG_MEMCG unsigned in_user_fault:1; #endif #ifdef CONFIG_COMPAT_BRK unsigned brk_randomized:1; #endif #ifdef CONFIG_CGROUPS /* disallow userland-initiated cgroup migration */ unsigned no_cgroup_migration:1; #endif #ifdef CONFIG_BLK_CGROUP /* to be used once the psi infrastructure lands upstream. */ unsigned use_memdelay:1; #endif unsigned long atomic_flags; /* Flags requiring atomic access. */ struct restart_block restart_block; pid_t pid; pid_t tgid; #ifdef CONFIG_STACKPROTECTOR /* Canary value for the -fstack-protector GCC feature: */ unsigned long stack_canary; #endif /* * Pointers to the (original) parent process, youngest child, younger sibling, * older sibling, respectively. (p-\u003efather can be replaced with * p-\u003ereal_parent-\u003ep","date":"2021-04-21","objectID":"/202104/process-ctracon1/:1:0","tags":["进程","进程通信","虚拟内存","Linux","PCB","task_struct"],"title":"进程控制和通信(一)","uri":"/202104/process-ctracon1/"},{"categories":["操作系统"],"content":"fork C语言中的fork用于创建进程. 如上一篇我们讲的进程是系统进行资源分配的最小单元, 所以在创建进程的时候, 自然而然主要是考虑进程的资源如何创建. C语言中的fork类似于github中的fork, 会把资源\"完全\"复制一份. 类比github, fork一个仓库, 在fork的时候, 原始仓库和fork之后的仓库内容完全一样, 并且在新仓库会有指针(链接)指向原始仓库, fork之后两个仓库的修改完全无关, 仓库内容开始分叉. 调用C语言的fork, 先是会复制调用进程的上下文, 包括虚拟空间, 映射关系, 调用栈等等, 然后会激活一个新的进程, 这个新的进程是调用进程的子进程, 调用进程是新进程的父进程. 如上述, 子进程会复制父进程的资源, 所以子进程也会有和父进程相同的PC指针, 在fork调用返回后, 父进程和子进程都会从程序的同一地址开始运行(即fork函数之后), 但是父子进程开始走向分化, 互不相关. 如下图, fork之后子进程会复制父进程的资源, PC指针指向相同的虚拟地址, 所以子进程从fork的位置开始运行. fork复制进程 以上, 调用fork即会生成一个新的进程, 通过fork的返回值pid可以判断当前进程是父进程还是子进程. int pid = fork(); if (pid \u003c 0) { // fork error } else if (pid == 0) { // children processor } else { // parrent processor } 我们可以验证一下fork父子进程互不干扰的结论: void inc(const char* s, int pid, int i) { printf(\"%s processor [%d %d] %d\\n\", s, getppid(), getpid(), i); } int main() { volatile int i = 0; int pid = fork(); i = 100; if (pid \u003c 0) { printf(\"fork error\"); return -1; } else if (pid == 0) { for (int j = 0; j \u003c 100; j++) { inc(\"child\", pid, i++); } } else { for (int j = 0; j \u003c 20; j++) { inc(\"parent\", pid, i++); } } i = 0; return 0; } 使用volatile保证变量i保存在内存而不是寄存器. fork会创建子进程循环100次输出, 父进程循化20次输出. 编译执行我们可以看到子进程从100-199输出, 父进程从100-119输出, 互不干扰. 同时我们printf了父进程ID和当前进程ID, 可以看到: parent processor [29629 20195] 100 parent processor [29629 20195] 101 parent processor [29629 20195] 102 29629是父进程ID, 20195是当前进程ID, 当前进程就是我们执行的程序, 所以这里的父进程就是执行程序的终端的进程. 子进程被唤醒执行后, 有如下输出: child processor [20195 20196] 100 parent processor [29629 20195] 110 child processor [20195 20196] 101 parent processor [29629 20195] 111 20195就是当前程序进程ID, 20196是fork之后的子进程ID. 最后也会有一些\"不符合预期\"的输出: child processor [1 20196] 138 child processor [1 20196] 139 child processor [1 20196] 140 子进程的父进程ID变成了1? 因为这时候原来执行程序的进程(20195)已经退出了, Linux一般不允许进程没有父进程, 所以得为还在执行的子进程找到一个父进程, 这就是1号进程. Linux中0号进程是内核启动进程, 也就是系统第一个启动的进程. 0号进程会创建一个新的进程, 即1号进程, 1号进程负责启动init程序并监视其他进程. ","date":"2021-04-21","objectID":"/202104/process-ctracon1/:2:0","tags":["进程","进程通信","虚拟内存","Linux","PCB","task_struct"],"title":"进程控制和通信(一)","uri":"/202104/process-ctracon1/"},{"categories":["操作系统"],"content":"写时复制 我们可以想到一个问题, 如果fork完全复制进程的上下文, 势必会造成资源浪费. 比如一个进程快要执行完了, 这时候通过缺页中断这个进程在物理内存中已经占据了不少的空间, 如果fork完全复制则子进程也需要复制父进程的物理内存. 可以想象, 在fork之前, 可以认为这有两个完全一样的进程, 所有内容共享, fork之后两进程开始分叉. 如果是完全复制, 则fork之前共享的内容也需要全部复制, 但是新进程不一定还需要使用之前的内容了, 这时候就会造成资源的浪费. 上述例子比较片面, 需要表达意思就是fork不需要完全复制物理内存, 因为可能有些是不需要再访问的. Linux帧对这种潜在的资源浪费提出的解法就是写时复制. 在fork的时候完全不复制物理内存, 仅复制虚拟内存和映射表. 所以在fork返回之后, 父子进程是共享的物理内存. 只有在有写操作时, 才会触发中断, 重新在物理内存中申请内存空间, 以区分父子进程的资源. 如下图, 是fork执行之后的某个时刻, 父子进程的PC指向将会分化, 指向不同的虚拟地址, 映射表的映射关系也会出现分化, 指向不同的物理内存或者不同的磁盘地址, 两者互不干扰. 需要注意的是, 图中标注的fork之前的地址映射关系相同, 并不是说fork所在地址之前的映射关系就一定会相同, 实际上也可能不同, 因为fork之后父子进程的某些操作也可能影响之前的值. 写时复制 写时复制的好处就是可以减少资源浪费, 能共享的就共享, 不能共享的就重新创建. 但是我认为写时复制也有一些性能问题, 比如需要在进程运行时不断触发中断, 如果包含频繁写操作的程序运行, 使用写时复制可能会比完全复制的时间复杂度更高. ","date":"2021-04-21","objectID":"/202104/process-ctracon1/:2:1","tags":["进程","进程通信","虚拟内存","Linux","PCB","task_struct"],"title":"进程控制和通信(一)","uri":"/202104/process-ctracon1/"},{"categories":["操作系统"],"content":"一秒死机程序 在学习fork之前, 如果写一些让电脑死机的恶作剧程序可能只会想到开大量线程, 然后线程不停申请内存空间, 使内存占满. 学习fork之后, 我们就可以用fork来干活了. 进程作为系统资源分配的最小单元, 相比于线程会消耗系统更多的资源(线程一般也就共享一个进程的资源), 所以我们可以写一个程序, 不停的创建进程, 这样系统中就会充斥大量的无用进程, 无用进程多到一定数量的时候, 系统命中有用进程的概率就会降低. 并且, 一般系统都会有最大进程数, 一般是65535, 如果无用进程把所有有效pid用完了, 则正常进程将无pid可分配, 也就可能造成正常无法启动. 流程如下图, 父进程不停创建子进程, 子进程死循环, 不停malloc和memset. 如上一篇所说, malloc只分配了虚拟内存, 当我们访问的时候会触发缺页中断, 才会真正分配物理内存, 所以malloc之后memset一下. 死机fork流程 下面来干活, 代码很少: #include \u003cstdlib.h\u003e #include \u003cunistd.h\u003e int main() { while(1) { int pid = fork(); if (pid \u003c 0) {return 1;} else if (pid == 0) { break; } else { continue; } } int i = 0; while(1) { long long s = sizeof(int) * 1024 * 1024; int *p = malloc(s); memset(p, i++, s); } return 1; } 保存代码为onesecond.c, 记得先保存重要文件, 编译并执行: gcc -o onesecond ./onesecond.c \u0026\u0026 ./onesecond 也可以下载编译好的程序, 点击下载. 好了, 不出意外, 数秒内你的电脑就死机了. ","date":"2021-04-21","objectID":"/202104/process-ctracon1/:2:2","tags":["进程","进程通信","虚拟内存","Linux","PCB","task_struct"],"title":"进程控制和通信(一)","uri":"/202104/process-ctracon1/"},{"categories":["操作系统"],"content":"再探fork 再来深入了解一下fork. 搜索fork, 可以找到_do_fork函数 /* * Ok, this is the main fork-routine. * * It copies the process, and if successful kick-starts * it and waits for it to finish using the VM if required. */ long _do_fork(unsigned long clone_flags, unsigned long stack_start, unsigned long stack_size, int __user *parent_tidptr, int __user *child_tidptr, unsigned long tls) { struct completion vfork; struct pid *pid; struct task_struct *p; int trace = 0; long nr; // 根据clone_flags判断clone分支 /* * Determine whether and which event to report to ptracer. When * called from kernel_thread or CLONE_UNTRACED is explicitly * requested, no event is reported; otherwise, report if the event * for the type of forking is enabled. */ if (!(clone_flags \u0026 CLONE_UNTRACED)) { if (clone_flags \u0026 CLONE_VFORK) trace = PTRACE_EVENT_VFORK; else if ((clone_flags \u0026 CSIGNAL) != SIGCHLD) trace = PTRACE_EVENT_CLONE; else trace = PTRACE_EVENT_FORK; if (likely(!ptrace_event_enabled(current, trace))) trace = 0; } //根据clone_flags copy_process p = copy_process(clone_flags, stack_start, stack_size, child_tidptr, NULL, trace, tls, NUMA_NO_NODE); add_latent_entropy(); if (IS_ERR(p)) return PTR_ERR(p); /* * Do this prior waking up the new thread - the thread pointer * might get invalid after that point, if the thread exits quickly. */ trace_sched_process_fork(current, p); pid = get_task_pid(p, PIDTYPE_PID); nr = pid_vnr(pid); if (clone_flags \u0026 CLONE_PARENT_SETTID) put_user(nr, parent_tidptr); if (clone_flags \u0026 CLONE_VFORK) { p-\u003evfork_done = \u0026vfork; init_completion(\u0026vfork); get_task_struct(p); } //唤醒子进程 wake_up_new_task(p); /* forking complete and child started to run, tell ptracer */ if (unlikely(trace)) ptrace_event_pid(trace, pid); if (clone_flags \u0026 CLONE_VFORK) { if (!wait_for_vfork_done(p, \u0026vfork)) ptrace_event_pid(PTRACE_EVENT_VFORK_DONE, pid); } put_pid(pid); return nr; } 大概分为三段: 根据clone_flags选择需要clone的内容; 唤醒子进程 获取并返回子进程pid clone_flags可选项. 注意 clone_flags的被宏__USE_GNU保护了, 所以在使用的时候要记得#define __USE_GNU. #ifdef __USE_GNU /* Cloning flags. */ # define CSIGNAL 0x000000ff /* Signal mask to be sent at exit. */ # define CLONE_VM 0x00000100 /* Set if VM shared between processes. */ # define CLONE_FS 0x00000200 /* Set if fs info shared between processes. */ # define CLONE_FILES 0x00000400 /* Set if open files shared between processes. */ # define CLONE_SIGHAND 0x00000800 /* Set if signal handlers shared. */ # define CLONE_PTRACE 0x00002000 /* Set if tracing continues on the child. */ # define CLONE_VFORK 0x00004000 /* Set if the parent wants the child to wake it up on mm_release. */ # define CLONE_PARENT 0x00008000 /* Set if we want to have the same parent as the cloner. */ # define CLONE_THREAD 0x00010000 /* Set to add to same thread group. */ # define CLONE_NEWNS 0x00020000 /* Set to create new namespace. */ # define CLONE_SYSVSEM 0x00040000 /* Set to shared SVID SEM_UNDO semantics. */ # define CLONE_SETTLS 0x00080000 /* Set TLS info. */ # define CLONE_PARENT_SETTID 0x00100000 /* Store TID in userlevel buffer before MM copy. */ # define CLONE_CHILD_CLEARTID 0x00200000 /* Register exit futex and memory location to clear. */ # define CLONE_DETACHED 0x00400000 /* Create clone detached. */ # define CLONE_UNTRACED 0x00800000 /* Set if the tracing process can't force CLONE_PTRACE on this clone. */ # define CLONE_CHILD_SETTID 0x01000000 /* Store TID in userlevel buffer in the child. */ # define CLONE_NEWCGROUP 0x02000000 /* New cgroup namespace. */ # define CLONE_NEWUTS 0x04000000 /* New utsname group. */ # define CLONE_NEWIPC 0x08000000 /* New ipcs. */ # define CLONE_NEWUSER 0x10000000 /* New user namespace. */ # define CLONE_NEWPID 0x20000000 /* New pid namespace. */ # define CLONE_NEWNET 0x40000000 /* New network namespace. */ # define CLONE_IO 0x80000000 /* Clone I/O context. */ #endif 上述调用的fork函数定义如下: #ifdef __ARCH_WANT_SYS_FORK SYSCALL_DEFINE0(fork) { #ifdef CONFIG_MMU //17 = 0x11 return _do_fork(SIGCHLD, 0, 0, NULL, NULL, 0); #else /* can not support in nommu mode */ return -EINV","date":"2021-04-21","objectID":"/202104/process-ctracon1/:2:3","tags":["进程","进程通信","虚拟内存","Linux","PCB","task_struct"],"title":"进程控制和通信(一)","uri":"/202104/process-ctracon1/"},{"categories":["操作系统"],"content":"vfork 搜索vfork, 可以找到vfork的代码: #ifdef __ARCH_WANT_SYS_VFORK SYSCALL_DEFINE0(vfork) { return _do_fork(CLONE_VFORK | CLONE_VM | SIGCHLD, 0, 0, NULL, NULL, 0); } #endif 同fork, vfork也是调用_do_fork函数, 只是参数不一样. 相比与fork, vfork的clone_flags增加了CLONE_VFORK和两个属性CLONE_VM. CLONE_VM使得父子进程享受相同的虚拟地址空间, CLONE_VFORK使得父进程被挂起直到被子进程唤醒. (有点像线程了) # define CLONE_VM 0x00000100 /* Set if VM shared between processes. */ # define CLONE_VFORK 0x00004000 /* Set if the parent wants the child to wake it up on mm_release. */ 同样, 实验一下vfork的功能. void inc(const char* s, int pid, int i) { printf(\"%s processor [%d %d] %d\\n\", s, getppid(), getpid(), i); } int main() { volatile int i = 0; int pid = vfork(); i = 100; if (pid \u003c 0) { printf(\"fork error\"); return -1; } else if (pid == 0) { for (int j = 0; j \u003c 100; j++) { inc(\"child\", pid, i++); } } else { for (int j = 0; j \u003c 20; j++) { inc(\"parent\", pid, i++); } } i = 0; return 0; } 程序会先输出child, child输出完后才会输出parent, 但是在程序执行最后会出现异常: parent processor [29629 23216] 118 parent processor [29629 23216] 119 Segmentation fault (core dumped) 因为调用vfork, 子进程需要使用exit或者exec才能不阻塞父进程. 所以我们将最后的return 0;改为exit(0);就可以了. vfork的出现本来是为了解决fork太过笨重的问题, 在没有写时复制策略之前, fork成本太高, 所以实现了vfork做轻量级的进程. ","date":"2021-04-21","objectID":"/202104/process-ctracon1/:3:0","tags":["进程","进程通信","虚拟内存","Linux","PCB","task_struct"],"title":"进程控制和通信(一)","uri":"/202104/process-ctracon1/"},{"categories":["操作系统"],"content":"clone 同样, 我们可以找到clone的实现: #ifdef __ARCH_WANT_SYS_CLONE #ifdef CONFIG_CLONE_BACKWARDS SYSCALL_DEFINE5(clone, unsigned long, clone_flags, unsigned long, newsp, int __user *, parent_tidptr, unsigned long, tls, int __user *, child_tidptr) #elif defined(CONFIG_CLONE_BACKWARDS2) SYSCALL_DEFINE5(clone, unsigned long, newsp, unsigned long, clone_flags, int __user *, parent_tidptr, int __user *, child_tidptr, unsigned long, tls) #elif defined(CONFIG_CLONE_BACKWARDS3) SYSCALL_DEFINE6(clone, unsigned long, clone_flags, unsigned long, newsp, int, stack_size, int __user *, parent_tidptr, int __user *, child_tidptr, unsigned long, tls) #else SYSCALL_DEFINE5(clone, unsigned long, clone_flags, unsigned long, newsp, int __user *, parent_tidptr, int __user *, child_tidptr, unsigned long, tls) #endif { return _do_fork(clone_flags, newsp, 0, parent_tidptr, child_tidptr, tls); } #endif #ifdef __USE_GNU /* Clone current process. */ extern int clone (int (*__fn) (void *__arg), void *__child_stack, int __flags, void *__arg, ...) __THROW; //... #endif C语言线程库, 最终调用的也是clone函数. clone最终调用_do_fork, 但是功能比fork更加强大, 传入函数指针, 子进程栈空间, clone_flag, 和函数参数, 就可以实现在子进程中调用函数, 这就是我们常用的线程. 简单使用一下clone: int addone(int *n) { *n = 21; printf(\"[%d %d] add one %d\\n\", getppid(), getpid(), (*n)); } int main() { volatile int n = 0; void* st; st = malloc(FIBER_STACK); if (!st) { printf(\"error malloc\\n\"); return -1; } printf(\"create clone\\n\"); printf(\"[%d %d] before add %d\\n\", getppid(), getpid(), n); clone(\u0026addone, (char *)st + FIBER_STACK, CLONE_VM|CLONE_VFORK, \u0026n); printf(\"[%d %d] after add %d\\n\", getppid(), getpid(), n); free(st); return 1; } 输出是: create clone [29629 25737] before add 0 [25737 25738] add one 21 [29629 25737] after add 21 即在子进程中的修改可以作用到父进程上. ","date":"2021-04-21","objectID":"/202104/process-ctracon1/:4:0","tags":["进程","进程通信","虚拟内存","Linux","PCB","task_struct"],"title":"进程控制和通信(一)","uri":"/202104/process-ctracon1/"},{"categories":["操作系统"],"content":"总结 这一篇介绍了PCB, Linux进程控制主要是操作PCB, PCB主要包含进程ID, 内核栈, 权限, 虚拟内存, CPU资源等信息. Linux使用了写时复制(COW)技术降低进程fork操作的成本. 子进程共享父进程的内存资源, 只有在写操作时, 子进程才会复制对应的内存区域. glibc库提供了fork, vfork, clone几个函数用来创建进程. fork创建的进程和父进程互不干扰, vfork创建的进程会阻塞父进程, 直到子进程调用exit或者exec. fork和vfork都是通过函数返回值判断是父进程还是子进程. clone提供比较高级的进程功能, 可以开一个进程来运行函数, 并且子进程的修改可以作用在父进程上, pthread库也是通过调用clone实现的. ","date":"2021-04-21","objectID":"/202104/process-ctracon1/:5:0","tags":["进程","进程通信","虚拟内存","Linux","PCB","task_struct"],"title":"进程控制和通信(一)","uri":"/202104/process-ctracon1/"},{"categories":["操作系统"],"content":"概念 问题: 什么是进程/线程/协程? 为什么要有这些概念? 读了一些文章, 要讲清楚这几个概念篇幅会很大, 所以会作为一个小专题来分享. 这篇的目的就是宏观上要对进程/线程/协程有基本的概念. ","date":"2021-04-15","objectID":"/202104/pandt-what/:1:0","tags":["进程","线程","协程","虚拟内存","Linux"],"title":"进程、线程和协程概念","uri":"/202104/pandt-what/"},{"categories":["操作系统"],"content":"进程 一般来说, 进程是操作系统资源分配和调度的最小单位. 运行一个程序, 我们会说这个程序占了多少内存, CPU利用率是多少, 磁盘读写效率是多少等等, 内存/CPU/磁盘等等都是进程的资源. 换句话说, 在资源分配的问题上, 可以认为操作系统只认进程, 一切资源都是按照进程为单位分配的. 进程是动态的, 只有在程序运行的时候才会有进程资源的分配; 程序则是静态的, 程序是躺在磁盘中的数据; 进程就是程序运行的一个实例; 一个程序可以有很多个进程, 比如我们打开Chrome的时候, 可以在后台看到多个Chrome进程对应Chrome这一个程序. 对用户来说, 一般是不需要过度关心进程资源的, 这些都是操作系统帮我们做了. 比如写完一段代码, 运行它, 代码是在磁盘上的, 怎么加载进内存, 需要分配多少内存空间, 需要如何调度这个程序, 都是由操作系统完成, 用户无需干预. 在多任务时代, CPU一般是不会将其精力一直放在某一个进程上的, 而是雨露均沾, 会给每一个进程都分配一定的时间片用来执行(和操作系统的调度算法有关). 这里就会涉及到进程的切换, 进程切换是需要保存和加载进程上下文的, 进程的上下文就是与该进程执行相关的一些参数和配置. 进程的上下文 简单记录进程上下文的大概内容: 各种寄存器 内存映射信息 环境变量信息, 比如程序所在目录等信息 打开的设备或者文件信息, 比如权限等信息 进程运行状态信息, 比如各种进程数据和堆栈信息 系统信息, 对进程管理和控制的信息, 比如进程任务结构体和内核堆栈(不太明白) 进程的内存资源 虚拟内存 问题: 程序从磁盘加载到内存的时候, 程序中的函数/变量等等都是用地址指代的, 也就是说, 编译完成之后, 这些地址是固定的. 如果同时运行两个程序, 他们的地址空间恰好冲突了怎么办? 这个问题在单核单任务时代是不那么容易出现的, 因为系统一次只跑一个进程, 跑完一个进程才会跑下一个进程, 所以基本不存在内存冲突的问题. 但是在多任务时代, 则是非常严重的问题, 编译器无法为每个程序分配不同的内存地址以保证不冲突. 这时候就用到了虚拟内存空间. 虚拟内存和物理内存 虚拟内存空间通俗的说就是假的内存空间, 它欺骗了进程, 让进程以为它有了整个物理内存的资源, 甚至更大. 比如一段代码编译之后, 某个变量a的地址在P, 编译时仅仅是给了一个虚拟的内存地址, 当然对于进程来说, 这个地址和真正的物理地址没有区别, 通过虚拟内存技术进程是完全无需关心的. 在程序执行的时候, 系统会为程序随机地分配一定的物理内存空间, 然后将程序加载进内存. 这时候的变量a对进程来说地址还是P, 但是对物理内存来说, 地址可能变成了Q, 程序退出下次再执行的时候, 变量a的物理地址又可能变成R. 那么, 当要访问变量a的时候怎么办呢? 这时候我只知道a的虚拟地址无法拿到它的物理地址啊. 操作系统的做法是建立内存映射表, 将进程的虚拟内存空间映射到物理内存空间. 有了映射关系, 就可以很容易的通过虚拟内存找到物理内存, 从而访问对应的值了. 如果是每一个虚拟地址都有映射关系, 也引发其他的问题: 我们至少需要两个空间(比如说都是8B)存储一个映射关系, 即[虚拟地址, 物理地址]. 如果对每个虚拟地址都有这样的映射关系的话, 可能会浪费至少两倍的内存. 怎么办呢? 解决方法是不要对每个地址都建立映射关系, 而是对一段连续的地址建立映射关系, 这就是页. 比如规定每个页的大小是1KB, 则1KB的空间只需要一个映射关系就可以表示, 即[页首地址, 物理地址]. 当从磁盘将程序装载进内存的时候, 根据映射表每次都在物理内存上开辟一页的空间. 当需要访问某个变量时, 通过变量虚拟地址在这一页的偏移和页首地址的映射关系就可以得到这个变量在物理内存中的物理地址. 然而, 程序一般都不是一次性加载进内存的. 内存映射表 问题: 内存映射表是如何建立且如何访问的呢? 上述中, 我们讲到了比较朴素的内存映射的结构是[虚拟地址, 物理地址]. 实际上内存映射表一般结构是这样的: 内存映射表 物理内存和虚拟内存一样, 都按照一页一页的划分. 在内存映射表中, 实际上是将虚拟内存的页映射到物理内存页上. 状态一栏表示虚拟内存页的状态, 一般分为三种: 已缓存, 在物理内存上已经缓存了对应的数据 未缓存, 物理内存上还没有缓存对应数据, 数据还在磁盘上 未分配, 没有用到的虚拟内存空间 CPU寻址内存映射表的时候, 如果遇到是已缓存状态(物理内存地址), 则转到对应物理内存上操作; 如果遇到未缓存状态(磁盘地址), 则触发缺页中断, 在物理内存上找到空闲页, 并将磁盘对应页上的数据复制到物理内存对应页上, 然后继续执行; 如果遇到的是未分配状态(空), 则不操作即可. 这就可以解释C++中new等内存分配操作需要在运行时才可能检查出异常行为的原因了. 因为new等内存分配操作只是在虚拟内存中分配了内存, 只有在运行状态, 且运行到对应指令时才会在物理内存上分配空间, 所以分配失败/越界等问题要在运行时才可能触发. ","date":"2021-04-15","objectID":"/202104/pandt-what/:1:1","tags":["进程","线程","协程","虚拟内存","Linux"],"title":"进程、线程和协程概念","uri":"/202104/pandt-what/"},{"categories":["操作系统"],"content":"线程 线程则是比进程更细的操作单位. 一个进程至少要有一个或者可以有多个线程, 并且这些线程都共享这个进程的资源. 这也说明, 当编写多线程程序的时候, 我们可以直接用一些变量来传递不同线程之间的数据, 因为同一个进程的不同线程的内存资源是共享的, 这些线程使用了同一个虚拟内存空间和内存映射表. 一般会把进程看作是静态的, 它只负责资源的管理, 把线程看作是动态的, 线程负责资源的执行, 线程是程序的实际执行者. 线程和进程的关系是这样的: 线程和进程 最大的方框代表进程, 包含了多个线程/虚拟内存空间/寄存器和IO设备等, T1-T4代表是进程中的线程. 进程可能有多个线程, 线程共享进程的虚拟内存空间和通用寄存器即IO设备等, 每个线程也有自己CPU寄存器, 所以在线程切换的时候, 相比进程切换, 不需要保存内存映射/设备/通用寄存器等信息, 一般只需保存线程的调用栈和CPU寄存器等信息. 所以线程切换的开销会比进程切换的开销更低. 通过这个图我们也可以理解, 线程就是流水线, 帮助工厂(进程)完成一定的功能. 所以线程一般是合作的, 共同完整进程的一部分功能. ","date":"2021-04-15","objectID":"/202104/pandt-what/:1:2","tags":["进程","线程","协程","虚拟内存","Linux"],"title":"进程、线程和协程概念","uri":"/202104/pandt-what/"},{"categories":["操作系统"],"content":"协程 以上, 我们已经知道: 进程是系统资源管理的最小单元; 线程是系统任务执行的最小单元; 进程和线程都是由操作系统管理; 线程的调度是操作系统控制的, 所以会涉及到内核态的上下文切换; 协程是完全由用户控制的, 和操作系统无关, 不会涉及到内核态的上下文切换. TODO: 有几个点难以理解, 暂时记录这么多. (1. 需要一个较好的例子, 理解协程和串行的区别; 2. 要理解一些协程库的作用, 不切换到内核态是怎么实现协程切换的?) ","date":"2021-04-15","objectID":"/202104/pandt-what/:1:3","tags":["进程","线程","协程","虚拟内存","Linux"],"title":"进程、线程和协程概念","uri":"/202104/pandt-what/"},{"categories":["数据结构与算法","Cpp"],"content":"先约定两个概念, 主串和模式串. 比如在S字符串中查找s字符串, 则S是主串, s是模式串. 如下, 在主串中搜索\"cdf\"模式串: 主串和模式串 ","date":"2021-04-06","objectID":"/202104/str-match/:0:0","tags":["字符串","BF","BM","Cpp"],"title":"数据结构与算法之字符串匹配","uri":"/202104/str-match/"},{"categories":["数据结构与算法","Cpp"],"content":"BF 暴力匹配是很朴素的字符串匹配算法, 将主串中的字符与模式串的字符一个一个匹配, 如果遇到不匹配的字符对则主串向后滑动一个字符, 从头开始匹配: 暴力匹配 代码实现如下, strStr的作用是从haystack字符串中找到needle字符串首次出现的位置, 如果没有找到则返回-1. (LC.28) int strStr(string haystack, string needle) { if (needle.empty()) return 0; int sh = haystack.size(); int sn = needle.size(); if (sh \u003c sn) return -1; for (int i = 0; i \u003c= (sh - sn); i++) { int j = 0; for (; j \u003c sn; j++) { if (haystack[i + j] != needle[j]) { break; } } if (j \u003e= sn) { return i; } } return -1; } 记主串长度为m, 模式串长度为n, 可以得到暴力匹配的时间复杂度是$O(mn)$, 空间复杂度是$O(1)$; ","date":"2021-04-06","objectID":"/202104/str-match/:1:0","tags":["字符串","BF","BM","Cpp"],"title":"数据结构与算法之字符串匹配","uri":"/202104/str-match/"},{"categories":["数据结构与算法","Cpp"],"content":"BM 暴力匹配没有用到主串的一些先验信息. 假设模式串首字符是’a’, 我们可以记住主串中’a’出现的位置, 然后用主串中’a’出现的位置与模式串匹配, 这样可以减少一些比较次数. (实际上最差时间复杂度也没有提高.) 接下来的BM就用到了主串和模式串中的一些先验信息, 提高空间复杂度, 但是降低了时间复杂度, 不同于暴力匹配, BM算法是从右向左遍历. 为什么需要从右向左遍历呢? 先来看看BM算法的两条规则. ","date":"2021-04-06","objectID":"/202104/str-match/:2:0","tags":["字符串","BF","BM","Cpp"],"title":"数据结构与算法之字符串匹配","uri":"/202104/str-match/"},{"categories":["数据结构与算法","Cpp"],"content":"坏字符原则 对模式串, 从右向左匹配, 如果是错误匹配, 则记主串的字符a, 在模式串中从右向左查找下一个与主串字符a匹配的字符, 再将模式串移动到这个位置. 如果没有找到, 则将整个模式串移动到这个字符后面. 如下: 从右向左, 主串’d’与模式串’f’不匹配, 则在模式串中从右向左找到下一个与主串’d’匹配的字符; 将模式串的下一个与主串’d’匹配的字符对齐; BM-坏字符原则一 从右向左, 主串’c’与模式串’f’不匹配, 则在模式串中从右向左找到下一个与主串’c’匹配的字符; 将模式串的下一个与主串’c’匹配的字符对齐; BM-坏字符原则二 模式串匹配成功. BM-坏字符原则三 对BF中匹配的例子来说, 使用BM的坏字符原则, 可以减少匹配次数: 从右向左, 主串’d’与模式串’f’不匹配, 则在模式串中从右向左找到下一个与主串’d’匹配的字符; 将模式串的下一个与主串’d’匹配的字符对齐; 从右向左, 主串’c’与模式串’f’不匹配, 则在模式串中从右向左找到下一个与主串’c’匹配的字符; 将模式串的下一个与主串’c’匹配的字符对齐; 从右向左, 主串’c’与模式串’f’不匹配, 则在模式串中从右向左找到下一个与主串’c’匹配的字符; 将模式串的下一个与主串’c’匹配的字符对齐; 模式串匹配成功. BM与BF比较 再看一个特殊的例子: 首先, 按照坏字符原则, 从右向左, 主串’d’与模式串’c’不匹配, 则在模式串中从右向左找到下一个与主串’d’匹配的字符, 没有找到则将模式串移动到主串’d’后面: BM-坏字符原则三 接下来主串’c’与模式串’c’匹配, 但是主串’d’与模式串’f’不匹配, 且在子串中找不到下一个’d’, 这时候我们依然可以按照坏字符原则移动模式串, 但是主串’c’与模式串’c’匹配这条信息却没有用上. 有没有办法用上已经匹配的子串信息呢? 这就是BM算法的好前缀原则. ","date":"2021-04-06","objectID":"/202104/str-match/:2:1","tags":["字符串","BF","BM","Cpp"],"title":"数据结构与算法之字符串匹配","uri":"/202104/str-match/"},{"categories":["数据结构与算法","Cpp"],"content":"好前缀原则 先看一个例子, 匹配以下字符串: BM-好前缀原则一 首先我们可以按照坏后缀原则匹配, 移动模式串后, 发现已经有一段子串是匹配好的, 这时候可以触发好前缀原则. 如下, 模式串的\"cd\"和主串的\"cd\"匹配, 但是主串’d’与模式串’f’不匹配, 这时候在模式串中从右向左查找下一个\"cd\"子串, 如果查找到, 则将模式串的下一个\"cd\"子串与主串\"cd\"子串对齐. BM-好前缀原则二 现在匹配成功了. BM-好前缀原则三 如果模式串中没有查找到下一个与\"cd\"匹配的子串呢? 这时候需要分两种情况考虑: 模式串头有子串的子串, 则将模式串头子串的最大子串与主串的子串对齐; 模式串头没有子串的子串, 则将模式串移动到主串的子串的后面. 如下例子: 主串’d’与模式串’d’匹配, 主串’a’与模式串’c’不匹配, 则在模式串中查找下一个与\"d\"匹配的子串, 并与主串对齐: BM-好前缀原则四 主串’dcd’与模式串’dcd’匹配, 主串’a’与模式串’f’不匹配, 模式串中没有查找到下一个与\"dcd\"匹配的子串, 但是模式串头的\"d\"是子串\"dcd\"的子串, 所以将\"d\"对齐: BM-好前缀原则五 问题: 为什么与末尾的\"d\"对齐而不是与第一个\"d\"对齐呢? 如果与第一个\"d\"对齐, 模式串中势必没有第二个\"dcd\"子串, 所以一定是不匹配的, 直接与末尾\"d\"对齐就可以了. ","date":"2021-04-06","objectID":"/202104/str-match/:2:2","tags":["字符串","BF","BM","Cpp"],"title":"数据结构与算法之字符串匹配","uri":"/202104/str-match/"},{"categories":["数据结构与算法","Cpp"],"content":"对BM两条原则的思考 问题一: 为什么是从右往左匹配? 对坏字符或者好前缀原则, 从右往左匹配可以让我们移动最少的距离, 防止错过一些匹配. 问题二: 为什么坏字符原则可以工作? 如果坏字符所在子串可能和模式串匹配, 则模式串中一定有一个和坏字符匹配的字符. 所以坏字符原则只是尝试以下这种可能. 问题三: 为什么好前缀原则可以工作? 同问题二, 如果好前缀是可能的匹配, 则模式串中一定有另一个匹配的后缀或者后缀子串. 问题四: 什么时候坏字符什么时候好前缀? 按照问题一的解释, 则两个原则都是在保证有一定匹配串的情况下, 移动尽量小的距离, 单独使用某一种原则再加上一些边界处理条件也可能完成匹配过程, 为了算法加速, 则可以使用坏字符和好前缀中移动距离最长的结果. 问题五: 怎么单独使用坏字符原则? 如果遇到坏字符, 并且找到了与坏字符匹配的其他字符的情况下, 是可以正常使用坏字符原则的. 如果没有找到呢? 不管有没有好前缀, 将模式串移动到坏字符后面重新尝试匹配就可以了. 问题六: 怎么单独使用好前缀原则? 同坏字符原则, 如果有匹配则正常匹配, 如果没有匹配则将匹配串移动到好后缀后面即可. ","date":"2021-04-06","objectID":"/202104/str-match/:2:3","tags":["字符串","BF","BM","Cpp"],"title":"数据结构与算法之字符串匹配","uri":"/202104/str-match/"},{"categories":["数据结构与算法","Cpp"],"content":"BM代码实现 坏字符的代码实现 坏字符原则的朴素实现比较简单, 每次遇到坏字符, 对模式串从右向左找到下一个与坏字符匹配的字符即可. 但是这样的操作效率十分低下. 因为是在模式串中查找一个字符, 我们可以考虑用一个map记录字符在模式串中最后的位置: void badChar(unordered_map\u003cchar, int\u003e \u0026badmps, const string \u0026pstr) { int size = pstr.size(); for (int i = 0; i \u003c size; i++) { //badmps代表的是模式串的字符的最右位置 badmps[pstr[i]] = i; } } 再提供一个函数计算移动距离: int badMove(unordered_map\u003cchar, int\u003e \u0026badmps, const char \u0026badc, const int \u0026pos) { //尽管可能是负数, 但是我们并不是很当心 //1. 负数可以用右移一位代替 //2. 增加复杂度, 不匹配模式串最右匹配, 而是匹配模式串以坏字符为界的右子串的最右匹配 return badmps.find(badc) != badmps.end() ? pos - badmps[badc] : -1; } 好前缀的代码实现 好前缀原则我们需要实现两个地方: 最右的与好前缀完全匹配的子串; 如果没有完全匹配的子串, 则找到头部的部分匹配的子串. 参考一般解法, 可以实现如下的代码: void goodMatch(vector\u003cint\u003e \u0026sufix, vector\u003cbool\u003e \u0026prefix, const string \u0026pstr) { int size = pstr.size(); sufix.reserve(size); prefix.reserve(size); for (int i = 0; i \u003c size; ++i) { //sufix[i]表示长度为i的子串的位置, 需要注意, 长度为i的子串是唯一的. //-1则时不存在这个子串 sufix[i] = -1; //prefix[i]表示这个子串是不是在头部 prefix[i] = false; } int pstr_max_index = size - 1; //不需要遍历整个模式串, 因为长度满的时候, 必定没有其他子串 for (int i = 0; i \u003c pstr_max_index; i++) { //是遍历的初始位置, 从右向左 int j = i; //k用来记录子串的长度 int k = 0; //这样我们拿到的sufix总是最右的 while ((j \u003e= 0) \u0026\u0026 (pstr[j] == pstr[pstr_max_index - k])) { sufix[++k] = j--; } if (j \u003c 0) { prefix[k] = true; } } } 为什么这么做? 因为待匹配的子串是已知的, 就是模式串的子串, 所以在预处理的时候获得这些一直子串的位置就可以在处理的时候减少一些计算, 降低时间复杂度. 做完预处理之后, 还需要一个函数计算偏移量: int goodMove(const vector\u003cint\u003e \u0026sufix, const vector\u003cbool\u003e \u0026prefix, const int \u0026mlen, const int \u0026pos) { if (mlen \u003c 1) return -1; int move_len = 0; int size = sufix.size(); move_len = sufix[mlen]; if (move_len \u003c 0) { for (int i = mlen - 1; i \u003e 0; i--) { if (prefix[i] == true) { move_len = sufix[i]; break; } } } return pos - move_len; } BM完整代码 int strStr(string haystack, string needle) { //边界条件比较少, 先处理一下 if (needle.empty()) return 0; int sh = haystack.size(); int sn = needle.size(); if (sh \u003c sn) return -1; //预处理 unordered_map\u003cchar, int\u003e badmps; badChar(badmps, needle); vector\u003cint\u003e sufix; vector\u003cbool\u003e prefix; goodMatch(sufix, prefix, needle); int i = 0; while (i \u003c= (sh - sn)) { int j = sn - 1; int mlen = 0; char bad_char = 0; while (j \u003e= 0) { if (haystack[i + j] != needle[j]) { bad_char = haystack[i + j]; break; } mlen++; j--; } if (mlen \u003e= sn) { return i; } //拿到不匹配字符的位置 int pos = sn - mlen - 1; int bad_step = badMove(badmps, bad_char, pos); int good_step = goodMove(sufix, prefix, mlen, pos); int step = max(bad_step, good_step); if (step \u003c 0) step = sn; i += (step \u003e 0 ? step : 1); } return -1; } ","date":"2021-04-06","objectID":"/202104/str-match/:2:4","tags":["字符串","BF","BM","Cpp"],"title":"数据结构与算法之字符串匹配","uri":"/202104/str-match/"},{"categories":["Cpp"],"content":"struct位域 位域可以将成员变量拆分成bit的粒度. 用法一般是: identifier(optional) attr(optional) : size 例如以下: struct BITS{ uint32_t d1 : 4; uint32_t d2 : 4; uint32_t d3 : 4; uint32_t d4 : 4; uint32_t : 16; }; BITS的成员d1/d2/d3/d4各占4bits, 最后还有16bit的保留位. 所以sizeof(BITS)的大小是4. 稍微改动一下, 去掉16bit的保留位: struct BITS{ uint32_t d1 : 4; uint32_t d2 : 4; uint32_t d3 : 4; uint32_t d4 : 4; }; 现在BITS的大小是2吗? 不是的, sizeof(BITS)还是4. 再改动, 保留20bit空间: struct BITS{ uint32_t d1 : 4; uint32_t d2 : 4; uint32_t d3 : 4; uint32_t d4 : 4; uint32_t : 20; }; 现在BITS的大小是4吗? 不是的, sizeof(BITS)是8. 以上, BITS声明的位域数和不足uint32_t占位时, BITS占位是sizeof(uint32_t), 超过时, 这是sizeof(uint32_t)的整数倍. 这一点和struct保持一致. 再来改一笔, 把uint32_t改成uint8_t: struct BITS{ uint8_t d1 : 4; uint8_t d2 : 4; uint8_t d3 : 4; uint8_t d4 : 4; }; 现在BITS的大小是4吗? 不是的, sizeof(BITS)是2. 如果把某个uint8_t改成uint16_t, sizeof(BITS)依然是2, 如果改成uint32_t, 则sizeof(BITS)是4. 有以下结论: struct位域占用的大小总是其最大标识符的整数倍. 我们可以单独写入或者读出每个成员: bit.d1 = 1; bit.d2 = 2; bit.d3 = bit.d1 | bit.d2; 如果成员比较多则比较麻烦, 这时候可以使用union. ","date":"2021-03-18","objectID":"/202103/c-strcut-bits/:1:0","tags":["Cpp","sturct","bit","bit-field","union"],"title":"struct位域","uri":"/202103/c-strcut-bits/"},{"categories":["Cpp"],"content":"union初始化位域 union BITS{ struct { uint32_t d1 : 4; uint32_t d2 : 4; uint32_t d3 : 4; uint32_t d4 : 4; uint32_t : 16; }u; uint32_t data; }; 我们可以直接初始化所有位域: BITS bits; bits.data = 0x0; 也可以通过data一次性设置所有位域: bits.data = 0x12345678; 但是data和d1-d4的对应关系如何? 则需要考虑系统的小大端. ","date":"2021-03-18","objectID":"/202103/c-strcut-bits/:2:0","tags":["Cpp","sturct","bit","bit-field","union"],"title":"struct位域","uri":"/202103/c-strcut-bits/"},{"categories":["Cpp"],"content":"小大端模式 小端: 低位Byte存低地址, 高位Byte存高地址; 大端: 低位Byte存高地址, 高位Byte存低地址; 可用以下代码判断: union MODE { uint16_t i = 1; uint8_t small; }; 如果是小端, 则small为true, 否则small为false. 如果是小端存储: bits.data = 0x12345678; 输出d1-d4则是: d1=8; d2=7; d3=6; d4=5; 如果是大端存储, 输出d1-d4则是: d1=1; d2=2; d3=3; d4=4; 了解小大端存储方式对开发有一定的帮助, 比如下面一个例子: 设计一个debug接口, 用户set一个属性, 系统通过获取这个属性可以支持不同的debug模式, 但是因为某些原因, 只允许设置一个属性, 值是32位. 此时我们就可以用上面的BITS. 获取prop: BITS prop; prop.data = getprop(\"debug.prop\"); int32_t debug_mode_value[MODE1] = prop.d1; int32_t debug_mode[MODE2] = prop.d2; int32_t debug_mode[MODE3] = prop.d3; int32_t debug_mode[MODE4] = prop.d4; 仅用一个prop, 就可以支持同时设置多个debug属性. 我们来看一个例子: union BITS{ struct { uint8_t d1 : 4; uint8_t d2 : 4; uint8_t d3 : 4; uint8_t d4 : 4; }u; uint32_t data; }; BITS bits; bits.data = 0x87654321; //低16bits 0100, 0011, 0010, 0001 在小端存储系统中, 输出d1-d4是: 1 2 3 4 我们改动一下: struct { uint8_t d1 : 4; uint8_t d2 : 2; uint8_t d3 : 4; uint8_t d4 : 4; }u; 预计输出是: //0001 //01 //1100 //0000 1 2 12 0 但是实际输出依然是: 1 2 3 4 原因是d1/d2已经占用6bit, 再加d3是10bit超过了uint8_t的8bit, 所以d1/d2补齐2bit按照8bit对齐. 我们可以在改动一下验证这个结论: struct { uint8_t d1 : 4; uint8_t d2 : 2; uint8_t d3 : 2; uint8_t d4 : 4; }u; 现在d1-d4的输出是: //0001 //10 //00 //0011 1 2 0 3 符合预期d1-d3正好占8bit, 所以不会有补齐对齐操作. ","date":"2021-03-18","objectID":"/202103/c-strcut-bits/:3:0","tags":["Cpp","sturct","bit","bit-field","union"],"title":"struct位域","uri":"/202103/c-strcut-bits/"},{"categories":["Cpp"],"content":"位域如何实现的 通过编译器翻译后的汇编代码, 我们可以基本知道其原理: union BITS{ struct { uint8_t d1 : 4; uint8_t d2 : 2; uint8_t d3 : 2; uint8_t d4 : 4; }u; uint32_t data; }; BITS bits; bits.data = 0x87654321; int d1 = bits.u.d1; int d2 = bits.u.d2; int d3 = bits.u.d3; int d4 = bits.u.d4; 汇编后: 将值0x87654321赋值给bits.data, 这里比较好理解. mov DWORD PTR [rbp-28], -2023406815 接下来时获取d1的值: movzx eax, BYTE PTR [rbp-28] and eax, 15 movzx eax, al mov DWORD PTR [rbp-4], eax 从首地址拿数据, 然后与0xFF(15)按位与. 再获取d2的数据: movzx eax, BYTE PTR [rbp-28] shr al, 4 and eax, 3 movzx eax, al mov DWORD PTR [rbp-8], eax 与d1的区别在于, 右移4bit, 然后与0x3按位与, 这时是提取2bit. 再获取d3: movzx eax, BYTE PTR [rbp-28] shr al, 6 movzx eax, al mov DWORD PTR [rbp-12], eax 有点不同, 为什么没有按位与的操作了? 因为这里是取的BYTE, 右移6bit就可以得到高位的2bit了. d4则和d1类似, 只不过取值地址需要+1: movzx eax, BYTE PTR [rbp-27] and eax, 15 movzx eax, al mov DWORD PTR [rbp-16], eax 所以, 位域操作在逻辑上和位操作是类似的, 也是通过移位和与或运算得到. ","date":"2021-03-18","objectID":"/202103/c-strcut-bits/:4:0","tags":["Cpp","sturct","bit","bit-field","union"],"title":"struct位域","uri":"/202103/c-strcut-bits/"},{"categories":["Cpp"],"content":"结论 综上, 总结struct位域: struct大小是最大标识符的整数倍 union赋值struct位域需要考虑小大端 位域不能横跨两个标识符, 此时需要补齐对齐 位域也是通过移位和与或运算得到 ","date":"2021-03-18","objectID":"/202103/c-strcut-bits/:5:0","tags":["Cpp","sturct","bit","bit-field","union"],"title":"struct位域","uri":"/202103/c-strcut-bits/"},{"categories":["工具"],"content":"github action 本站使用的是github action作为自动编译和部署工具. 为什么不使用Gitee的Gitee Go? 它是收费的… 以下是本站的一个github action配置, 需要在.git同级目录建立.github/workflows/action.yml 功能是push master或者conten分支后, github自动使用hugo编译项目, 并且将编译后的项目推送到阿里云oss. 阿里云oss打开了静态网页配置, 如此就相当于直接更新网站了. name: aliyun sso on: push: branches: - master - content jobs: build-and-deploy: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 with: ref: master submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Update Content run: cd ./content \u0026\u0026 git pull origin content - name: Update Live2d run: cd ./static/live2d \u0026\u0026 git pull origin live2d - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: 'latest' # extended: true - name: Build run: hugo --minify - name: Nojekyll run: touch ./public/.nojekyll - name: Deploy uses: fangbinwei/aliyun-oss-website-action@v1 with: accessKeyId: ${{ secrets.KEYID }} accessKeySecret: ${{ secrets.KEYSECRET }} bucket: ${{ secrets.BUCKET }} # e.g. \"oss-cn-shanghai.aliyuncs.com\" endpoint: ${{ secrets.ENDPOINT }} folder: public - name: Post Urls run: . urls.sh 其含义: 使用aliyun oss (名字其是随便起, 但是有一定意义最好) 在push master或conten分支时会触发这个action 这个action的jobs运行在ubuntu环境下 这个action会拉取一些仓库和分支 这个action会调用其他的一些action实现编译和部署功能 这个action最后会调用一个urls.sh脚本(目前功能是将本站所有url更新到百度站长) ","date":"2021-03-16","objectID":"/202103/git-cicd/:1:0","tags":["Git","CICD"],"title":"使用CICD自动部署","uri":"/202103/git-cicd/"},{"categories":["工具"],"content":"gitlab CI/CD 这是我在gitlab上的一个项目的配置, 目的比较简单, 在项目更新到master分支后, gitlab会帮我做一些接口测试. 作为项目owner或者maintainer, 仅在merge request的CI通过时, 才会merge对应patch. image: gcc before_script: - apt-get update --yes - apt-get install --yes cmake build: script: - cd ./build; cmake -DDEBUG=ON -DGUI=OFF -DTEST=ON ..; make -j2; cd .. - cd ./debug/bin/ - /bin/bash testinterface.sh only: - master - web 其含义: 使用gcc docker image 在编译和部署之前会更新一些依赖 仅在master分支或者web操作更新时触发(push/merge等操作) 本文目的不是告诉怎么写CI/CD配置, 不同git服务可能不一样. 本文目的是告诉有这么一个东西, 具体按照需求自查即可. ","date":"2021-03-16","objectID":"/202103/git-cicd/:2:0","tags":["Git","CICD"],"title":"使用CICD自动部署","uri":"/202103/git-cicd/"},{"categories":["工具"],"content":"本站结构 根目录下是hugo框架仓库, 使用了master分支, 同时还使用了以下子仓库: [submodule \"themes/LoveIt\"] path = themes/LoveIt url = https://github.com/dillonzq/LoveIt.git [submodule \"content\"] path = content url = https://github.com/***********/blog.git branch = content [submodule \"live2d\"] path = static/live2d url = https://github.com/***********/blog.git branch = live2d 注意到content和live2d其实和hugo框架在同一个仓库, 但是使用的是不同的分支. PS: 这里的blog仓库是private的就不展示啦! ","date":"2021-03-16","objectID":"/202103/git-branch-content/:1:0","tags":["Git"],"title":"不同分支存储不同内容","uri":"/202103/git-branch-content/"},{"categories":["工具"],"content":"为什么这样做 目的是期望一个仓库管理一个项目, 上述content和live2d都是blog的一部分, 只是期望其内容分离, 互相不要有太多偶合. 网站配置一个分支, 文档内容一个分支, 这样之后迁移起来就很方便啦! 目前的结构: branch content master hugo框架 content 文章源文 live2d live2d模型和配置 所以, 如果有需要, 我只需备份content分支就可以只备份文章内容了, 不会引入一些其他的干扰配置. 如果是有共同开发的分支, 可以起一个新的名字, 比如: branch content master hugo框架 master-feature1 hugo框架-开发feature1功能 content 文章源文 content-user 投稿 本站在github上存储的是源码, 而不是hugo渲染之后的内容. 使用CI/CD开发流程, 实现自动编译和部署, 用源码就够了. 看这里. ","date":"2021-03-16","objectID":"/202103/git-branch-content/:2:0","tags":["Git"],"title":"不同分支存储不同内容","uri":"/202103/git-branch-content/"},{"categories":["Cpp"],"content":" const用来修饰只读. constexpr用来修饰编译期可以确定的值.(编译期常量) ","date":"2021-03-11","objectID":"/202103/cpp-const-adconsexpr/:0:0","tags":["Cpp","const","constexpr","编译时"],"title":"const和constexpr","uri":"/202103/cpp-const-adconsexpr/"},{"categories":["Cpp"],"content":"只读的const修饰符 和一般认知一样, 用const修饰的变量不可被修改, 但是变量不可被修改并不代表变量值不可被修改; 按照cppreference的解释, const代表的是只读, 只读不代表不变, 看下面一段例子: int main() { int a = 1; const int\u0026 b = a; a = 2; cout \u003c\u003c b; } 编译通过, 输出b的结果是2; 上面代码中, 变量b被const修饰, 代表b是只读, 我们不能改变b, 但是可以改变a的值(这样b的值也被改变了), 尽管可以认为他们是同一个东西. 可以看成const只认名字不认内容. ","date":"2021-03-11","objectID":"/202103/cpp-const-adconsexpr/:1:0","tags":["Cpp","const","constexpr","编译时"],"title":"const和constexpr","uri":"/202103/cpp-const-adconsexpr/"},{"categories":["Cpp"],"content":"编译期可以确定值的constexpr修饰符 constexpr是C++引入的关键词, 和const很像, 但是两者并不是完全替代关系. constexpr修饰变量时修饰的时字面量/常量, 修饰函数时表示编译期有能力(可以)确定的值. 下面的例子是不行的: int a = 1; constexpr int b = a; 编译期会报错说a不是一个常量表达式: the value of 'a' is not usable in a constant expression 下面的例子是不行的: int a = 1; const int\u0026 b = a; constexpr int c = b; 编译期会报错说b不是一个常量表达式: the value of 'b' is not usable in a constant expression 下面的例子是可行的: const int a = 1; constexpr int b = a; 对这个例子我的理解是, a被修饰为一个只读变量, 并且a又是一个字面量, 所以a是一个常量. 但是这个例子是不行的: const int a = 1; const int \u0026b = a; constexpr int c = b; 编译器同样报错说b不是一个常量表达式. 我的理解是, 所有的值引用应该都不被当做常量. 看下面一个例子: // const int a = 1; int a = 1; const int \u0026b = a; // 1 a = 2; cout \u003c\u003c b \u003c\u003c endl; // 2 不用const修饰a, 但是用const修饰b\u0026, 表示b只能作为a的引用, 这时候我们是可以修改变量a的值并且反映在引用b上的. ","date":"2021-03-11","objectID":"/202103/cpp-const-adconsexpr/:2:0","tags":["Cpp","const","constexpr","编译时"],"title":"const和constexpr","uri":"/202103/cpp-const-adconsexpr/"},{"categories":["Cpp"],"content":"用constexpr做编译期函数 const修饰的函数在运行时才可以返回函数值, 但是constexpr修饰的函数有能力在编译阶段就返回值. 比如以下函数: constexpr int add(const int\u0026 a, const int\u0026 b) { return a + b; } 有能力在编译期计算并不代表一定在编译期计算, 调用上述add函数时, 只有在a和b是可以在编译期确定时, 函数才会在编译期返回计算结果, 否则依然时运行时返回. int a = add(2, 3); //编译期就可以确定结果 int b = add(a, 3); //运行时确定结果 再看以下: constexpr int a = add(2, 3); //编译期就可以确定结果 int b = add(a, 3); //编译期就可以确定结果 在我们看来, 上述代码可以说是一样的, 但是第二段代码给变量a加上了常量修饰符, 这样在b调用add时, a就是一个字面量, 编译期可以确定的. 不要把编译期想的太智能, 如上, 如果你确定某个变量是常量, 那么应该直接告诉编译器, 而不要让编译器来猜. 不是所有函数都可以使用constexpr修饰. 在C++11的标准中, constexpr修饰的函数应该只有一个return语句. 不同C++版本对此有不同的支持, 详见cppreference. ","date":"2021-03-11","objectID":"/202103/cpp-const-adconsexpr/:2:1","tags":["Cpp","const","constexpr","编译时"],"title":"const和constexpr","uri":"/202103/cpp-const-adconsexpr/"},{"categories":["Cpp"],"content":"参考链接 http://c.biancheng.net/view/7807.html https://en.cppreference.com/w/cpp/language/constexpr https://en.cppreference.com/w/c/language/const ","date":"2021-03-11","objectID":"/202103/cpp-const-adconsexpr/:3:0","tags":["Cpp","const","constexpr","编译时"],"title":"const和constexpr","uri":"/202103/cpp-const-adconsexpr/"},{"categories":["数据结构与算法","Cpp"],"content":"什么是图 在前面的文章中, 我们了解了树的概念, 重点是二叉树, 图在拓扑结构上和树有点类似, 但是图不是树. 直观地, 先来看一个图的拓扑结构: 无向图 上述展示的是无向图, 无向图就是没有方向的图, 只要两个结点之间是联通的, 就可以从一个结点到另外一个结点. 我们可以将其理解为简化后的地图, A-G代表的是地点. 一般地, 对图我们有以下的一般性概念: 图的结点叫做顶点; 顶点(结点)之间的连接叫做边; 一个顶点(结点)有多少条边叫做这个顶点(结点)的度; 对应的, 还有有向图, 有向图就是有方向的图, 链接的两个顶点的边有方向, 可以从一个顶点到另外一个顶点, 如果两个顶点互通, 则至少要有两条不同方向的边. 有向图类似于行车单向道. 有向图 有向图的边可能从一个顶点指出, 也可能指向一个顶点, 我们把从顶点指出的边的数量叫做这个顶点的出度, 指向一个顶点的边的数量叫做这个顶点的入度. 类比于地图, 两顶点之间的边不仅可以表示联通关系, 还可以表示距离, 给每条边带上一个\"距离\"参数(权重), 这样的图叫做带权图: 带权图 ","date":"2021-03-09","objectID":"/202103/cpp-graph/:1:0","tags":["Cpp","图","搜索","DFS","BFS"],"title":"数据结构与算法之图","uri":"/202103/cpp-graph/"},{"categories":["数据结构与算法","Cpp"],"content":"图的类比对象 用图这种数据结构可以表示日常生活中的一些常用对象, 这里举一些例子: 地图可以用图表示, 顶点就是地点, 边就是两个地点之间的路径, 边带上权重就可以表示距离; 好友关系也可以用图表示, 顶点就是每个个体, 边表示这两个个体之间是否有联系, 边带上权重可以表示好感度; 编译器也用到了图, C/C++编译时的头文件include就可以用图的顶点表示, 有向边可以表示依赖关系; ","date":"2021-03-09","objectID":"/202103/cpp-graph/:1:1","tags":["Cpp","图","搜索","DFS","BFS"],"title":"数据结构与算法之图","uri":"/202103/cpp-graph/"},{"categories":["数据结构与算法","Cpp"],"content":"邻接表存储法 图如何存储? 很直观的时类似树一样的存储方法, 用链表表示图的拓扑结构. 但是这种方法的问题在于不知道图的每个顶点会有多少条边, 所以不太好定义结构体. 邻接表存储法也是使用链表存储的方法, 它把每个顶点表示为链表的头, 后继结点则是与顶点连接的其他顶点, 如下图表示无向图的邻接表存储法: 邻接表存储法 template \u003ctypename T\u003e struct Graph{ T val; vector\u003cGraph\u003cT\u003e*\u003e link; }; 以上, val表示顶点的值, link中则是存与这个顶点联通的其他顶点. 这里的link看起来是顺序存储, 如果查找与顶点连接的某个其他顶点时, 时间复杂度时$O(n)$, 我们可以使用查找二叉树或者红黑树等结构来替代顺序结构, 提高查找效率, 具体使用的数据结构还需根据具体场景分析. ","date":"2021-03-09","objectID":"/202103/cpp-graph/:2:0","tags":["Cpp","图","搜索","DFS","BFS"],"title":"数据结构与算法之图","uri":"/202103/cpp-graph/"},{"categories":["数据结构与算法","Cpp"],"content":"广度优先搜索(BFS) 图的搜索/遍历和树类似, 需要注意的就是图可以有回环, 不要陷入死循环即可. 广度优先搜索是先访问起始结点的所有子结点, 再访问子结点的所有子结点, 从树的结构来看, 是一层一层的访问. 下面我们用树的结构来展示一下BFS是怎么搜索的: BFS 先定义图的结构: template \u003ctypename T\u003e struct Graph{ T val; vector\u003cGraph\u003cT\u003e*\u003e link; Graph(const T\u0026 v) : val(v) {} }; using Map = Graph\u003cchar\u003e; 我们的主函数, 使用上文中的无向图: int main() { vector\u003cvector\u003cchar\u003e\u003e link_map{ {'A', 'B'}, {'B', 'A', 'C', 'E'}, {'C', 'B', 'D'}, {'D', 'C', 'E', 'G'}, {'E', 'B', 'D', 'F'}, {'F', 'E', 'G'}, {'G', 'D', 'F'}, }; auto graph = initGraph(link_map); return 1; } link_map的条元素的第一个元素代表顶点, 之后的元素则代表与该顶点连接的其他顶点; 编写一个图打印函数, 用来输出使用邻接表存储法的图: void printGraph(const vector\u003cMap\u003e \u0026graph) { using std::begin; using std::end; for_each(begin(graph), end(graph), [](auto\u0026 g){ cout \u003c\u003c g.val \u003c\u003c \"(\" \u003c\u003c \u0026g \u003c\u003c \")\"; auto \u0026link = g.link; for_each(begin(link), end(link), [](auto\u0026 l){ cout \u003c\u003c \"-\u003e\" \u003c\u003c l-\u003eval \u003c\u003c \"(\" \u003c\u003c l \u003c\u003c \")\"; }); cout \u003c\u003c endl; }); } 将图的初始化数据转化为邻接表存储: vector\u003cMap\u003e initGraph(const vector\u003cvector\u003cchar\u003e\u003e \u0026link_map) { using std::next; using std::begin; using std::end; vector\u003cMap\u003e graph; unordered_map\u003cchar, int\u003e map_map; int pos = 0; for (auto \u0026link : link_map) { const char\u0026 c = link[0]; Map g(c); graph.emplace_back(g); map_map.emplace(c, pos++); } auto g = begin(graph); for (auto \u0026link : link_map) { for_each(next(begin(link)), end(link), [\u0026](auto\u0026 c){ pos = map_map[c]; auto pg = \u0026graph[pos]; g-\u003elink.emplace_back(pg); }); g = next(g); } printGraph(graph); return graph; } 初始化graph后, 我们得到输出: A(0x11852a0)-\u003eB(0x11852c0) B(0x11852c0)-\u003eA(0x11852a0)-\u003eC(0x11852e0)-\u003eE(0x1185320) C(0x11852e0)-\u003eB(0x11852c0)-\u003eD(0x1185300) D(0x1185300)-\u003eC(0x11852e0)-\u003eE(0x1185320)-\u003eG(0x1185360) E(0x1185320)-\u003eB(0x11852c0)-\u003eD(0x1185300)-\u003eF(0x1185340) F(0x1185340)-\u003eE(0x1185320)-\u003eG(0x1185360) G(0x1185360)-\u003eD(0x1185300)-\u003eF(0x1185340) 针对广度优先搜索算法, 我们使用open-close表实现. open表中存储接下来需要访问的结点, 一般可以用双端队列; close表中存储已经访问过的结点, 一般可以用任意容器; 接下来确定对每个结点的操作: 判断结点是否已经被访问过(是否在close表中): using std::begin; using std::end; auto isInClose = [\u0026vclose](auto\u0026 node){ auto node_pos = find_if(begin(vclose), end(vclose), [\u0026](auto\u0026 cnode){ return cnode == node; }); return node_pos != end(vclose); }; 将接下来需要访问的结点放到open表: auto openPush = [\u0026vopen](auto\u0026 node){ vopen.emplace_back(node); }; 从open表中取出结点, 并访问: auto openGet = [\u0026vopen](){ auto node = vopen.front(); vopen.pop_front(); return node; }; 这里要注意open表的操作, push的时候是将结点push到末尾, 取元素时则是从头开始取. 对结点处理, 简单起见, 这里使用cout auto processNode = [](auto\u0026 node){ cout \u003c\u003c node-\u003eval \u003c\u003c \" \"; }; 有了上述基本操作, 广度优先遍历实现如下: void algoBFS(vector\u003cMap\u003e\u0026 graph) { deque\u003cMap*\u003e vopen; vector\u003cMap*\u003e vclose; auto isInClose = [\u0026vclose](auto\u0026 node){ auto node_pos = find_if(begin(vclose), end(vclose), [\u0026](auto\u0026 cnode){ return cnode == node; }); return node_pos != end(vclose); }; auto openPush = [\u0026vopen](auto\u0026 node){ vopen.emplace_back(node); }; auto openGet = [\u0026vopen](){ auto node = vopen.front(); vopen.pop_front(); return node; }; auto processNode = [](auto\u0026 node){ cout \u003c\u003c node-\u003eval \u003c\u003c \" \"; }; auto node = \u0026graph[0]; openPush(node); do{ node = openGet(); if(!isInClose(node)) { processNode(node); vclose.emplace_back(node); for(auto\u0026 l : node-\u003elink) { if (!isInClose(l)) { openPush(l); } } } }while(!vopen.empty()); } 输出得到: A B C E D F G ","date":"2021-03-09","objectID":"/202103/cpp-graph/:3:0","tags":["Cpp","图","搜索","DFS","BFS"],"title":"数据结构与算法之图","uri":"/202103/cpp-graph/"},{"categories":["数据结构与算法","Cpp"],"content":"深度优先搜索(DFS) 深度优先搜索从树的结构来看就是从根结点一直访问到叶子结点. 下面我们用树的结构来展示一下DFS是怎么搜索的: DFS 深度优先搜索的逻辑和广度优先搜索基本一样, 区别在于从open表中取值的方式不同. 在广度优先搜索中, 我们将待访问结点push到open表的末尾, 再从open表的表头拿下一个访问的结点, 这样的结果就是先访问了结点的所有子结点, 再访问子结点的所有子结点. 深度优先搜索是将待访问结点push到open表的末尾, 再从open表的末尾拿下一个访问的结点, 这样相当于是从一个几点一直追溯子结点, 直到末尾, 如此往复. 以下是深度优先搜索中的openGet操作: auto openGet = [\u0026vopen](){ auto node = vopen.back(); vopen.pop_back(); return node; }; 完整实现如下: void algoDFS(vector\u003cMap\u003e\u0026 graph) { deque\u003cMap*\u003e vopen; vector\u003cMap*\u003e vclose; using std::begin; using std::end; auto isInClose = [\u0026vclose](auto\u0026 node){ auto node_pos = find_if(begin(vclose), end(vclose), [\u0026](auto\u0026 cnode){ return cnode == node; }); return node_pos != end(vclose); }; auto openPush = [\u0026vopen](auto\u0026 node){ vopen.emplace_back(node); }; auto openGet = [\u0026vopen](){ auto node = vopen.back(); vopen.pop_back(); return node; }; auto processNode = [](auto\u0026 node){ cout \u003c\u003c node-\u003eval \u003c\u003c \" \"; }; auto node = \u0026graph[0]; openPush(node); do{ node = openGet(); if(!isInClose(node)) { processNode(node); vclose.emplace_back(node); for(auto\u0026 l : node-\u003elink) { if (!isInClose(l)) { openPush(l); } } } }while(!vopen.empty()); } 输出得到: A B E F G D C ","date":"2021-03-09","objectID":"/202103/cpp-graph/:4:0","tags":["Cpp","图","搜索","DFS","BFS"],"title":"数据结构与算法之图","uri":"/202103/cpp-graph/"},{"categories":["Cpp","STL"],"content":"问题 先来看一段代码: #include \u003ciostream\u003e #include \u003calgorithm\u003e using namespace std; #define ARRAY_SIZE(array) sizeof(array) / sizeof(array[0]) int main() { int nums[] = {1, 2, 3, 4}; auto print_nums = [] (auto\u0026 n) { cout \u003c\u003c n \u003c\u003c endl; }; auto process_nums = [] (auto\u0026 n) { //do more process here n *= n; }; for_each(nums, nums + ARRAY_SIZE(nums), process_nums); for_each(nums, nums + ARRAY_SIZE(nums), print_nums); } 我们有一个数组, 对其进行了某种操作process_nums之后, 打印print_nums出数组的值; 接下来, 假设我们发现, 使用数组来表示这段数据已经不符合项目要求了, 打算将数组换成list, 代码应该怎么改呢? int main() { // int nums[] = {1, 2, 3, 4}; list\u003cint\u003e nums{1, 2, 3, 4}; auto print_nums = [] (auto\u0026 n) { cout \u003c\u003c n \u003c\u003c endl; }; auto process_nums = [] (auto\u0026 n) { //do more process here n *= n; }; // for_each(nums, nums + ARRAY_SIZE(nums), process_nums); // for_each(nums, nums + ARRAY_SIZE(nums), print_nums); for_each(nums.begin(), nums.end(), process_nums); for_each(nums.begin(), nums.end(), print_nums); } 可以看到, 不仅原始数据结构要改(int[]改为list\u003cint\u003e), 对这些数据调用的部分(两个for_each)也需要改. 按照这种情况, 如果是设计算法, 就需要根据不同数据的访问方法实现不同的接口. ","date":"2021-03-04","objectID":"/202103/cpp-what-iterator/:1:0","tags":["Cpp","迭代器","traits"],"title":"STL-迭代器","uri":"/202103/cpp-what-iterator/"},{"categories":["Cpp","STL"],"content":"迭代器 所幸, 所有的STL容器有考虑到这一点, 无论何种容器, 都应该有统一的接口给算法调用, 这样算法就可以处理所有容器的数据. 这就是迭代器. 迭代器可以隔离容器的底层实现, 调用容器数据只需依赖迭代器的统一接口. 再看一个例子, 使用通用迭代器和不使用通用迭代器的区别, 将上文的代码改造一下: int main() { int nums[] = {1, 2, 3, 4}; // list\u003cint\u003e nums{1, 2, 3, 4}; auto print_nums = [] (auto\u0026 n) { cout \u003c\u003c n \u003c\u003c endl; }; auto process_nums = [] (auto\u0026 n) { //do more process here n *= n; }; using std::begin; using std::end; for_each(begin(nums), end(nums), process_nums); for_each(begin(nums), end(nums), print_nums); } 我们使用迭代器, 无论是普通数组还是容器(容器已经有通用的接口了), 都可以使用相同的接口访问其数据. begin: returns an iterator to the beginning of a container or array end: returns an iterator to the end of a container or array ","date":"2021-03-04","objectID":"/202103/cpp-what-iterator/:2:0","tags":["Cpp","迭代器","traits"],"title":"STL-迭代器","uri":"/202103/cpp-what-iterator/"},{"categories":["Cpp","STL"],"content":"begin和end 除了我们认知的容器中的C.begin()和C.end()的方法, C++也给我们提供了函数模板, 可以获取容器和数组的迭代器. (上文中的begin和end). 先来看看begin的定义, end类似: template \u003cclass Container\u003e auto begin (Container\u0026 cont) -\u003e decltype (cont.begin()); template \u003cclass Container\u003e auto begin (const Container\u0026 cont) -\u003e decltype (cont.begin()); template \u003cclass T, size_t N\u003e T* begin (T(\u0026arr)[N]); 对容器, begin返回的是容器的begin()方法的返回值; 对数组, begin返回的是指针. 在上文和之前的文章中已经用到过begin和end了, 这里就不在介绍用法. 当然, 可以返回迭代器的不只有begin和end. 我们注意到begin可以返回指针, 所以对下面这种情况也没有什么意外的: int main() { using std::begin; using std::end; { int nums[] = {1, 2, 3}; auto it = begin(nums); cout \u003c\u003c typeid(it).name() \u003c\u003c endl; } cout \u003c\u003c \"--------------\" \u003c\u003c endl; { vector\u003cint\u003e nums{1, 2, 3}; auto it = begin(nums); cout \u003c\u003c typeid(it).name() \u003c\u003c endl; } return 1; } 输出是: Pi -------------- N9__gnu_cxx17__normal_iteratorIPiSt6vectorIiSaIiEEEE 第一个it是指针类型(指针), 第二个it是iterator类型(类). 指针和迭代器是一回事吗? ","date":"2021-03-04","objectID":"/202103/cpp-what-iterator/:2:1","tags":["Cpp","迭代器","traits"],"title":"STL-迭代器","uri":"/202103/cpp-what-iterator/"},{"categories":["Cpp","STL"],"content":"迭代器的分类 迭代器的分类(来自http://www.cplusplus.com/reference/iterator/) 按照cplusplus给出分类, 迭代器分为以下几种: 对所有的迭代器, 均支持拷贝构造和复制操作, 均可执行自加操作(++a和a++); 对input迭代器, 支持等于或不等于判断, 支持解引用操作; 对output迭代器, 可被解引用并且被赋值(解引用后可以作为左值); 对forward迭代器, 支持input和output的所有特性, 目前所有的标准容器至少支持forward迭代器; 对bidirectional迭代器, 支持forward迭代器的所有特性, 同时可以自减, 相当于可以双向访问; 对random access迭代器, 支持bidirectional迭代器的所有特性, 同时可以使用迭代器+偏置的方法访问所有元素, 也支持迭代器的大小比较, 可以使用下标访问; 指针满足random access迭代器的所有特性. 所以, 指针是random access迭代器. ","date":"2021-03-04","objectID":"/202103/cpp-what-iterator/:2:2","tags":["Cpp","迭代器","traits"],"title":"STL-迭代器","uri":"/202103/cpp-what-iterator/"},{"categories":["Cpp","STL"],"content":"自定义迭代器 template \u003cclass Category, class T, class Distance = ptrdiff_t, class Pointer = T*, class Reference = T\u0026\u003e struct iterator { typedef T value_type; typedef Distance difference_type; typedef Pointer pointer; typedef Reference reference; typedef Category iterator_category; }; 上述代码是C++提供的迭代器的基类, 但是没有提供任何方法, 只是定义了一些成员类型. value_type指代元素类型 difference_type指代两个元素距离的数据类型 pointer指代元素指针形式的类型 reference指代元素引用形式的类型 iterator_category指代迭代器所属的迭代器类型(上文中的五类类型) 前四种类型还好理解, iterator_category指代迭代器类型我认为是用来限制迭代器权限的. 我们来看下面的一段改编的例子: // std::iterator example #include \u003ciostream\u003e // std::cout #include \u003citerator\u003e // std::iterator, std::input_iterator_tag #include \u003calgorithm\u003e // for_each class MyIterator : public std::iterator\u003cstd::input_iterator_tag, int\u003e { int* p; public: MyIterator(int* x) :p(x) {} MyIterator(const MyIterator\u0026 mit) : p(mit.p) {} MyIterator\u0026 operator++() {++p;return *this;} MyIterator operator++(int) {MyIterator tmp(*this); operator++(); return tmp;} bool operator==(const MyIterator\u0026 rhs) const {return p==rhs.p;} bool operator!=(const MyIterator\u0026 rhs) const {return p!=rhs.p;} int\u0026 operator*() {return *p;} }; int main () { int numbers[]={10,20,30,40,50}; MyIterator begin(numbers); MyIterator end(numbers+5); for_each(begin, end, [](const int\u0026 n){ std::cout \u003c\u003c n \u003c\u003c ' '; }); std::cout \u003c\u003c '\\n'; return 0; } 这里自定义了迭代器MyIterator. 通过iterator基类可以知道, 这是一个input迭代器, 元素是int型的. 接下来需要按照input迭代器的权限去实现不同的方法, 需要支持: 拷贝构造/自加/等于或不等于判断/解引用. ","date":"2021-03-04","objectID":"/202103/cpp-what-iterator/:2:3","tags":["Cpp","迭代器","traits"],"title":"STL-迭代器","uri":"/202103/cpp-what-iterator/"},{"categories":["Cpp","STL"],"content":"iterator_traits iterator基类的成员类型在使用trait的时候很有用, C++也为迭代器提供了trait模板iterator_traits. 根据trait模板, 我们可以提取上述迭代器定义的成员类型. 下面又是一段官方例子: // iterator_traits example #include \u003ciostream\u003e // std::cout #include \u003citerator\u003e // std::iterator_traits #include \u003ctypeinfo\u003e // typeid int main() { typedef std::iterator_traits\u003cint*\u003e traits; if (typeid(traits::iterator_category)==typeid(std::random_access_iterator_tag)) std::cout \u003c\u003c \"int* is a random-access iterator\"; return 0; } 输出是: int* is a random-access iterator 同上文结论一样, 指针是random access迭代器. ","date":"2021-03-04","objectID":"/202103/cpp-what-iterator/:2:4","tags":["Cpp","迭代器","traits"],"title":"STL-迭代器","uri":"/202103/cpp-what-iterator/"},{"categories":["Cpp","STL"],"content":"小结 这篇文章的目的是理解什么是迭代器, 而不是知道这样用就行了(这也是我此前对迭代器的疑惑). 综上所述, 我们对迭代器的认知可以有以下结论: 迭代器是访问数组或容器数据的一种方式; 迭代器的目的是为数组或容器数据提供统一的访问接口; 指针也是迭代器, 但是不怎么通用; 在强调一点我认为比较重要的, 迭代器是访问数组或容器数据的方式, 而不是访问任何数据的方式, 这里要和指针区分的. ","date":"2021-03-04","objectID":"/202103/cpp-what-iterator/:3:0","tags":["Cpp","迭代器","traits"],"title":"STL-迭代器","uri":"/202103/cpp-what-iterator/"},{"categories":["Cpp"],"content":"问题 先来看一个问题: #include \u003ciostream\u003e using namespace std; #define ARRAY_SIZE(array) (sizeof((array)) / sizeof((array)[0])) int main() { int num_array[] = {1, 2, 3}; int* num = num_array; cout \u003c\u003c sizeof(num_array) \u003c\u003c endl; cout \u003c\u003c ARRAY_SIZE(num_array) \u003c\u003c endl; return 1; } 上面的代码输出是多少? 我们可以直接回答是12和3, 没问题. 但是稍微改动一下代码呢? 下面的代码输出是多少? cout \u003c\u003c sizeof(num) \u003c\u003c endl; cout \u003c\u003c ARRAY_SIZE(num) \u003c\u003c endl; 输出是: 8 2 看到答案后想想也是那么回事. 因为num是个指针所以sizeof(num) = 8, 没问题. 但是这个答案也揭示了一个问题: 数组和指针是有区别的. ","date":"2021-03-03","objectID":"/202103/cpp-arrynotpointer/:1:0","tags":["Cpp","数组","指针"],"title":"数组名不是指针","uri":"/202103/cpp-arrynotpointer/"},{"categories":["Cpp"],"content":"编译器的解释 使用cppinsights展开上面的代码, 看不到什么区别: #include \u003ciostream\u003e using namespace std; #define ARRAY_SIZE(array) (sizeof((array)) / sizeof((array)[0])) int main() { int num_array[3] = {1, 2, 3}; int* num = num_array; std::cout.operator\u003c\u003c(sizeof(num)).operator\u003c\u003c(std::endl); std::cout.operator\u003c\u003c((sizeof((num)) / sizeof((num)[0]))).operator\u003c\u003c(std::endl); return 1; } 但是, 编译器已经提醒我们注意了, sizeof(num)会返回指针的size, 而不是数组本身. warning: 'sizeof ((num))' will return the size of the pointer, not the array itself [-Wsizeof-pointer-div] ","date":"2021-03-03","objectID":"/202103/cpp-arrynotpointer/:2:0","tags":["Cpp","数组","指针"],"title":"数组名不是指针","uri":"/202103/cpp-arrynotpointer/"},{"categories":["Cpp"],"content":"汇编的解释 先看下面代码段的汇编代码: int num_array[] = {1, 2, 3}; int *num = num_array; 编译汇编后是: mov DWORD PTR [rbp-0x14],0x1 # 写入1 int num_array[] = {1, 2, 3}; mov DWORD PTR [rbp-0x10],0x2 # 写入2 int num_array[] = {1, 2, 3}; mov DWORD PTR [rbp-0xc],0x3 # 写入3 int num_array[] = {1, 2, 3}; lea rax,[rbp-0x14] # 取数组首地址的有效地址 int *num = num_array; mov QWORD PTR [rbp-0x8],rax # 有效地址赋值给num int *num = num_array; 符合我们的认知, num中存的是数组的首地址. 接下来添加一个函数: void pTest(int *pnum) { cout \u003c\u003c pnum[0] \u003c\u003c endl; } 调用这个函数: pTest(num); 汇编之后: mov rax,QWORD PTR [rbp-0x8] mov rdi,rax call 401182 \u003cpTest(int*)\u003e 可以理解, 是将指针指向的地址(指针的值)传递给函数参数, 有取值操作. 使用数组名调用这个函数: pTest(num_array); 汇编之后: lea rax,[rbp-0x14] mov rdi,rax call 401182 \u003cpTest(int*)\u003e 和使用指针有区别, 使用数组名传递的是地址, 没有取值操作. 到此结合int *num = num_array;的汇编, 我们可以知道数组名代表的是地址(!!!不是指针!!!) ","date":"2021-03-03","objectID":"/202103/cpp-arrynotpointer/:3:0","tags":["Cpp","数组","指针"],"title":"数组名不是指针","uri":"/202103/cpp-arrynotpointer/"},{"categories":["Cpp"],"content":"数组名是个右值 如果清楚理解了上文的结论\"数组名代表的是地址\", 就能清楚的理解\"数组名是个右值“这一结论. 我们使用代码来增强一下印象: num_array++; 数组名作为左值是不行的! 上一段代码会报错: \u003csource\u003e: In function 'int main()': \u003csource\u003e:23:5: error: lvalue required as increment operand 23 | num_array++; | ^~~~~~~~~ Execution build compiler returned: 1 ","date":"2021-03-03","objectID":"/202103/cpp-arrynotpointer/:4:0","tags":["Cpp","数组","指针"],"title":"数组名不是指针","uri":"/202103/cpp-arrynotpointer/"},{"categories":["Cpp"],"content":"结论 教科书中应该是提过这个观点: “数组名代表的是数组首地址”, 但是很少强调数组名和指针的区别. 综上所述, 我们强调数组和指针的区别, 并且有以下结论: 数组名是地址, 不是指针, 而是地址; 数组名是右值; 指针不是地址, 指针的值才是地址. ","date":"2021-03-03","objectID":"/202103/cpp-arrynotpointer/:5:0","tags":["Cpp","数组","指针"],"title":"数组名不是指针","uri":"/202103/cpp-arrynotpointer/"},{"categories":["Cpp"],"content":" 用const/constexpr修饰常量可以减少内存占用和拷贝操作. 这是我们在很多书上可以看到的结论, 但是为什么用const/constexpr修饰常量可以减少内存占用和拷贝操作呢? ","date":"2021-03-02","objectID":"/202103/cpp-addconst/:0:0","tags":["Cpp","const","constexpr","编译时"],"title":"为什么推荐加const或constexpr修饰常量","uri":"/202103/cpp-addconst/"},{"categories":["Cpp"],"content":"测试 ","date":"2021-03-02","objectID":"/202103/cpp-addconst/:1:0","tags":["Cpp","const","constexpr","编译时"],"title":"为什么推荐加const或constexpr修饰常量","uri":"/202103/cpp-addconst/"},{"categories":["Cpp"],"content":"不使用const/constexpr修饰 我们先来看一个反例, 不使用const/constexpr修饰常量: using namespace std; int num = 10; int main() { int get_num = num; return 1; } 我们可以得到汇编代码: mov eax,DWORD PTR [rip+0x2f1c] # 404028 \u003cnum\u003e mov DWORD PTR [rbp-0x4],eax 上面的汇编代码是int get_num = num;这一句, num被放在内存中, 先给寄存器eax, eax再将值赋给get_num. 在这里, 我们消耗了sizeof(int)的内存空间, 多了一个赋值操作. ","date":"2021-03-02","objectID":"/202103/cpp-addconst/:1:1","tags":["Cpp","const","constexpr","编译时"],"title":"为什么推荐加const或constexpr修饰常量","uri":"/202103/cpp-addconst/"},{"categories":["Cpp"],"content":"使用const/constexpr修饰 using namespace std; const int num = 10; int main() { int get_num = num; return 1; } int get_num = num;汇编后: mov DWORD PTR [rbp-0x4],0xa 将num的值直接赋值给get_num, 没有额外的内存占用, 没有额外的赋值操作. 但是, 使用const/constexpr修饰会让常量暴露出来(反汇编程序之后, 我们可以直接知道常量值是多少), 安全性较低. ","date":"2021-03-02","objectID":"/202103/cpp-addconst/:1:2","tags":["Cpp","const","constexpr","编译时"],"title":"为什么推荐加const或constexpr修饰常量","uri":"/202103/cpp-addconst/"},{"categories":["数据结构与算法"],"content":"一维链表 链表不需要一块很大的连续的存储空间是其优点, 但是对一串有序序列, 使用一维链表查询的时间复杂度是$O(n)$, 能否如查找二叉树之类, 将其查找时间复杂度降为$O(logn)$呢? 一维链表 一种常用的方法是升维. 升维也是一种空间换时间的思考方式, 会提高数据结构的空间复杂度, 但是可以降低一些操作的时间复杂度. ","date":"2021-03-01","objectID":"/202103/salgo-gaplink/:1:0","tags":["链表","跳表","查找","搜索"],"title":"数据结构与算法之跳表","uri":"/202103/salgo-gaplink/"},{"categories":["数据结构与算法"],"content":"跳表 跳表的一般结构, 将一维链表升维成二维: 跳表 跳表类似于图书馆的图书管理结构. 一般地, 图书馆存放图书有以下约定: 每本图书有其对应的唯一ID(key); 每本图书的ID可以比较大小关系; 图书是按照ID顺序存放的; 每一段ID的图书会放到同一个书架; 每个书架标识了存放图书的ID范围; 我们人工找书的操作是: 确定需要查找的图书的ID; 将图书ID与每个房间的最大最小ID比较, 如果在范围内则进入房间查找, 否则继续遍历下一个房间; 进入房间后, 将图书ID与每个书架的最大最小ID比较, 如果在范围内则进入书架查找, 否则继续遍历下一个书架; 走到对应书架, 按照顺序遍历书架上的每本书的ID, 如果与待查ID匹配则找到, 否则, 继续查找下一本书, 如果该书架所有书遍历完没找到, 则不存在; 放在跳表中, 这个数据结构是这样的: 每本书: 这里存储了每本书的ID(Key), 和书的内容; 每本书的ID 每个书架: 这里只存储书ID范围, 可以不包括书的内容; 每个书架的ID范围 每个房间: 这里只存储书ID范围, 可以不包括书的内容; 每个房间的ID范围 每栋楼: 这里只存储书ID范围, 可以不包括书的内容; 每栋楼的ID范围 ","date":"2021-03-01","objectID":"/202103/salgo-gaplink/:2:0","tags":["链表","跳表","查找","搜索"],"title":"数据结构与算法之跳表","uri":"/202103/salgo-gaplink/"},{"categories":["数据结构与算法"],"content":"查找 比如, 按照上文的数据, 查找元素7的流程是: 7与1判断, 7比1大, 且第四层1没有后继, 转第三层; 7与8比较, 比8小, 且8的前驱是1, 转第二层; 7与5比较, 7比5大, 且5的后继是8, 转第一层; 7与7比较, 匹配, 退出. 跳表-查找 在这里我们规定, 跳表的层级结构是从下往上的, 即每本书是第一层, 每栋楼是最高层. 按照这种结构(跳表), 对$N$个有序数据, 我们可以将连续$S$个数据划分为一组, 又将$S$个组划分为一个大组, 以此类推. 可以知道, 这种\"组\"的层数和每个组的成员数目有关, 为$log_S N$. 每次查找操作的时间复杂度是$O(S)$. 所以, 跳表的查找时间复杂度是$O(Slog_SN)$, $S$一般是常数, 即查找时间复杂度是$O(logn)$. 跳表需要用到额外的索引, 如果取$S = 2$, 可以知道额外的索引空间是 $\\lim\\limits_{N\\rightarrow\\infty}\\sum_1 ^N \\frac{N}{2^i} = N$, 如果$S$越大, 则需要越少的额外空间, 所以跳表的空间复杂度是$O(n)$. ","date":"2021-03-01","objectID":"/202103/salgo-gaplink/:2:1","tags":["链表","跳表","查找","搜索"],"title":"数据结构与算法之跳表","uri":"/202103/salgo-gaplink/"},{"categories":["数据结构与算法"],"content":"插入 按照查找操作找到待插入数据的位置, 之后插入即可. 但是这样可能带来退化的问题, 如果大量数据插入, 而我们没有更新索引, 则会导致跳表退化成链表(时间复杂度接近链表). 为了解决插入导致的退化问题, 我们需要在插入的时候, 动态更新索引, 比较常规的规则是: 根据某种条件, 确定待插入的结点是否要构建索引. 比如按照随机数规则, 如果rand(1, 10) \u003c= 1, 则对当前插入元素建立索引, 从多少层元素开始建立索引呢? 也可以根据随机数来确定, 从第k = rand(2, log(N))层开始建立索引. 以下, 插入元素6, 从第二层开始建立索引. 跳表-插入 当然, 我们也可以按照其他规则建立索引, 根据数据与项目的规则, 比如: 根据数据奇偶性; 根据某哈希函数(奇偶性判断也可以理解为哈希); 根据已插入结点的数目; ","date":"2021-03-01","objectID":"/202103/salgo-gaplink/:2:2","tags":["链表","跳表","查找","搜索"],"title":"数据结构与算法之跳表","uri":"/202103/salgo-gaplink/"},{"categories":["数据结构与算法"],"content":"删除 和链表操作一样, 直接删除元素即可, 但是需要注意, 如果有上级索引, 则也要删除上级索引. 跳表-删除 同样, 如果过多删除索引结点, 也可能引起跳表的退化. 类比于动态更新索引的操作, 删除操作时也可以制定一些规则来动态更新索引, 比如: 如果删除结点是索引结点且前驱/后继结点存在, 则可以对前驱/后继结点建立索引, 索引深度和被删除结点一致; 同1, 但是加入随机数判断是否对前驱/后继结点建立索引; 同1, 但是加入随机数计算前驱/后继结点建立索引的深度; ","date":"2021-03-01","objectID":"/202103/salgo-gaplink/:2:3","tags":["链表","跳表","查找","搜索"],"title":"数据结构与算法之跳表","uri":"/202103/salgo-gaplink/"},{"categories":["数据结构与算法","Cpp"],"content":"堆的结构 同二叉查找树类似, 堆也是一种特殊的二叉树: 堆是一颗完全二叉树; 堆的孩子结点都小于或者大于父结点; 所以, 堆可以像一颗完全二叉树一样, 很自然地可以使用顺序存储; 区别于二叉查找树, 堆的孩子结点是都小于或者大于父结点. 一般地, 堆划分为小顶堆和大顶堆: 父结点小于孩子结点的堆叫做小顶堆; 父结点大于孩子结点的堆叫做大顶堆; 如下是一个小顶堆: 堆-小顶堆 可以化做线形存储: [3, 4, 5, 9, 8, 7, 6, 10] ","date":"2021-02-24","objectID":"/202102/salgo-heap/:1:0","tags":["Cpp","二叉树","堆","查找","搜索","排序"],"title":"数据结构与算法之堆","uri":"/202102/salgo-heap/"},{"categories":["数据结构与算法","Cpp"],"content":"插入 插入时需要考虑堆的两个条件: 完全二叉树和大小关系. 一种较为简单的插入方式是从下到上插入, 在线形存储中就是在末尾插入: 插入到末尾结点; 比较与父结点的大小关系; 如果不满足大小关系, 则与父结点交换, 回到2, 否则退出; 比如对上文的小顶堆插入元素1, 则是如下过程: 堆-插入 对应堆线形存储的插入操作: 待插入元素插入到末尾. // 0 1 2 3 4 5 6 7 8 [ 3, 4, 5, 9, 8, 7, 6, 10, 1] 与父结点比较, 父结点index = (8 - 1) / 2 = 3, 不满足大小关系, 交换下标3和8结点. // 0 1 2 3 4 5 6 7 8 [ 3, 4, 5, 1, 8, 7, 6, 10, 9] 与父结点比较, 父结点index = (3 - 1) / 2 = 1, 不满足大小关系, 交换下标1和3结点. // 0 1 2 3 4 5 6 7 8 [ 3, 1, 5, 4, 8, 7, 6, 10, 9] 与父结点比较, 父结点index = (1 - 1) / 2 = 0, 不满足大小关系, 交换下标0和1结点. // 0 1 2 3 4 5 6 7 8 [ 1, 3, 5, 4, 8, 7, 6, 10, 9] 插入结束. 可以知道, 堆的插入操作的复杂度和堆的高度相关, 是$O(logn)$. ","date":"2021-02-24","objectID":"/202102/salgo-heap/:1:1","tags":["Cpp","二叉树","堆","查找","搜索","排序"],"title":"数据结构与算法之堆","uri":"/202102/salgo-heap/"},{"categories":["数据结构与算法","Cpp"],"content":"删除 堆的删除操作同插入操作类似, 是不断比较和交换的过程. 将待删除结点和末尾结点交换; 删除末尾结点; 比较交换后的结点和孩子结点的关系; 如果不满足堆的大小关系, 则与最小/最大的孩子结点交换, 回到3, 否则退出; 例如删除元素3, 链式结构的删除操作如下: 堆-删除 需要注意的是, 我们需要比较交换后的结点和孩子结点的最小/最大关系, 不需要和父结点比较, 因为和父结点必定是满足大小关系的. 如果是顺序存储: 交换被删除和末尾元素, 交换3和9. // 0 1 2 3 4 5 6 7 8 [ 1, 9, 5, 4, 8, 7, 6, 10, 3] 删除末尾元素, 删除3. // 0 1 2 3 4 5 6 7 [ 1, 9, 5, 4, 8, 7, 6, 10] 交换后的元素合孩子元素比较, 不满足大小关系, 则和最小的孩子结点交换, 交换9和4. // 0 1 2 3 4 5 6 7 [ 1, 4, 5, 9, 8, 7, 6, 10] ","date":"2021-02-24","objectID":"/202102/salgo-heap/:1:2","tags":["Cpp","二叉树","堆","查找","搜索","排序"],"title":"数据结构与算法之堆","uri":"/202102/salgo-heap/"},{"categories":["数据结构与算法","Cpp"],"content":"C++中的heap 先来看如下一段代码, 使用hp作为待堆化堆数据. #include \u003calgorithm\u003e #include \u003ciostream\u003e using namespace std; int main() { int hp[9] = {1, 3, 4, 5, 6, 7, 8, 9, 10}; using std::begin; using std::end; auto php = [\u0026]() { for_each(begin(hp), end(hp), [](const int \u0026n) { cout \u003c\u003c n \u003c\u003c \" \"; }); cout \u003c\u003c endl; }; make_heap(begin(hp), end(hp)); php(); cout \u003c\u003c is_heap(begin(hp), end(hp)) \u003c\u003c endl; pop_heap(begin(hp), end(hp)); php(); cout \u003c\u003c is_heap(begin(hp), end(hp)) \u003c\u003c endl; hp[8] = 11; push_heap(begin(hp), end(hp)); php(); cout \u003c\u003c is_heap(begin(hp), end(hp)) \u003c\u003c endl; sort_heap(begin(hp), end(hp)); php(); cout \u003c\u003c is_heap(begin(hp), end(hp)) \u003c\u003c endl; } 输出是 10 9 8 5 6 7 4 3 1 1 9 6 8 5 1 7 4 3 10 0 11 9 8 6 1 7 4 3 5 1 1 3 4 5 6 7 8 9 11 0 这里使用了begin和end, 起到迭代器的作用, 可以返回给定容器或者数组的迭代器. using std::begin; using std::end; begin和end, 是半闭半开的区间, [begin, end). 官网上的图是比较好的解释. begin和end ","date":"2021-02-24","objectID":"/202102/salgo-heap/:2:0","tags":["Cpp","二叉树","堆","查找","搜索","排序"],"title":"数据结构与算法之堆","uri":"/202102/salgo-heap/"},{"categories":["数据结构与算法","Cpp"],"content":"make_heap make_heap(begin(hp), end(hp)); 将hp指定区间堆化, 如果是begin和end, 则是堆化hp, 默认是大顶堆. 可以接受第三个参数f, 代表堆化规则, 因此可以实现大顶堆/小顶堆, 或者根据指定key堆化. ","date":"2021-02-24","objectID":"/202102/salgo-heap/:2:1","tags":["Cpp","二叉树","堆","查找","搜索","排序"],"title":"数据结构与算法之堆","uri":"/202102/salgo-heap/"},{"categories":["数据结构与算法","Cpp"],"content":"pop_heap pop_heap(begin(hp), end(hp)); 删除堆顶元素, 实际上是将堆顶元素和尾部元素交换, 然后堆化. 需要注意的是, 如上代码pop后, [begin, end)不再满足堆的条件, is_heap返回是false, 但是[begin, end - 1)是一个堆. ","date":"2021-02-24","objectID":"/202102/salgo-heap/:2:2","tags":["Cpp","二叉树","堆","查找","搜索","排序"],"title":"数据结构与算法之堆","uri":"/202102/salgo-heap/"},{"categories":["数据结构与算法","Cpp"],"content":"push_heap push_heap(begin(hp), end(hp)); push_heap会将末尾堆元素插入堆中, 但是需要保证[begin, end - 1]是一个堆. ","date":"2021-02-24","objectID":"/202102/salgo-heap/:2:3","tags":["Cpp","二叉树","堆","查找","搜索","排序"],"title":"数据结构与算法之堆","uri":"/202102/salgo-heap/"},{"categories":["数据结构与算法","Cpp"],"content":"sort_heap sort_heap(begin(hp), end(hp)); 堆排序, 事件复杂度是稳定的$O(nlogn)$, 相当于: pop_heap(begin(hp), end(hp) - i); ","date":"2021-02-24","objectID":"/202102/salgo-heap/:2:4","tags":["Cpp","二叉树","堆","查找","搜索","排序"],"title":"数据结构与算法之堆","uri":"/202102/salgo-heap/"},{"categories":["数据结构与算法","Cpp"],"content":"is_heap is_heap(begin(hp), end(hp)); 判断[begin, end)是否满足堆条件. ","date":"2021-02-24","objectID":"/202102/salgo-heap/:2:5","tags":["Cpp","二叉树","堆","查找","搜索","排序"],"title":"数据结构与算法之堆","uri":"/202102/salgo-heap/"},{"categories":["Cpp"],"content":"C++闭包 在一些现代对高级语言, 比如Python或者JavaScript中, 经常会提到闭包的概念, 但是在C++里面很少会听说闭包的概念. C++可以实现闭包吗? 可以. 闭包函数: 可以理解为函数里面定义的函数; 闭包: 可以理解为闭包函数可以访问到外层函数的变量, 即使外层函数已经返回. 这一点可能不是很好理解, 先来看一个例子: int main() { auto add = [] (const int\u0026 a) { int b = a * a; cout \u003c\u003c \"call f1 \" \u003c\u003c b \u003c\u003c endl; return [b] (const int \u0026c) { int d = b + c; cout \u003c\u003c \"call f2 \" \u003c\u003c d \u003c\u003c endl; return d; }; }; auto add_2 = add(2); cout \u003c\u003c \"------------\" \u003c\u003c endl; auto add_2_3 = add_2(3); return 1; } 定义一个add函数, 作用是$f(x, y) = x * x + y$; add_2获取了外层函数, 外层函数有局部变量b, $b = a * a$, 存储了入参2的初步计算结果, 返回值是另外一个匿名函数; add_2_3相当于获取了外层函数的局部变量b, 同时也获取了内层函数对返回值. 所以, 上述输出会是: call f1 4 ------------ call f2 7 也可以这样调用: auto add_2 = add(2); add_2(3); //7 add_2(4); //8 上述的调用方法会让add_2看起来和int add_2 = 2之类的定义很像.(就像是一个普通的变量) 或者: add(2)(3); //7 add(4)(5); //13 ","date":"2021-02-23","objectID":"/202102/cpp-closure/:1:0","tags":["Cpp","lambda","constexpr","编译时"],"title":"C++闭包","uri":"/202102/cpp-closure/"},{"categories":["Cpp"],"content":"lambda表达式 一般形式: [捕获变量] (形参) {语句}; ","date":"2021-02-23","objectID":"/202102/cpp-closure/:2:0","tags":["Cpp","lambda","constexpr","编译时"],"title":"C++闭包","uri":"/202102/cpp-closure/"},{"categories":["Cpp"],"content":"捕获变量 一般我们可以用=和\u0026来捕获所有变量, =代表值捕获, \u0026代表应用捕获; 或者, 可以是某个具体的参数, 如果直接使用参数, 就是值捕获, 如果是参数前带\u0026就是引用捕获; 再或者, 可以是一条语句, 比如[\u0026, sum = cal_sum()]() {//...}. 我们来看一个例子: int num = 1; [num](){ num = 2; cout \u003c\u003c num \u003c\u003c endl; }(); cout \u003c\u003c num \u003c\u003c endl; 会编译失败, 提示: \u003csource\u003e:36:13: error: assignment of read-only variable 'num' 因为lambda模式是const的, 不可修改捕获变量.(可以理解成类中的const成员函数, 捕获变量则理解为成员变量) 我们可以加一个mutable声明, 同类一样, 加上mutable声明后, 就可以在const成员函数中修改成员变量了, 相当于明确告诉编译器, 我非常明确知道我接下来的操作会有什么影响, 你不用优化了. int num = 1; [num]() mutable { num = 2; cout \u003c\u003c num \u003c\u003c endl; }(); cout \u003c\u003c num \u003c\u003c endl; 输出是: 2 1 这里和预期是相符的, 因为我们使用的是值捕获, 如果改成引用捕获就会输出: 2 2 引用捕获可以减少拷贝行为, 但是无脑使用引用捕获也会引起一些问题. auto add = [] (const int\u0026 a) { int c = a * a; return [\u0026c] (const int \u0026b) { return c + b; }; }; cout \u003c\u003c add(1)(2) \u003c\u003c endl; 在我的编译环境下, 这段代码对输出是32769, 是意料之外的, 预期输出应该是3. 问题在于使用了引用捕获, 在add(1)调用外层函数的之后, int c = a * a;作为局部变量已经被释放了, 所以调用add(1)(2)会出现引用错误. 正确做法是使用值捕获, 会拷贝一次, 但是不管怎样拷贝的值是我们想要的, 不会引起错误. ","date":"2021-02-23","objectID":"/202102/cpp-closure/:2:1","tags":["Cpp","lambda","constexpr","编译时"],"title":"C++闭包","uri":"/202102/cpp-closure/"},{"categories":["Cpp"],"content":"形参 用到lambda会想到一个问题, 能不能像模板函数一样呢? 可以的. 比如实现加法计算, 可以如下定义: auto add = [] (auto a, auto b) { return a + b; }; cout \u003c\u003c add(1, 2.2) \u003c\u003c endl; 如果是模板实现, 则要麻烦得多: template\u003ctypename T\u003e auto add(T a, T b) { return a + b; } //... cout \u003c\u003c add(1, 2.2) \u003c\u003c endl; 调用add(1, 2.2)是会报错的, 因为入参2.2时T推导时double, 入参1时推导是int, 找不到匹配函数. 得定义两个模板类型: template\u003ctypename T1, typename T2\u003e auto add(T1 a, T2 b) { return a + b; } 很明显, 使用lambda和auto会简单一些. ","date":"2021-02-23","objectID":"/202102/cpp-closure/:2:2","tags":["Cpp","lambda","constexpr","编译时"],"title":"C++闭包","uri":"/202102/cpp-closure/"},{"categories":["Cpp"],"content":"一般性用法 代码片段打包 一般性, 可以将lambda用于打包小段功能代码, 比如重复性的log: const auto stat_log = [=](const int \u0026index, const PROCESSSTAT \u0026process_stat) { logi(\"processing index[{}] stat {} next {}, ret {}\", index, statStr(process_stat).c_str(), statStr(getCurrentStat()).c_str(), statStr(m_algo_ret).c_str()); }; 在需要调用对地方, 只需要调用stat_log函数就行了: stat_log(index, PROCESSSTAT::PROCESSRUN); stat_log(index, PROCESSSTAT::PROCESSERROR); 相较于非lambda情况, 我们不再需要在外部定义一个函数, 减少了接口暴露的问题. 作为入参 在以往, 实现回调功能需要使用函数指针实现, 但是C++11之后可以使用function对象. lambda表达式是一个function对象, 我们可以将其作为函数对入参. 比如sort函数: int main() { vector\u003cint\u003e v{4, 3, 1, 2}; sort(v.begin(), v.end()); for_each(v.begin(), v.end(), [](const int\u0026 a){ cout \u003c\u003c a \u003c\u003c endl; }); } 默认是按照递增排序, 如果需要递减, 则: sort(v.begin(), v.end(), greater\u003cint\u003e()); 或者, 我们也可以实现自己定义的排序规则, 比如: sort(v.begin(), v.end(), [](const int\u0026 a, const int\u0026 b){ return a \u003c b; }); 自定义排序函数, 在对一些复杂结构(如struct)排序时很有用, 我们可以指定排序的参考key. 再看这一段: for_each(v.begin(), v.end(), [](const int\u0026 a){ cout \u003c\u003c a \u003c\u003c endl; }); 借用for_each遍历, 使用lambda表达式, 我们可以实现很多不同的功能, 仅仅修改表达式的内容即可. 比如实现四则运算: unordered_map\u003cchar, function\u003cint(const int\u0026, const int\u0026)\u003e\u003e cal{ {'+', [](const int\u0026 a, const int\u0026 b){ return a + b; } }, //... }; cout \u003c\u003c cal['+'](1, 2) \u003c\u003c endl; ","date":"2021-02-23","objectID":"/202102/cpp-closure/:2:3","tags":["Cpp","lambda","constexpr","编译时"],"title":"C++闭包","uri":"/202102/cpp-closure/"},{"categories":["Cpp"],"content":"lambda展开 lambda表达式的功能很强大, 是怎么做到的呢? 来看一个简单的例子: #include \u003calgorithm\u003e #include \u003ciostream\u003e using namespace std; int main() { auto lmd_func = [] (const int\u0026 a) { int b = a * a; return b; }; auto lmd_ret = lmd_func(2); cout \u003c\u003c lmd_ret \u003c\u003c endl; return 1; } 编译过程中, 会将lambda展开, 实际上是一个类, 重载()运算符. int main() { class __lambda_8_21 { public: inline int operator()(const int \u0026 a) const { int b = a * a; return b; } using retType_8_21 = int (*)(const int \u0026); inline operator retType_8_21 () const noexcept { return __invoke; }; private: static inline int __invoke(const int \u0026 a) { int b = a * a; return b; } public: // inline /*constexpr */ __lambda_8_21(__lambda_8_21 \u0026\u0026) noexcept = default; }; __lambda_8_21 lmd_func = __lambda_8_21(__lambda_8_21{}); int lmd_ret = lmd_func.operator()(2); std::cout.operator\u003c\u003c(lmd_ret).operator\u003c\u003c(std::endl); return 1; } 上面的lmd_func被展开成了类__lambda_8_21. 关注这条语句: __lambda_8_21 lmd_func = __lambda_8_21(__lambda_8_21{}); 使用了默认构造函数, 为什么要多此一举呢? 在这里直接使用: __lambda_8_21 lmd_func = __lambda_8_21(); 也是可以的. 但是, 如果情况稍微复杂一点, 就不能满足了. 比如我们使用捕获: int main() { auto init = 3; auto lmd_func = [init] (const int\u0026 a) { int b = a * a + init; return b; }; auto lmd_ret = lmd_func(2); cout \u003c\u003c lmd_ret \u003c\u003c endl; return 1; } 经过展开后, lambda表达式展开为: class __lambda_10_21 { public: inline int operator()(const int \u0026 a) const { int b = (a * a) + init; return b; } private: int init; public: // inline /*constexpr */ __lambda_10_21(__lambda_10_21 \u0026\u0026) noexcept = default; __lambda_10_21(int \u0026 _init) : init{_init} {} }; 捕获变量被构造成了展开类的成员变量, 并且实现了类的带参构造函数, lambda的调用语句被展开成了: __lambda_10_21 lmd_func = __lambda_10_21(__lambda_10_21{init}); 所以, 上述的值捕获, 在这里是通过构造函数传递给lambda表达式的. 以上展开式使用工具cppinsights ","date":"2021-02-23","objectID":"/202102/cpp-closure/:2:4","tags":["Cpp","lambda","constexpr","编译时"],"title":"C++闭包","uri":"/202102/cpp-closure/"},{"categories":["Cpp"],"content":"lambda编译期运算 lambda表达式结果可以在编译期计算 lambda表达式是可以在编译期就计算出结果的. auto lmd_func = [] (const int\u0026 a) { int b = a * a; return b; }; 上式展开得到以下的类, 我们看到了constexpr关键词, 这似乎意味lambda可以作为constexpr函数. class __lambda_7_21 { public: inline /*constexpr */ int operator()(const int \u0026 a) const { int b = a * a; return b; } using retType_7_21 = int (*)(const int \u0026); inline /*constexpr */ operator retType_7_21 () const noexcept { return __invoke; }; private: static inline int __invoke(const int \u0026 a) { int b = a * a; return b; } public: // /*constexpr */ __lambda_7_21() = default; }; 目前看来, C++11标准的编译器一般不会默认给lambda表达式添加上constexpr关键词. 但是C++17标准后, 给lambda表达式添加上了constexpr关键词. 所以在C++17编译条件下, 可以这样使用: constexpr int dbl1 = lmd_func(3); 这时候就已经是编译期计算, 并且将值赋值给内存. 在C++11标准为了启动优化, 我们需要加上-O2参数(gcc编译器). 调用接口: int dbl1 = lmd_func(3); 在汇编时编译器已经计算出结果, 并赋值给寄存器了(启动编译器优化后, 直接赋值给寄存器, 而不是内存). mov esi, 9 ","date":"2021-02-23","objectID":"/202102/cpp-closure/:2:5","tags":["Cpp","lambda","constexpr","编译时"],"title":"C++闭包","uri":"/202102/cpp-closure/"},{"categories":["数据结构与算法"],"content":"平衡树 对于一个普通的二叉查找树, 我们可以发现一个问题, 存在一定的可能性, 一般的二叉查找树会退化成一般的链表. 不太平衡的二叉树 上图还没有完全退化, 但是如果查找6这个结点, 会比其他的叶子结点走更多的路程. 为了解决一般二叉查找树可能带来的退化问题, 引入了平衡树的概念. 完全二叉树和满二叉树是平衡树. 平衡树的定义就是: 左右子树的高度差不大于1的树. ","date":"2021-02-20","objectID":"/202102/salgo-234tree/:1:0","tags":["二叉树","2-3-4树","平衡树","查找","搜索"],"title":"数据结构与算法之2-3-4树","uri":"/202102/salgo-234tree/"},{"categories":["数据结构与算法"],"content":"2-3-4树 2-3-4树 2-3-4树的意思就是二叉/三叉/四叉树. 简单起见, 可以把2-3-4树定义为四叉树, 一个结点可以存储三个元素和四个孩子结点的指针. 如上图, 先约定左中右三个元素代号是A, B, C; 从左到右的四个孩子结点的指针是a, b, c, d. 可以看到, 每个结点元素不一定要填满, 每个子结点指针也不一定要填满. ","date":"2021-02-20","objectID":"/202102/salgo-234tree/:2:0","tags":["二叉树","2-3-4树","平衡树","查找","搜索"],"title":"数据结构与算法之2-3-4树","uri":"/202102/salgo-234tree/"},{"categories":["数据结构与算法"],"content":"查找 和二叉查找树类似, 每个结点的子树也是根据元素与结点大小划分的. a指向P \u003c A的子树; b指向A \u003c P \u003c B的子树; c指向B \u003c P \u003c C的子树; d指向C \u003c P的子树; 所以, 查找一个结点的时候, 根据被查找元素P与A/B/C的大小关系, 走不同的路径来查找元素. 以下, 是查找元素4的搜索路径. 2-3-4树-查找 ","date":"2021-02-20","objectID":"/202102/salgo-234tree/:3:0","tags":["二叉树","2-3-4树","平衡树","查找","搜索"],"title":"数据结构与算法之2-3-4树","uri":"/202102/salgo-234tree/"},{"categories":["数据结构与算法"],"content":"插入 对2-3-4树的插入操作需要分类讨论, 根据不同的情况需要做对应对调整, 使插入后的树依然保持平衡. ","date":"2021-02-20","objectID":"/202102/salgo-234tree/:4:0","tags":["二叉树","2-3-4树","平衡树","查找","搜索"],"title":"数据结构与算法之2-3-4树","uri":"/202102/salgo-234tree/"},{"categories":["数据结构与算法"],"content":"插入结点是不满的叶子结点 2-3-4树-直接插入 对插入结点是不满的叶子结点的情况, 和查找元素类似, 根据大小关系找到被插入元素在树中的位置, 因为结点没有插入满, 所以元素可以直接插入. ","date":"2021-02-20","objectID":"/202102/salgo-234tree/:4:1","tags":["二叉树","2-3-4树","平衡树","查找","搜索"],"title":"数据结构与算法之2-3-4树","uri":"/202102/salgo-234tree/"},{"categories":["数据结构与算法"],"content":"插入结点是满的叶子结点 2-3-4树-插入满叶子结点 如果发现插入的结点是满叶子结点, 则需要进行调整. 首先, A元素不动. 调整B元素 我们仅截取需要调整对那颗子树. 2-3-4树-调整B元素 将B元素插入到父结点; 调整C元素 2-3-4树-调整C元素 新建一个被调整结点对兄弟结点. 将C元素插入兄弟结点. 所以, 最终的插入结果是 2-3-4树-插入后 ","date":"2021-02-20","objectID":"/202102/salgo-234tree/:4:2","tags":["二叉树","2-3-4树","平衡树","查找","搜索"],"title":"数据结构与算法之2-3-4树","uri":"/202102/salgo-234tree/"},{"categories":["数据结构与算法"],"content":"插入结点是满的非叶子结点 2-3-4树-插入满非叶子结点 如果发现插入的结点是满非叶子结点, 情况稍微复杂一点, 需要考虑被调整结点的子结点. 同样, A元素不动. 调整B元素 2-3-4树-调整B元素 如果被调整结点没有父结点, 则新建一个父结点, 将B元素插入父结点.(也就是说, 被调整结点是根结点.) 如果被调整结点有父结点, 则将B元素插入父结点. 调整C元素 2-3-4树-调整C元素 新建一个被调整结点对兄弟结点. 将C元素插入兄弟结点. 同时, 将c, d也插入到兄弟结点.(这个可以理解为C带着他的左右孩子一起插入到兄弟结点, A带着他的左右孩子一起留在原来的结点) ","date":"2021-02-20","objectID":"/202102/salgo-234tree/:4:3","tags":["二叉树","2-3-4树","平衡树","查找","搜索"],"title":"数据结构与算法之2-3-4树","uri":"/202102/salgo-234tree/"},{"categories":["数据结构与算法"],"content":"总结:直接插入和结点分裂 总结一下上面的操作, 其是就分为两种: 直接插入和分裂后插入 直接插入 在元素插入的结点不满的时候, 可以使用直接插入操作, 这里就不再赘述. 2-3-4树-直接插入 元素5直接插入到4的右边. 结点分裂 在元素插入的结点满的时候, 需要进行结点分裂操作. 简单来说, 就是将中间元素放到父结点, 如果没有父结点则新建父结点, 然后将右元素及其孩子分裂出去, 作为当前结点的兄弟结点. 2-3-4树-分裂 元素6在结点分裂后插入到5的右边. 可以认为, a和b是A的孩子, c和d是C的孩子, 所以A和C移动时, 需要带上自己的孩子. ","date":"2021-02-20","objectID":"/202102/salgo-234tree/:4:4","tags":["二叉树","2-3-4树","平衡树","查找","搜索"],"title":"数据结构与算法之2-3-4树","uri":"/202102/salgo-234tree/"},{"categories":["数据结构与算法"],"content":"删除 ","date":"2021-02-20","objectID":"/202102/salgo-234tree/:5:0","tags":["二叉树","2-3-4树","平衡树","查找","搜索"],"title":"数据结构与算法之2-3-4树","uri":"/202102/salgo-234tree/"},{"categories":["数据结构与算法"],"content":"被删除的元素在非叶子结点 找到被删除元素的位置, 标记为D 中序遍历D 用D的中序遍历的后继元素D'替换D, 将D'作为被删除元素D 如果D在叶子结点, 则退出, 否则回到2 2-3-4树-删除非叶子结点 如上, 我们要删除元素5, 则先找到元素5, 然后中序遍历, 5的后继元素是7, 则用7替换5; 再将7的位置标记为待删除元素, 中序遍历之, 其后继元素是8, 所以用8替换, 且8在叶子结点, 则退出; ","date":"2021-02-20","objectID":"/202102/salgo-234tree/:5:1","tags":["二叉树","2-3-4树","平衡树","查找","搜索"],"title":"数据结构与算法之2-3-4树","uri":"/202102/salgo-234tree/"},{"categories":["数据结构与算法"],"content":"被删除元素在叶子结点 被删除元素在叶子结点且不是2结点 因为没有孩子了, 所以此时直接删除即可. 被删除元素在叶子结点且是2结点 如果直接删除, 会让整颗树看起来缺了一块, 按照以下操作: 删除该元素 如果兄弟结点不是2结点, 则父结点中的一个元素下移到该结点, 兄弟结点的一个元素上移到父结点, 退出 如果兄弟结点是2结点且父结点是3或4结点, 则兄弟的元素与父结点合并(实际上是作为插入操作, 插入父结点), 退出 如果兄弟结点是2结点且父结点是2结点, 则兄弟结点的元素与父结点合并, 形成3结点, 并将该结点作为考察结点, 回到2 以下: 删除元素6, 则按照规则2 2-3-4树-删除-1 删除元素6, 则按照规则3, 按照插入操作, 父结点满了, 再插入元素3, 此时需要分裂 2-3-4树-删除-2 删除元素6, 则按照规则4, 如果还没有结束, 则重复2-3-4 2-3-4树-删除-3 ","date":"2021-02-20","objectID":"/202102/salgo-234tree/:5:2","tags":["二叉树","2-3-4树","平衡树","查找","搜索"],"title":"数据结构与算法之2-3-4树","uri":"/202102/salgo-234tree/"},{"categories":["数据结构与算法"],"content":"2-3-4树为什么可以保持平衡 根据2-3-4树的插入操作不难看出, 2-3-4树是按照向上(生成/插入父结点)和向左(生成兄弟结点)扩展的, 所以插入操作不会导致2-3-4树出现某颗子树特别高的情况. 从删除操作看, 删除某个元素之后会尽量不齐, 无法不齐的情况, 则考虑先父亲迭代(减少层数), 总之其目的是尽量保证叶子层是平的, 没有坑坑洼洼. ","date":"2021-02-20","objectID":"/202102/salgo-234tree/:6:0","tags":["二叉树","2-3-4树","平衡树","查找","搜索"],"title":"数据结构与算法之2-3-4树","uri":"/202102/salgo-234tree/"},{"categories":["数据结构与算法"],"content":"什么是二叉查找树 对一般容器的查找, 我们可以按顺序遍历, 找到符合要求的元素就返回; 对于元素是有序的容器, 可以使用二分查找等方法查找, 减少操作的时间复杂度. 容易知道, 一般查找的平均时间复杂度是O(n), 二分查找的平均时间复杂度是O(logn). 什么是二叉查找树? 根结点的左子树的结点都小(大)于根结点, 根结点的右子树的结点都大(小)于根结点; 二叉查找树 你也可能听过二叉排序树, 二叉排序树就是二叉查找树, 名字不同罢了. 二叉查找树是怎么排序的呢? 我们可以想象一颗二叉查找树, 最左边的结点最小, 最右边的结点最大, 对每个子树这个结论也成立. 所以, 二叉查找树的中序遍历就是排序操作. 如上二叉查找树, 中序遍历的结果是 1, 2, 3, 4, 5, 6, 7, 8, 9 ","date":"2021-02-08","objectID":"/202102/salgo-binschtree/:1:0","tags":["Cpp","二叉树","查找","搜索","排序"],"title":"数据结构与算法之二叉查找树","uri":"/202102/salgo-binschtree/"},{"categories":["数据结构与算法"],"content":"二叉查找树的查找操作 根据二叉查找树的定义, 左子树的结点都小于根结点, 右子树的结点都大于根结点. 对于输入待查找的一个结点, 我们可以先与根结点比较, 如果小于, 则继续递归左子树, 如果大于, 则继续递归右子树, 直到找到匹配的结点. NodeTree *bsearch(NodeTree *root, const int \u0026val) { if (!root) { return nullptr; } if (val == root-\u003eval) { return root; } if (val \u003c root-\u003eval) { return bsearch(root-\u003eleft, val); } if (val \u003e root-\u003eval) { return bsearch(root-\u003eright, val); } } ","date":"2021-02-08","objectID":"/202102/salgo-binschtree/:2:0","tags":["Cpp","二叉树","查找","搜索","排序"],"title":"数据结构与算法之二叉查找树","uri":"/202102/salgo-binschtree/"},{"categories":["数据结构与算法"],"content":"二叉查找树的插入操作 构建一颗二叉查找树也就是不停地执行二叉查找树的插入操作, 要保证插入之后的二叉树还是二叉查找树. 二叉树的插入操作就是其查找操作的进阶版本. 对需要插入的元素, 与根结点比较, 如果小于则对左子树递归, 如果大于则对右子树递归, 直到最终的叶子结点; 如果比叶子结点小, 则作为叶子结点的左子结点, 如果比叶子结点大, 则作为叶子结点的右子结点. 二叉查找树-插入 比如说插入元素6, 则按照加粗标记的箭头插入. 最终遍历到结点5时, 发现是叶子结点, 且6比5大, 则6作为5的右子结点插入. ","date":"2021-02-08","objectID":"/202102/salgo-binschtree/:3:0","tags":["Cpp","二叉树","查找","搜索","排序"],"title":"数据结构与算法之二叉查找树","uri":"/202102/salgo-binschtree/"},{"categories":["数据结构与算法"],"content":"二叉查找树的删除操作 对二叉查找树的删除可以分类讨论. 对于没有子结点和只有一个子结点的删除操作, 可以参考这个图 二叉查找树-删除-一个子结点 ","date":"2021-02-08","objectID":"/202102/salgo-binschtree/:4:0","tags":["Cpp","二叉树","查找","搜索","排序"],"title":"数据结构与算法之二叉查找树","uri":"/202102/salgo-binschtree/"},{"categories":["数据结构与算法"],"content":"删除的结点没有子结点 如果被删除的结点没有子结点, 即是叶子结点, 则直接将叶子结点的父结点指向该叶子结点的指针置空就行. 伪代码如下: node-\u003eparent-\u003eleft == node ? (node-\u003eparent-\u003eleft = nullptr) : (node-\u003eparent-\u003eright = nullptr); delete node; ","date":"2021-02-08","objectID":"/202102/salgo-binschtree/:4:1","tags":["Cpp","二叉树","查找","搜索","排序"],"title":"数据结构与算法之二叉查找树","uri":"/202102/salgo-binschtree/"},{"categories":["数据结构与算法"],"content":"删除的结点只有一个子结点 如果被删除的结点只有一个子结点, 则将该结点的父结点指向该结点的指针重新指向该结点的子结点即可. 伪代码如下: node-\u003eparent-\u003eleft == node ? (node-\u003eparent-\u003eleft = node-\u003eleft) : (node-\u003eparent-\u003eright = node-\u003eright); delete node; ","date":"2021-02-08","objectID":"/202102/salgo-binschtree/:4:2","tags":["Cpp","二叉树","查找","搜索","排序"],"title":"数据结构与算法之二叉查找树","uri":"/202102/salgo-binschtree/"},{"categories":["数据结构与算法"],"content":"删除的结点有两个子结点 如果被删除的结点有两个子结点, 则情况稍微复杂一点, 我们可以看一个特例, 被删除的结点是根结点. (不是根结点也是子树的根结点) 二叉查找树-删除-两个子结点 我们需要删除结点3, 怎么操作? 根据二叉查找树的定义, 我们可以知道: 二叉查找树的最左边结点是最小的结点; 二叉查找树的最右边结点是最大的结点; 所以, 又有下面两个结论: 左子树的最右边结点是左子树的最大结点; 右子树的最左边结点是右子树的最小结点; 所以, 我们有两种方案删除有两个子结点的结点; 用左子树的最右边结点替换被删除结点, 这时候被替换的结点依然满足左子树的结点都小于它, 右子树的结点都大于它; 用右子树的最左边结点替换被删除结点, 这时候被替换的结点依然满足左子树的结点都小于它, 右子树的结点都大于它; 二叉查找树-删除-左子树最右 二叉查找树-删除-右子树最左 所以伪代码可以是: bool is_rl = false; //判断是否是左子树根结点 Nodetree *rl_node = node-\u003eright; //右子树 while (rl_node-\u003eleft) //右子树最左边 { is_rl = true; rl_node = rl_node-\u003eleft; } rl_node-\u003eleft = node-\u003eleft; if (is_rl) { rl_node-\u003eright = node-\u003eright; rl_node-\u003eparent-\u003eleft = nullptr; } delete node; ","date":"2021-02-08","objectID":"/202102/salgo-binschtree/:4:3","tags":["Cpp","二叉树","查找","搜索","排序"],"title":"数据结构与算法之二叉查找树","uri":"/202102/salgo-binschtree/"},{"categories":["数据结构与算法"],"content":"遍历二叉树的作用 基于二叉树的结构, 衍生出了二叉查找树/平衡二叉查找树/堆等等结构或算法(这些之后会讲), 学会如何遍历一颗二叉树是学习此类\"派生二叉树\"的基础. ","date":"2021-02-01","objectID":"/202102/salgo-bintree-list/:1:0","tags":["Cpp","二叉树","排序"],"title":"数据结构与算法之二叉树的遍历","uri":"/202102/salgo-bintree-list/"},{"categories":["数据结构与算法"],"content":"二叉树的遍历 我们先来看一颗一般的二叉树. 然后根据不同的遍历方式, 看看这颗二叉树结点最终遍历的顺序. 二叉树 ","date":"2021-02-01","objectID":"/202102/salgo-bintree-list/:2:0","tags":["Cpp","二叉树","排序"],"title":"数据结构与算法之二叉树的遍历","uri":"/202102/salgo-bintree-list/"},{"categories":["数据结构与算法"],"content":"前序遍历 前序遍历就是按照先根结点, 再左右子结点的方式去遍历(root -\u003e left -\u003e right). 对一个链式存储的二叉树来说, 代码如下: vector\u003cint\u003e pre; vector\u003cint\u003e preorderTraversal(TreeNode* root) { if (!root) { return pre; } pre.push_back(root-\u003eval); preorderTraversal(root-\u003eleft); preorderTraversal(root-\u003eright); return pre; } 我们先跟着代码的逻辑走一遍: N1是根结点, push进队列 [N1] 操作N1左子结点N2, N2是N2子树的根结点, push进队列 [N1, N2] 操作N2左子结点N4, N4是N4子树的根结点, push进队列 [N1, N2, N4] N4没有子结点, 操作N4的父结点N2的右子结点N5, N5是N5子树的根结点, push进队列 [N1, N2, N4, N5] 操作N5左子结点N7, N7是N7子树的根结点, push进队列 [N1, N2, N4, N5, N7] N7没有子结点, 退回到父结点, 直到发现N1有右子结点N3, N3是N3子树的根结点, push进队列 [N1, N2, N4, N5, N7, N3] 操作N3左子结点N6, N6是N6子树的根结点, push进队列, 全部遍历完成 [N1, N2, N4, N5, N7, N3, N6] 所以, 最终按照前序遍历的结果是: [N1, N2, N4, N5, N7, N3, N6] 使用递归的编程技巧很容易实现前序遍历的代码, 但是递归有太多的临时变量, 随着递归深度的增加, 消耗的内存也在一直增加; (对二叉树这种结构, 递归还可接受, 递归深度一般是logn, 不过极端情况可以达到n) 如何不使用递归实现前序遍历呢? 非递归方法实现前序遍历 这里, 我参考图遍历中一般会用的两个表, OPEN表和CLOSE表实现二叉树的前序遍历, OPEN表和CLOSE表在图论中会讲到. vector\u003cint\u003e preorderTraversal(TreeNode* root) { vector\u003cint\u003e pre; if (!root) { return pre; } stack\u003cTreeNode *\u003e open; vector\u003cTreeNode *\u003e close; auto is_visited = [\u0026] (TreeNode * node) -\u003e bool { for (const auto cn : close) { if (cn == node) { return true; } } return false; }; open.push(root); while(!open.empty()) { TreeNode *top = open.top(); if (!is_visited(top)) { close.emplace_back(top); pre.emplace_back(top-\u003eval); } if (top-\u003eleft \u0026\u0026 !is_visited(top-\u003eleft)) { open.push(top-\u003eleft); } else if (top-\u003eright \u0026\u0026 !is_visited(top-\u003eright)) { open.push(top-\u003eright); } else { open.pop(); } } return pre; } open表中存储了待遍历的结点, close表中存储了已经遍历过的结点. 那么上述代码的大致思想是: 初始化open表, 将root结点push进表; 如果open表的top元素没有被遍历过(不在close)表, 这储存其值, 并将top结点加入到close表; 如果open表的top元素的left结点存在且没有被遍历过, 则将left结点push进open表; 如果3失败, 但是open表的top元素的right结点存在且没有被遍历过, 则将right结点push进open表; 如果3/4都失败, 则说明子结点不存在或者都被遍历过, 则弹出top元素; ","date":"2021-02-01","objectID":"/202102/salgo-bintree-list/:2:1","tags":["Cpp","二叉树","排序"],"title":"数据结构与算法之二叉树的遍历","uri":"/202102/salgo-bintree-list/"},{"categories":["数据结构与算法"],"content":"中序遍历 中序遍历就是按照先左子结点, 再根结点, 最后右子结点的方式去遍历(left -\u003e root -\u003e right). vector\u003cint\u003e pre; vector\u003cint\u003e preorderTraversal(TreeNode* root) { if (!root) { return pre; } preorderTraversal(root-\u003eleft); pre.push_back(root-\u003eval); preorderTraversal(root-\u003eright); return pre; } 中序遍历可以自行思考遍历的过程, 按照中序遍历的结果是: [N4, N2, N7, N5, N1, N6, N3] ","date":"2021-02-01","objectID":"/202102/salgo-bintree-list/:2:2","tags":["Cpp","二叉树","排序"],"title":"数据结构与算法之二叉树的遍历","uri":"/202102/salgo-bintree-list/"},{"categories":["数据结构与算法"],"content":"后序遍历 后序遍历就是按照先左右子结点, 再根结点的方式去遍历(left -\u003e right -\u003e root). vector\u003cint\u003e pre; vector\u003cint\u003e preorderTraversal(TreeNode* root) { if (!root) { return pre; } preorderTraversal(root-\u003eleft); preorderTraversal(root-\u003eright); pre.push_back(root-\u003eval); return pre; } 后序遍历可以自行思考遍历的过程, 按照后序遍历的结果是: [N4, N7, N5, N2, N6, N3, N1] ","date":"2021-02-01","objectID":"/202102/salgo-bintree-list/:2:3","tags":["Cpp","二叉树","排序"],"title":"数据结构与算法之二叉树的遍历","uri":"/202102/salgo-bintree-list/"},{"categories":["数据结构与算法"],"content":"二叉树非递归遍历总结 以leetcode题AC作为验证: [144] 二叉树的前序遍历 [94] 二叉树的中序遍历 [145] 二叉树的后序遍历 ","date":"2021-02-01","objectID":"/202102/salgo-bintree-list/:3:0","tags":["Cpp","二叉树","排序"],"title":"数据结构与算法之二叉树的遍历","uri":"/202102/salgo-bintree-list/"},{"categories":["数据结构与算法"],"content":"栈 前序遍历 vector\u003cint\u003e preorderTraversal(TreeNode* root) { if (root == nullptr) return {}; vector\u003cint\u003e result; stack\u003cTreeNode *\u003e st; st.push(root); while(!st.empty()) { TreeNode *node = st.top(); st.pop(); result.emplace_back(node-\u003eval); if (node-\u003eright) st.push(node-\u003eright); if (node-\u003eleft) st.push(node-\u003eleft); } return result; } 中序遍历 vector\u003cint\u003e inorderTraversal(TreeNode* root) { if (root == nullptr) return {}; vector\u003cint\u003e result; stack\u003cTreeNode *\u003e st; TreeNode *node = root; while(!st.empty() || node != nullptr) { if (node) { st.push(node); node = node-\u003eleft; } else { node = st.top(); st.pop(); result.emplace_back(node-\u003eval); node = node-\u003eright; } } return result; } 后序遍历 后序遍历中, 任一节点的前驱节点是它的右子节点, 如果右子节点不存在则是左子节点, 这即是lastnode存在的意义. vector\u003cint\u003e postorderTraversal(TreeNode* root) { if (root == nullptr) return {}; vector\u003cint\u003e result; stack\u003cTreeNode *\u003e st; st.push(root); TreeNode *lastnode = root; while(!st.empty()) { TreeNode *node = st.top(); st.pop(); bool is_leaf = (node-\u003eleft == nullptr) \u0026\u0026 (node-\u003eright == nullptr); bool is_lastpre = (node-\u003eleft == lastnode || node-\u003eright == lastnode); if (is_leaf || is_lastpre) { result.emplace_back(node-\u003eval); lastnode = node; } else { st.push(node); if (node-\u003eright) st.push(node-\u003eright); if (node-\u003eleft) st.push(node-\u003eleft); } } return result; } ","date":"2021-02-01","objectID":"/202102/salgo-bintree-list/:3:1","tags":["Cpp","二叉树","排序"],"title":"数据结构与算法之二叉树的遍历","uri":"/202102/salgo-bintree-list/"},{"categories":["数据结构与算法"],"content":"morris morris的目标是将遍历的空间复杂度降低到O(1), 通过对本文提及的三种遍历方法的认识, 可以理解到, 其难点在于怎么回到\"父节点\"(这里的父节点相对广义, 也可以是祖父节点之类). 那么, morris的核心思想就是通过利用二叉树叶子节点的空闲指针帮助回到\"父节点\". 如下: morris指针 利用左子树的最右侧叶子节点的右指针指向root节点, 在前序遍历和中序遍历的时候, 可以很方便的回到root节点. 比如前序遍历, 先做root节点, 然后做左子树, 左子树做完, 正好通过左子树的最右侧叶子节点的右指针回到了root节点(因为左子树的最右侧叶子节点是左子树最后一个被访问的节点), 此时可以做右子树. 又比如中序遍历, 然后做左子树, 左子树做完, 正好通过左子树的最右侧叶子节点的右指针回到了root节点(因为左子树的最右侧叶子节点是左子树最后一个被访问的节点), 然后做root节点, 接下来又方便的转移到右子树. 但是后序遍历则不这么直观, 因为root节点是在右子树做完之后才需要回去. 前序遍历 vector\u003cint\u003e preorderTraversal(TreeNode* root) { if (root == nullptr) return {}; vector\u003cint\u003e result; TreeNode *mostright = nullptr; while(root != nullptr) { if (root-\u003eleft) { mostright = root-\u003eleft; while(mostright-\u003eright != nullptr \u0026\u0026 mostright-\u003eright != root) mostright = mostright-\u003eright; if (mostright-\u003eright == nullptr) { mostright-\u003eright = root; result.emplace_back(root-\u003eval); root = root-\u003eleft; } else { mostright-\u003eright = nullptr; root = root-\u003eright; } } else { result.emplace_back(root-\u003eval); root = root-\u003eright; } } return result; } 中序遍历 vector\u003cint\u003e inorderTraversal(TreeNode* root) { if (root == nullptr) return {}; vector\u003cint\u003e result; TreeNode *mostright = nullptr; while(root != nullptr) { if (root-\u003eleft) { mostright = root-\u003eleft; while(mostright-\u003eright != nullptr \u0026\u0026 mostright-\u003eright != root) mostright = mostright-\u003eright; if (mostright-\u003eright == nullptr) { mostright-\u003eright = root; root = root-\u003eleft; } else { result.emplace_back(root-\u003eval); mostright-\u003eright = nullptr; root = root-\u003eright; } } else { result.emplace_back(root-\u003eval); root = root-\u003eright; } } return result; } 后序遍历 后序遍历就是\"前序遍历\"(中-\u003e右-\u003e左)的反转. vector\u003cint\u003e postorderTraversal(TreeNode* root) { if (root == nullptr) return {}; vector\u003cint\u003e result; TreeNode *mostright = nullptr; while(root != nullptr) { if (root-\u003eright) { mostright = root-\u003eright; while(mostright-\u003eleft != nullptr \u0026\u0026 mostright-\u003eleft != root) mostright = mostright-\u003eleft; if (mostright-\u003eleft == nullptr) { mostright-\u003eleft = root; result.emplace_back(root-\u003eval); root = root-\u003eright; } else { mostright-\u003eleft = nullptr; root = root-\u003eleft; } } else { result.emplace_back(root-\u003eval); root = root-\u003eleft; } } reverse(result.begin(), result.end()); return result; } ","date":"2021-02-01","objectID":"/202102/salgo-bintree-list/:3:2","tags":["Cpp","二叉树","排序"],"title":"数据结构与算法之二叉树的遍历","uri":"/202102/salgo-bintree-list/"},{"categories":["Cpp"],"content":"stdarg.h 这里用到的是stdarg.h这个库, 可以在C语言里面实现可变长参数. 当然C++会简单得多, C++11之后的模板原生支持可变长参数. 几个函数va_list、va_start、va_arg、va_end，定义在stdarg.h ","date":"2021-01-27","objectID":"/202101/purec-stdarg/:1:0","tags":["Cpp","模板"],"title":"C里面的变长参数","uri":"/202101/purec-stdarg/"},{"categories":["Cpp"],"content":"内存结构 先需要理解C/C++函数入参的顺序. 按照以下的demo, 将其翻译成汇编代码. #include \u003ciostream\u003e using namespace std; int sum(const int \u0026a, const int \u0026b, const int \u0026c) { int d = 0; d = a + b + c; return d; } int main() { int s = sum(1, 2, 3); cout \u003c\u003c s \u003c\u003c endl; return 1; } 首先是main函数, 主体部分的汇编 mov DWORD PTR [rbp-0x10],0x3 mov DWORD PTR [rbp-0xc],0x2 mov DWORD PTR [rbp-0x8],0x1 lea rdx,[rbp-0x10] lea rcx,[rbp-0xc] lea rax,[rbp-0x8] mov rsi,rcx mov rdi,rax call 401172 \u003csum(int const\u0026, int const\u0026, int const\u0026)\u003e 可以看到, main函数调用了sum函数, 首先搜获取三个参数, 1, 2, 3; 获取顺序是从右往左的. 先获取了3再是2再是1. 之后是一些操作将这三个参数从内存放到寄存器(Why?), 然后调用sum函数. sum函数的汇编代码如下 mov QWORD PTR [rbp-0x18],rdi mov QWORD PTR [rbp-0x20],rsi mov QWORD PTR [rbp-0x28],rdx mov DWORD PTR [rbp-0x4],0x0 mov rax,QWORD PTR [rbp-0x18] mov edx,DWORD PTR [rax] mov rax,QWORD PTR [rbp-0x20] mov eax,DWORD PTR [rax] add edx,eax mov rax,QWORD PTR [rbp-0x28] mov eax,DWORD PTR [rax] add eax,edx mov DWORD PTR [rbp-0x4],eax mov eax,DWORD PTR [rbp-0x4] 首先是从寄存器取值, 放到内存, 然后进入函数, 执行函数内部的操作, 最后将计算结果从内存放到寄存器. 这里注意一下型参的顺序. rdi, rsi, rdx对应的内存分别是a, b, c. 所以, 可以对上面的demo, 可以知道其内存分布是 对函数本体: 从低地址到高地址, 型参按照从左往右的顺序, 函数体按照从上往下的顺序执行; 函数本体 对函数调用: 从低地址到高地址, 实参按照从右往左的顺序, 函数体按照从上往下的顺序执行; 函数调用 ","date":"2021-01-27","objectID":"/202101/purec-stdarg/:2:0","tags":["Cpp","模板"],"title":"C里面的变长参数","uri":"/202101/purec-stdarg/"},{"categories":["Cpp"],"content":"内存对齐 源码头文件中，注意一下这个宏，内存对齐作用 看这里： #define __va_rounded_size(TYPE) \\ (((sizeof (TYPE) + sizeof (int) - 1) / sizeof (int)) * sizeof (int)) TYPE size \u003e= 4，偏移量=(sizeof(TYPE) / 4) * 4 TYPE size \u003c 4, 偏移量=4 所以是按4Byte，32位对齐。 ","date":"2021-01-27","objectID":"/202101/purec-stdarg/:3:0","tags":["Cpp","模板"],"title":"C里面的变长参数","uri":"/202101/purec-stdarg/"},{"categories":["Cpp"],"content":"va_list typedef char *va_list; 仅是一个指针, 这是一个适用于 va_start()、va_arg() 和 va_end() 这三个宏存储信息的类型。 ","date":"2021-01-27","objectID":"/202101/purec-stdarg/:4:0","tags":["Cpp","模板"],"title":"C里面的变长参数","uri":"/202101/purec-stdarg/"},{"categories":["Cpp"],"content":"va_start 将AP指向第一个参数的下一个参数的地址. #ifndef __sparc__ #define va_start(AP, LASTARG) \\ (AP = ((char *) \u0026(LASTARG) + __va_rounded_size (LASTARG))) #else #define va_start(AP, LASTARG) \\ (__builtin_saveregs (), \\ AP = ((char *) \u0026(LASTARG) + __va_rounded_size (LASTARG))) #endif ","date":"2021-01-27","objectID":"/202101/purec-stdarg/:5:0","tags":["Cpp","模板"],"title":"C里面的变长参数","uri":"/202101/purec-stdarg/"},{"categories":["Cpp"],"content":"va_arg AP指向下一个参数, 同时返回上一个参数的内容. #define va_arg(AP, TYPE) \\ (AP += __va_rounded_size (TYPE), \\ *((TYPE *) (AP - __va_rounded_size (TYPE)))) ","date":"2021-01-27","objectID":"/202101/purec-stdarg/:6:0","tags":["Cpp","模板"],"title":"C里面的变长参数","uri":"/202101/purec-stdarg/"},{"categories":["Cpp"],"content":"va_end 将AP指针置空, 做保护用. #define va_end(AP) //有些代码中定义为 #define va_end(ap) ( ap = (va_list)0 ) ","date":"2021-01-27","objectID":"/202101/purec-stdarg/:7:0","tags":["Cpp","模板"],"title":"C里面的变长参数","uri":"/202101/purec-stdarg/"},{"categories":["Cpp"],"content":"用例 int sum(int count, ...) { va_list vl; int sum = 0; va_start(vl, count); for (int i = 0; i \u003c count; ++i) { sum += va_arg(vl, int); } va_end(vl); return sum; } 结合开头讲述的内存分布就不难理解, va_list是一个指针, 型参都是在连续内存中的. va_start(vl, count)的时候, 指向了count的下一个指针(count地址, 加上count的size). va_arg(vl, int)的时候, 先是将vl指向下一个地址, 然后再返回上一个地址的值. ","date":"2021-01-27","objectID":"/202101/purec-stdarg/:8:0","tags":["Cpp","模板"],"title":"C里面的变长参数","uri":"/202101/purec-stdarg/"},{"categories":["数据结构与算法"],"content":"什么是二叉树 二叉树的知识点, 需要有链表的基础知识, 一般二叉树的结构如图示: 二叉树 二叉树是一种树状结构. 所谓二叉, 就是一个节点最多可以延伸出两个子节点. 对于二叉树的节点一般会有一些固有称呼. 如上图, 一般会把N1节点叫做\"根结点“或者”root节点\"; 会把N2叫做N1的\"左子节点\", N3叫做N1的\"右子节点\"; N1则是N2或者N3的\"父节点“或者”parent节点\"; N2或者N3可以是N2或者N3子树的根结点, 但是不是N1树的根结点; 同理, 对N4或者N5, N2是他们的父节点, N3是他们的\"叔叔节点“或者”uncle节点\"; 对于N4, N6或者N7这种在末尾的节点, 叫做\"叶子节点\"; 从根结点到叶子节点经历过的最多的节点数叫做\"树的深度\", 所以N1树的深度是4, 节点N1的深度是1(从上往下); 从叶子结点到根节点经历过的最多的节点数叫做\"树的层数\", 所以N1树的层数是4, 节点N1的层数是4(从下往上); 一般对于普通的二叉树, 我们可以用链表表示, 比如给定一个二叉树节点的结构体类型 struct Node{ int val; Node *left; Node *right; Node() : val(0), left(nullptr), right(nullptr) {} Node(const int\u0026 v) : val(v), left(nullptr), right(nullptr) {} Node(const int\u0026 v, Node *l, Node *r) : val(v), left(l), right(r) {} }; 如上链表结构的结构体Node, 至少占用24Byte, 而实际数据只有一个int(假设是4Byte), 浪费了较多的空间. 占用24Byte是因为struct会有内存对齐的策略, 比如64位机器上int是4Byte, 但是两个指针是8Byte, 则需要按照8Byte对齐, 所以一共是24Byte ","date":"2021-01-25","objectID":"/202101/salgo-bintree/:1:0","tags":["Cpp","二叉树"],"title":"数据结构与算法之二叉树","uri":"/202101/salgo-bintree/"},{"categories":["数据结构与算法"],"content":"完全二叉树 普通二叉树一般会用链表结构存储, 会多出至少两个成员用来存储其左右孩子节点, 但是有一种比较特殊的二叉树, 可以直接使用顺序结构存储, 不需要存储左右孩子节点的指针; 这就是完全二叉树; 完全二叉树的结构如下图所示, 完全二叉树/满二叉树 完全二叉树 上面有两种二叉树, 一种是满二叉树, 一种是完全二叉树; 满二叉树是指, 除了叶子节点外, 每个节点有且只有两个只节点; 假设一棵满二叉树的深度为h, 有n个节点, 最大层数为k, 则满足: 满二叉树的节点数 n = 2 ^ h - 1; 满二叉树第一层的节点树 = 2 * (h - 1); 假设一棵完全二叉树的深度为h, 有n个节点, 最大层数为k, 则满足, 深度为1 ~ h-1的结点构成满二叉树, 深度h的结点都是叶子结点, 如果是右结点, 则必有左结点. 相当于是一个装了球的盒子, 往左倾斜, 则如果有右边的球(结点), 则必有左边的球(结点). 完全二叉树的节点数 2 ^ h - 1 \u003e= n \u003e= 2 ^ (h - 1) - 1 完全二叉树第一层的节点树 \u003c= 2 * (h - 1); ","date":"2021-01-25","objectID":"/202101/salgo-bintree/:2:0","tags":["Cpp","二叉树"],"title":"数据结构与算法之二叉树","uri":"/202101/salgo-bintree/"},{"categories":["数据结构与算法"],"content":"完全二叉树顺序存储 区别于一般的链式存储, 顺序存储一般会占用更少的内存空间, 而且连续的内存也可以方便硬件加速. 满二叉树 满二叉树可以说是特殊的完全二叉树(其实完全二叉树是通过满二叉树演变过来的). 对于满二叉树, 我们从上往下, 从左往右, 给每个结点从0开始按顺序编号. 对于第k个结点, 可以推算出其左右孩子结点分别是第2*(K + 1) - 1个结点和第2*(K + 1)个结点; 其父结点是第[(k - 1)/2](取整)个结点; 所以, 即使我们把满二叉树的所有结点放在顺序结构, 如数组中, 可以非常方便的遍历每个结点的子结点和父结点. //0, 1, 2, 3, 4, 5, 6 [N1, N2, N3, N4, N5, N6, N7] 完全二叉树 方便理解, 可以把完全二叉树补充为满二叉树, 也用顺序结构存储. 对于原本不存在的数据(N9-N15), 用null表示; 这样在遍历的时候, 遇到null则表示没有这个数据; //0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14 [N1, N2, N3, N4, N5, N6, N7, N8, null, null, null, null, null, null, null] 完全二叉树补充为满二叉树 实际上, 这些null的数据都在数组的末尾, 进一步简化, 可以把这些null数据都去掉, 仅保存完全二叉树中有效的数据. //0, 1, 2, 3, 4, 5, 6, 7 [N1, N2, N3, N4, N5, N6, N7, N8] 此时, 在遍历父结点或者子结点是, 只需要判断当前结点的下标或者子结点的下标是否在数组的大小范围内即可; int ppos = (i - 1) \u003e\u003e 1; //父结点下标 int clpos = ((i + 1) \u003c\u003c 1) - 1; //左孩子下标 int crpos = (i + 1) \u003c\u003c 1; //右孩子下标 bool ppos_ok = (0 \u003c= i) \u0026\u0026 (i \u003c lsize); //父结点存在 bool clpos_ok = (0 \u003c= clpos) \u0026\u0026 (clpos \u003c lsize); //左孩子存在 bool crpos_ok = (0 \u003c= crpos) \u0026\u0026 (crpos \u003c lsize); //右孩子存在 ","date":"2021-01-25","objectID":"/202101/salgo-bintree/:2:1","tags":["Cpp","二叉树"],"title":"数据结构与算法之二叉树","uri":"/202101/salgo-bintree/"},{"categories":["数据结构与算法"],"content":"单调栈 顾名思义, 单调栈就是其元素单调的栈, 满足两个特性: 是栈 栈元素单调递减(\u003c)或者单调递增(\u003e) 当然, 关于第二点也可以是单调不递减(\u003e=)或者单调不递增(\u003c=). ","date":"2021-01-20","objectID":"/202101/salgo-mstack/:1:0","tags":["Cpp","栈","排序","状态机"],"title":"数据结构与算法之单调栈","uri":"/202101/salgo-mstack/"},{"categories":["数据结构与算法"],"content":"构造一个单调栈 从实践出发, 看看怎么构建一个单调栈; 比如有一个正整数列表: [2 1 3 4 7 5] 构建其中之一的单调不递减栈: 列表是否空? 如果空则转2, 否则转3; 退出; 从列表中取出元素, 转4; 栈是否空? 如果空则转5, 否则转6; 元素入栈, 转1; 新元素与栈顶元素比较, 如果满足大小关系, 入栈, 转1; 否则, 出栈, 转4; 按照上述算法, 构建单调栈: 栈空, 则元素入栈(1-\u003e3-\u003e4-\u003e5) 2 新元素比栈顶元素小(1-\u003e3-\u003e4-\u003e6-\u003e4-\u003e5) 1 新元素比栈顶元素大, 入栈(1-\u003e3-\u003e4-\u003e6) 1 3 新元素比栈顶元素大, 入栈(1-\u003e3-\u003e4-\u003e6) 1 3 4 新元素比栈顶元素大, 入栈(1-\u003e3-\u003e4-\u003e6) 1 3 4 7 新元素比栈顶元素小, 则弹出栈顶元素, 直到新元素比栈顶元素小或者栈空(1-\u003e3-\u003e4-\u003e6-\u003e4-\u003e5-\u003e2) 1 3 4 5 以上, 已经有几分像是一个状态机, 入栈出栈都是状态的变化. 单调栈 上图是将单调栈转换成状态和操作, 蓝色字体表示状态, 黑色字体表示操作, 实线表示状态转换, 虚线表示附加操作. 下面, 我们不妨尝试使用状态机实现从一个列表生成单调栈的函数. ","date":"2021-01-20","objectID":"/202101/salgo-mstack/:2:0","tags":["Cpp","栈","排序","状态机"],"title":"数据结构与算法之单调栈","uri":"/202101/salgo-mstack/"},{"categories":["数据结构与算法"],"content":"单调栈的代码实现 首先, 我们定义几个状态, 根据上述的流程图, 有以下几个状态: 开始/下一个/栈空/栈不空/满足大小/不满足大小/列表空/列表不空/退出 enum class STAT { START, NEXT, SEMPTY_T, SEMPTY_F, OP_T, OP_F, LEMPTY_T, LEMPTY_F, EXIT }; 与状态对应的, 还有一些操作: 判断栈是否空/比较操作/判断队列是否空/从队列中取下一个元素/入栈/出栈 auto sempty = [\u0026]() -\u003e bool { return s.empty(); }; auto op = [\u0026](const int \u0026a) -\u003e bool { return fop(s.top(), a); }; int lpos = 0; auto lempty = [\u0026]() -\u003e bool { return lpos \u003e= list.size(); }; auto lnext = [\u0026]() -\u003e int { return list[lpos++]; }; auto push = [\u0026](const int \u0026a) { s.push(a); }; auto pop = [\u0026]() { s.pop(); }; 最后就是状态之间的跳转规则, 直接按照流程编写跳转规则就好 do { switch (stat) { case STAT::START: stat = lempty() ? STAT::LEMPTY_T : STAT::LEMPTY_F; break; case STAT::NEXT: a = lnext(); stat = sempty() ? STAT::SEMPTY_T : STAT::SEMPTY_F; break; case STAT::SEMPTY_T: push(a); stat = STAT::START; break; case STAT::SEMPTY_F: stat = op(a) ? STAT::OP_T : STAT::OP_F; break; case STAT::OP_T: push(a); stat = STAT::START; break; case STAT::OP_F: pop(); stat = sempty() ? STAT::SEMPTY_T : STAT::SEMPTY_F; break; case STAT::LEMPTY_T: stat = STAT::EXIT; break; case STAT::LEMPTY_F: stat = STAT::NEXT; break; } } while (STAT::EXIT != stat); 下面是完整的代码: #include \u003cstack\u003e #include \u003cvector\u003e #include \u003ciostream\u003e #include \u003cstring\u003e using namespace std; enum class STAT { START, NEXT, SEMPTY_T, SEMPTY_F, OP_T, OP_F, LEMPTY_T, LEMPTY_F, EXIT }; template \u003ctypename FOP\u003e void mStack(stack\u003cint\u003e \u0026s, const vector\u003cint\u003e \u0026list, FOP \u0026\u0026fop) { auto sempty = [\u0026]() -\u003e bool { return s.empty(); }; auto op = [\u0026](const int \u0026a) -\u003e bool { return fop(s.top(), a); }; int lpos = 0; auto lempty = [\u0026]() -\u003e bool { return lpos \u003e= list.size(); }; auto lnext = [\u0026]() -\u003e int { return list[lpos++]; }; auto push = [\u0026](const int \u0026a) { s.push(a); }; auto pop = [\u0026]() { s.pop(); }; STAT stat = STAT::START; int a = -1; do { switch (stat) { case STAT::START: stat = lempty() ? STAT::LEMPTY_T : STAT::LEMPTY_F; break; case STAT::NEXT: a = lnext(); stat = sempty() ? STAT::SEMPTY_T : STAT::SEMPTY_F; break; case STAT::SEMPTY_T: push(a); stat = STAT::START; break; case STAT::SEMPTY_F: stat = op(a) ? STAT::OP_T : STAT::OP_F; break; case STAT::OP_T: push(a); stat = STAT::START; break; case STAT::OP_F: pop(); stat = sempty() ? STAT::SEMPTY_T : STAT::SEMPTY_F; break; case STAT::LEMPTY_T: stat = STAT::EXIT; break; case STAT::LEMPTY_F: stat = STAT::NEXT; break; } } while (STAT::EXIT != stat); } int main() { vector\u003cint\u003e cs{2, 1, 3, 4, 7, 5}; stack\u003cint\u003e ss; mStack(ss, cs, [](const int \u0026a, const int \u0026b) { return a \u003c b; }); while (!ss.empty()) { cout \u003c\u003c ss.top() \u003c\u003c \" \"; ss.pop(); } return 1; } ","date":"2021-01-20","objectID":"/202101/salgo-mstack/:2:1","tags":["Cpp","栈","排序","状态机"],"title":"数据结构与算法之单调栈","uri":"/202101/salgo-mstack/"},{"categories":["数据结构与算法"],"content":"聊一两句状态机 要写状态机, 需要明确有几个状态, 和状态的对应操作, 也需要明确状态间的跳转规则; 个人认为, 状态机的代码很容易维护, 只需要关注下一个状态就行了, 需求变更的时候, 改起来非常的方便; 上面的状态机肯定还有很多优化空间的, 但是目前还没打算研究这个专题, 后期会专门系统地看看状态机的编写方法; ","date":"2021-01-20","objectID":"/202101/salgo-mstack/:2:2","tags":["Cpp","栈","排序","状态机"],"title":"数据结构与算法之单调栈","uri":"/202101/salgo-mstack/"},{"categories":["数据结构与算法"],"content":"每日温度 这是对应leetcode题739. 给一个每天的温度列表, 返回一个列表, 表示至少多少天后的温度比这一天高, 例如输入温度[73, 74, 75, 71, 69, 72, 76, 73], 返回[1, 1, 4, 2, 1, 1, 0, 0]。 这是比较经典的单调栈的例子, “第一个比当前大/小的元素”. 我们可以从后往前构造一个单调递减栈, 栈中元素是温度的下标, 用温度大小做比较; 代码如下: vector\u003cint\u003e dailyTemperatures(vector\u003cint\u003e \u0026T) { stack\u003cint\u003e st; int si = T.size(); vector\u003cint\u003e rd(si); for (int i = si - 1; i \u003e= 0; i--) { while (!st.empty() \u0026\u0026 T[i] \u003e= T[st.top()]) { st.pop(); } if (!st.empty()) { rd[i] = st.top() - i; } else { rd[i] = 0; } st.push(i); } return rd; } ","date":"2021-01-20","objectID":"/202101/salgo-mstack/:3:0","tags":["Cpp","栈","排序","状态机"],"title":"数据结构与算法之单调栈","uri":"/202101/salgo-mstack/"},{"categories":["数据结构与算法"],"content":"什么是栈 栈是一种数据结构, 满足先入后出. 一般栈支持以下几个操作: push(n); //数据入栈 a.pop(); //数据出栈 a.top(); //获取栈顶元素 a.size(); //获取栈中元素数量 a.empty(); //是否是空栈 ","date":"2021-01-15","objectID":"/202101/salgo-stack/:1:0","tags":["Cpp","栈"],"title":"数据结构与算法之栈","uri":"/202101/salgo-stack/"},{"categories":["数据结构与算法"],"content":"C++中的stack容器 官方文档中, 定义如下 template\u003c class T, class Container = std::deque\u003cT\u003e \u003e class stack; std::stack是一个C++模板类, 有两个模板参数T和Container, T代表容器元素的数据类型, Container则代表stack使用的容器, 默认使用std::deque这个容器. 这意味着, stack相当于是对已有容器的改装, 也可以使用用户自定义的容器. Container必须提供以下几种方法: 支持back(); 支持pop_back(); 支持push_back(); 相当于都是往Container的后面塞入或者弹出数据, 也就是Container也需要满足的stack的基本功能. 因此, 我们将自定义或者其他C++标准容器转换为stack容器. 以下是官方的demo, 我添加了vector的转换以加强理解. #include \u003cstack\u003e #include \u003cdeque\u003e #include \u003cvector\u003e #include \u003ciostream\u003e int main() { std::stack\u003cint\u003e c1; c1.push(5); std::cout \u003c\u003c c1.size() \u003c\u003c '\\n'; std::stack\u003cint\u003e c2(c1); std::cout \u003c\u003c c2.size() \u003c\u003c '\\n'; std::deque\u003cint\u003e deq {3, 1, 4, 1, 5}; std::stack\u003cint\u003e c3(deq); //stack的Container默认就是deque, 所以无需再次声明 std::cout \u003c\u003c c3.size() \u003c\u003c '\\n'; // int ds[3] = {1, 2, 3}; //使用数组是不行的, 因为普通数组没有实现Container要求的操作 std::vector\u003cint\u003e ds {1, 2, 3}; std::stack\u003cint, std::vector\u003cint\u003e\u003e c4(ds); //vector不是stack默认的Container类型, 所以需要声明 std::cout \u003c\u003c c4.size() \u003c\u003c '\\n'; } ","date":"2021-01-15","objectID":"/202101/salgo-stack/:2:0","tags":["Cpp","栈"],"title":"数据结构与算法之栈","uri":"/202101/salgo-stack/"},{"categories":["数据结构与算法"],"content":"括号匹配问题 括号匹配问题一般描述是: 给定一个字符串S, 其中包含’{}’/’[]’/’()‘三种括号对, 例如S1 = “[]{}({})”, S2 = “[{(}])”, 其中S1是合法的, S2是不合法的. 设计一个函数, 判断输入的仅包含括号字符的字符串是否合法. bool isBracketOk(const string \u0026s) { const static char brackets_table[][2] = { {'(', ')'}, {'[', ']'}, {'{', '}'} }; auto is_match = [=] (const char \u0026a, const char \u0026b) -\u003e bool { bool match = false; for (int i = 0; i \u003c 3; i++) { match = ((a == brackets_table[i][0]) \u0026\u0026 (b == brackets_table[i][1])); if (match) { return match; } } return match; }; auto is_left = [=] (const char \u0026a) -\u003e bool { for (int i = 0; i \u003c 3; i++) { if (a == brackets_table[i][0]) { return true; } } return false; }; auto is_right = [=] (const char \u0026a) -\u003e bool { for (int i = 0; i \u003c 3; i++) { if (a == brackets_table[i][1]) { return true; } } return false; }; stack\u003cchar\u003e ss; for (const char \u0026c : s){ if (ss.empty()) { if (is_left(c)) { ss.push(c); continue; } else { return false; } } else { if (is_left(c)) { ss.push(c); continue; } if (is_right(c)) { if (is_match(ss.top(), c)) { ss.pop(); continue; } else { return false; } } } } return ss.empty(); } 我们先定义一些函数, 用于判断给定字符是不是括号, 是左括号还是右括号, 判断给定字符对是不是匹配的括号. 对待判断的字符串, 如果是左括号则入栈, 如果是右括号, 则从判度栈顶字符和当前字符是不是匹配的括号对, 并弹出; ","date":"2021-01-15","objectID":"/202101/salgo-stack/:3:0","tags":["Cpp","栈"],"title":"数据结构与算法之栈","uri":"/202101/salgo-stack/"},{"categories":["数据结构与算法"],"content":"一个思考 曾经有一段时间, 我坚信一个函数应该且必须只有一个return. 但是渐渐也发现这样做的弊端, 代码会需要重构, 可能会有很多的临时变量, 也可能会有很深的嵌套逻辑, 而且多个return的可读性也不差. 所以, 一个函数该不该有多个return呢? 还有待更多的经验积累, 不能听风就是雨. ","date":"2021-01-15","objectID":"/202101/salgo-stack/:3:1","tags":["Cpp","栈"],"title":"数据结构与算法之栈","uri":"/202101/salgo-stack/"},{"categories":["Cpp"],"content":"以下的代码片段涉及到了不少的模板函数, 可以自行去官网查询. ","date":"2021-01-14","objectID":"/202101/cpp-temp-meta/:0:0","tags":["Cpp","模板","traits"],"title":"通过返回值'重载'函数","uri":"/202101/cpp-temp-meta/"},{"categories":["Cpp"],"content":"前言 从实际问题出发, 期望开发一个函数, 可以计算另外一个函数的耗时; 比如测试下面函数的耗时 int funcA(int \u0026a, float \u0026b); void funcB(bool \u0026c, char \u0026d, double \u0026e); 期望可以这样调用: (cost, ret) = costTime(funcA, a, b); cost = costTime(funcB, c, d, e); 对于有返回值的函数, 不仅需要计算函数的耗时, 还需要能过获取函数的返回值; 对没有返回值的函数, 则只需要计算函数的耗时; 有多种设计思路, 一是上述的代码, 通过返回值获取时间和被测函数的返回值; 二可以通过函数参数获取时间和被测函数返回值, 但是第二种方法总有一点不适合, 因为其结构不是很美观.(一般第一个参数是func, 最后的参数是args, 那么时间或被测函数的返回值就在参数中间, 太不好看了!!!) 以下, 仅针对第一种方法, 看看怎么设计这个函数; ","date":"2021-01-14","objectID":"/202101/cpp-temp-meta/:1:0","tags":["Cpp","模板","traits"],"title":"通过返回值'重载'函数","uri":"/202101/cpp-temp-meta/"},{"categories":["Cpp"],"content":"函数设计准备 编写只有一个返回值的函数来测试函数耗时比较简单, 通过可变长模板就很容易实现了, 如下 template \u003ctypename Func, typename... Args\u003e static double costTimeMs(Func\u0026\u0026 func, Args\u0026\u0026... args) { auto get_time_us = [] () -\u003e double { struct timeval time; gettimeofday(\u0026time, NULL); double ms = time.tv_sec * 1000.0 + time.tv_usec / 1000.0; return ms; }; double start = get_time_us(); func(args...); double end = get_time_us(); double cost = end - start; return cost; } 但是, 还有一个需求, 就是期望也能输出函数的返回值, 并且期望函数的调用接口不要变, 怎么设计呢? 其实有点像是函数重载, 但是这里是针对函数返回值的重载. C++为我们提供了enable_if这个模板函数. ","date":"2021-01-14","objectID":"/202101/cpp-temp-meta/:2:0","tags":["Cpp","模板","traits"],"title":"通过返回值'重载'函数","uri":"/202101/cpp-temp-meta/"},{"categories":["Cpp"],"content":"enable_if 下面摘取官方文档中的源码 template\u003cbool B, class T = void\u003e struct enable_if {}; template\u003cclass T\u003e struct enable_if\u003ctrue, T\u003e { typedef T type; }; 当使用enable_if的时候, 没有任何返回; 当是用enable_if的时候, 可以返回一个T类型; 刚开始看这个函数的时候不太好理解, 我们来实验一下吧. 以下改编自官方demo, 在验证的时候, 一定要结合编译报错信息帮助理解. 在线编译器 #include \u003ctype_traits\u003e #include \u003ciostream\u003e #include \u003cstring\u003e using namespace std; template\u003cclass T, class Enable = void\u003e class A { public: A(){ cout \u003c\u003c 111 \u003c\u003c endl; } }; // primary template template\u003cclass T\u003e class A\u003cT, typename std::enable_if\u003cstd::is_void\u003cT\u003e::value\u003e::type\u003e { public: A(){ cout \u003c\u003c 333 \u003c\u003c endl; } template\u003ctypename TT\u003e static typename std::enable_if\u003cstd::is_integral\u003cTT\u003e::value, char\u003e::type func(TT a) { cout \u003c\u003c \"444\" \u003c\u003c endl; return 'a'; } template\u003ctypename TT\u003e static typename std::enable_if\u003cstd::is_floating_point\u003cTT\u003e::value, int\u003e::type func(TT a) { cout \u003c\u003c \"555\" \u003c\u003c endl; func(0); cout \u003c\u003c \"666\" \u003c\u003c endl; return 1; } template\u003ctypename Func, typename... Args\u003e static typename std::enable_if\u003cstd::is_void\u003ctypename std::result_of\u003cFunc(Args...)\u003e::type\u003e::value, float\u003e::type func(Func\u0026\u0026 f, Args\u0026\u0026... args) { cout \u003c\u003c \"777\" \u003c\u003c endl; f(args...); cout \u003c\u003c \"888\" \u003c\u003c endl; return 1.1; } }; int main() { A\u003cint\u003e{}; // OK, 用第一个A A\u003cdouble\u003e{}; // OK, 用第一个A A\u003cvoid\u003e a; // OK, 用第二个A cout \u003c\u003c A\u003cvoid\u003e::func(0.0) \u003c\u003c endl; cout \u003c\u003c A\u003cvoid\u003e::func(0) \u003c\u003c endl; auto f = [] (int a, int b) -\u003e void { cout \u003c\u003c a \u003c\u003c b \u003c\u003c endl; }; cout \u003c\u003c A\u003cvoid\u003e::func(f, 999, 999) \u003c\u003c endl; } 输出是 111 111 333 555 444 666 1 444 a 777 999999 888 1.1 说明, 给A的模板传入int和double类型的时候, 调用的都是第一个A的实现, 因为这时候没有其他匹配的模板; 给A的模板传入void类型的时候, 调用的是第二个A. template\u003cclass T\u003e class A\u003cT, typename std::enable_if\u003cstd::is_void\u003cT\u003e::value\u003e::type\u003e {} 使用A::func(0.0)函数, 调用的这是第二个A里面的通过float匹配的func函数…其余可以自行配对看看调用的是哪个类和哪个函数. 接下来我们写一点bug, 让编译器报错, 看看它怎么说; 这样改写第二个A, 把与int匹配的func去掉, 编译看看 template\u003cclass T\u003e class A\u003cT, typename std::enable_if\u003cstd::is_void\u003cT\u003e::value\u003e::type\u003e { public: A(){ cout \u003c\u003c 333 \u003c\u003c endl; } template\u003ctypename TT\u003e static typename std::enable_if\u003cstd::is_floating_point\u003cTT\u003e::value, int\u003e::type func(TT a) { cout \u003c\u003c \"555\" \u003c\u003c endl; func(0); cout \u003c\u003c \"666\" \u003c\u003c endl; return 1; } template\u003ctypename Func, typename... Args\u003e static typename std::enable_if\u003cstd::is_void\u003ctypename std::result_of\u003cFunc(Args...)\u003e::type\u003e::value, float\u003e::type func(Func\u0026\u0026 f, Args\u0026\u0026... args) { cout \u003c\u003c \"777\" \u003c\u003c endl; f(args...); cout \u003c\u003c \"888\" \u003c\u003c endl; return 1.1; } }; 编译报错, 它说了什么呢? 它找遍了A里面的所有的func函数, 期望找到一个匹配的, 结果都没找到, 相当于是func没有定义, 最后抛出\"error: no matching function for call to ‘func’“的错误. \u003csource\u003e:50:13: error: no matching function for call to 'func' cout \u003c\u003c A\u003cvoid\u003e::func(0) \u003c\u003c endl; ^~~~~~~~~~~~~ \u003csource\u003e:25:5: note: candidate template ignored: requirement 'std::is_floating_point\u003cint\u003e::value' was not satisfied [with TT = int] func(TT a) ^ \u003csource\u003e:35:5: note: candidate template ignored: substitution failure [with Func = int, Args = \u003c\u003e]: no type named 'type' in 'std::result_of\u003cint ()\u003e' func(Func\u0026\u0026 f, Args\u0026\u0026... args) ^ \u003csource\u003e:28:9: error: use of undeclared identifier 'func' func(0); ^ \u003csource\u003e:49:22: note: in instantiation of function template specialization 'A\u003cvoid, void\u003e::func\u003cdouble\u003e' requested here cout \u003c\u003c A\u003cvoid\u003e::func(0.0) \u003c\u003c endl; ^ \u003csource\u003e:25:5: note: must qualify identifier to find this declaration in dependent base class func(TT a) ^ \u003csource\u003e:35:5: note: must qualify identifier to find this declaration in dependent base class func(Func\u0026\u0026 f, Args\u0026\u0026... args) ^ \u003csource\u003e:28:9: error: no matching function for call to 'func' func(0); ^~~~ \u003csource\u003e:25:5: note: candidate template ignored: requirement 'std::is_floating_point\u003cint\u003e::value' was not satisfied [with TT = int] func(TT a) ^ \u003csource\u003e:35:5: note: candidate template ignored: substitution failure [with Func = int, Args = \u003c\u003e]: no type named 'type' in 'std::result_of\u003cint ()\u003e' func(Func\u0026\u0026 f, Args\u0026\u0026... args) ^ 3 errors generated. 所以, 对enable_if, 不太准确的说就是, enable_if是一个函数开关, 它通过第一个模板的true/false来使能函数, 如果是false, 则函数直接被\"关闭”(不使能), 如果是true, 则可以把第二个参数(类型)作为函数的返回类型(当然也可以不使用, 仅做开关也可). ","date":"2021-01-14","objectID":"/202101/cpp-temp-meta/:2:1","tags":["Cpp","模板","traits"],"title":"通过返回值'重载'函数","uri":"/202101/cpp-temp-meta/"},{"categories":["Cpp"],"content":"耗时计算函数 以上, 我们使用enable_if可以来设计我们的计算耗时的函数了. 直接上代码 //当被测试函数的返回值 是void 的时候, 调用这个函数, 返回值的double类型的毫秒时间 template \u003ctypename Func, typename... Args\u003e static typename std::enable_if\u003cstd::is_void\u003ctypename std::result_of\u003cFunc(Args...)\u003e::type\u003e::value, double\u003e::type costTimeMs(Func\u0026\u0026 func, Args\u0026\u0026... args) { auto get_time_us = [] () -\u003e double { struct timeval time; gettimeofday(\u0026time, NULL); double ms = time.tv_sec * 1000.0 + time.tv_usec / 1000.0; return ms; }; double start = get_time_us(); func(args...); double end = get_time_us(); double cost = end - start; return cost; } //当被测试函数的返回值 非void 的时候, 调用这个函数, 返回值的tuple, 第一个值是double类型的毫秒时间, 第二个值是函数的返回值 template \u003ctypename Func, typename... Args\u003e static typename std::enable_if\u003c!(std::is_void\u003ctypename std::result_of\u003cFunc(Args...)\u003e::type\u003e::value), std::tuple\u003cdouble, typename std::result_of\u003cFunc(Args...)\u003e::type\u003e\u003e::type costTimeMs(Func\u0026\u0026 func, Args\u0026\u0026... args) { using RT = typename std::result_of\u003cFunc(Args...)\u003e::type; std::tuple\u003cdouble, RT\u003e ret; auto nfunc = [\u0026] () -\u003e void { std::get\u003c1\u003e(ret) = func(args...); }; std::get\u003c0\u003e(ret) = costTimeMs(nfunc); return ret; } 使用typename std::result_of\u003cFunc(Args…)\u003e::type获取函数返回值类型, 如果是void, 则调用第一个函数, 如果不是void则调用第二个函数, 第二个函数会稍微改装以下func, 使其满足返回值是void的样式. 通过返回值\"重载\"函数, 到此就好了. ","date":"2021-01-14","objectID":"/202101/cpp-temp-meta/:3:0","tags":["Cpp","模板","traits"],"title":"通过返回值'重载'函数","uri":"/202101/cpp-temp-meta/"},{"categories":["Cpp"],"content":"原因 为什么可以这么工作呢? 其实还是比较好理解的. 模板函数编译与否, 要不要参与编译是在编译期就确定的(废话). 比如使用enable_if这个模板函数, 在编译的时候会匹配这个模板, 如果匹配上了, 那么就会返回一个类型, 正常编译; 如果没有匹配上, enable_if就什么也不返回, 函数编译不过; 比如尝试匹配后的两个函数: void funcA(); //1 funcA(); //2 显然, 第二个是编译不过的, 但是编译器不会报错, 因为有正确匹配版本的funcA. (这里的意思是, 使用enable_if等, 需要考虑的所有情况, 不然可能会有某个调用找不到匹配的模板, 就会报错.) ","date":"2021-01-14","objectID":"/202101/cpp-temp-meta/:4:0","tags":["Cpp","模板","traits"],"title":"通过返回值'重载'函数","uri":"/202101/cpp-temp-meta/"},{"categories":["Cpp"],"content":"问题 先看以下代码 #include \u003ciostream\u003e using namespace std; using uint32 = unsigned int; template\u003cbool ISIN\u003e static void updateVal(uint32 \u0026val) { static uint32 sval; if (ISIN) { sval = val; } else { val = sval; } } int main() { uint32 a = 1; uint32 b = 2; updateVal\u003ctrue\u003e(a); updateVal\u003cfalse\u003e(b); cout \u003c\u003c b \u003c\u003c endl; } 期望是根据ISIN生成不同的语句, 但是实际上是生成了不同函数. updateVal函数期望实现的功能是, 当模板值为true的时候, 表示向sval存入变量val的值; 当模板值为false时, 表示将sval的值存入到val中. 期望上述代码的b的输出时1(原本时2, 然后被赋值1). 实际输出是 0 ","date":"2021-01-13","objectID":"/202101/cpp-more-static/:1:0","tags":["Cpp","模板","static"],"title":"C++模板问题之多出的static","uri":"/202101/cpp-more-static/"},{"categories":["Cpp"],"content":"验证 可以查看上述代码的汇编代码, 仅截取一小段. lea rdi,[rbp-0x4] call 401230 \u003cvoid updateVal\u003cfalse\u003e(unsigned int\u0026)\u003e lea rdi,[rbp-0x8] call 401250 \u003cvoid updateVal\u003ctrue\u003e(unsigned int\u0026)\u003e 以上, 两个call实际上就是两次调用updateVal函数, 但是很奇怪, 两次call的地址不一样, 也就是updateVal实际上有两份, 我们再看看updateVal函数的汇编. 401230 push rbp mov rbp,rsp mov QWORD PTR [rbp-0x8],rdi mov eax,DWORD PTR ds:0x404198 mov rcx,QWORD PTR [rbp-0x8] mov DWORD PTR [rcx],eax pop rbp ret nop WORD PTR [rax+rax*1+0x0] 401250 push rbp mov rbp,rsp mov QWORD PTR [rbp-0x8],rdi mov rax,QWORD PTR [rbp-0x8] mov ecx,DWORD PTR [rax] mov DWORD PTR ds:0x40419c,ecx pop rbp ret nop WORD PTR [rax+rax*1+0x0] 可以看到有两个ds区的数据, 这代表有两个static变量, 也就是说, 因为函数有两份, 导致sval也有两份, 互不干扰, 所以函数无效. 实际上, 给模板输入不同的参数本来就会生成不同的函数, 即使是模板变量也是如此, 所以在上面我们可以看到, 这两个updateVal函数, 在编译期就已经确定了. 正确的写法应该是不使用模板, 或者将static移动到函数体外. 如下, 在运行期可以少做一点运算, 但是会占用更多的内存空间. static uint32 sval = 0; template\u003cbool ISIN\u003e static void updateVal(uint32 \u0026val) { if (ISIN) { sval = val; } else { val = sval; } } ","date":"2021-01-13","objectID":"/202101/cpp-more-static/:2:0","tags":["Cpp","模板","static"],"title":"C++模板问题之多出的static","uri":"/202101/cpp-more-static/"},{"categories":["Cpp"],"content":"结论 模板变量会在编译期确定; 使用了\"任意\"模板的函数可能在编译期生成多份; 看起来是对\"语句\"模板, 实际上模板是对函数作用的; ","date":"2021-01-13","objectID":"/202101/cpp-more-static/:3:0","tags":["Cpp","模板","static"],"title":"C++模板问题之多出的static","uri":"/202101/cpp-more-static/"},{"categories":["工具"],"content":"git目录 新建一个git项目，查看.git目录 .git/ ├── branches ├── config ├── description ├── HEAD ├── hooks │ ├── applypatch-msg.sample │ ├── commit-msg.sample │ ├── fsmonitor-watchman.sample │ ├── post-update.sample │ ├── pre-applypatch.sample │ ├── pre-commit.sample │ ├── prepare-commit-msg.sample │ ├── pre-push.sample │ ├── pre-rebase.sample │ ├── pre-receive.sample │ └── update.sample ├── info │ └── exclude ├── objects │ ├── info │ └── pack └── refs ├── heads └── tags 9 directories, 15 files ","date":"2021-01-11","objectID":"/202101/git-dir/:1:0","tags":["Git"],"title":"Git的目录结构","uri":"/202101/git-dir/"},{"categories":["工具"],"content":"objects 我的理解是，项目中你看到的每个东西都是一个object，实际上object有：commit、tree、blob、tag（加tag的时候才会有） 添加一个文件 echo 111 \u003e a.txt # 此时看git目录没有任何变化 git add . # 此时看git 目录可以看到多了objects下多了一个目录，运行以下命令： git cat-file -p 58c9 #xxxx是遗传16进制的值，由目录名和里面的文件名组成 # 输出 111 git cat-file -t 58c9 #可以看到当前objects的类型，此时是blob # 通过上述的操作，可以知道，blob是一个只包含文件内容的object # 接下来执行commit操作，此时会发现objects目录下多了两个文件，我们一个一个查看 git cat-file -p 9759 # # 内容是tree f253233a1a0e59f33115daca3fa494eaa20758d8，还有一些其他信息 # 我们可以看到f253233a1a0e59f33115daca3fa494eaa20758d8也是objects中的一个对象，接着看看它，其实已经可以判断它是一个tree类型 git cat-file -t 9759 #类型是commit git cat-file -p f253 #内容 100644 blob 58c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c a.txt git cat-file -t f253 #类型tree 通过以上的信息，实际上一次commit是构建了一棵树。 以上： 9759-\u003ef253-\u003e58c9 || commit-\u003etree-\u003eblob 如果修改a.txt的内容，可以看到会生成新的objects，并且有一个新的blob完全包含了新的a.txt的全部内容，这意味着，git是保存文件的完全的副本，而不是差异。同时会有新的commit object 和 新的tree object。实践吧！ 添加了b.txt的objects tree ├── objects │ ├── 4c │ │ └── aaa1a9ae0b274fba9e3675f9ef071616e5b209 │ ├── 58 │ │ └── c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c │ ├── 97 │ │ └── 590a17d455bf791b68561588bddae174d125d1 │ ├── c2 │ │ └── 00906efd24ec5e783bee7f23b5d7c941b0c12c │ ├── d6 │ │ └── 43f2709193bf972c2d01a0119934e8789ec915 │ ├── f2 │ │ └── 53233a1a0e59f33115daca3fa494eaa20758d8 │ ├── info │ └── pack # d643是新的commit，可以看它的内容，会多了一个parent 97590a17d455bf791b68561588bddae174d125d1 # parent 把新的commit和过去的commit连接起来了！ 可以试着reset一下，会发现其实所有的objects都还在的，只是改变了HEAD等指针； git的所有内容都是实例和指向它的指针。 [以下在git magic] ","date":"2021-01-11","objectID":"/202101/git-dir/:2:0","tags":["Git"],"title":"Git的目录结构","uri":"/202101/git-dir/"},{"categories":["工具"],"content":"blob Git基于“内容寻址”：文件并不按它们的文件名存储，而是按它们包含内容的哈希值， 在一个叫“blob对象”的文件里。我们可以把文件内容的哈希值看作一个唯一ID，这样 在某种意义上我们通过他们内容放置文件。开始的“blob 6”只是一个包含对象类型与 其长度的头；它简化了内部存储。 这样我可以轻易预言你所看到的输出：文件名是无关的：只有里面的内容被用作构 建blob对象。 你可能想知道对相同的文件会发生什么。试图填加一个你文件的拷贝，什么文件名都行。 在 .git/objects 的内容保持不变，不管你加了多少。Git都只存储一次数据。 以下内容hash值： \"blob\" SP \"6\" NUL \"[内容]\" LF 以上， blob结构是， 按照文件内容生成的，只要内容相同， 就是同一个blob ","date":"2021-01-11","objectID":"/202101/git-dir/:3:0","tags":["Git"],"title":"Git的目录结构","uri":"/202101/git-dir/"},{"categories":["工具"],"content":"tree “tree”对象：一组包含文件类型，文件名和哈希值的数据。在我们的例 子里，文件类型是100644，这意味着“rose”是一个一般文件，并且哈希值指blob对象， 包含“rose”的内容。其他可能文件类型有可执行，链接或者目录。在最后一个例子里， 哈希值指向一个tree对象。 以上， tree结构是， 包含了文件名/类型（一般文件/可执行/链接/目录），和其指向的对象（目录指向tree， 一般指向blob） 以下内容hash值： \"tree\" SP \"32\" NUL \"[文件类型] 文件名\" NUL 0xaa823728ea7d592acc69b36875a482cdf3fd5c8d[指向的对象] ","date":"2021-01-11","objectID":"/202101/git-dir/:4:0","tags":["Git"],"title":"Git的目录结构","uri":"/202101/git-dir/"},{"categories":["工具"],"content":"commmit commit 结构， 会包含commit信息/作者等， 会包含父commit指针， 包含tree指针 ","date":"2021-01-11","objectID":"/202101/git-dir/:5:0","tags":["Git"],"title":"Git的目录结构","uri":"/202101/git-dir/"},{"categories":["工具"],"content":"结构 结构图 ","date":"2021-01-11","objectID":"/202101/git-dir/:6:0","tags":["Git"],"title":"Git的目录结构","uri":"/202101/git-dir/"},{"categories":["工具"],"content":"问题 需要构建不同平台的bin，但是本地电脑是ubuntu18的系统，怎么构建ubuntu16可用的bin呢？ ","date":"2021-01-11","objectID":"/202101/docker-build/:1:0","tags":["Docker","平台"],"title":"使用Docker构建不同平台编译环境","uri":"/202101/docker-build/"},{"categories":["工具"],"content":"方案 使用docker, 是下是qt项目举例 ","date":"2021-01-11","objectID":"/202101/docker-build/:2:0","tags":["Docker","平台"],"title":"使用Docker构建不同平台编译环境","uri":"/202101/docker-build/"},{"categories":["工具"],"content":"编写Dockerfile FROM daocloud.io/library/ubuntu:16.04 VOLUME /nyuv/ RUN apt update \u0026\u0026 apt install -y make cmake gcc build-essential qt5-default 可以再更自动化一点 WORKDIR /nyuv/ CMD [\"source\", \"build.sh\"] 在build.sh里面编写build脚本即可 ","date":"2021-01-11","objectID":"/202101/docker-build/:2:1","tags":["Docker","平台"],"title":"使用Docker构建不同平台编译环境","uri":"/202101/docker-build/"},{"categories":["工具"],"content":"构建镜像 docker build -t nyuv . ","date":"2021-01-11","objectID":"/202101/docker-build/:2:2","tags":["Docker","平台"],"title":"使用Docker构建不同平台编译环境","uri":"/202101/docker-build/"},{"categories":["工具"],"content":"挂载本地目录，构建容器并进入 docker run -it -v /home/xx/bin/nyuv/:/nyuv/ nyuv /bin/bash 至此，剩下操作如同本地编译一样 ","date":"2021-01-11","objectID":"/202101/docker-build/:2:3","tags":["Docker","平台"],"title":"使用Docker构建不同平台编译环境","uri":"/202101/docker-build/"},{"categories":["工具"],"content":"本文主要介绍docker的基本使用方式。 ","date":"2021-01-11","objectID":"/202101/docker-start/:0:0","tags":["Docker"],"title":"开始使用Docker","uri":"/202101/docker-start/"},{"categories":["工具"],"content":"docker安装 wget -qO- https://get.docker.com/ | sh # 或者 apt install docker.io docker --version docker system info 如果遇到permission的问题，则将当前用户添加到用户组，并且之后要记得重新登录（注销当前用户） $ sudo groupadd docker #创建docker用户组 $ sudo usermod -aG docker ${USER} #将当前用户加入docker用户组 $ sudo systemctl restart docker #重启docker服务 $ su root #切换到root用户，或注销再登录当前用户 $ su ${USER} #再切换到原来的应用用户以上配置才生效 ","date":"2021-01-11","objectID":"/202101/docker-start/:1:0","tags":["Docker"],"title":"开始使用Docker","uri":"/202101/docker-start/"},{"categories":["工具"],"content":"下载镜像和运行、删除 docker search xxx //从docker hub查询xxx镜像 docker image pull xxx //安装xxx镜像 docker container run xxx [cmd] //启动一个xxx容器，并在其中运行cmd命令 # 或者 docker run -it [image] [cmd]，可以-v映射本地路径到容器 docker images #查看当前docker客户端有哪些images 删除则是加上rm参数，不过多记录了 ","date":"2021-01-11","objectID":"/202101/docker-start/:2:0","tags":["Docker"],"title":"开始使用Docker","uri":"/202101/docker-start/"},{"categories":["工具"],"content":"更多命令 一些命令可以参考 这里 善用help docker run -p [port in container]:[port in physical system] -d [image] [command] #端口映射 docker ps #类似于linux ps命令，查看在运行的container信息，-a 则是查看所有 docker stop [container] #停止container docker kill [container] #同上，强制杀死 docker start/restart [container] #启动/重启container docker update xxx [container] #可以更新container的一些标记 ","date":"2021-01-11","objectID":"/202101/docker-start/:3:0","tags":["Docker"],"title":"开始使用Docker","uri":"/202101/docker-start/"},{"categories":["工具"],"content":"Dockerfile 如果需要将一个应用容器化，则需要有一个Dockerfile来描述镜像的构建过程。 运行以下命令则可以读取Dockerfile，并将应用容器化 docker build -t [image-name] . #要注意这里最后有一个点 # -t代表终端 # -i代表交互式命令 例如，以下 $ cat Dockerfile FROM alpine LABEL maintainer=\"nigelpoulton@hotmail.com\" RUN apk add --update nodejs nodejs-npm COPY . /src WORKDIR /src RUN npm install EXPOSE 8080 ENTRYPOINT [\"node\", \"./app.js\"] 镜像是一层一层构建的，一般新构建的镜像可以基于另外一个镜像上构建，比如上述例子，其镜像则基于alpine镜像构建。 FROM 指令用于指定要构建的镜像的基础镜像。它通常是 Dockerfile 中的第一条指令。 LABEL 打标签，是一个key-value对。 RUN 在build时执行，每个 RUN 指令创建一个新的镜像层，所以应该把尽量多的执行命令放在一个RUN里面，这时候使用‘\\’换行。 CMD 在docker run时运行，且仅最后一条CMD有效。 ENTRYPOINT 指令用于指定镜像以容器方式启动后默认运行的程序，类似于CMD。 COPY 指令用于将文件作为一个新的层添加到镜像中。通常使用 COPY 指令将应用代码赋值到镜像中。 ADD 同COPY，但是对压缩格式为 gzip, bzip2 以及 xz 的文件，会自动解压缩到目标路径下。所以如果不需要自动解压，则使用COPY。 EXPOSE 指令用于记录应用所使用的网络端口。 ENV 环境变量，也是key-value对。 其他的 Dockerfile 指令还有 ONBUILD、HEALTHCHECK 等。 在执行build时，按照顺序执行 基于alpine镜像创建镜像 设置label 在alpine镜像中运行命令 将当前路径文件 . 复制COPY到 apline 的 /src中 设置alpine 的 /src 为工作目录，此时如果进入这个容器，则默认进入到/src 路径下 设置端口 设置默认app，如果运行docker run -it [image-name] 则默认执行该app，如果不指定则会进入容器交互式终端 基于以上，可以把一些项目打包成一个镜像，做到即开即用了。 ","date":"2021-01-11","objectID":"/202101/docker-start/:4:0","tags":["Docker"],"title":"开始使用Docker","uri":"/202101/docker-start/"},{"categories":["工具"],"content":"docker应用场景 在非web项目中，能不能用到docker呢？比如Android底层开发？ 将本地文件映射（挂在到docker中） 详细：这里 #在eis容器中，将本地的eisdebugsite挂在到/www下 #端口映射，第一个8080是指docker对外映射的端口，客户端通过这个端口可以访问到服务器；第二个8080则是服务器对docker的内部端口，外部访问不到 docker container run -d -p 8080:8080 --name eisweb --volume /home/xx/project/eisdebugsite/:/www eis ","date":"2021-01-11","objectID":"/202101/docker-start/:5:0","tags":["Docker"],"title":"开始使用Docker","uri":"/202101/docker-start/"},{"categories":["工具"],"content":"离线安装与离线分享镜像 有些机器只能在内网环境下运行，不能也连不上外网，此时需要使用离线的方式构建docker环境。 下载离线docker bin https://download.docker.com/linux/static/stable/x86_64/ 具体参考这里 解压bin tar -xvf docker-18.06.1-ce.tgz 将解压出来的docker文件内容移动到 /usr/bin/ 目录下 sudo cp docker/* /usr/bin/ 将docker注册为service sudo vim /etc/systemd/system/docker.service 将下列配置加到docker.service中并保存 [Unit] Description=Docker Application Container Engine Documentation=https://docs.docker.com After=network-online.target firewalld.service Wants=network-online.target [Service] Type=notify # the default is not to use systemd for cgroups because the delegate issues still # exists and systemd currently does not support the cgroup feature set required # for containers run by docker ExecStart=/usr/bin/dockerd ExecReload=/bin/kill -s HUP $MAINPID # Having non-zero Limit*s causes performance problems due to accounting overhead # in the kernel. We recommend using cgroups to do container-local accounting. LimitNOFILE=infinity LimitNPROC=infinity LimitCORE=infinity # Uncomment TasksMax if your systemd version supports it. # Only systemd 226 and above support this version. #TasksMax=infinity TimeoutStartSec=0 # set delegate yes so that systemd does not reset the cgroups of docker containers Delegate=yes # kill only the docker process, not all processes in the cgroup KillMode=process # restart the docker process if it exits prematurely Restart=on-failure StartLimitBurst=3 StartLimitInterval=60s [Install] WantedBy=multi-user.target 启动，以下会需要选择用户，选择需要的用户即可 chmod +x /etc/systemd/system/docker.service #添加文件权限并启动docker systemctl daemon-reload #重载unit配置文件 systemctl start docker #启动Docker systemctl enable docker.service #设置开机自启 验证 systemctl status docker #查看Docker状态 docker -v #查看Docker版本 导出离线镜像 docker save [id] \u003e xxx.tar 导入离线镜像 导入镜像需要先将本地对应的镜像删除 docker load \u003c xxx.tar ","date":"2021-01-11","objectID":"/202101/docker-start/:6:0","tags":["Docker"],"title":"开始使用Docker","uri":"/202101/docker-start/"},{"categories":["工具"],"content":"能否在docker shell下使用Python等镜像？ 目前遇到的问题是，在docker Python镜像下，我不能使用Python的交互式环境（-i -t），但是如果是Ubuntu镜像则可以使用Ubuntu的shell交互式环境。 ","date":"2021-01-11","objectID":"/202101/docker-start/:7:0","tags":["Docker"],"title":"开始使用Docker","uri":"/202101/docker-start/"},{"categories":["Cpp"],"content":"目的 验证值传递和引用传递的区别。 值传递会拷贝，引用传递不会拷贝； 如果类是禁止拷贝的，就不能使用值传递； C++推荐使用引用传递； ","date":"2021-01-10","objectID":"/202101/cpp-cp-ref/:1:0","tags":["Cpp"],"title":"值传递OR引用传递","uri":"/202101/cpp-cp-ref/"},{"categories":["Cpp"],"content":"实验 禁止拷贝使用引用传递 #include \u003ciostream\u003e using namespace std; class A { public: A(){} private: A(const A\u0026 other) { cout \u003c\u003c \"copy construcor\" \u003c\u003c endl; } void operator=(const A\u0026 other) { cout \u003c\u003c \"copy function\" \u003c\u003c endl; } }; void tA(A \u0026a) { ; } int main() { A a; tA(a); } 以上，类A的拷贝函数是private的，所以认为是禁止拷贝，此时tA函数参数是引用传递的，编译通过。 禁止拷贝使用值传递 修改代码： void tA(A a) { ; } 编译是不通过的，以下报错，这个可以说明值传递是需要拷贝函数的。 error: 'A::A(const A\u0026)' is private within this context 允许拷贝使用引用传递 修改代码： class A { public: A(){} A(const A\u0026 other) { cout \u003c\u003c \"copy construcor\" \u003c\u003c endl; } void operator=(const A\u0026 other) { cout \u003c\u003c \"copy function\" \u003c\u003c endl; } }; void tA(A \u0026a) { ; } 编译通过，运行程序没有输出，则说明引用传递没有调用拷贝函数。 允许拷贝使用值传递 修改代码： void tA(A a) { ; } 编译通过，输出 copy construcor 这样说明值传递是会做拷贝的，看这个例子，值传递是调用的拷贝构造函数 ","date":"2021-01-10","objectID":"/202101/cpp-cp-ref/:2:0","tags":["Cpp"],"title":"值传递OR引用传递","uri":"/202101/cpp-cp-ref/"},{"categories":["Cpp"],"content":"结论 值传递是需要拷贝函数的 值传递是调用的拷贝构造函数 引用传递没有调用拷贝函数 ","date":"2021-01-10","objectID":"/202101/cpp-cp-ref/:3:0","tags":["Cpp"],"title":"值传递OR引用传递","uri":"/202101/cpp-cp-ref/"},{"categories":["Cpp","STL"],"content":"问题 容器存指针，调用erase、clear是否会调用元素的析构函数？ 不会调用析构函数 容器存类（非指针），是否会调用构造拷贝函数？使用erase、clear是否会调用析构函数？ 会调用拷贝构造函数 会调用析构函数 ","date":"2021-01-08","objectID":"/202101/cpp-erase-clear/:1:0","tags":["Cpp"],"title":"C++容器操作","uri":"/202101/cpp-erase-clear/"},{"categories":["Cpp","STL"],"content":"容器存指针 #include \u003ciostream\u003e #include \u003clist\u003e #include \u003cvector\u003e using namespace std; class ELE { public: ELE() : m_id(-1){ print(\"create ++++A \"); } ELE(const int \u0026id) : m_id(id){ print(\"create ++++B \"); } ELE(const ELE \u0026ele){ m_id = ele.id(); print(\"copy ====A \", ele); } void operator=(const ELE\u0026 ele) { m_id = ele.id(); print(\"copy ====B \", ele); } ~ELE(){ print(\"delete ----A \"); } int id() const { return m_id; } void print() { cout \u003c\u003c \"print \" \u003c\u003c this \u003c\u003c \"(\" \u003c\u003c m_id \u003c\u003c \")\" \u003c\u003c endl; } private: void print(const char* head){ cout \u003c\u003c head \u003c\u003c this \u003c\u003c \"(\" \u003c\u003c m_id \u003c\u003c \")\" \u003c\u003c endl; } void print(const char* head, const ELE \u0026ele){ cout \u003c\u003c head \u003c\u003c \u0026ele \u003c\u003c \"(\" \u003c\u003c ele.id() \u003c\u003c \")\" \u003c\u003c \" --\u003e \" \u003c\u003c this \u003c\u003c \"(\" \u003c\u003c m_id \u003c\u003c \")\" \u003c\u003c endl; } int m_id; }; int main() { vector\u003cELE *\u003e eleList; eleList.reserve(5); ELE *ele; cout \u003c\u003c \"************start push************\" \u003c\u003c endl; for (int i = 0; i \u003c 3; i++) { ele = new ELE(i); eleList.emplace_back(ele); } cout \u003c\u003c \"************end push************\" \u003c\u003c endl \u003c\u003c endl; cout \u003c\u003c \"************start process************\" \u003c\u003c endl; for (auto ele : eleList) { ele-\u003eprint(); } cout \u003c\u003c \"************end process************\" \u003c\u003c endl \u003c\u003c endl; cout \u003c\u003c \"************start erase************\" \u003c\u003c endl; for (auto it = eleList.begin(); it != eleList.end(); it) { eleList.erase(it); } // eleList.clear(); cout \u003c\u003c \"************end erase************\" \u003c\u003c endl \u003c\u003c endl; return 1; } 需要注意erase那一段代码，erase之后迭代器已经指向了下一个元素，所以不能再it++，可以实验以下，我这里测试的结果是会陷入死循环，打印不出“end erase”。 以上输出， ************start push************ create ++++B 0xfefeb0(0) create ++++B 0xfefed0(1) create ++++B 0xfefef0(2) ************end push************ ************start process************ print 0xfefeb0(0) print 0xfefed0(1) print 0xfefef0(2) ************end process************ ************start erase************ ************end erase************ push操作没有多余的拷贝（会拷贝指针的值），process部分也没有多余的拷贝（会拷贝指针的值），但是erase部分，没有任何输出！这里内存泄漏了。 以上，可以有以下结论： erase操作不会调用指针的析构函数； push操作不会调用指针的拷贝构造函数； 所以容器指针还需要额外调用delete删除。 for (auto ele : eleList) { delete ele; } ","date":"2021-01-08","objectID":"/202101/cpp-erase-clear/:2:0","tags":["Cpp"],"title":"C++容器操作","uri":"/202101/cpp-erase-clear/"},{"categories":["Cpp","STL"],"content":"容器存非指针 #include \u003ciostream\u003e #include \u003clist\u003e #include \u003cvector\u003e using namespace std; class ELE { public: ELE() : m_id(-1){ print(\"create ++++A \"); } ELE(const int \u0026id) : m_id(id){ print(\"create ++++B \"); } ELE(const ELE \u0026ele){ m_id = ele.id(); print(\"copy ====A \", ele); } void operator=(const ELE\u0026 ele) { m_id = ele.id(); print(\"copy ====B \", ele); } ~ELE(){ print(\"delete ----A \"); } int id() const { return m_id; } void print() { cout \u003c\u003c \"print \" \u003c\u003c this \u003c\u003c \"(\" \u003c\u003c m_id \u003c\u003c \")\" \u003c\u003c endl; } private: void print(const char* head){ cout \u003c\u003c head \u003c\u003c this \u003c\u003c \"(\" \u003c\u003c m_id \u003c\u003c \")\" \u003c\u003c endl; } void print(const char* head, const ELE \u0026ele){ cout \u003c\u003c head \u003c\u003c \u0026ele \u003c\u003c \"(\" \u003c\u003c ele.id() \u003c\u003c \")\" \u003c\u003c \" --\u003e \" \u003c\u003c this \u003c\u003c \"(\" \u003c\u003c m_id \u003c\u003c \")\" \u003c\u003c endl; } int m_id; }; int main() { vector\u003cELE\u003e eleList; eleList.reserve(5); ELE ele; cout \u003c\u003c \"************start push************\" \u003c\u003c endl; for (int i = 0; i \u003c 3; i++) { ele = ELE(i); eleList.emplace_back(ele); } cout \u003c\u003c \"************end push************\" \u003c\u003c endl \u003c\u003c endl; cout \u003c\u003c \"************start process************\" \u003c\u003c endl; for (auto ele : eleList) { ele.print(); } cout \u003c\u003c \"************end process************\" \u003c\u003c endl \u003c\u003c endl; cout \u003c\u003c \"************start erase************\" \u003c\u003c endl; eleList.clear(); cout \u003c\u003c \"************end erase************\" \u003c\u003c endl \u003c\u003c endl; return 1; } 输出： create ++++A 0x7ffd82be4afc(-1) ************start push************ create ++++B 0x7ffd82be4b24(0) copy ====B 0x7ffd82be4b24(0) --\u003e 0x7ffd82be4afc(0) delete ----A 0x7ffd82be4b24(0) copy ====A 0x7ffd82be4afc(0) --\u003e 0x112ee70(0) create ++++B 0x7ffd82be4b24(1) copy ====B 0x7ffd82be4b24(1) --\u003e 0x7ffd82be4afc(1) delete ----A 0x7ffd82be4b24(1) copy ====A 0x7ffd82be4afc(1) --\u003e 0x112ee74(1) create ++++B 0x7ffd82be4b24(2) copy ====B 0x7ffd82be4b24(2) --\u003e 0x7ffd82be4afc(2) delete ----A 0x7ffd82be4b24(2) copy ====A 0x7ffd82be4afc(2) --\u003e 0x112ee78(2) ************end push************ ************start process************ copy ====A 0x112ee70(0) --\u003e 0x7ffd82be4af4(0) print 0x7ffd82be4af4(0) delete ----A 0x7ffd82be4af4(0) copy ====A 0x112ee74(1) --\u003e 0x7ffd82be4af4(1) print 0x7ffd82be4af4(1) delete ----A 0x7ffd82be4af4(1) copy ====A 0x112ee78(2) --\u003e 0x7ffd82be4af4(2) print 0x7ffd82be4af4(2) delete ----A 0x7ffd82be4af4(2) ************end process************ ************start erase************ delete ----A 0x112ee70(0) delete ----A 0x112ee74(1) delete ----A 0x112ee78(2) ************end erase************ delete ----A 0x7ffd82be4afc(2) 以上，有几点结论： 类直接push到容器，会调用拷贝构造函数；（两个地址不一样了） clear方法会调用容器元素的析构函数； 直接push和调用普通类会多一些copy操作（重构=）； 如果去掉reserve方法，还会有点问题： 容器长度是动态增长的，所以不加reserve会有更多的copy操作； 用erase替换clear操作 for (auto it = eleList.begin(); it != eleList.end(); it) { eleList.erase(it); } 得到输出 ************start erase************ copy ====B 0x1c0ae74(1) --\u003e 0x1c0ae70(1) copy ====B 0x1c0ae78(2) --\u003e 0x1c0ae74(2) delete ----A 0x1c0ae78(2) copy ====B 0x1c0ae74(2) --\u003e 0x1c0ae70(2) delete ----A 0x1c0ae74(2) delete ----A 0x1c0ae70(2) ************end erase************ 可以看到，相比clear多了很多copy操作。看起来是erase不仅调用析构函数，同时也会清除容器空间。 erase会调用析构函数； erase会删除容器空间； ","date":"2021-01-08","objectID":"/202101/cpp-erase-clear/:3:0","tags":["Cpp"],"title":"C++容器操作","uri":"/202101/cpp-erase-clear/"},{"categories":["Cpp","STL"],"content":"结论 erase之后迭代器已经指向了下一个元素，不需要it++； erase操作不会调用指针的析构函数； push操作不会调用指针的拷贝构造函数； 类直接push到容器，会调用拷贝构造函数；（两个地址不一样了） clear方法会调用容器元素的析构函数； 直接push和调用普通类会多一些copy操作（重构=）； 容器长度是动态增长的，所以不加reserve会有更多的copy操作； erase会调用析构函数； erase会删除容器空间； 所以，我认为： 容器使用前尽量reserve 容器尽量存类的指针； 容器如果存的指针要记得显示地调用delete； ","date":"2021-01-08","objectID":"/202101/cpp-erase-clear/:4:0","tags":["Cpp"],"title":"C++容器操作","uri":"/202101/cpp-erase-clear/"},{"categories":["Cpp"],"content":"union 改名操作 比如以下这个类，我期望外部不仅能通过P1这个名字访问P1这个成员变量，也能通过Y/R等名字访问他的P1。 template\u003ctypename T = UCHAR\u003e class __P3F__ { public: union{ struct{ T P1, P2, P3; }; struct{ T Y, U, V; }; struct{ T R, G, B; }; struct{ T H, L, S; }; }; public: __P3F__(const T \u0026_P1, const T \u0026_P2, const T \u0026_P3) : P1(_P1), P2(_P2), P3(_P3) {} __P3F__() : P1(0), P2(0), P3(0) {} virtual ~__P3F__() {} VOID operator=(const __P3F__ \u0026p3f) { P1 = p3f.P1; P2 = p3f.P2; P3 = p3f.P3; } }; template\u003ctypename T = UCHAR\u003e using YUV = __P3F__\u003cT\u003e; template\u003ctypename T = UCHAR\u003e using RGB = __P3F__\u003cT\u003e; template\u003ctypename T = UCHAR\u003e using HLS = __P3F__\u003cT\u003e; 通过union，实现了给成员变量重命名，这样定义一个基础类即可。 这里用到了using，目的是给重命名类名，但是因为类是模板类，所以使用using，这样即使是重命名的类，也能使用模板，如果使用typedef就需要明确模板类类型。 ","date":"2021-01-07","objectID":"/202101/cpp-how-union/:1:0","tags":["Cpp","union"],"title":"Union可以怎么用","uri":"/202101/cpp-how-union/"},{"categories":["Cpp"],"content":"验证内存结构 #include \u003ciostream\u003e using namespace std; typedef union { struct { char low_byte; char mlow_byte; char mhigh_byte; char high_byte; } float_byte; float value; } FLAOT_UNION; int main() { FLAOT_UNION f; f.float_byte = {0, 0, -128, 63}; cout \u003c\u003c f.value \u003c\u003c endl; return 1; } 以上, 可以验证比如float的内存结构是怎样的. 这里推荐C++在线编译器https://gcc.godbolt.org/ ","date":"2021-01-07","objectID":"/202101/cpp-how-union/:2:0","tags":["Cpp","union"],"title":"Union可以怎么用","uri":"/202101/cpp-how-union/"},{"categories":["Cpp","STL"],"content":"tie std::tie会把变量打包成一个tuple(pair)，实现变量赋值；这个行为叫做解包 tuple\u003cint,double,string\u003e t3 = {1, 2.0, \"3\"}; int i; double d; string s; tie(i, d, s) = t3; 以上，i, d, s就可以被赋值为与tuple对应元素的值，在应用中，这在处理函数多返回值的时候比较有用。 同时，也提供了占位符，std::ignore来忽略某些值。 tie(i, std::ignore, s) = t3; 或者可以用于比较， 表示的是与逻辑，即元素全部满足才满足，有一个不满足就是不满足。 struct S { int n; std::string s; float d; bool operator\u003c(const S\u0026 rhs) const { // 比较 n 与 rhs.n, // 然后为 s 与 rhs.s, // 然后为 d 与 rhs.d return std::tie(n, s, d) \u003c std::tie(rhs.n, rhs.s, rhs.d); } }; ","date":"2021-01-05","objectID":"/202101/cpp-func-tie/:1:0","tags":["Cpp"],"title":"C++解包函数tie的用法","uri":"/202101/cpp-func-tie/"},{"categories":["Cpp"],"content":"bind的设计思想: 高内聚, 低耦合, 使被调用的函数和调用者完全隔离开来. 调用者可以根据需要任意设计接口和传参, 而被调用函数通过bind可以不经修改接口就可以兼容各种需求的变化. 在博客上查到我认为比较精髓的理解是, 使被调用的函数和调用者完全隔离开来 ","date":"2021-01-04","objectID":"/202101/cpp-func-bind/:0:0","tags":["Cpp","bind"],"title":"对C++bind的理解","uri":"/202101/cpp-func-bind/"},{"categories":["Cpp"],"content":"例子 bind默认参数是拷贝，而不是引用，摘自cnblog的一段代码 #include \u003cfunctional\u003e #include \u003ciostream\u003e void f(int\u0026 n1, int\u0026 n2, const int\u0026 n3) { std::cout \u003c\u003c \"In function: \" \u003c\u003c n1 \u003c\u003c ' ' \u003c\u003c n2 \u003c\u003c ' ' \u003c\u003c n3 \u003c\u003c '\\n'; ++n1; // increments the copy of n1 stored in the function object ++n2; // increments the main()'s n2 // ++n3; // compile error } int main() { int n1 = 1, n2 = 2, n3 = 3; std::function\u003cvoid()\u003e bound_f = std::bind(f, n1, std::ref(n2), std::cref(n3)); n1 = 10; n2 = 11; n3 = 12; std::cout \u003c\u003c \"Before function: \" \u003c\u003c n1 \u003c\u003c ' ' \u003c\u003c n2 \u003c\u003c ' ' \u003c\u003c n3 \u003c\u003c '\\n'; bound_f(); std::cout \u003c\u003c \"After function: \" \u003c\u003c n1 \u003c\u003c ' ' \u003c\u003c n2 \u003c\u003c ' ' \u003c\u003c n3 \u003c\u003c '\\n'; } 如上输出是以下， 意味着， bind绑定参数时使用的是值拷贝（在绑定的时候就已经拷贝值了， 后续再改变这个变量也无济于事），而不是引用，使用std::ref可以把这种绑定指定为引用的。std::cref则是const referrence Before function: 10 11 12 In function: 1 11 12 After function: 10 12 12 占位符可以不是顺序的，可以改变参数顺序和个数 如下，_2和_1没有按顺序，最终返回的函数f1也算是打乱了函数f的顺序的。 auto f1 = std::bind(f, _2, 42, _1, std::cref(n), n); n = 10; f1(1, 2, 1001); // 1 is bound by _1, 2 is bound by _2, 1001 is unused // makes a call to f(2, 42, 1, n, 7) 绑定函数中再绑定函数 如下，绑定函数f的同时，再绑定了函数g作为参数，并且都共享占位符_3。这里也可以看到函数f2有两个参数_1,_2是直接认为无效的。 // nested bind subexpressions share the placeholders auto f2 = std::bind(f, _3, std::bind(g, _3), _3, 4, 5); f2(10, 11, 12); // makes a call to f(12, g(12), 12, 4, 5); 绑定普通成员函数 要注意把类实例也绑定上去，不然是找不到这个函数地址的！ Foo foo; auto f3 = std::bind(\u0026Foo::print_sum, \u0026foo, 95, _1); f3(5); mem_fn和bind类似，我认为算是bind子集，但是对入参有扩展，mem_fn绑定成员函数(成员函数绑定)后的可调用函数的第一个参数，是类实例，可以实现无限多成员参数。而bind只能实现10个参数的绑定。 #include \u003cfunctional\u003e #include \u003ciostream\u003e struct Foo { void display_greeting() { std::cout \u003c\u003c \"Hello, world.\\n\"; } void display_number(int i) { std::cout \u003c\u003c \"number: \" \u003c\u003c i \u003c\u003c '\\n'; } int data = 7; }; int main() { Foo f; auto greet = std::mem_fn(\u0026Foo::display_greeting); greet(f); auto print_num = std::mem_fn(\u0026Foo::display_number); print_num(f, 42); auto access_data = std::mem_fn(\u0026Foo::data); std::cout \u003c\u003c \"data: \" \u003c\u003c access_data(f) \u003c\u003c '\\n'; } 输出是， Hello, world. number: 42 data: 7 ","date":"2021-01-04","objectID":"/202101/cpp-func-bind/:1:0","tags":["Cpp","bind"],"title":"对C++bind的理解","uri":"/202101/cpp-func-bind/"},{"categories":["Cpp"],"content":"问题 更详细的学习, 参考C++类的内存分布(二). 使用gdb、g++工具。 class A{ public: int funcA(){} virtual int funcV(){} public: int a; char b; double c; }; class B : public A{ public: int funcB(){} int funcV(){} public: char d; }; int main() { A *a = new A(); B *b = new B(); delete a; delete b; } ","date":"2021-01-04","objectID":"/202101/cpp-class-mem/:1:0","tags":["Cpp","内存"],"title":"C++类的内存分布","uri":"/202101/cpp-class-mem/"},{"categories":["Cpp"],"content":"验证 以下每一小节中的地址互不相关。 编译 编译需要带上-g参数，这样可以在gdb调试的时候打印源码。 g++ -g test.cpp -o test 派生类重写 按照上述源码来 gdb test # 在main函数打断点 (gdb) b main Breakpoint 1 at 0x555555554863: file test.cpp, line 23. # 运行至断点处 (gdb) r # 执行next若干次 (gdb) n # 查看*a = new A() 的虚表 (gdb) i vtbl a vtable for 'A' @ 0x555555754d80 (subobject @ 0x555555767e70): [0]: 0x5555555548fe \u003cA::funcV()\u003e # 查看*b = new B() 的虚表 (gdb) i vtbl b vtable for 'B' @ 0x555555754d68 (subobject @ 0x555555767e90): [0]: 0x55555555490a \u003cB::funcV()\u003e 以上，有几个类（不是实例）虚表就有几份，也就是同一个类的多个实例，也只维护一份虚表。 a的funcV和b的funcV的地址是不一样的。0x5555555548fe \u003cA::funcV()\u003e 和 0x55555555490a \u003cB::funcV()\u003e。 注意和以下作对比。 派生类不重写 class B : public A{ public: int funcB(){} public: char d; }; 则派生类的funcV指向了A的funcV，是同一个funcV，地址相同0x555555554932 \u003cA::funcV()\u003e (gdb) i vtbl a vtable for 'A' @ 0x555555754d80 (subobject @ 0x555555767e70): [0]: 0x555555554932 \u003cA::funcV()\u003e (gdb) i vtbl b vtable for 'B' @ 0x555555754d68 (subobject @ 0x555555767eb0): [0]: 0x555555554932 \u003cA::funcV()\u003e # A::funcV() 编译器优化 如果此时在gdb中尝试打印funcA的地址，发现找不到，我猜测的原因是编译器优化了，因为在源码中没有任何地方调用了funcA，但是为什么编译器会编译funcV呢？源码中也没任何地方调用了funcV啊？ 内存分布 现在在main函数中尝试调用funcA，让编译器编译它。 先来看一下地址： (gdb) p a-\u003efuncA $1 = {int (A * const)} 0x55555555493e \u003cA::funcA()\u003e (gdb) p \u0026(b-\u003efuncA) $12 = (int (*)(A * const)) 0x55555555493e \u003cA::funcA()\u003e (gdb) p a-\u003efuncV $2 = {int (A * const)} 0x55555555494a \u003cA::funcV()\u003e 可以看到funcA和funcV应该是在一块的，地址比较近0x55555555494a-0x55555555493e=12。 B没有重写funcA，所以b-\u003efuncA和a的funcA是指向同一个函数。 a和b的内存也在同一块，但是和func*的内存块隔得比较远。 (gdb) p a $3 = (A *) 0x555555767e70 (gdb) p b $4 = (B *) 0x555555767eb0 类的成员变量接在类的实例化地址之后，是在同一块内存的。 如下，尽管B继承了A，但是B从A继承过来的成员变量并不指向A的成员变量，B有自己的备份。 a-\u003ea的地址和b-a的地址并不一样。 (gdb) p \u0026(a-\u003ea) $6 = (int *) 0x555555767e78 (gdb) p \u0026(a-\u003eb) $7 = 0x555555767e7c \"\" (gdb) p \u0026(a-\u003ec) $8 = (double *) 0x555555767e80 (gdb) p \u0026(b-\u003ea) $9 = (int *) 0x555555767eb8 (gdb) p \u0026(b-\u003eb) $10 = 0x555555767ebc \"\" (gdb) p \u0026(b-\u003ec) $11 = (double *) 0x555555767ec0 每个类维护自己的虚表，虚表地址和类实例化地址也不一样. 每个类的虚表只有一份， 同一个类的所有实例共享一份。 (gdb) i vtbl a vtable for 'A' @ 0x555555754d80 (subobject @ 0x555555767e70): [0]: 0x55555555494a \u003cA::funcV()\u003e (gdb) i vtbl b vtable for 'B' @ 0x555555754d68 (subobject @ 0x555555767eb0): [0]: 0x55555555494a \u003cA::funcV()\u003e 怎么找到虚表 从上面的实验中可以看到, 虚表和类不在同一块内存, 一般来说, 我们会需要一个额外的指针指向这个虚表的地址, 这样才可以找到这个虚表. 实际上C++编译器也是这么做的, 在编译的时候会给类添加一个__vptr成员变量且指向虚表的地址, 这样就可以通过__vptr找到虚表了. 如果是继承自基类的虚函数, 则在虚表中指向的是同一个函数地址. ","date":"2021-01-04","objectID":"/202101/cpp-class-mem/:2:0","tags":["Cpp","内存"],"title":"C++类的内存分布","uri":"/202101/cpp-class-mem/"},{"categories":["Cpp"],"content":"结论 以上可以猜测出来的几个结论是： 类成员函数只有一份，所有实例共享（成员函数地址与实例地址隔得比较远） 类的成员变量有多份，不同实例维护不同的成员变量（成员变量地址接在实例地址之后，相隔很近） 即使是继承关系，派生类的成员变量也只是基类的复制体，而不是指向同一块内存（派生类的成员变量和基类的地址不一样） 派生类会把从基类继承过来的成员变量当做自己的普通成员变量一样看待？（从成员变量的地址可以猜测这个结论） 类的虚表只有一份，所有实例共享（虚表的地址和实例化地址隔得比较远，也和成员函数的地址隔得比较远） 编译器在编译的时候, 通过给类添加__vptr指针指向虚表而得到虚表地址. ","date":"2021-01-04","objectID":"/202101/cpp-class-mem/:3:0","tags":["Cpp","内存"],"title":"C++类的内存分布","uri":"/202101/cpp-class-mem/"},{"categories":["Cpp"],"content":"图例 不同的方块表示不同的内存块 结构图 ","date":"2021-01-04","objectID":"/202101/cpp-class-mem/:4:0","tags":["Cpp","内存"],"title":"C++类的内存分布","uri":"/202101/cpp-class-mem/"},{"categories":null,"content":"自建工具 简易计时器 \"方便在家HIIT运动计时\" 股票计算器 \"计算股票价格\" 纯色背景 \"展示纯色背景，没准用得上呢\" 记忆训练 \"想法来自\u003c刻意练习\u003e\" ascii码转光信号 \"通过摄像头捕捉\" 棋盘格找茬 \"找茬游戏\" ","date":"0001-01-01","objectID":"/tools/:0:1","tags":null,"title":"工具人","uri":"/tools/"},{"categories":null,"content":"代码 现代 C++ 教程 \"高速上手 C++ 11/14/17/20\" cppreference \"C++参考文档\" Compiler Explorer \"方便验证小demo\" C++ Insights \"方便阅读C++展开式\" code examples \"各种代码示例, 方便学习\" woboq \"C/C++源码阅读, Linux源码\" The Linux Kernel \"The Linux Kernel documentation\" kaggle \"模型训练, 在线Python\" mklab \"MKLab在线工具提供常用的在线工具,在线文档,站点导航,JS美化压缩,JSON美化压缩,XML美化压缩,SQL美化压缩,CSS美化压缩,HTML美化压缩,YAML美化压缩,正则表达式,URL编码解码,ASCII编码解码,Unicode编码解码,Base64编码解码,MD5加密,图片转换处理,RGB转换,大小写字母转换,中文转拼音,中文简繁体转换,进制转换,计量单位转换,时间格式转换,Markdown编辑器,在线PS,图片Base64转换,ASCII码表,Content-Type,HTML转义字符,二维码,计算器,文本处理\" ","date":"0001-01-01","objectID":"/tools/:0:2","tags":null,"title":"工具人","uri":"/tools/"},{"categories":null,"content":"效率 diagrams \"Security-first diagramming for teams.\" ","date":"0001-01-01","objectID":"/tools/:0:3","tags":null,"title":"工具人","uri":"/tools/"},{"categories":null,"content":"建站 leancloud \"线上存储\" Vercel \"Vercel托管\" 百度统计 \"百度统计\" bing统计 \"bing统计\" google统计 \"google统计\" 站长之家 \"网站测速\" uptimerobot \"网站存活检测\" ","date":"0001-01-01","objectID":"/tools/:0:4","tags":null,"title":"工具人","uri":"/tools/"},{"categories":null,"content":"好玩 九歌 \"人工智能诗歌写作系统\" 扫雷游戏网页版 \"本站提供了经典扫雷游戏，并略作改进，在电脑或手机上打开网页就可以玩，无需下载安装。增加了满屏级别，自适应屏幕大小。成绩榜实时显示大家的扫雷成绩。\" ","date":"0001-01-01","objectID":"/tools/:0:5","tags":null,"title":"工具人","uri":"/tools/"},{"categories":null,"content":"博客取名“BBing”或者“Bing”是因为大多数人叫我“冰冰”，遂想取名“bingbing”，又因为字符太多啦，便取名为“BBing”或“Bing”。 我出生于江西省萍乡市武功山，先是跟随爷爷奶奶就读于蔡家小学，后跟随父母转校至南台小学、萍乡四中，初三下学期免试升学至萍乡中学，大学则在华中科技大学自动化（后更名为“人工智能与自动化”）学院自动化专业学习，是HUST思存工作室2015、2016届成员，是HUST RoboMaster狼牙战队2017、2018届队员。 第一次较深入地接触计算机是在2013年，那时候家里购买了第一台电脑，当然，我是以想参加计算机竞赛“忽悠”家里购买的。然后稀里糊涂地就接触到了单片机，那时候学习的还是51单片机，高考完填志愿的时候，我期望继续学习单片机，就填了自动化专业。 结果学校教材里也没有教授这些知识，不过那时候我可能已经忘记我想要干什么了。 大概大一大二的时候我加入了学校的思存工作室学习前端，大二到大三渐渐脱离工作室，加入了RoboMaster团队，学习计算机视觉。 毕业后的第一份工作，我加入了小米，应聘了算法工程师的岗位。本想继续学习和深入计算机视觉，结果因为学历不够被分配到了软件。当时本着既来之则安之的想法，我想着，做软件也可以做得很牛逼，便渐渐放弃了继续做计算机视觉的想法。 本博客是在工作之后建立的，因此大多数内容都是围绕软件、工程、编程相关的。也尝试过继续学习CV相关的内容，但是因为和工作内容不搭边，平常很难应用上，并且在工作和学习中也发现，纯软件有太多东西需要学习了，可以做得很深入、可以做得很高级，设计代码结构和编写代码对我来说都很有意思。所以，我未来的职业规划，大概率是软件研发工程师到架构师，至于软件要做什么行业，我目前的想法是不要限制太死，尽量多了解一些行业，成为“一专多能”的人才，比如CV相关的内容就可以充当我“一专多能”计划里面的多能。 以上，本博客未来更新内容的大致范畴会是软件、工程、编程、算法、应用等之类，会涉猎和学习更多某些专业领域的知识。 ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":" 把学习成果和未来计划公开，明确计划的时间/行为/书名等，以作鼓励和动力。以输出内容为目标或导向，降低半途而废/掌握半吊子的概率。有些书籍可以多周目阅读，因为知识、经验积累增加，会有不同的收获。 本页计划摘自我的部分滴答清单. 将用滴答清单管理进度. 我的书单 ","date":"0001-01-01","objectID":"/list/:0:0","tags":null,"title":"清单","uri":"/list/"},{"categories":null,"content":"最近在做的 更新于2023.03.06 LC刷125题：108/125 leetcode连续2/3场周赛完成3题及以上 读《邓小平时代》~40% 读《程序员的自身修养——链接、装载与库》~40% 练字, 控笔练习(因为看到了自己签名不好看, 所以想着练字) ","date":"0001-01-01","objectID":"/list/:0:1","tags":null,"title":"清单","uri":"/list/"},{"categories":null,"content":"2023计划 确定的计划应该是低风险的，为了达到目标应该做的 STL源码阅读累计输出3/8篇 内容不限 glibc源码阅读累计输出9/13篇 内容不限 LC刷125题：108/125 leetcode连续2/3场周赛完成3题及以上 英语学习累计2/75小时 学习chibicc源码，输出至少一篇笔记心得 输出simula、smalltalk对比 读完《邓小平时代》 读完《胡耀邦》 《程序员的自身修养——链接、装载与库》二周目 通读一遍《大话设计模式》 练字, 把买的六本小册子练完, 预计3~6个月 资产记账APP ~1% 读完《刻意练习》 ","date":"0001-01-01","objectID":"/list/:0:2","tags":null,"title":"清单","uri":"/list/"},{"categories":null,"content":"备选的计划 因为计划安排导致暂没有加入日程的，如果确定了安排，未来某段时间就会加入日程 《UCB CS61a SICP Python 中文》二周目 完成极客时间《现代C++编程实战》一周目阅读：69% 完成极客时间《数据结构与算法》阅读：87% 完成极客时间《程序员的数学基础课》阅读：30% 完成极客时间《MySQL实战45讲》阅读：4% ","date":"0001-01-01","objectID":"/list/:0:3","tags":null,"title":"清单","uri":"/list/"},{"categories":null,"content":"期望新增的技术栈 优先级比较低的计划 C++的内存结构和时序（编译原理方面） Rust，目前仅在helloworld的水平 编译原理，对理论和工程都感兴趣 ","date":"0001-01-01","objectID":"/list/:0:4","tags":null,"title":"清单","uri":"/list/"},{"categories":null,"content":"结果 结果是自认为成体系或独立的、拿得出手的内容，和复杂度、难易度无关，尽量避免零散的内容，所以有些计划完成后因为暂不成体系，并不会被添加到成果中。以下自2021.01.01起。 《STL源码阅读》系列累计输出3篇 《glibc源码阅读》系列累计输出9篇 《UCB CS61a SICP Python 中文》一周目阅读笔记累计输出4篇 《数据结构和算法》系列累计输出11篇 《进程控制》系列累计输出6篇 开发和维护的小工具/库： djeva：指数基金历史估值查询网站 rssblog：基于rss的博客内容聚合网站 rssblog-source：csv和json格式的rssblog数据源 orlike：使用leancloud作为存储的博文点赞插件 hugo-algolia2: 自动构建和提交博客内容索引到algolia的github-action picvt：静态博客图床转换工具 fkfish：模拟不同系统重启、crash等界面的摸鱼工具 fstats：支持用户自定义脚本和界面的系统信息悬浮窗工具 md5any：一个支持计算文件、文件夹md5（伪）的工具库 codebrowser-bookmark：用于codebrowser书签功能的油猴插件 sudoku：终端数独游戏 ","date":"0001-01-01","objectID":"/list/:0:5","tags":null,"title":"清单","uri":"/list/"},{"categories":null,"content":"2023 书名 评分 书评 状态 读完日期 许三观卖血记 4/5 已读 2023-01-02 刻意练习 3.5/5 刻意练习 已读 2023-02-20 邓小平时代 – 傅高义 在读:40% 程序员的自我修养–链接装载与库 二刷, 在读:40% 搞定一：无压工作的艺术 待读 搞定二：提升工作与生活效率的52项原则 待读 搞定三：平衡工作与生活的艺术 待读 月亮与六便士 待读 胡耀邦 待读 ","date":"0001-01-01","objectID":"/books/:1:0","tags":null,"title":"书单","uri":"/books/"},{"categories":null,"content":" 技巧 ","date":"0001-01-01","objectID":"/offercode/:0:0","tags":null,"title":"題","uri":"/offercode/"},{"categories":null,"content":"友链文章 ","date":"0001-01-01","objectID":"/friends/:0:1","tags":null,"title":"友链墙","uri":"/friends/"},{"categories":null,"content":"大佬都在这啦 ","date":"0001-01-01","objectID":"/friends/:0:2","tags":null,"title":"友链墙","uri":"/friends/"},{"categories":null,"content":"无法访问 ","date":"0001-01-01","objectID":"/friends/:0:3","tags":null,"title":"友链墙","uri":"/friends/"},{"categories":null,"content":"本站友链 { \"name\":\"Bing's Blog\", \"url\":\"https://imcbc.cn/\", \"logo\":\"https://imcbc.cn/android-chrome-192x192.png\", \"word\":\"自由 分享 合作\" } ","date":"0001-01-01","objectID":"/friends/:0:4","tags":null,"title":"友链墙","uri":"/friends/"},{"categories":null,"content":"和我交换友链吧 按照以下格式发送到评论区。 { \"name\":\"站点名称\", \"url\":\"站点链接\", \"logo\":\"站点图标或个人头像\", \"word\":\"站点描述\" } 如果你有开启rss订阅的话，就可以在顶部“友链文章”栏目下显示你的最新文章了~~~ 本站会根据uptimerobot的检测结果判断友链的可访问性，不可访问的友链会被移动至“无法访问”栏目，如果连续长时间不可访问，则该友链会被隐藏，直至可正常访问。 ","date":"0001-01-01","objectID":"/friends/:0:5","tags":null,"title":"友链墙","uri":"/friends/"}]